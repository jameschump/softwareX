/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "../fhirlib/BundleDefinitionLoader.js":
/*!********************************************!*\
  !*** ../fhirlib/BundleDefinitionLoader.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const { DefinitionLoader } = __webpack_require__(/*! ./DefinitionLoader */ \"../fhirlib/DefinitionLoader.js\");\nconst { DefinitionIndex } = __webpack_require__(/*! ./DefinitionIndex */ \"../fhirlib/DefinitionIndex.js\");\n\nclass BundleDefinitionLoader extends DefinitionLoader {\n  constructor(...definitions) {\n    super();\n    this.structureDefinitions = new DefinitionIndex();\n    this.codesystemUrls = new DefinitionIndex();\n\n    for (let argNo = 0; argNo < definitions.length; ++argNo) {\n      const arg = definitions[argNo];\n      const entries = arg.resourceType === \"Bundle\"\n          ? arg.entry.map(e => e.resource)\n          : Array.isArray(arg)\n          ? arg\n          : [arg];\n      for (let entryNo = 0; entryNo < entries.length; ++entryNo) {\n        const where = `[${argNo}][${entryNo}]`; // make it easy to debug duplicate defintions\n        this.indexDefinition(entries[entryNo], where);\n      }\n    }\n  }\n\n  indexDefinition (entry, where) {\n    switch (entry.resourceType) {\n      case 'CodeSystem':\n        this.codesystemUrls.add(entry.url, entry, where);\n        break;\n      case 'ValueSet':\n        this.structureDefinitions.add(entry.id, entry, where);\n        break;\n      case 'CapabilityStatement':\n      case 'CompartmentDefinition':\n      case 'OperationDefinition':\n        break;\n      case 'StructureDefinition':\n        this.structureDefinitions.add(entry.id, entry, where);\n        break;\n      default:\n        throw Error(`what's a ${entry.resourceType}`);\n    }\n  }\n\n  async getStructureDefinitionByName (target) { return this.structureDefinitions.get(target); }\n  async getCodesystemByUrl (target) { return this.codesystemUrls.get(target); }\n}\n\nif (true)\n  module.exports = {BundleDefinitionLoader};\n\n\n//# sourceURL=webpack://playground/../fhirlib/BundleDefinitionLoader.js?");

/***/ }),

/***/ "../fhirlib/DefinitionIndex.js":
/*!*************************************!*\
  !*** ../fhirlib/DefinitionIndex.js ***!
  \*************************************/
/***/ ((module) => {

eval("class DefinitionIndex {\n  constructor () {\n    this.index = new Map();\n  }\n\n  add (id, entry, where) {\n    if (this.index.has(id)) {\n      const old = this.index.get(id)\n      console.warn(`duplicate ${id}\nold: ${old.entry.resourceType} ${old.entry.kind} at ${old.where},\nnew: ${entry.resourceType} ${entry.kind} at ${where}`);\n    }\n    this.index.set(id, {where, entry});\n  }\n\n  get (target) {\n    return this.index.has(target)\n        ? this.index.get(target).entry\n        : undefined;\n  }\n}\n\nif (true)\n  module.exports = {DefinitionIndex};\n\n\n//# sourceURL=webpack://playground/../fhirlib/DefinitionIndex.js?");

/***/ }),

/***/ "../fhirlib/DefinitionLoader.js":
/*!**************************************!*\
  !*** ../fhirlib/DefinitionLoader.js ***!
  \**************************************/
/***/ ((module) => {

eval("/**\n * abstract DefinitionLoader for FhirRdfModelGenerator\n * This doesn't do anything more than define what would be a TypeScript interface.\n */\nclass DefinitionLoader {\n\n  async getStructureDefinitionByName (target) { throw new Error(`DefinitionLoader.getStructureDefinitionByName(${target}) must be overloaded`); }\n  async getCodesystemByUrl (target) { throw new Error(`DefinitionLoader.getCodesystemByUrl(${target}) must be overloaded`); }\n}\n\nif (true)\n  module.exports = {DefinitionLoader};\n\n\n//# sourceURL=webpack://playground/../fhirlib/DefinitionLoader.js?");

/***/ }),

/***/ "../fhirlib/FhirJsonLdContextGenerator.js":
/*!************************************************!*\
  !*** ../fhirlib/FhirJsonLdContextGenerator.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const ShExUtil = __webpack_require__(/*! @shexjs/util */ \"../fhirlib/node_modules/@shexjs/util/shex-util.js\");\nconst Prefixes = __webpack_require__(/*! ./Prefixes */ \"../fhirlib/Prefixes.js\");\nconst Ns_fh = 'http://hl7.org/fhir/'\nconst Ns_fhsh = 'http://hl7.org/fhir/shape/'\nconst Ns_rdf = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#'\n// const StupidBaseUrl = r => `http://uu3.org/fhir/${r}-R4-jsonld-1.1-context.jsonld`\nconst StupidBaseUrl = r => `${r}.context.jsonld`;\n\nclass FhirJsonLdContextGenerator {\n\n  static HEADER = {\n    \"@version\": 1.1,\n    \"@vocab\": \"http://example.com/UNKNOWN#\",\n  };\n\n  static NAMESPACES = {\n    \"fhir\": \"http://hl7.org/fhir/\",\n    \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n    \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",\n    \"owl\": \"http://www.w3.org/2002/07/owl#\",\n  }\n\n  static TYPE_AND_INDEX = {\n    \"resourceType\": {\n      \"@id\": \"rdf:type\",\n      \"@type\": \"@id\"\n    },\n    \"index\": {\n      \"@id\": \"fhir:index\",\n      \"@type\": \"http://www.w3.org/2001/XMLSchema#integer\"\n    },\n  };\n\n  static ROOT = {\n    \"@context\": {\n      \"fhir\": \"http://hl7.org/fhir/\",\n      \"owl\": \"http://www.w3.org/2002/07/owl#\",\n      \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n      \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n      \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",\n      \"dc\": \"http://purl.org/dc/elements/1.1/\",\n      \"cs\": \"http://hl7.org/orim/codesystem/\",\n      \"dcterms\": \"http://purl.org/dc/terms/\",\n      \"dt\": \"http://hl7.org/orim/datatype/\",\n      \"ex\": \"http://hl7.org/fhir/StructureDefinition/\",\n      \"fhir-vs\": \"http://hl7.org/fhir/ValueSet/\",\n      \"loinc\": \"http://loinc.org/rdf#\",\n      \"os\": \"http://open-services.net/ns/core#\",\n      // \"rim\": \"http://hl7.org/orim/class/\",\n      \"rim\": \"http://hl7.org/owl/rim/\",\n      \"sct\": \"http://snomed.info/id/\",\n      \"vs\": \"http://hl7.org/orim/valueset/\",\n      \"w5\": \"http://hl7.org/fhir/w5#\"\n    }\n  };\n\n  static GEND_CONTEXT_SUFFIX = \".context.jsonld\";\n\n  static STEM = \"https://fhircat.org/fhir-r4/original/contexts/\"; // could be a parameter but convenient to write in one place\n  static SUFFIX = \".context.jsonld\";\n\n  constructor(shexj, index) {\n    this.shexj = shexj;\n    this.index = index || shexj._index || ShExUtil.index(shexj);\n    this.cache = new Map();\n    this.cache.set(\"root\", FhirJsonLdContextGenerator.ROOT);\n  }\n\n  genJsonldContext (target, config) {\n    if (!this.cache.has(target)) {\n      const v = new Converter(this.shexj, config);\n      const ret = v.convert(this.index.shapeExprs['http://hl7.org/fhir/shape/' + target], this.index);\n      this.cache.set(target, ret);\n    }\n    return this.cache.get(target);\n  }\n};\n\nclass Converter {\n  constructor (schema, config) {\n    this.schema = schema;\n    this.config = config;\n  }\n\n  convert (shexpr, index) {\n    const ret = {\n      '@context': Object.assign(\n          {},\n          FhirJsonLdContextGenerator.HEADER,\n          FhirJsonLdContextGenerator.NAMESPACES,\n          this.visitShapeExpr(shexpr, index)\n      ) // this.lookup(from)\n    }\n    return ret\n  }\n\n  lookup (label) {\n    const found = this.schema.shapes.find(e => e.id === label)\n    if (!found) {\n      report(Error(`${label} not found`))\n      return null\n    }\n    return found\n  }\n\n  visitShapeExpr (shexpr, index) {\n    if (typeof shexpr === 'string')\n      return this.visitShapeExpr(this.lookup(shexpr), index);\n\n    switch (shexpr.type) {\n    case 'Shape': return this.visit(shexpr.expression, index);\n    case 'ShapeOr': {\n      return Object.assign.apply(Object, shexpr.shapeExprs.map(junct => this.visitShapeExpr(junct, index)));\n    }\n    case 'NodeConstraint':\n    case 'ShapeNot': return {};\n    default: throw Error('what\\'s a ' + JSON.stringify(shexpr))\n    }\n  }\n\n  visit (expr, index) {\n    switch (expr.type) {\n      case 'OneOf':\n      case 'EachOf':\n        return Object.assign(\n            {},\n            FhirJsonLdContextGenerator.TYPE_AND_INDEX, // rdf:type, fhir:index, and all of the...\n            Object.assign.apply({}, expr.expressions.map(e => this.visit(e, index))) // generated properties\n        )\n      case 'TripleConstraint':\n        const {id, property} = shorten(expr.predicate)\n        if (id === 'fhir:nodeRole')\n          return {}\n        if (id === 'rdf:type')\n          return {\"resourceType\": {\"@id\": \"rdf:type\", \"@type\": \"@id\"}}\n        const ret = {}\n        ret[property] = {'@id': id}\n        if (\"max\" in expr && expr.max !== 1 && this.config.axes.c)\n          ret[property][\"@container\"] = \"@list\"\n        if (typeof expr.valueExpr === \"string\") {\n          if (false) {} else {\n            // all other references (Datatypes, Resources)\n            const firstRef = this.findFirstOfCollection(expr.valueExpr, index)\n            ret[property]['@context'] = StupidBaseUrl(firstRef.substr(Ns_fhsh.length).replace(/OneOrMore_/, ''))\n          }\n        } else if (typeof expr.valueExpr === 'object') {\n          const a = (expr.annotations || []).find(a => a.predicate === \"http://shex2json.example/map#property\")\n          if (a) {\n            ; // no need for an @type\n          } else if (expr.valueExpr.type === \"NodeConstraint\") {\n            if (expr.valueExpr.nodeKind === 'iri') {\n              // e.g. `fhir:link IRI`\n              ret[property]['@type'] = \"@id\"\n            } else if (\"datatype\" in expr.valueExpr) {\n              // e.g. `fhir:v xsd:string`\n              ret[property]['@type'] = expr.valueExpr.datatype\n            }\n          } else if (expr.valueExpr.type === \"Shape\") {\n            ret[property]['@context'] = this.visit(expr.valueExpr.expression)\n          } else if (expr.valueExpr.type === \"ShapeOr\"\n                     && !(expr.valueExpr.shapeExprs.find(v => typeof v !== \"string\"\n                                                         || !v.startsWith(Ns_fhsh))) /* all refs */) {\n            /* Observation.value -> { valueAttachment: {@id: 'fhir:v', @context: 'Attachment.context.jsonld'},\n                                      valueBoolean: {@id: 'fhir:v', @context: 'boolean.context.jsonld'} }\n             */\n            delete ret[property]; // N/A for curried names.\n            expr.valueExpr.shapeExprs.forEach(v => {\n              const type = v.substr(Ns_fhsh.length)\n              const curriedPredicate = property\n                    + type.substr(0, 1).toUpperCase() // capitolize this letter\n                    + type.substr(1)\n              /*\n                !! not tested with list. current resources and types have no polymorphic property with max card > 1 per this query:\n                jq '.entry[].resource.differential.element[]? | select((.id | endswith(\"[x]\")) and .max != \"1\")' profiles-resources.json\n               */\n              ret[curriedPredicate] = {\n                '@id': id,\n                '@context': StupidBaseUrl(type/*.replace(/OneOrMore_/, '')*/)\n              }\n            })\n          } else {\n            // e.g. `fhir:gender @fhirs:code AND { fhir:v @fhirvs:adminstritative-gender }`\n            const ref = firstRef(expr.valueExpr);\n            if (ref) {\n              // TODO: why isn't this need here like it is above?: this.findFirstOfCollection(ref, index);\n              ret[property]['@context'] = StupidBaseUrl(ref.substr(Ns_fhsh.length).replace(/OneOrMore_/, ''))\n            }\n          }\n        }\n        return ret\n      default:\n        throw Error('what\\'s a ' + JSON.stringify(expr))\n    }\n  }\n\n  findFirstOfCollection (label, index) {\n    if (!label.substr(Ns_fhsh.length).startsWith('OneOrMore_'))\n      return label;\n    const valueExpr = index.shapeExprs[label].expression.expressions[0].valueExpr;\n    return firstRef(valueExpr);\n  }\n}\n\nfunction firstRef (expr) {\n  if (typeof expr === \"string\")\n    return expr;\n  if ([\"ShapeOr\", \"ShapeAnd\"].indexOf(expr.type) !== -1)\n    return expr.shapeExprs.find(firstRef)\n  return null // nothing found\n}\n\nfunction shorten (p) {\n  if (p === Ns_rdf + 'type')\n    return {id: 'rdf:type', attr: 'resourceType'}\n  const pairs = [\n    {prefix: 'fhir', ns: Ns_fh},\n    {prefix: 'rdf', ns: Ns_rdf},\n  ]\n  return pairs.reduce((acc, pair) => {\n    if (!p.startsWith(pair.ns))\n      return acc\n    const localName = p.substr(pair.ns.length) // .replace(/[a-zA-Z]+\\./, '')\n    const lastDot = localName.lastIndexOf('.'); // may be -1\n    const property = localName.substr(lastDot + 1);\n    const n = pair.prefix + ':' + escape(localName)\n    return acc.id === null || n.length < acc.id.length ? {id: n, property} : acc\n  }, {id: null, attr: null})\n}\n\nfunction escape (localName) {\n  return localName\n}\n\nif (true)\n  module.exports = FhirJsonLdContextGenerator;\n\n\n//# sourceURL=webpack://playground/../fhirlib/FhirJsonLdContextGenerator.js?");

/***/ }),

/***/ "../fhirlib/FhirPreprocessors.js":
/*!***************************************!*\
  !*** ../fhirlib/FhirPreprocessors.js ***!
  \***************************************/
/***/ ((module) => {

eval("const CODE_SYSTEM_MAP = {\n  \"http://snomed.info/sct\": \"sct\",\n  \"http://loinc.org\": \"loinc\"\n};\nconst NS_fhir = \"http://hl7.org/fhir/shape/\";\nconst NS_xsd = \"http://www.w3.org/2001/XMLSchema#\";\n\nfunction parseResourceType(resourceType) {\n  return resourceType.includes(':') ? resourceType.split(':')[1] : resourceType\n}\n\nclass FhirR5Preprocessor {\n  constructor (shexj, opts = {axes: {r:true, d:true, v:true, c:false, h:false}}) {\n    this.shexj = shexj;\n    this.opts = opts;\n    this.resourceTypeSet = new Set();\n  }\n\n  preprocess(input) {\n    if ('@context' in input) {\n      return \"input preprocessed\";\n    }\n    let resourceType;\n    if (input.resourceType) {\n      resourceType = parseResourceType(input.resourceType);\n      this.resourceTypeSet.add(resourceType);\n    }\n    input['nodeRole'] = 'fhir:treeRoot';\n\n    // TODO: replace this with @included once the bug is fixed\n    const shexpr = this.shexj.shapes.find(s => s.id === NS_fhir + resourceType);\n    if (!shexpr)\n      throw Object.assign(Error(`No shape found for ${resourceType}`), {shapes: this.shexj.shapes.map(s => s.id)});\n    let graph = this.processFhirObject(input, shexpr, resourceType, false, false);\n\n    // add ontology header\n    let hdr = {};\n    hdr['@id'] = graph['@id'] + '.ttl';\n    hdr['owl:versionIRI'] = hdr['@id'];\n    hdr['owl:imports'] = 'fhir:fhir.ttl';\n    hdr[\"@type\"] = 'owl:Ontology';\n\n    let output = { ...graph, \"@included\": hdr };\n\n    let context = [];\n    if (this.resourceTypeSet.size > 0) {\n      Array.from(this.resourceTypeSet).sort().forEach(rt => {\n        context.push(this.getFhirContextUrl(rt));\n      })\n      context.push(this.getFhirContextUrl('root'));\n    }\n    context.push({\n      '@base': 'http://hl7.org/fhir/',\n      'nodeRole': { '@type': '@id', '@id': 'fhir:nodeRole' },\n      'owl:imports': { '@type': '@id' },\n      'owl:versionIRI': { '@type': '@id' },\n    });\n    output = { '@context': context, ...output };\n\n    return JSON.stringify(output, null, 2);\n  }\n\n  getFhirContextUrl(resourceType) {\n    return `https://fhircat.org/fhir-r5/original/contexts/${resourceType}.context.jsonld`\n    // return `https://fhircat.org/fhir/contexts/r5/${resourceType}.context.jsonld`\n    // return `https://raw.githubusercontent.com/fhircat/jsonld_context_files/master/contextFiles/${resourceType}.context.jsonld`;\n  }\n\n  fromFhirValue(value) {\n    return value['v'] || value['@value'] || value\n  }\n\n  toFhirValue(value) {\n    return value;\n  };\n\n  addTypeArc(value) {\n    if (value.system && value.code) {\n      let system = this.valueOf(this.fromFhirValue(value.system));\n      let code = this.valueOf(this.fromFhirValue(value.code));\n      let system_root = '/#'.includes(system.slice(-1)) ? system.slice(0, -1) : system;\n      let base;\n      if (system_root in CODE_SYSTEM_MAP) {\n        base = CODE_SYSTEM_MAP[system_root] + ':'\n      } else {\n        base = system + ('/#'.includes(system.slice(-1)) ? '' : '/')\n      }\n      value['@type'] = base + code\n    }\n    return value\n\n  }\n\n  valueOf (v) {\n    if (this.opts.axes.h) { return v; }\n    return v['@value'];\n  }\n\n  processFhirObject(fhirObj, schemaObject, resourceType, inside = false, injectTypeArc = false) {\n    for (let key in fhirObj) {\n      let value = fhirObj[key];\n      if (key.startsWith('@')) {\n        continue;\n      } else if (key === 'resourceType') {\n        if (!(value.startsWith('fhir:'))) {\n          this.resourceTypeSet.add(value);\n          fhirObj[key] = 'fhir:' + value;\n        }\n      } else if (key === 'contained') {\n        value.forEach(contained => this.processAbstractReference(contained, schemaObject, resourceType, inside));\n      } else if (key === 'resource' /* TODO: make sure in a Bundle.entry? */) {\n        this.processAbstractReference(value, schemaObject, resourceType, inside);\n      } else {\n        if (injectTypeArc) {\n          fhirObj['@type'] = 'fhir:' + schemaObject.id.substr(NS_fhir.length);\n        }\n        const [nestObject, nestType, nestInjectTypeArc] = this.lookupNestedObject(schemaObject, resourceType, key);\n        if (Array.isArray(value)) {\n          fhirObj[key] = this.processFhirArray(key, value, nestObject, nestType, nestInjectTypeArc);\n        } else if (typeof value === 'object') {\n          fhirObj[key] = this.processFhirObject(value, nestObject, nestType, true, nestInjectTypeArc);\n        } else if (key === 'id') {\n          fhirObj['@id'] = (inside && !value.startsWith('#') ? '#' : resourceType + '/') + value\n          fhirObj.id = this.toFhirValue(fhirObj.id, nestObject, nestType)\n        } else if (key === 'reference') {\n          if (!('link' in fhirObj)) {\n            fhirObj['fhir:link'] = this.genFhirReference(fhirObj);\n          }\n          fhirObj[key] = this.toFhirValue(value, nestObject, nestType)\n        } else if (!['nodeRole', 'index', 'div'].includes(key)) {\n          fhirObj[key] = this.toFhirValue(value, nestObject, nestType);\n        }\n        if (key === 'coding') {\n          fhirObj[key] = value.map(n => this.addTypeArc(n))\n        }\n      }\n    }\n    return fhirObj;\n  }\n\n  processAbstractReference (contained, schemaObject, resourceType, inside = false) {\n    if (!('resourceType' in contained))\n      throw Error(`expected resourceType in contained object ${JSON.stringify(contained)}`);\n    const containedType = contained.resourceType;\n    const shapeForContained = this.shexj.shapes.find(se => se.id === Prefixes.fhirshex + containedType);\n    if (!shapeForContained)\n      throw Error(`no ShEx shape found for ${containedType}`);\n    this.processFhirObject(contained, shapeForContained, containedType, true, false);\n  }\n\n  lookupNestedObject (schemaObject, resourceType, key) {\n    let tc = undefined;\n    let nestedShapeExprRef = null;\n    let injectTypeArc = false;\n    if (schemaObject.expression.type === \"TripleConstraint\") {\n      tc = schemaObject.expression;\n    } else if (schemaObject.expression.type === \"EachOf\") {\n      for (let i = 0; tc === undefined && i < schemaObject.expression.expressions.length; ++i) {\n        const eachOfTE = schemaObject.expression.expressions[i];\n        if (eachOfTE.type === \"TripleConstraint\") {\n          if (eachOfTE.predicate.endsWith('.' + key) || eachOfTE.predicate.endsWith('/' + key)/* nodeRole */) {\n            tc = eachOfTE;\n          } else if (!this.opts.axes.v && eachOfTE.valueExpr.type === \"ShapeOr\") {\n            const valueChoices = eachOfTE.valueExpr.shapeExprs;\n            if ((nestedShapeExprRef = valueChoices.find(ref => {\n              if (typeof ref !== \"string\") throw Error(`expected only references to datatypes in ${JSON.stringify(eachOfTE)}`);\n              if (!(ref.startsWith(NS_fhir))) throw Error(`reference ${ref} doesn't expected to start with ${NS_fhir}`);\n              const typeLabel = ref.substr(NS_fhir.length);\n              const curriedPredicate = eachOfTE.predicate + typeLabel.substr(0, 1).toUpperCase() + typeLabel.substr(1);\n              return curriedPredicate.endsWith('.' + key) || curriedPredicate.endsWith('/' + key);\n            }))) {\n              tc = eachOfTE;\n              injectTypeArc = true;\n            }\n          }\n        } else if (eachOfTE.type === \"OneOf\") {\n          tc = eachOfTE.expressions.find(oneOfTE => oneOfTE.predicate.endsWith('.' + key) || oneOfTE.predicate.endsWith('/' + key));\n        } else throw Error(\"HERE\");\n      }\n    }\n    if (!nestedShapeExprRef) {\n      if (!tc) throw Error(`Can't find ${resourceType}.${key} in ${JSON.stringify(schemaObject, null, 2)}`);\n      let valueExpr = tc.valueExpr;\n      const Pfhirshex = \"http://hl7.org/fhir/shape/\";\n      const listOfStem = Pfhirshex + \"OneOrMore_\";\n      if (typeof valueExpr === \"string\" && valueExpr.startsWith(listOfStem)) {\n        // TODO: track down actual shape and use firstRef(rdf:first)\n        valueExpr = Pfhirshex + valueExpr.substr(listOfStem.length).replace(/_AND_.*$/, '');\n      }\n      if (typeof valueExpr === \"object\") {\n        if (valueExpr.type === \"ShapeAnd\") {\n          nestedShapeExprRef = valueExpr.shapeExprs[0];\n        } else if (valueExpr.type === \"ShapeOr\") {\n          return [valueExpr, resourceType, false];\n        } else if (valueExpr.type === \"NodeConstraint\") {\n          return [valueExpr, resourceType, false];\n        } else if (valueExpr.type === \"Shape\") { // nested shapes shows up only in nested schemas\n          return [valueExpr, resourceType, false];\n        } else throw Error(\"HERE\");\n      } else if (typeof valueExpr === \"string\") {\n        if (!valueExpr.startsWith(NS_fhir)) throw Error(`unexpected valueExpr in ${tc}`);\n        nestedShapeExprRef = valueExpr;\n      } else throw Error(\"HERE\");\n    }\n    const nestObject = this.shexj.shapes.find(se => se.id === nestedShapeExprRef);\n    const nestType = nestedShapeExprRef.substr(NS_fhir.length);\n    return [nestObject, nestType, injectTypeArc];\n  }\n\n  processExtensions(fhirObj) {\n    // merge extensions\n    for (let key in fhirObj) {\n      if (!key.startsWith('_')) {\n        continue;\n      }\n      let baseKey = key.substr(1);\n      if (fhirObj[baseKey] && typeof fhirObj[baseKey] === 'object') {\n        for (let subkey in fhirObj[key]) {\n          if (subkey in fhirObj[baseKey]) {\n            console.log(`Extension object ${subkey} is already in the base for ${key}`)\n          } else {\n            fhirObj[baseKey][subkey] = fhirObj[key][subkey]\n          }\n        }\n      } else {\n        console.log(`Badly formed extension element: ${key}`);\n      }\n      delete fhirObj[key]\n    }\n    return fhirObj;\n  }\n\n  processFhirArray(key, value, schemaObject, resourceType, injectTypeArc) {\n    return value.map((e, i) => {\n      let v = null\n      if (Array.isArray(e)) {\n        throw Error(`Problem: ${key} has a list in a list`)\n      } else if (typeof e === 'object') {\n        v = this.processFhirObject(e, schemaObject, resourceType, injectTypeArc)\n      } else {\n        v = this.toFhirValue(e, schemaObject, resourceType)\n      }\n      if (this.opts.axes.c) {\n        return v // handled by the @context's \"@container\": \"@list\"\n      }\n      if (typeof v === \"string\")\n        throw Error(`Can't add index to RDF literal \\\"${v}\\\" for ${resourceType}.${key}`)\n      if (typeof v !== 'object')\n        throw Error(`Can't add index to \\\"${JSON.stringify(v)}\\\" for ${resourceType}.${key}`)\n      if (\"@value\" in v)\n        throw Error(`Can't add index to RDF literal \\\"${JSON.stringify(v)}\\\" for ${resourceType}.${key}`)\n      v['index'] = i\n      return v\n    })\n  }\n\n  genFhirReference(fhirObj) {\n    let typ, link\n    if (!fhirObj.reference.includes('://') && !fhirObj.reference.startsWith('/')) {\n      typ = 'type' in fhirObj ? fhirObj.type : fhirObj.reference.split('/', 1)[0]\n      link = '../' + fhirObj.reference\n    } else {\n      link = fhirObj.reference;\n      typ = fhirObj.type\n    }\n    let rval = { '@id': link };\n    if (typ) {\n      rval['@type'] = 'fhir:' + typ\n    }\n    return rval\n  }\n}\n\nconst UnionedTypes = {\n  dateTime: { pattern: /^[+-]?\\d{4}-[01]\\d-[0-3]\\dT[0-5]\\d:[0-5]\\d:[0-5]\\d(\\.\\d+)?([+-][0-2]\\d:[0-5]\\d|Z)?$/, dt: \"xsd:dateTime\" },\n  date: { pattern: /^[0-9]{4}-[0-9]{2}-[0-9]{2}$/, dt: \"xsd:date\" },\n  gYearMonth: { pattern: /^[0-9]{4}-[0-9]{2}$/, dt: \"xsd:gYearMonth\" },\n  gYear: { pattern: /^[0-9]{4}$/, dt: \"xsd:gYearMonth\" },\n  decimal: { pattern: /^[+-]?(?:[0-9]*\\.[0-9]+|[0-9]+)$/, dt: \"xsd:decimal\" },\n  double: { pattern: /^[+-]?(?:[0-9]*\\.[0-9]+|[0-9]+)E[+-]?(?:[0-9]+)$/, dt: \"xsd:double\" },\n};\n\nclass FhirR4Preprocessor extends FhirR5Preprocessor {\n  toFhirValue(jsonValue, schemaObject, nestType) {\n    let typedValue = null;\n\n    const [nestScalar, t] = this.lookupNestedObject(schemaObject, nestType, \"v\");\n    if (nestScalar.type === \"NodeConstraint\") {\n      typedValue = {\n        \"@type\": nestScalar.datatype.replace(/^http:\\/\\/www\\.w3\\.org\\/2001\\/XMLSchema#/, \"xsd:\"),\n        \"@value\": jsonValue,\n      };\n    } else if (nestScalar.type === \"ShapeOr\") {\n      const ut = nestScalar.shapeExprs.map(\n          nc => UnionedTypes[nc.datatype.substr(NS_xsd.length)]\n      ).find(\n          t => t.pattern.test(jsonValue)\n      );\n      typedValue = { '@type': ut.dt, '@value': jsonValue };\n    } else {\n      throw new Error(`deal with toFhirValue(${JSON.stringify(jsonValue)}, ${JSON.stringify(schemaObject)}, ${JSON.stringify(nestType)})`);\n    }\n    return this.opts.axes.h ? typedValue : { 'v': typedValue };\n  }\n\n  processFhirObject(fhirObj, schemaObject, resourceType, inside = false, injectTypeArc = false) {\n    fhirObj = super.processFhirObject(fhirObj, schemaObject, resourceType, inside, injectTypeArc);\n    fhirObj = this.processExtensions(fhirObj);\n    return fhirObj;\n  }\n\n  getFhirContextUrl(resourceType) {\n    return `https://fhircat.org/fhir-r4/original/contexts/${resourceType}.context.jsonld`\n    // return `https://fhircat.org/fhir/contexts/r5/${resourceType}.context.jsonld`\n    // return `https://raw.githubusercontent.com/fhircat/jsonld_context_files/master/contextFiles/${resourceType}.context.jsonld`;\n  }\n}\n\nif (true)\n  module.exports = { FhirR5Preprocessor, FhirR4Preprocessor };\n\n\n//# sourceURL=webpack://playground/../fhirlib/FhirPreprocessors.js?");

/***/ }),

/***/ "../fhirlib/FhirRdfModelGenerator.js":
/*!*******************************************!*\
  !*** ../fhirlib/FhirRdfModelGenerator.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const { StructureError } = __webpack_require__(/*! ./errors */ \"../fhirlib/errors.js\");\nconst Prefixes = __webpack_require__(/*! ./Prefixes */ \"../fhirlib/Prefixes.js\");\n\nconst DatatypeTypes = [\n  \"http://hl7.org/fhir/StructureDefinition/DataType\",\n  \"http://hl7.org/fhir/StructureDefinition/PrimitiveType\",\n];\n\n/**\n * Used in the visitor API to communicate JSON properties definitions mapped to RDF.\n */\nclass PropertyMapping {\n  constructor(isScalar, element, property, predicate, type, binding, specializes) {\n    this.isScalar = isScalar;\n    this.element = element;\n    this.property = property;\n    this.predicate = predicate;\n    this.type = type;\n    this.binding = binding;\n    this.specializes = specializes;\n  }\n}\n\nclass ModelVisitor {\n\n  constructor(definitionLoader) {\n    this.definitionLoader = definitionLoader;\n  }\n  enter (propertyMapping) { throw new Error(`ModelVistor.enter(${propertyMapping}) must be overloaded`); }\n  element (propertyMapping) { throw new Error(`ModelVistor.complex(${propertyMapping}) must be overloaded`); }\n  exit (propertyMapping) { throw new Error(`ModelVistor.exit(${propertyMapping}) must be overloaded`); }\n}\n\nclass FhirResourceDefinitionError extends StructureError {\n  constructor (msg, resourceDef) {\n    super(`Error in ${resourceDef.id}: ${msg}`);\n    this.resourceDef = resourceDef;\n  }\n\n  logMessage (log) {\n    log(`Bad resource`, this.resourceDef);\n  }\n}\n\nclass FhirElementDefinitionError extends StructureError {\n  constructor (msg, resourceDef, elt) {\n    const ordinal = resourceDef.differential.element.indexOf(elt);\n    super(`Error in ${resourceDef.id} differential.element[${ordinal}] ${elt.id}: ${msg}`);\n    this.resourceDef = resourceDef;\n    this.elt = elt;\n    this.ordinal = ordinal;\n  }\n\n  logMessage (log) {\n    log(`Bad element in resource differential.element[${this.ordinal}]`, this.resourceDef);\n  }\n}\n\n/**\n * Walk a FHIR Resource definition and call a visitor for each scalar or complex element property definition when entering or exiting a nested Element.\n */\nclass FhirRdfModelGenerator {\n  static STRUCTURE_DEFN_ROOT = \"http://hl7.org/fhir/StructureDefinition/\";\n  static FHIRPATH_ROOT = \"http://hl7.org/fhirpath/System.\";\n  static NS_fhir = \"http://hl7.org/fhir/\";\n  static NS_xsd = \"http://www.w3.org/2001/XMLSchema#\";\n  static NS_s2j = \"http://shex2json.example/map#\"\n\n  // Overrides by element.path\n  static propertyOverrides = {\n    'uri.value': {nodeConstraint: { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'anyURI' }}, // FHIR type String\n    'base64Binary.value': {nodeConstraint: { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'base64Binary' }}, // also type String\n    'instant.value': {nodeConstraint: { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'dateTime' }}, // Datetime\n    'dateTime.value': {nodeConstraint: { \"type\": \"ShapeOr\", \"shapeExprs\": [\n      { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'dateTime'   },\n      { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'date'       },\n      { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'gYearMonth' },\n      { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'gYear'      },\n    ], \"annotations\": FhirRdfModelGenerator.unTyped() } }, // Datetime\n    'integer64.value': {nodeConstraint: { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'long' }}, // Datetime\n    'Narrative.div': {normalPredicate: true, nodeConstraint: { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'string' }}, // XHTML narrative text\n    // this doesn't work because the value was already defined by `\"baseDefinition\": \".../integer\"`:\n    //   'positiveInt.value': {nodeConstraint: { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'positiveInt' }}\n  };\n\n  // Overrides by value type\n  static fhirScalarTypeToXsd = { // overrides by trimmedTypeCode\n    \"Boolean\": { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + \"boolean\" },\n    \"String\": { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + \"string\" },\n    \"Date\": { \"type\": \"ShapeOr\", \"shapeExprs\": [\n      { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'date'       },\n      { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'gYearMonth' },\n      { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'gYear'      },\n    ], \"annotations\": FhirRdfModelGenerator.unTyped() },\n    \"Decimal\": { \"type\": \"ShapeOr\", \"shapeExprs\": [\n      { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'decimal'    },\n      { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + 'double'     },\n    ], \"annotations\": FhirRdfModelGenerator.unTyped() },\n    \"Integer\": { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + \"integer\" },\n    \"Time\": { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + \"time\" },\n    \"Instant\": { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + \"dateTime\" },\n    \"DateTime\": { \"type\": \"NodeConstraint\", \"datatype\": FhirRdfModelGenerator.NS_xsd + \"dateTime\" },\n  };\n\n  // fault-tolerance - construct name with \"UNKNOWN\" in it if missing from fhirScalarTypeToXsd\n  static synthesizeScalarTypeName (resourceDef, elt, typeString) {\n    if (typeString in FhirRdfModelGenerator.fhirScalarTypeToXsd)\n      return FhirRdfModelGenerator.fhirScalarTypeToXsd[typeString];\n\n    const e = new FhirElementDefinitionError(`unknown mapping to XSD for target: ${resourceDef.id}, id: ${elt.id}, code: ${typeString}`, resourceDef, elt);\n    console.warn(e.stack);\n    return `UNKNOWN-${resourceDef.id}-${elt.id}-${typeString}`;\n  }\n\n  // These element.type.code imply following elements are in a nested structure.\n  static NestedStructureTypeCodes = [\"BackboneElement\", /*\"BackboneType\", ?*/ \"Element\"];\n\n  static FhirTypeExtension = \"http://hl7.org/fhir/StructureDefinition/structuredefinition-fhir-type\";\n\n  constructor (definitionLoader, opts = {}) {\n    this.definitionLoader = definitionLoader;\n    this.stack = [];\n    this.opts = opts;\n  }\n\n  myError (error) {\n    if ('error' in this.opts) {\n      this.opts.error(error);\n    } else {\n      throw error;\n    }\n  }\n\n  /**\n   * Recursive function to generate a content model for a FHIR Resource\n   */\n  async visitResource (resourceDef, visitor, config) {\n    await this.visitElement(resourceDef, visitor, config);\n    this.stack.reverse().forEach(n => visitor.exit(n));\n    this.stack = [];\n  }\n\n  async visitElementByName (target, visitor, config) {\n    const resourceDef = await this.definitionLoader.getStructureDefinitionByName(target);\n    if (resourceDef === null) {\n      return [];\n    }\n\n    return await this.visitElement(resourceDef, visitor, config);\n  }\n\n  async visitElement (resourceDef, visitor, config) {\n    if (\"baseDefinition\" in resourceDef && !(resourceDef.baseDefinition.startsWith(FhirRdfModelGenerator.STRUCTURE_DEFN_ROOT))) {\n      this.myError(new FhirResourceDefinitionError(`Don't know where to look for base structure ${resourceDef.baseDefinition}`, resourceDef));\n      return [];\n    }\n\n    let baseElts = [];\n    if (\"baseDefinition\" in resourceDef) {\n      const recursionTarget = resourceDef.baseDefinition.substr(FhirRdfModelGenerator.STRUCTURE_DEFN_ROOT.length);\n      if (recursionTarget !== 'base')\n        baseElts = await this.visitElementByName(recursionTarget, visitor, config); // Get content model from base type\n    }\n\n    // Walk differential elements\n    return await resourceDef.differential.element.slice(1).reduce(async (visitedEltsP, elt) => {\n      const visitedElts = await visitedEltsP;\n      if (elt.id !== elt.path) { // test assumptions\n        this.myError(new FhirElementDefinitionError(`id !== path in ${resourceDef.id} ${elt.id}`, resourceDef, elt));\n        return visitedElts;\n      }\n\n      // Early return for the first entry in a Resource's elements\n      if (!((\"type\" in elt) ^ (\"contentReference\" in elt))) { // 1st elt points to itself or something like that. Anyways, it doesn't have a type.\n        this.myError(new FhirElementDefinitionError(`expected one of (type, contentReference)`, resourceDef, elt));\n        return visitedElts;\n      }\n\n      // Calculate path components\n      const path = elt.id.split('.');\n      const resourceName = path.shift();\n      if (resourceName !== resourceDef.id)\n        console.warn(`property id ${elt.id} does not start with target \\\"${resourceDef.id}\\\" in ${resourceDef.id} structure def`);\n      let rawName = path.pop();\n\n      // Handle curried datatype names\n      if (\"type\" in elt && rawName.endsWith(\"[x]\") ^ elt.type.length > 1) { // assume \"...[x]\" only applies if you have multiple types\n        this.myError(new Error(`Not sure whether ${resourceDef.id}.${elt.id} is a curried property or not: '${JSON.stringify(typeEntry)}'`));\n        return visitedElts;\n      }\n      const [curried, name] = \"type\" in elt && elt.type.length > 1\n            ? [true, rawName.substr(0, rawName.length - \"[x]\".length)]\n            : [false, rawName];\n\n      // Trim down any nested properties we've passed as evidenced by them not having a corresponding name in the path.\n      for (let i = this.stack.length - 1; i >= 0; --i) {\n        if (this.stack[i].property !== path[i]) {\n          // `i` has the index of the first Nesting not consistent with `path`.\n          this.stack.slice(i).reverse().forEach(n => visitor.exit(n)); // call exit on each extra element in the stack\n          this.stack = this.stack.slice(0, i); // trim down the stack\n          break;\n        }\n      }\n\n      // aggregate element's types into a disjunction\n      const disjointPMaps = \"contentReference\" in elt\n            ? [new PropertyMapping(false, elt, name, this.makePredicate(resourceDef, path, resourceName, name), elt.contentReference.slice(1), null, [])]\n            : await elt.type.reduce(async (accP, typeEntry, idx) => {\n              const acc = await accP;\n              if (typeof typeEntry !== \"object\"\n                  || !(\"code\" in typeEntry)\n                  || typeof typeEntry.code !== \"string\") {\n                this.myError(new FhirElementDefinitionError(`${idx}th type entry not recognized '${JSON.stringify(typeEntry)}' in ${JSON.stringify(elt.id)}`, resourceDef, elt));\n                return visitedElts;\n              }\n\n              // Calculate final element name.\n              const typeCode = typeEntry.code;\n              const curriedName = curried && this.opts.axes.v\n                    ? name + typeCode.substr(0, 1).toUpperCase() + typeCode.substr(1)\n                    : name;\n              // Elements and BackboneElements indicate a nested structure.\n              const predicate = this.makePredicate(resourceDef, path, resourceName, curriedName);\n\n              if (FhirRdfModelGenerator.NestedStructureTypeCodes.indexOf(typeCode) !== -1) {\n                if (elt.type.length > 1) {\n                  this.myError(new FhirElementDefinitionError(`expected exactly one type for nested structure '${elt.id}'`, resourceDef));\n                }\n\n                // Construct a Nesting for this property and visitor.enter it.\n                const n = new PropertyMapping(false, elt, curriedName, predicate, FhirRdfModelGenerator.STRUCTURE_DEFN_ROOT + typeCode, null, []);\n                this.stack.push(n);\n                visitor.enter(n);\n\n                // if this element extends another, process the base.\n                // This is probably always true BackboneElements extend DomainResource and Elements extend BackboneType or Datatype.\n                if (elt.id === resourceDef.id) {\n                  this.myError(new FhirElementDefinitionError(`Resource root element should not have a type and so shouldn't get here. got type '${elt.type}'`, resourceDef, elt));\n                }\n                const nestedTarget = typeCode;\n\n                // Because the nested element has a different name, we will appear to have exited any nested elements,\n                // so save and hide the stack.\n                const saveStack = this.stack;\n                this.stack = [];\n                await this.visitElementByName(nestedTarget, visitor, config);\n                this.stack = saveStack;\n                return []; // return await acc ?\n              } else {\n                const isFhirPath = typeCode.startsWith(FhirRdfModelGenerator.FHIRPATH_ROOT);\n                const trimmedTypeCode = isFhirPath\n                      ? typeCode.substr(FhirRdfModelGenerator.FHIRPATH_ROOT.length) // http://hl7.org/fhirpath/System.String -> String\n                      : typeCode;                                                   // Address -> Address, uri -> uri\n\n                let propertyOverride = FhirRdfModelGenerator.propertyOverrides[elt.id];\n                const isScalar = (elt.id === resourceDef.id + \".value\" && \"representation\" in elt && elt.representation[0] === \"xmlAttr\") //  e.g. elt.id is \"string.value\", \"date.value\"\n                      || !!propertyOverride;\n                const specializes = path.length > 0\n                      ? []\n                      : baseElts.find(disjuncts => disjuncts.find(pMap => pMap.property === curriedName)) || [];\n\n                if (isScalar) {\n                  if (elt.type.length > 1) {\n                    this.myError(new FhirElementDefinitionError(`expected exactly one type for scalar '${elt.id}'`, resourceDef, elt));\n                  }\n\n                  // Calculate XML Schema datatype\n                  const nodeConstraint = (propertyOverride ? propertyOverride.nodeConstraint : null)\n                        || FhirRdfModelGenerator.synthesizeScalarTypeName(resourceDef, elt, trimmedTypeCode);\n\n                  // A propertyOverride with normalPredicate === true says to use the calculated predicate, e.g. `Narrative.div`.\n                  const overridePredicate = propertyOverride && propertyOverride.normalPredicate\n                        ? predicate\n                  // otherwse construct from the bare curried name (e.g. string.value => value, integer64.value => value)\n                        : FhirRdfModelGenerator.NS_fhir + 'v';\n\n                  const pMap = new PropertyMapping(true, elt, curriedName, overridePredicate, nodeConstraint, null, specializes);\n                  return acc.concat([pMap]);\n                } else {\n                  const binding = 'binding' in elt ? elt.binding : null;\n                  const shapeLabel = isFhirPath\n                        ? FhirRdfModelGenerator.expectFhirType(resourceDef, elt, typeEntry)\n                        : typeCode;\n                  const pMap = new PropertyMapping(false, elt, curriedName, predicate, shapeLabel, binding, specializes);\n                  return acc.concat([pMap]);\n                }\n              }\n            }, Promise.resolve([]));\n\n      if (disjointPMaps.length) // will be 0 if elt.id was in NestedStructureTypeCodes, as verified by (elt.type.length > 1) assertions\n        visitor.element(disjointPMaps);\n      return visitedElts.concat([disjointPMaps]);\n    }, Promise.resolve([]));\n  }\n\n\n  makePredicate (resourceDef, path, resourceName, curriedName) {\n    return FhirRdfModelGenerator.NS_fhir + // elt.id\n      (\n        DatatypeTypes.indexOf(resourceDef.baseDefinition) !== -1 || ([\n          \"Timing\"\n        ]).indexOf(resourceDef.id) !== -1\n          ? (\n            this.opts.axes.d\n              ? [resourceName].concat(path).concat(curriedName).join('.')\n              : curriedName\n          )\n          : this.opts.axes.r\n          ? [resourceName].concat(path).concat(curriedName).join('.')\n          : curriedName\n      );\n  }\n\n\n  static expectFhirType (resourceDef, elt, typeEntry) {\n    const ft = (typeEntry.extension || []).find(ext => ext.url === FhirRdfModelGenerator.FhirTypeExtension);\n    if (!ft) {\n      this.myError(FhirElementDefinitionError(`Expected ${elt.id} ${typeEntry.code} to have an <${FhirRdfModelGenerator.FhirTypeExtension}> extension`, resourceDef, elt));\n      return 'UNKNOWN_FHIR_TYPE';\n    }\n    return ft.valueUrl || ft.valueUri; // latter is deprecated?\n  }\n\n  static unTyped (property) {\n    return [ {\n      \"type\": \"Annotation\",\n      \"predicate\": FhirRdfModelGenerator.NS_s2j + \"property\",\n      \"object\": FhirRdfModelGenerator.NS_s2j + \"unTyped\"\n    } ];\n  }\n\n  /*\n  static propAnnot (property) {\n    return [ {\n      \"type\": \"Annotation\",\n      \"predicate\": FhirRdfModelGenerator.NS_s2j + \"property\",\n      \"object\": { \"value\": property }\n    } ];\n  }\n  */\n}\n\nif (true)\n  module.exports = {FhirRdfModelGenerator, FhirResourceDefinitionError, FhirElementDefinitionError, ModelVisitor, PropertyMapping, DatatypeTypes};\n\n\n//# sourceURL=webpack://playground/../fhirlib/FhirRdfModelGenerator.js?");

/***/ }),

/***/ "../fhirlib/FhirShExJGenerator.js":
/*!****************************************!*\
  !*** ../fhirlib/FhirShExJGenerator.js ***!
  \****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const Hierarchy = __webpack_require__(/*! hierarchy-closure */ \"../fhirlib/node_modules/hierarchy-closure/hierarchy-closure.js\");\nconst {FhirRdfModelGenerator, PropertyMapping, DefinitionBundleLoader, ModelVisitor, DatatypeTypes} = __webpack_require__(/*! ./FhirRdfModelGenerator */ \"../fhirlib/FhirRdfModelGenerator.js\");\nconst Prefixes = __webpack_require__(/*! ./Prefixes */ \"../fhirlib/Prefixes.js\");\nconst ShExUtil = __webpack_require__(/*! @shexjs/util */ \"../fhirlib/node_modules/@shexjs/util/shex-util.js\");\nconst P = __webpack_require__(/*! ./Prefixes */ \"../fhirlib/Prefixes.js\");\n\nconst GEN_SHEXJ_STEM = 'http://hl7.org/fhir/StructureDefinition/';\nconst CODE_SYSTEM_STEM = 'http://hl7.org/fhir/CodeSystem/';\nconst VALUE_SET_STEM = 'http://hl7.org/fhir/ValueSet/';\n\n/**\n * Leverage a FhirRdfModelGenerator to traverse StructureDefinitions and generate equivalent ShExJ.\n */\nclass FhirShExJGenerator extends ModelVisitor {\n\n  // prototype for generated schema.\n  static EMPTY_FHIR_RESOURCE_SCHEMA = {\n    type: \"Schema\",\n    start: {\n      type: \"ShapeAnd\",\n      shapeExprs: [\n        Prefixes.fhirshex + 'Base', // everything that extends Base\n        {\n          type: \"Shape\",\n          expression: {\n            type: \"TripleConstraint\",\n            predicate: \"http://hl7.org/fhir/nodeRole\",\n            valueExpr: {\n              type: \"NodeConstraint\",\n              values: [\n                \"http://hl7.org/fhir/treeRoot\"\n              ]\n            }\n          }\n        }\n      ]\n    },\n    shapes: [\n    ]\n  };\n\n  static BindingMaps = [\n    {fhirStem: Prefixes.fhirvs, shexStem: ''},\n    {fhirStem: 'http://terminology.hl7.org/ValueSet/', shexStem: 'hl7-'},\n    {fhirStem: 'http://loinc.org/vs/', shexStem: 'loinc-'},\n  ];\n\n  // prototype for fhir:index list emulations.\n  static INDEX = {\n    type: \"TripleConstraint\",\n    predicate: \"http://hl7.org/fhir/index\",\n    valueExpr: { type: \"NodeConstraint\", datatype: \"http://www.w3.org/2001/XMLSchema#integer\" },\n    min: 0, max: 1 // TODO <- remove max\n  };\n\n  static PARENT_TYPES = ['Resource'];\n  static TODO_ABSTRACT_RESOURCES = ['Base', 'Resource', 'DomainResource', 'CanonicalResource'];\n  static ResourcesThatNeedALink = [\"Reference\"];\n\n  constructor (definitionLoader, config = {}) {\n    super(definitionLoader);\n    this.config = config;\n    if (typeof config.axes === \"undefined\")\n      config.axes = 'RDVch';\n    if (typeof config.axes === \"string\") {\n      if (!config.axes.match(/^rdvch$/i))\n        throw Error(`expected axes string \"${rdvch}\" to match /rdvch/i`);\n      config.axes = Array.from(config.axes).reduce((acc, l) => {\n        acc[l.toLowerCase()] = l === l.toUpperCase();\n        return acc;\n      }, {});\n    }\n    // make a fresh copy of the prototype schema.\n    this.schema = JSON.parse(JSON.stringify(FhirShExJGenerator.EMPTY_FHIR_RESOURCE_SCHEMA));\n    // conjunctions of TripleExpressions to add to current shape.\n    this.teListStack = [];\n    // shift in nested shape on genShape and enter. unshift on exit and when done in genShape.\n    this.shapeStack = [];\n    // list of top-level shape labels added to schema. differs from shapes.map(se => se.id) if nested shapes get top-level entries.\n    this.added = [];\n    // walk StructureDefinition, calling enter, scalar, complex, exit.\n    this.modelGenerator = new FhirRdfModelGenerator(this.definitionLoader, config);\n    // be able to look up TripleConstraints by the PropertyMapping that begat them.\n    this.pMap2TC = new Map();\n    // rdf:Collection type to add\n    this.lists = {};\n    // closure of strurecture definitition baseDefinitions\n    this.extensions = Hierarchy.create();\n  }\n\n  listName (typeName) {\n    return 'OneOrMore_' + typeName;\n  }\n\n  myError (error) {\n    if ('error' in this.config) {\n      this.config.error(error);\n    } else {\n      throw error;\n    }\n  }\n\n  async genShExJ (sources, skip = []) {\n    const generated = await sources.reduce(async (generated1, source) => {\n      return source.entry.reduce(async (last, entry) => {\n        const generated2 = await last;\n        const genMe = entry.resource.id;\n        if (skip.indexOf(genMe) !== -1)\n          return generated2;\n\n        switch (entry.resource.resourceType) {\n          // can optimize by passing entry.resource, but for now, exercise generation by name\n        case \"CodeSystem\":\n        case \"CapabilityStatement\":\n        case \"CompartmentDefinition\":\n        case \"OperationDefinition\":\n          break;\n        case \"ValueSet\": await this.genValueset(entry.resource, this.config); break;\n        case \"StructureDefinition\": await this.genShape(entry.resource, true, this.config); break;\n        default:\n          this.myError(Error(`Unknown resourceType: ${entry.resource.resourceType} for ${entry.fullUrl}`));\n          return generated2;\n        }\n        return generated2.concat(genMe);\n      }, generated1);\n    }, Promise.resolve([]));\n    Array.prototype.push.apply(\n      this.schema.shapes,\n      Object.entries(this.lists)\n        .map(([id, valueExpr]) => ({\n          type: 'Shape',\n          id,\n          expression:\n          { type: \"EachOf\",\n            expressions: [\n              { type: \"TripleConstraint\",\n                predicate: P.rdf + \"first\",\n                valueExpr\n              },\n              { type: \"TripleConstraint\",\n                predicate: P.rdf + \"rest\",\n                valueExpr: {\n                  type: \"ShapeOr\",\n                  shapeExprs: [\n                    { \"type\": \"NodeConstraint\", \"values\": [ P.rdf + \"nil\" ] },\n                    id\n                  ] } }\n            ] }\n        } ) )\n    );\n\n    // < 4.5 FHIR resources-types didn't have a 'Base'\n    // c.f. https://github.com/fhircat/fhir-rdf-playground/issues/10\n    if (!this.schema.shapes.find(se => se.id === P.fhirshex + 'Base'))\n      this.schema.shapes.push({type: 'Shape', id: P.fhirshex + 'Base'});\n\n    this.replaceAbstractClasses(this.config);\n    return this.schema;\n  }\n\n  /**\n   * Generate a Shape for target. This may entail creating nested shapes.\n   * @param resourceDef_id shape label for generates Shape.\n   * @param config control predicates and lists in RDF model.\n   * @returns {FhirShExJGenerator} this.\n   */\n  async genShape (resourceDef, root, generatorConfig = this.config) {\n    const isParent = FhirShExJGenerator.PARENT_TYPES.indexOf(resourceDef.id) === -1;\n    const label = Prefixes.fhirshex + resourceDef.id;\n    if ('baseDefinition' in resourceDef) {\n      if (!resourceDef.baseDefinition.startsWith(GEN_SHEXJ_STEM))\n        throw Error(`Unknown URL stem in ${resourceDef.baseDefinition}, expected ${GEN_SHEXJ_STEM}`);\n      const base = resourceDef.baseDefinition.substr(GEN_SHEXJ_STEM.length);\n      this.extensions.add(base, resourceDef.id);\n    }\n    this.added.push(label);\n    this.pushShape(label, isParent);\n    if (resourceDef.kind === 'resource') {\n      if (isParent) {\n        this.add(this.makeTripleConstraint(\n          Prefixes.rdf + 'type',\n          { \"type\": \"NodeConstraint\", \"values\": [Prefixes.fhir + resourceDef.id] },\n          null));\n        if (root) {\n          this.add(this.makeTripleConstraint(\n            Prefixes.fhir + 'nodeRole',\n            { \"type\": \"NodeConstraint\", \"values\": [\"http://hl7.org/fhir/treeRoot\"] },\n            {min: 0, max: 1}\n          ));\n        }\n      } else {\n        this.add(this.makeTripleConstraint(\n          Prefixes.rdf + 'type',\n          undefined,\n          {min: 1, max: -1}\n        ));\n      }\n    }\n    if (\"addTypesTo\" in this.config && this.config.addTypesTo.indexOf(resourceDef.id) !== -1) {\n      this.add(this.makeTripleConstraint(\n          Prefixes.rdf + 'type',\n          { \"type\": \"NodeConstraint\", \"nodeKind\": 'iri' },\n          {min: 0, max: 1}\n      ));\n    } else if (!this.config.axes.v) {\n      this.add(this.makeTripleConstraint(\n          Prefixes.rdf + 'type',\n          { \"type\": \"NodeConstraint\", \"values\": [Prefixes.fhir + resourceDef.id] },\n          {min: 0, max: 1}\n      ));\n    }\n\n    if (FhirShExJGenerator.ResourcesThatNeedALink.indexOf(resourceDef.id) !== -1) {\n      this.add(this.makeTripleConstraint(\n        Prefixes.fhir + 'link',\n        { \"type\": \"NodeConstraint\", \"nodeKind\": \"iri\" },\n        {min: 0, max: 1}\n      ));\n    }\n    await this.modelGenerator.visitResource(resourceDef, this, generatorConfig);\n    // this.resources._index.entries.forEach(\n    //   entry => { if (this.skip.indexOf(entry)) modelGenerator.visitResource(target, this, generatorConfig); }\n    // );\n    this.popShape(resourceDef.id);\n    return this;\n  }\n\n  enter (propertyMapping) {\n    const shapeName = Prefixes.fhirshex + propertyMapping.element.id;\n    let typeName = propertyMapping.element.id;\n    let valueExpr = Prefixes.fhirshex + typeName;\n    if (this.config.axes.c && propertyMapping.element.max !== \"1\") {\n      valueExpr = Prefixes.fhirshex + this.listName(typeName);\n      this.lists[valueExpr] = Prefixes.fhirshex + typeName;\n    }\n    this.add(this.indexTripleConstraint(\n      propertyMapping,\n      valueExpr,\n      this.makeCard(propertyMapping.element.min, propertyMapping.element.max)\n    ));\n    this.pushShape(shapeName, true); // TODO: would break if nested *inside* a DomainResource.\n  }\n\n  element (propertyMappings) {\n    const valueExprs = propertyMappings.reduce((acc, propertyMapping) => {\n      // Early return if this specializes another.\n      if (propertyMapping.specializes.length > 0) {\n        propertyMapping.specializes.forEach(specializes => {\n          const tc = this.pMap2TC.get(specializes);\n          tc.predicate = propertyMapping.predicate;\n          // TODO: what are the real semantics of specialization?\n        })\n        return acc; // no additional TCs\n      }\n\n      let valueExpr;\n      let annotations = null;\n      if (propertyMapping.isScalar) {\n        valueExpr = Object.assign({}, propertyMapping.type); // e.g. http://www.w3.org/2001/XMLSchema#string\"\n        // TODO: by luck, there are (so far) no scalars with propertyMapping.element.max !== \"1\"\n        if (\"annotations\" in valueExpr) {\n          annotations = valueExpr.annotations;\n          delete valueExpr.annotations;\n        }\n      } else {\n        let typeName = propertyMapping.type;\n        valueExpr = Prefixes.fhirshex + typeName;\n        if (propertyMapping.binding && propertyMapping.binding.strength === 'required') {\n          const bindingMap = FhirShExJGenerator.BindingMaps.find(\n            bindingMap => propertyMapping.binding.valueSet.startsWith(bindingMap.fhirStem)\n          );\n          if (!bindingMap)\n            throw Error(`Don't know anything about binding ${propertyMapping.binding}`);\n          const valueSetSpec = bindingMap.shexStem +\n                propertyMapping.binding.valueSet.substr(bindingMap.fhirStem.length);\n          const [valueSet, version] = valueSetSpec.split(/\\|/);\n          typeName = typeName + '_AND_' + valueSet;\n          const annotations = this.config.addValueSetVersionAnnotation && version\n                ? {\n                  \"annotations\": [{\n                    \"type\": \"Annotation\",\n                    \"predicate\": \"http://hl7.org/fhir/version\",\n                    \"object\": {\"value\": version}\n                  }]\n                }\n                : {};\n          if (this.config.axes.h) {\n            valueExpr = {\n              type: \"ShapeAnd\",\n              shapeExprs: [valueExpr, Prefixes.fhirvs + valueSet]\n              // TODO: does not pass annotation into triple constraint\n            };\n          } else {\n            const expression = Object.assign(\n              {\n                type: \"TripleConstraint\",\n                predicate: Prefixes.fhir + 'v',\n                valueExpr: Prefixes.fhirvs + valueSet\n              },\n              annotations\n            );\n            valueExpr = {\n              type: \"ShapeAnd\",\n              shapeExprs: [valueExpr, {type: \"Shape\", expression}]\n            };\n          }\n        }\n        if (this.config.axes.c && propertyMapping.element.max !== \"1\") {\n          typeName = this.listName(typeName);\n          this.lists[Prefixes.fhirshex + typeName] = valueExpr;\n          valueExpr = Prefixes.fhirshex + typeName;\n        }\n      }\n      return acc.concat([this.indexTripleConstraint(\n        propertyMapping,\n        valueExpr,\n        null,\n        annotations\n      )]);\n    }, []);\n\n    if (valueExprs.length > 0) { // 0 if specializing an earlier element\n      if (this.config.axes.v) {\n        const teDisjuncts = Object.assign(\n          valueExprs.length > 1\n            ? {\n              type: \"OneOf\",\n              expressions: valueExprs\n            }\n          : valueExprs[0],\n          this.makeCard(propertyMappings[0].element.min, propertyMappings[0].element.max)\n        );\n        this.add(teDisjuncts); // e.g. MedicationRequest.dose.dosageInstruction\n      } else {\n        const seDisjuncts =\n              valueExprs.length > 1\n              ? {\n                type: \"ShapeOr\",\n                shapeExprs: valueExprs.map(ve => ve.valueExpr)\n              }\n              : valueExprs[0].valueExpr\n        const tc = Object.assign(\n          {\n            type: \"TripleConstraint\",\n            predicate: valueExprs[0].predicate, // if !axes.v, all predicates will be the same\n            valueExpr: seDisjuncts\n          },\n          this.makeCard(propertyMappings[0].element.min, propertyMappings[0].element.max)\n        );\n        this.add(tc);\n      }\n    }\n  }\n\n  exit (propertyMapping) {\n    this.popShape(propertyMapping.type);\n  }\n\n  pushShape (name, isClosed) {\n    const newShape = Object.assign({\n      type: \"Shape\",\n      id: name,\n    }, isClosed\n    ? {  closed: true }\n    : {}\n    );\n    this.teListStack.unshift([]);\n    this.schema.shapes.push(newShape);\n    this.shapeStack.push(newShape);\n  }\n\n  popShape (name) {\n    const teList = this.teListStack.shift();\n    if (teList.length === 0 && name !== \"Base\")\n      throw new Error(`Unexpected 0-length TE list when serializing ${name}?`);\n    if (!this.config.axes.c && FhirShExJGenerator.PARENT_TYPES.indexOf(name) === -1) {\n      teList.push(FhirShExJGenerator.INDEX);\n    }\n    this.shapeStack.pop().expression = teList.length === 1\n      ? teList[0]\n      : {\n        type: \"EachOf\",\n        expressions: teList\n      };\n  }\n\n  makeCard(minP, maxP) {\n    const min = minP === undefined ? 1 : minP;\n    const max = maxP === undefined\n        ? 1\n        : maxP === '*'\n        ? -1\n        : parseInt(maxP);\n    return min === 1 && max === 1\n        ? {}\n        : {min, max};\n  }\n\n  indexTripleConstraint(propertyMapping, valueExpr, cardObj = {}, annotations = null) {\n    const ret = this.makeTripleConstraint(propertyMapping.predicate, valueExpr, cardObj, annotations);\n    this.pMap2TC.set(propertyMapping, ret);\n    return ret;\n  }\n\n  makeTripleConstraint(predicate, valueExpr, cardObj = {}, annotations) {\n    return Object.assign({\n      type: \"TripleConstraint\",\n      predicate: predicate,\n    },\n        valueExpr ?\n            { valueExpr: valueExpr }\n            : {},\n        cardObj,\n        annotations\n            ? { annotations}\n            : {});\n  }\n\n  add(te) {\n    this.teListStack[0].push(te)\n  }\n\n  /**\n   * Generate a NodeConstraint for target, pulling values from FHIR valuesets and ConceptMaps.\n   * @param target shape label for generated NodeConstraint.\n   * @param config control predicates and lists in RDF model.\n   * @returns {FhirShExJGenerator}\n   */\n  async genValueset (resourceDef, generatorConfig = this.config) {\n    const label = Prefixes.fhirvs + resourceDef.id;\n    if (\"baseDefinition\" in resourceDef && !(resourceDef.baseDefinition.startsWith(FhirRdfModelGenerator.STRUCTURE_DEFN_ROOT))) {\n      this.myError(Error(`Don't know where to look for base structure ${resourceDef.baseDefinition}`));\n      return this;\n    }\n\n    if (\"baseDefinition\" in resourceDef) {\n      const recursionTarget = resourceDef.baseDefinition.substr(FhirRdfModelGenerator.STRUCTURE_DEFN_ROOT.length);\n      await this.visitElement(recursionTarget, visitor, generatorConfig); // Get content model from base type\n    }\n\n    // added empty default because https://build.fhir.org/valueset-device-operational-state-mode.html has no expansion as of 2022-05-04\n    const values = await this.parseCompose(resourceDef.compose || {include:[]});\n    let nodeConstraint = {\n      type: \"NodeConstraint\",\n      id: label\n    };\n    if (values.length > 0) {\n      nodeConstraint.values = values;\n    }\n    this.schema.shapes.push(nodeConstraint);\n    this.added.push(resourceDef.id);\n    return this;\n  }\n\n  async parseCompose (compose) {\n    return await compose.include.reduce(async (accP, i) => {\n      let acc = await accP;\n      if (\"system\" in i) {\n        const cs = await this.definitionLoader.getCodesystemByUrl(i.system);\n        if (cs !== undefined) {\n          if (\"concept\" in cs) {\n            acc = acc.concat(this.parseConcept(cs.concept));\n          }\n          if (\"property\" in cs) {\n            acc = acc.concat(this.parseConcept(cs.property));\n          }\n        } else {\n          this.missing(\"codesystems\", i.system);\n        }\n      }\n      return (\"concept\" in i)\n        ? acc.concat(i.concept.map(c => ({value: c.code})))\n        : acc;\n    }, Promise.resolve([]))\n  }\n\n  missing (type, missing) {\n    if (\"missing\" in this.config) {\n      if (!(type in this.config.missing)) {\n        this.config.missing[type] = new Set();\n      }\n      this.config.missing[type].add(missing);\n    } else {\n      const msg = `can't find definition for ${type} ${missing}`;\n      if (this.config.log) {\n        console.log(msg);\n      } else {\n        this.myError(Error(msg));\n      }\n    }\n  }\n\n  parseConcept (concept) {\n    return concept.reduce((acc, c) => {\n      if (\"code\" in c) {\n        acc = acc.concat([{value: c.code}]);\n      }\n      if (\"concept\" in c) {\n        acc = acc.concat(this.parseConcept(c.concept));\n      }\n      return acc;\n    }, [])\n  }\n\n  /**\n   *\n   * @param label shape label for generated NodeConstraint.\n   * @param config control predicates and lists in RDF model.\n   * @returns {FhirShExJGenerator}\n   */\n  replaceAbstractClasses (generatorConfig = this.config) {\n    const extended = ['Resource']\n          .concat(this.extensions.children['Resource'].filter(\n            p => this.extensions.children[p].length > 0\n          ));\n\n    extended.forEach(p => {\n      const id = P.fhirshex + p; // the name of this shape\n\n      // Replace id in schema.shapes with a ShapeOr of its (unextended) children.\n      const replaceMe = this.schema.shapes.find(se => se.id === id);\n      if (!replaceMe)\n        throw Error(`did not find ${id} in \\n  ${this.schema.shapes.map(se => se.id).join('\\n  ')}`);\n\n      const children = (this.extensions.children[p] || []) // all children on e\n            .filter(c => this.extensions.children[c].length === 0); // that weren't also extended\n\n      const shapeExprs = children.map(c => ({\n          type: \"ShapeOr\",\n          shapeExprs: [\n            { type: \"ShapeNot\",\n              shapeExpr: {\n                type: \"Shape\",\n                expression: {\n                  type: \"EachOf\",\n                  expressions: [\n                    { type: \"TripleConstraint\",\n                      predicate: P.fhirshex + \"nodeRole\",\n                      valueExpr: {\n                        type: \"NodeConstraint\",\n                        values: [ P.fhirshex + \"treeRoot\" ] }\n                    },\n                    { type: \"TripleConstraint\",\n                      predicate: P.rdf + \"type\",\n                      valueExpr: {\n                        type: \"NodeConstraint\",\n                        values: [ P.fhirshex + c ] }\n                  } ]\n            } } },\n            P.fhirshex + c\n          ]\n      }) );\n\n      // Replace replaceMe in schema.shapes.\n      const replaceIdx = this.schema.shapes.indexOf(replaceMe);\n      this.schema.shapes[replaceIdx] = { id, type: \"ShapeOr\", shapeExprs };\n    } )\n    this.schema[\"@context\"] = \"http://www.w3.org/ns/shex.jsonld\";\n    return this;\n  }\n\n  /**\n   * Create a copy of `schema` with ShapeExpressions nested in place of their references.\n   * @param schema an input ShapeExpressions schema\n   * @returns {schema} nested copy of schema\n   */\n  static nestShapes (schema) {\n    const index = schema._index || ShExUtil.index(schema);\n\n    // Create a visitor to count references to labeled (i.e. appearing in schema.shapes) ShapeExpressions.\n    const seFinder = ShExUtil.Visitor();\n\n    let refCounts = {}\n\n    seFinder.visitShapeRef = function (reference) {\n      if (!(reference in refCounts)) { refCounts[reference] = 0; }\n      refCounts[reference]++;\n      return reference;\n    }\n\n    seFinder.visitSchema(schema) // Throw away the copy this created. We only want the ref counts.\n\n    // Create another visitor to make a nested copy of schema.\n    const seRenamer = ShExUtil.Visitor()\n\n    // We want to nest this ShapeExpression if:\n    function nestTest (shapeExprLabel) {\n      return refCounts[shapeExprLabel] === 1 &&                // it has a ref count == 1, AND\n          shapeExprLabel.startsWith(P.fhirshex) &&             // it is a FHIR shape (probably unnecessary in the FHIR schema), AND\n          shapeExprLabel.substr(P.fhirshex.length).indexOf('.') !== -1 // it has a '.' in the name (our naming convention for nested shape).\n    }\n\n    seRenamer.visitShapeRef = function (reference) {\n      return nestTest(reference)                               // If this reference is a candidate for nesting,\n          ? seRenamer.visitShapeExpr(index.shapeExprs[reference]) // add (a copy of) it from the initial schema,\n          : reference                                          // otherwise keep a reference to it.\n    }\n\n    seRenamer.visitShapes = function (shapes) {\n      return shapes.reduce(\n          (acc, shapeExpr) => nestTest(shapeExpr.id)             // If this id is a candidate for nesting,\n              ? acc                                                // don't add it to the outer shapes,\n              : acc.concat([seRenamer.visitShapeExpr(shapeExpr)]), // otherwise add (a copy of) it.\n          []\n      )\n    }\n\n    return seRenamer.visitSchema(schema)\n  }\n};\n\nif (true)\n  module.exports = FhirShExJGenerator;\n\n\n//# sourceURL=webpack://playground/../fhirlib/FhirShExJGenerator.js?");

/***/ }),

/***/ "../fhirlib/FhirTurtleSerializer.js":
/*!******************************************!*\
  !*** ../fhirlib/FhirTurtleSerializer.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/**\n *\n */\nconst {PropertyMapping} = __webpack_require__(/*! ./FhirRdfModelGenerator */ \"../fhirlib/FhirRdfModelGenerator.js\");\nconst EvalSimple1err = __webpack_require__(/*! @shexjs/eval-simple-1err */ \"../fhirlib/node_modules/@shexjs/eval-simple-1err/eval-simple-1err.js\");\nconst P = __webpack_require__(/*! ./Prefixes */ \"../fhirlib/Prefixes.js\");\n\nconst N3Store = (__webpack_require__(/*! n3/lib/N3Store */ \"../fhirlib/node_modules/n3/lib/N3Store.js\")[\"default\"]);\nconst N3DataFactory = (__webpack_require__(/*! n3/lib/N3DataFactory */ \"../fhirlib/node_modules/n3/lib/N3DataFactory.js\")[\"default\"]);\nconst ShExUtil = __webpack_require__(/*! @shexjs/util */ \"../fhirlib/node_modules/@shexjs/util/shex-util.js\");\nconst ShExValidator = __webpack_require__(/*! @shexjs/validator */ \"../fhirlib/node_modules/@shexjs/validator/shex-validator.js\");\n\nclass Serializer {\n  store = null;\n\n  constructor(schema) {\n    this.schema = schema;\n  }\n\n  addResource(resource, printer, config, rest = new N3Store()) {\n    const rootTriple = this.expectOne(resource.store.getQuads(null, P.fhir + 'nodeRole', P.fhir + 'treeRoot'), 'nodeRole treeRoot');\n    const node = rootTriple.subject;\n    const typeTriple = this.expectOne(resource.store.getQuads(node, P.rdf + 'type', null), 'fhir type');\n    const type = this.expectFhirResource(typeTriple.object);\n    // printer.addQuads([typeTriple, rootTriple]);\n\n    const shape = P.fhirshex + type;\n    const db = ShExUtil.rdfjsDB(resource.store, null); // no query tracker needed\n    const validator = ShExValidator.construct(this.schema, db, {\n      regexModule: EvalSimple1err\n    });\n    const res = validator.validate([{node, shape}]);\n    // if (process.env.DEBUG) { console.log('validation res: ' + JSON.stringify(res, null, 2)) };\n\n    // Test for .solution because `<S> .` or `<S> {}` will pass with no solutions.\n    // This is analogous to testing for `(\"referenced\" in s)` in a TestedTriple.\n    if (!(\"solution\" in res))\n      throw res;\n    const matched = [];\n    const seen = new N3Store(); // use N3Store to de-duplicate quads that were validated multiple ways.\n    const matchedDb = {\n      addQuad: function (q) {\n        if (!seen.countQuads(q.subject, q.predicate, q.object, q.graph)) {\n          seen.addQuad(q);\n          matched.push(q);\n        }\n      }\n    }\n    ShExUtil.getProofGraph(res, matchedDb, N3DataFactory);\n    if (rest) {\n      rest.addQuads(resource.store.getQuads()); // the resource giveth\n      matched.forEach(q => rest.removeQuad(q)); // the matched taketh away\n    }\n\n    printer.addQuads(matched.filter(q => (['first', 'rest']).map(l => P.rdf + l).indexOf(q.predicate.value) === -1));\n    return this;\n  }\n\n  addRest(restDb, printer, config, comment = \"\\n# remaining triples:\") {\n    if (restDb.size > 0) {\n      printer.comment(comment);\n      printer.addQuads(restDb.getQuads());\n    }\n  }\n\n  expectOne(oneQuad, description) {\n    if (oneQuad.length !== 1) {\n      throw new Error(`Expected 1, got ${oneQuad.length} matches for ${description}`);\n    }\n    // this.store.removeQuads(oneQuad);\n    return oneQuad[0];\n  }\n\n  expectFhirResource(node) {\n    // if (node.id.startsWith())\n    return node.id.substr(P.fhir.length);\n  }\n}\n\nif (true)\n  module.exports = {Serializer};\n\n\n//# sourceURL=webpack://playground/../fhirlib/FhirTurtleSerializer.js?");

/***/ }),

/***/ "../fhirlib/NestedWriter.js":
/*!**********************************!*\
  !*** ../fhirlib/NestedWriter.js ***!
  \**********************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/**\n * options: {\n *   indent: '    ',\n *   checkCorefs: n => false, // meaning \"trust me, it's a tree\"\n * }\n */\n\n// **N3Writer** writes N3 documents.\nconst namespaces = (__webpack_require__(/*! n3/lib/IRIs */ \"../fhirlib/node_modules/n3/lib/IRIs.js\")[\"default\"]);\nconst N3Fac = __webpack_require__(/*! n3/lib/N3DataFactory */ \"../fhirlib/node_modules/n3/lib/N3DataFactory.js\");\nconst { Term } = N3Fac;\nconst N3DataFactory = N3Fac.default;\nconst { isDefaultGraph } = __webpack_require__(/*! n3/lib/N3Util */ \"../fhirlib/node_modules/n3/lib/N3Util.js\");\n\nconst DEFAULTGRAPH = N3DataFactory.defaultGraph();\n\nconst { rdf, xsd } = namespaces;\n\n// Characters in literals that require escaping\nconst escape    = /[\"\\\\\\t\\n\\r\\b\\f\\u0000-\\u0019\\ud800-\\udbff]/,\n    escapeAll = /[\"\\\\\\t\\n\\r\\b\\f\\u0000-\\u0019]|[\\ud800-\\udbff][\\udc00-\\udfff]/g,\n    escapedCharacters = {\n      '\\\\': '\\\\\\\\', '\"': '\\\\\"', '\\t': '\\\\t',\n      '\\n': '\\\\n', '\\r': '\\\\r', '\\b': '\\\\b', '\\f': '\\\\f',\n    };\nconst rdf10LocalName = `[a-zA-Z][\\\\-_a-zA-Z0-9]*`;\nconst rdf11LocalName = `[a-zA-Z0-9][\\\\-_a-zA-Z0-9.]*`;\n\n// ## Placeholder class to represent already pretty-printed terms\nclass SerializedTerm extends Term {\n  // Pretty-printed nodes are not equal to any other node\n  // (e.g., [] does not equal [])\n  equals() {\n    return false;\n  }\n}\n\nconst INDENT = '  ';\n\nclass Nesting {\n  constructor (stream, indent, subject, predicate) {\n    if (this.constructor === Nesting)\n      throw new TypeError(`Cannot construct ${new.target.name} instances directly`);\n    const missing = (['close']).filter(m => this[m] === Nesting.prototype[m]);\n    if (missing.length)\n      throw new TypeError(`${new.target.name} missing methods: ${missing.join(', ')}`);\n\n    this._stream = stream;\n    this._indent = indent;\n    this._subject = subject;\n    this._predicate = predicate; // gets updated by _writeQuad()\n  }\n\n  close (done) { this._abstract('close'); }\n\n  _abstract (method) { throw new TypeError(`${this.constructor.name}.${method} not implemented`); }\n}\n\nclass Root extends Nesting {\n  constructor (stream, subject, predicate) { super(stream, '  ', subject, predicate); }\n  close (done) {\n    if (this.used) {\n      this._stream._write('.\\n', done);\n      this.used = false;\n    }\n  }\n}\n\nclass BNode extends Nesting {\n  constructor (stream, indent, node) { super(stream, indent, node, null); }\n  close (done, p) {\n    this._stream._write((this.used ? `\\n${p._indent}` : '') + ']', done);\n  }\n}\n\nclass Collection extends Nesting {\n  constructor (stream, indent, members) {\n    super(stream, indent, null, null);\n    this._members = members;\n    this.leadSpace = false;\n  }\n  close (done, p) {\n    this._stream._write(`\\n${p._indent})`, done);\n  }\n}\n\n\n// ## Constructor\nclass Writer {\n  constructor(outputStream, options) {\n    // ### `_prefixRegex` matches a prefixed name or IRI that begins with one of the added prefixes\n    this._prefixRegex = /$0^/;\n\n    // Shift arguments if the first argument is not a stream\n    if (outputStream && typeof outputStream.write !== 'function')\n      options = outputStream, outputStream = null;\n    options = options || {};\n    this._lists = options.lists;\n    this._indent = options.indent || '  ';\n    this._checkCorefs = options.checkCorefs || (n => false); // if unsupplied; assume a tree\n    this._version = options.version || 1.0;\n    this._localName = this._version === 1.0\n        ? rdf10LocalName\n        : rdf11LocalName;\n\n    // If no output stream given, send the output as string through the end callback\n    if (!outputStream) {\n      let output = '';\n      this._outputStream = {\n        write(chunk, encoding, done) { if (options.debug) { console.log({chunk, output}); } output += chunk; done && done(); },\n        end: done => { done && done(null, output); },\n      };\n      this._endStream = true;\n    }\n    else {\n      this._outputStream = outputStream;\n      this._endStream = options.end === undefined ? true : !!options.end;\n    }\n\n    // Initialize writer, depending on the format\n    this._nestings = [new Root(this, null, null)];\n    if (!(/triple|quad/i).test(options.format)) {\n      this._lineMode = false;\n      this._graph = DEFAULTGRAPH;\n      this._baseIRI = options.baseIRI;\n      this._prefixIRIs = Object.create(null);\n      options.prefixes && this.addPrefixes(options.prefixes);\n    }\n    else {\n      this._lineMode = true;\n      this._writeQuad = this._writeQuadLine;\n    }\n  }\n\n  // ## Private methods\n\n  // ### Whether the current graph is the default graph\n  get _inDefaultGraph() {\n    return DEFAULTGRAPH.equals(this._graph);\n  }\n\n\n  // ### `_write` writes the argument to the output stream\n  _write(string, callback) {\n    this._outputStream.write(string, 'utf8', callback);\n  }\n\n  // ### `_writeQuad` writes the quad to the output stream\n  _writeQuad(subject, predicate, object, graph, done) {\n    try {\n      // Write the graph's label if it has changed\n      if (!graph.equals(this._graph)) {\n        // Close the previous graph and start the new one\n        this._getNestingForSubject(DEFAULTGRAPH); // TODO: should be fresh bnode or null-ish thingy\n        this._write((this._nestings.length === 1 ? '' : (this._inDefaultGraph ? '.\\n' : '\\n}\\n')) +\n                    (DEFAULTGRAPH.equals(graph) ? '' : `${this._encodeIriOrBlank(graph)} {\\n`));\n        this._graph = graph;\n      }\n\n      const oldLength = this._nestings.length;\n      let [nesting, matched] = this._getNestingForSubject(subject);\n\n      let objectStr;\n      if (this._lists && (object.value in this._lists)) {\n        objectStr = '(';\n        this._nestings.push(new Collection(this, nesting._indent + INDENT, this._lists[object.value]));\n      } else if (object.termType === 'BlankNode'\n          && this._checkCorefs\n          && !this._checkCorefs(object)) {\n        objectStr = '[';\n        this._nestings.push(new BNode(this, nesting._indent + INDENT, object));\n      } else {\n        objectStr = this._encodeObject(object);\n      }\n\n      // Don't repeat the subject if it's the same\n      if (matched) {\n        // Don't repeat the predicate if it's the same\n        if (predicate.equals(nesting.predicate)) {\n          this._write(`, ${objectStr}`, done);\n          // Same subject, different predicate\n        } else {\n          this._write(`${nesting.used ? ';' : ''}\\n${nesting._indent}${\n              this._encodePredicate(nesting.predicate = predicate)} ${\n              objectStr}`, done);\n        }\n      }\n      // Different subject; write the whole quad\n      else {\n        nesting._subject = subject; nesting._predicate = predicate;\n        this._write(`${\n                    this._encodeSubject(subject)} ${\n                    this._encodePredicate(predicate)} ${\n                    objectStr}`, done);\n      }\n      nesting.used = true;\n    }\n    catch (error) { if (done) done(error); else throw error;  }\n  }\n\n  /*\n    closes BNodes and iterates and closes Collections until finding subject.\n   */\n  _getNestingForSubject (subject) {\n    let nesting = this._nestings.length > 0\n        ? this._nestings[this._nestings.length - 1]\n        : null;\n\n    while (nesting && !subject.equals(nesting._subject)) {\n\n      if (nesting instanceof Collection) {\n\n        const leadSpace = nesting.leadSpace ? ' ' : '';\n        if (nesting._subject) {\n          this._write(`${leadSpace}${this._encodeObject(nesting._subject)}`);\n          nesting._subject = null; // don't serialize again if e.g. returning from nested list\n          nesting.leadSpace = true;\n        }\n        if (nesting._members.length === 0) {\n          nesting = this._closeNesting();\n        } else {\n          const li = nesting._members.shift();\n          if (li.value in this._lists) {\n            // list in a list\n            this._write(`${leadSpace}(`)\n            this._nestings.push(nesting = new Collection(this, nesting._indent + INDENT, this._lists[li.value]));\n            nesting.leadSpace = false;\n          } else {\n            // any other element in the list\n            if (li.equals(subject)) {\n              this._write(\"\\n\" + nesting._indent + '[');\n              nesting._subject = null;\n              this._nestings.push(nesting = new BNode(this, nesting._indent + INDENT, subject));\n              nesting.leadSpace = false;\n            } else {\n              nesting._subject = li;\n            }\n          }\n        }\n      } else if (nesting instanceof BNode) {\n        nesting = this._closeNesting();\n      } else {\n        nesting.close();\n        return [nesting, false]; // didn't match subject\n      }\n    }\n    return [nesting, subject.equals(nesting._subject)]; // hard code true?\n\n  }\n\n  _closeNesting () {\n    const nesting = this._nestings.pop();\n    const ret = this._nestings[this._nestings.length - 1];\n    nesting.close(null, ret);\n    return ret;\n  }\n\n  _finish() {\n    const oldLength = this._nestings.length;\n    this._getNestingForSubject(DEFAULTGRAPH); // TODO: should be fresh bnode or null-ish thingy\n    if (oldLength !== 1) {\n      if (this._inDefaultGraph) {\n      } else {\n        this._write('\\n}\\n');\n      }\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n  // ### `_writeQuadLine` writes the quad to the output stream as a single line\n  _writeQuadLine(subject, predicate, object, graph, done) {\n    // Write the quad without prefixes\n    delete this._prefixMatch;\n    this._write(this.quadToString(subject, predicate, object, graph), done);\n  }\n\n  // ### `quadToString` serializes a quad as a string\n  quadToString(subject, predicate, object, graph) {\n    const ret =  `${this._encodeSubject(subject)} ${\n            this._encodeIriOrBlank(predicate)} ${\n            this._encodeObject(object)\n            }${graph && graph.value ? ` ${this._encodeIriOrBlank(graph)} .\\n` : ' .\\n'}`;\n    return ret;\n  }\n\n  // ### `quadsToString` serializes an array of quads as a string\n  quadsToString(quads) {\n    return quads.map(t => {\n      return this.quadToString(t.subject, t.predicate, t.object, t.graph);\n    }).join('');\n  }\n\n  // ### `_encodeSubject` represents a subject\n  _encodeSubject(entity) {\n    return entity.termType === 'Quad' ?\n      this._encodeQuad(entity) : this._encodeIriOrBlank(entity);\n  }\n\n  // ### `_encodeIriOrBlank` represents an IRI or blank node\n  _encodeIriOrBlank(entity) {\n    // A blank node or list is represented as-is\n    if (entity.termType !== 'NamedNode') {\n      // If it is a list head, pretty-print it\n      return 'id' in entity ? entity.id : `_:${entity.value}`;\n    }\n    let iri = entity.value;\n    // Use relative IRIs if requested and possible\n    if (this._baseIRI && iri.startsWith(this._baseIRI))\n      iri = iri.substr(this._baseIRI.length);\n    // Escape special characters\n    if (escape.test(iri))\n      iri = iri.replace(escapeAll, characterReplacer);\n    // Try to represent the IRI as prefixed name\n    const prefixMatch = this._prefixRegex.exec(iri);\n    return !prefixMatch ? `<${iri}>` :\n           (!prefixMatch[1] ? iri : this._prefixIRIs[prefixMatch[1]] + prefixMatch[2]);\n  }\n\n  // ### `_encodeLiteral` represents a literal\n  _encodeLiteral(literal) {\n    // Escape special characters\n    let value = literal.value;\n    if (escape.test(value))\n      value = value.replace(escapeAll, characterReplacer);\n\n    // Write a language-tagged literal\n    if (literal.language)\n      return `\"${value}\"@${literal.language}`;\n\n    // Write dedicated literals per data type\n    if (this._lineMode) {\n      // Only abbreviate strings in N-Triples or N-Quads\n      if (literal.datatype.value === xsd.string)\n        return `\"${value}\"`;\n    }\n    else {\n      // Use common datatype abbreviations in Turtle or TriG\n      switch (literal.datatype.value) {\n      case xsd.string:\n        return `\"${value}\"`;\n      case xsd.boolean:\n        if (value === 'true' || value === 'false')\n          return value;\n        break;\n      case xsd.integer:\n        if (/^[+-]?\\d+$/.test(value))\n          return value;\n        break;\n      case xsd.decimal:\n        if (/^[+-]?\\d*\\.\\d+$/.test(value))\n          return value;\n        break;\n      case xsd.double:\n        if (/^[+-]?(?:\\d+\\.\\d*|\\.?\\d+)[eE][+-]?\\d+$/.test(value))\n          return value;\n        break;\n      }\n    }\n\n    // Write a regular datatyped literal\n    return `\"${value}\"^^${this._encodeIriOrBlank(literal.datatype)}`;\n  }\n\n  // ### `_encodePredicate` represents a predicate\n  _encodePredicate(predicate) {\n    return predicate.value === rdf.type ? 'a' : this._encodeIriOrBlank(predicate);\n  }\n\n  // ### `_encodeObject` represents an object\n  _encodeObject(object) {\n    switch (object.termType) {\n    case 'Quad':\n      return this._encodeQuad(object);\n    case 'Literal':\n      return this._encodeLiteral(object);\n    default:\n      return this._encodeIriOrBlank(object);\n    }\n  }\n\n  // ### `_encodeQuad` encodes an RDF* quad\n  _encodeQuad({ subject, predicate, object, graph }) {\n    return `<<${\n      this._encodeSubject(subject)} ${\n      this._encodePredicate(predicate)} ${\n      this._encodeObject(object)}${\n      isDefaultGraph(graph) ? '' : ` ${this._encodeIriOrBlank(graph)}`}>>`;\n  }\n\n  // ### `_blockedWrite` replaces `_write` after the writer has been closed\n  _blockedWrite() {\n    throw new Error('Cannot write because the writer has been closed.');\n  }\n\n  // ### `addQuad` adds the quad to the output stream\n  addQuad(subject, predicate, object, graph, done) {\n    // The quad was given as an object, so shift parameters\n    if (object === undefined)\n      this._writeQuad(subject.subject, subject.predicate, subject.object, subject.graph, predicate);\n    // The optional `graph` parameter was not provided\n    else if (typeof graph === 'function')\n      this._writeQuad(subject, predicate, object, DEFAULTGRAPH, graph);\n    // The `graph` parameter was provided\n    else\n      this._writeQuad(subject, predicate, object, graph || DEFAULTGRAPH, done);\n  }\n\n  // ### `addQuads` adds the quads to the output stream\n  addQuads(quads) {\n    for (let i = 0; i < quads.length; i++)\n      this.addQuad(quads[i]);\n  }\n\n  // ### `addPrefix` adds the prefix to the output stream\n  addPrefix(prefix, iri, done) {\n    const prefixes = {};\n    prefixes[prefix] = iri;\n    this.addPrefixes(prefixes, done);\n  }\n\n  // ### `addPrefixes` adds the prefixes to the output stream\n  addPrefixes(prefixes, done) {\n    // Ignore prefixes if not supported by the serialization\n    if (!this._prefixIRIs)\n      return done && done();\n\n    // Write all new prefixes\n    let hasPrefixes = false;\n    for (let prefix in prefixes) {\n      let iri = prefixes[prefix];\n      if (typeof iri !== 'string')\n        iri = iri.value;\n      hasPrefixes = true;\n      // Finish a possible pending quad\n      if (this._finish())\n        this._graph = '';\n      // Store and write the prefix\n      this._prefixIRIs[iri] = (prefix += ':');\n      if (this._version > 1) {\n        this._write(`PREFIX ${prefix} <${iri}>\\n`);\n      } else {\n        this._write(`@prefix ${prefix} <${iri}>.\\n`);\n      }\n    }\n    // Recreate the prefix matcher\n    if (hasPrefixes) {\n      let IRIlist = '', prefixList = '';\n      for (const prefixIRI in this._prefixIRIs) {\n        IRIlist += IRIlist ? `|${prefixIRI}` : prefixIRI;\n        prefixList += (prefixList ? '|' : '') + this._prefixIRIs[prefixIRI];\n      }\n      IRIlist = IRIlist.replace(/[\\]\\/\\(\\)\\*\\+\\?\\.\\\\\\$]/g, '\\\\$&');\n      this._prefixRegex = new RegExp(`^(?:${prefixList})[^\\/]*$|` +\n                                     `^(${IRIlist})(${this._localName})$`);\n    }\n    // End a prefix block with a newline\n    this._write(hasPrefixes ? '\\n' : '', done);\n  }\n\n  // ### `blank` creates a blank node with the given content\n  blank(predicate, object) {\n    let children = predicate, child, length;\n    // Empty blank node\n    if (predicate === undefined)\n      children = [];\n    // Blank node passed as blank(Term(\"predicate\"), Term(\"object\"))\n    else if (predicate.termType)\n      children = [{ predicate: predicate, object: object }];\n    // Blank node passed as blank({ predicate: predicate, object: object })\n    else if (!('length' in predicate))\n      children = [predicate];\n\n    switch (length = children.length) {\n    // Generate an empty blank node\n    case 0:\n      return new SerializedTerm('[]');\n    // Generate a non-nested one-triple blank node\n    case 1:\n      child = children[0];\n      if (!(child.object instanceof SerializedTerm))\n        return new SerializedTerm(`[ ${this._encodePredicate(child.predicate)} ${\n                                  this._encodeObject(child.object)} ]`);\n    // Generate a multi-triple or nested blank node\n    default:\n      let contents = '[';\n      // Write all triples in order\n      for (let i = 0; i < length; i++) {\n        child = children[i];\n        // Write only the object is the predicate is the same as the previous\n        if (child.predicate.equals(predicate))\n          contents += `, ${this._encodeObject(child.object)}`;\n        // Otherwise, write the predicate and the object\n        else {\n          contents += `${(i ? ';\\n  ' : '\\n  ') +\n                      this._encodePredicate(child.predicate)} ${\n                      this._encodeObject(child.object)}`;\n          predicate = child.predicate;\n        }\n      }\n      return new SerializedTerm(`${contents}\\n]`);\n    }\n  }\n\n  // ### `list` creates a list node with the given content\n  list(elements) {\n    const length = elements && elements.length || 0, contents = new Array(length);\n    for (let i = 0; i < length; i++)\n      contents[i] = this._encodeObject(elements[i]);\n    return new SerializedTerm(`(${contents.join(' ')})`);\n  }\n\n  // ### `end` signals the end of the output stream\n  comment(text) {\n    // Finish a possible pending quad\n    this._finish();\n    this._write(text + \"\\n\");\n  }\n\n  // ### `end` signals the end of the output stream\n  end(done) {\n    // Finish a possible pending quad\n    this._finish();\n    // Disallow further writing\n    this._write = this._blockedWrite;\n\n    // Try to end the underlying stream, ensuring done is called exactly one time\n    let singleDone = done && ((error, result) => { singleDone = null, done(error, result); });\n    if (this._endStream) {\n      try { return this._outputStream.end(singleDone); }\n      catch (error) { /* error closing stream */ }\n    }\n    singleDone && singleDone();\n  }\n}\n\n// Replaces a character by its escaped version\nfunction characterReplacer(character) {\n  // Replace a single character by its escaped version\n  let result = escapedCharacters[character];\n  if (result === undefined) {\n    // Replace a single character with its 4-bit unicode escape sequence\n    if (character.length === 1) {\n      result = character.charCodeAt(0).toString(16);\n      result = '\\\\u0000'.substr(0, 6 - result.length) + result;\n    }\n    // Replace a surrogate pair with its 8-bit unicode escape sequence\n    else {\n      result = ((character.charCodeAt(0) - 0xD800) * 0x400 +\n                 character.charCodeAt(1) + 0x2400).toString(16);\n      result = '\\\\U00000000'.substr(0, 10 - result.length) + result;\n    }\n  }\n  return result;\n}\n\nif (true)\n  module.exports = {Writer};\n\n\n//# sourceURL=webpack://playground/../fhirlib/NestedWriter.js?");

/***/ }),

/***/ "../fhirlib/Prefixes.js":
/*!******************************!*\
  !*** ../fhirlib/Prefixes.js ***!
  \******************************/
/***/ ((module) => {

eval("Prefixes = {\n  'rdf': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n  'fhir': 'http://hl7.org/fhir/',\n  'shex': 'http://www.w3.org/ns/shex#',\n  'xsd': 'http://www.w3.org/2001/XMLSchema#',\n  'rdfs': 'http://www.w3.org/2000/01/rdf-schema#',\n  'owl': 'http://www.w3.org/2002/07/owl#',\n  'fhirshex': 'http://hl7.org/fhir/shape/',\n  'fhirvs': 'http://hl7.org/fhir/ValueSet/',\n/* not needed yet\n  'dc': 'http://purl.org/dc/elements/1.1/',\n  'cs': 'http://hl7.org/orim/codesystem/',\n  'dc': 'http://purl.org/dc/elements/1.1/',\n  'dcterms': 'http://purl.org/dc/terms/',\n  'dt': 'http://hl7.org/orim/datatype/',\n  'ex': 'http://hl7.org/fhir/StructureDefinition/',\n  'fhir-vs': 'http://hl7.org/fhir/ValueSet/',\n  'loinc': 'http://loinc.org/rdf#',\n  'os': 'http://open-services.net/ns/core#',\n  'rim': 'http://hl7.org/orim/class/', // oops\n  'rim': 'http://hl7.org/owl/rim/',\n  'sct': 'http://snomed.info/id/',\n  'vs': 'http://hl7.org/orim/valueset/',\n  'w5': 'http://hl7.org/fhir/w5#'\n*/\n};\n\nif (true)\n  module.exports = Prefixes;\n\n\n//# sourceURL=webpack://playground/../fhirlib/Prefixes.js?");

/***/ }),

/***/ "../fhirlib/errors.js":
/*!****************************!*\
  !*** ../fhirlib/errors.js ***!
  \****************************/
/***/ ((module) => {

eval("/**\n * abstract class for structure errors in e.g. FHIR StructureDefinitions or ShExJ\n */\n\nclass StructureError extends Error {\n  /**\n   * dump additional debugging information\n    * @param log a stream like `console.log`\n   */\n  logMessage (log) {\n    log(`Unknown StructureError`, this);\n  }\n}\n\nif (true)\n  module.exports = {StructureError};\n\n\n//# sourceURL=webpack://playground/../fhirlib/errors.js?");

/***/ }),

/***/ "../fhirlib/node_modules/@shexjs/eval-simple-1err/eval-simple-1err.js":
/*!****************************************************************************!*\
  !*** ../fhirlib/node_modules/@shexjs/eval-simple-1err/eval-simple-1err.js ***!
  \****************************************************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("const EvalSimple1ErrCjsModule = (function () {\n  const ShExTerm = __webpack_require__(/*! @shexjs/term */ \"../fhirlib/node_modules/@shexjs/term/shex-term.js\");\n\n  const Split = \"<span class='keyword' title='Split'>|</span>\";\n  const Rept  = \"<span class='keyword' title='Repeat'>×</span>\";\n  const Match = \"<span class='keyword' title='Match'>␃</span>\";\n  /* compileNFA - compile regular expression and index triple constraints\n   */\n  const UNBOUNDED = -1;\n\n  function compileNFA (schema, shape, index) {\n    const expression = shape.expression;\n    return NFA();\n\n    function NFA () {\n      // wrapper for states, startNo and matchstate\n      const states = [];\n      const matchstate = State_make(Match, []);\n      let startNo = matchstate;\n      const stack = [];\n      let pair;\n      if (expression) {\n        const pair = walkExpr(expression, []);\n        patch(pair.tail, matchstate);\n        startNo = pair.start;\n      }\n      const ret = {\n        algorithm: \"rbenx\",\n        end: matchstate,\n        states: states,\n        start: startNo,\n        match: rbenx_match\n      }\n      // matchstate = states = startNo = null;\n      return ret;\n\n      function walkExpr (expr, stack) {\n        let s, starts;\n        let lastTail;\n        function maybeAddRept (start, tail) {\n          if ((expr.min == undefined || expr.min === 1) &&\n              (expr.max == undefined || expr.max === 1))\n            return {start: start, tail: tail}\n          s = State_make(Rept, [start]);\n          states[s].expr = expr;\n          // cache min/max in normalized form for simplicity of comparison.\n          states[s].min = \"min\" in expr ? expr.min : 1;\n          states[s].max = \"max\" in expr ? expr.max === UNBOUNDED ? Infinity : expr.max : 1;\n          patch(tail, s);\n          return {start: s, tail: [s]}\n        }\n\n        if (typeof expr === \"string\") { // Inclusion\n          const included = index.tripleExprs[expr];\n          return walkExpr(included, stack);\n        }\n\n        else if (expr.type === \"TripleConstraint\") {\n          s = State_make(expr, []);\n          states[s].stack = stack;\n          return {start: s, tail: [s]};\n        }\n\n        else if (expr.type === \"OneOf\") {\n          lastTail = [];\n          starts = [];\n          expr.expressions.forEach(function (nested, ord) {\n            pair = walkExpr(nested, stack.concat({c:expr, e:ord}));\n            starts.push(pair.start);\n            lastTail = lastTail.concat(pair.tail);\n          });\n          s = State_make(Split, starts);\n          states[s].expr = expr;\n          return maybeAddRept(s, lastTail);\n        }\n\n        else if (expr.type === \"EachOf\") {\n          expr.expressions.forEach(function (nested, ord) {\n            pair = walkExpr(nested, stack.concat({c:expr, e:ord}));\n            if (ord === 0)\n              s = pair.start;\n            else\n              patch(lastTail, pair.start);\n            lastTail = pair.tail;\n          });\n          return maybeAddRept(s, lastTail);\n        }\n\n        throw Error(\"unexpected expr type: \" + expr.type);\n      };\n\n      function State_make (c, outs, negated) {\n        const ret = states.length;\n        states.push({c:c, outs:outs});\n        if (negated)\n          states[ret].negated = true; // only include if true for brevity\n        return ret;\n      }\n\n      function patch (l, target) {\n        l.forEach(elt => {\n          states[elt].outs.push(target);\n        });\n      }\n    }\n\n\n    function nfaToString () {\n      const known = {OneOf: [], EachOf: []};\n      function dumpTripleConstraint (tc) {\n        return \"<\" + tc.predicate + \">\";\n      }\n      function card (obj) {\n        const x = \"\";\n        if (\"min\" in obj) x += obj.min;\n        if (\"max\" in obj) x += \",\" + obj.max;\n        return x ? \"{\" + x + \"}\" : \"\";\n      }\n      function junct (j) {\n        const id = known[j.type].indexOf(j);\n        if (id === -1)\n          id = known[j.type].push(j)-1;\n        return j.type + id; // + card(j);\n      }\n      function dumpStackElt (elt) {\n        return junct(elt.c) + \".\" + elt.e + (\"i\" in elt ? \"[\" + elt.i + \"]\" : \"\");\n      }\n      function dumpStack (stack) {\n        return stack.map(elt => { return dumpStackElt(elt); }).join(\"/\");\n      }\n      function dumpNFA (states, startNo) {\n        return states.map((s, i) => {\n          return (i === startNo ? s.c === Match ? \".\" : \"S\" : s.c === Match ? \"E\" : \" \") + i + \" \" + (\n            s.c === Split ? (\"Split-\" + junct(s.expr)) :\n              s.c === Rept ? (\"Rept-\" + junct(s.expr)) :\n              s.c === Match ? \"Match\" :\n              dumpTripleConstraint(s.c)\n          ) + card(s) + \"→\" + s.outs.join(\" | \") + (\"stack\" in s ? dumpStack(s.stack) : \"\");\n        }).join(\"\\n\");\n      }\n      function dumpMatched (matched) {\n        return matched.map(m => {\n          return dumpTripleConstraint(m.c) + \"[\" + m.triples.join(\",\") + \"]\" + dumpStack(m.stack);\n        }).join(\",\");\n      }\n      function dumpThread (thread) {\n        return \"S\" + thread.state + \":\" + Object.keys(thread.repeats).map(k => {\n          return k + \"×\" + thread.repeats[k];\n        }).join(\",\") + \" \" + dumpMatched(thread.matched);\n      }\n      function dumpThreadList (list) {\n        return \"[[\" + list.map(thread => { return dumpThread(thread); }).join(\"\\n  \") + \"]]\";\n      }\n      return {\n        nfa: dumpNFA,\n        stack: dumpStack,\n        stackElt: dumpStackElt,\n        thread: dumpThread,\n        threadList: dumpThreadList\n      };\n    }\n\n    function rbenx_match (graph, node, constraintList, constraintToTripleMapping, tripleToConstraintMapping, neighborhood, semActHandler, trace) {\n      const rbenx = this;\n      let clist = [], nlist = []; // list of {state:state number, repeats:stateNo->repetitionCount}\n\n      if (rbenx.states.length === 1)\n        return matchedToResult([], constraintList, constraintToTripleMapping, neighborhood, semActHandler);\n\n      let chosen = null;\n      // const dump = nfaToString();\n      // console.log(dump.nfa(this.states, this.start));\n      addstate(rbenx, clist, this.start, {repeats:{}, avail:[], matched:[], stack:[], errors:[]});\n      while (clist.length) {\n        nlist = [];\n        if (trace)\n          trace.push({threads:[]});\n        for (let threadno = 0; threadno < clist.length; ++threadno) {\n          const thread = clist[threadno];\n          if (thread.state === rbenx.end)\n            continue;\n          const state = rbenx.states[thread.state];\n          const nlistlen = nlist.length;\n          // may be Accept!\n          if (state.c.type === \"TripleConstraint\") {\n            const constraintNo = constraintList.indexOf(state.c);\n            const min = \"min\" in state.c ? state.c.min : 1;\n            const max = \"max\" in state.c ? state.c.max === UNBOUNDED ? Infinity : state.c.max : 1;\n            if (\"negated\" in state.c && state.c.negated)\n              min = max = 0;\n            if (thread.avail[constraintNo] === undefined)\n              thread.avail[constraintNo] = constraintToTripleMapping[constraintNo].map(pair => pair.tNo);\n            const taken = thread.avail[constraintNo].splice(0, max);\n            if (taken.length >= min) {\n              do {\n                addStates(rbenx, nlist, thread, taken);\n              } while ((function () {\n                if (thread.avail[constraintNo].length > 0 && taken.length < max) {\n                  taken.push(thread.avail[constraintNo].shift());\n                  return true; // stay in look to take more.\n                } else {\n                  return false; // no more to take or we're already at max\n                }\n              })());\n            }\n          }\n          if (trace)\n            trace[trace.length-1].threads.push({\n              state: clist[threadno].state,\n              to:nlist.slice(nlistlen).map(x => {\n                return stateString(x.state, x.repeats);\n              })\n            });\n        }\n        // console.log(dump.threadList(nlist));\n        if (nlist.length === 0 && chosen === null)\n          return reportError(localExpect(clist, rbenx.states));\n        const t = clist;\n        clist = nlist;\n        nlist = t;\n        const longerChosen = clist.reduce((ret, elt) => {\n          const matchedAll =\n              elt.matched.reduce((ret, m) => {\n                return ret + m.triples.length; // count matched triples\n              }, 0) === tripleToConstraintMapping.reduce((ret, t) => {\n                return t === \"NO_TRIPLE_CONSTRAINT\" ? ret : ret + 1; // count expected\n              }, 0);\n          return ret !== null ? ret : (elt.state === rbenx.end && matchedAll) ? elt : null;\n        }, null)\n        if (longerChosen)\n          chosen = longerChosen;\n        // if (longerChosen !== null)\n        //   console.log(JSON.stringify(matchedToResult(longerChosen.matched)));\n      }\n      if (chosen === null)\n        return reportError();\n      function reportError () { return {\n        type: \"Failure\",\n        node: node,\n        errors: localExpect(clist, rbenx.states)\n      } }\n      function localExpect (clist, states) {\n        const lastState = states[states.length - 1];\n        return clist.reduce((acc, elt) => {\n          const c = rbenx.states[elt.state].c;\n          // if (c === Match)\n          //   return { type: \"EndState999\" };\n          let valueExpr = null;\n          if (typeof c.valueExpr === \"string\") { // ShapeRef\n            valueExpr = c.valueExpr;\n            if (ShExTerm.isBlank(valueExpr))\n              valueExpr = schema.shapes[valueExpr];\n          } else if (c.valueExpr) {\n            valueExpr = extend({}, c.valueExpr)\n          }\n          if (elt.state !== rbenx.end) {\n            return acc.concat([extend({\n              type: \"MissingProperty\",\n              property: lastState.c.predicate,\n            }, valueExpr ? { valueExpr: valueExpr } : {})])\n          } else {\n            const unmatchedTriples = {};\n            // Collect triples assigned to some constraint.\n            Object.keys(tripleToConstraintMapping).forEach(k => {\n              if (tripleToConstraintMapping[k] !== \"NO_TRIPLE_CONSTRAINT\")\n                unmatchedTriples[k] = tripleToConstraintMapping[k];\n            });\n            // Removed triples matched in this thread.\n            elt.matched.forEach(m => {\n              m.triples.forEach(t => {\n                delete unmatchedTriples[t];\n              });\n            });\n\n          return acc.concat(Object.keys(unmatchedTriples).map(i => extend({\n            type: \"ExcessTripleViolation\",\n            property: lastState.c.predicate,\n            triple: neighborhood[unmatchedTriples[i]],\n          }, valueExpr ? { valueExpr: valueExpr } : {})));\n          }\n        }, []);\n      }\n      // console.log(\"chosen:\", dump.thread(chosen));\n      return \"errors\" in chosen.matched ?\n        chosen.matched :\n        matchedToResult(chosen.matched, constraintList, constraintToTripleMapping, neighborhood, semActHandler);\n    }\n\n    function addStates (rbenx, nlist, thread, taken) {\n      const state = rbenx.states[thread.state];\n      // find the exprs that require repetition\n      const exprs = rbenx.states.map(x => { return x.c === Rept ? x.expr : null; });\n      const newStack = state.stack.map(e => {\n        let i = thread.repeats[exprs.indexOf(e.c)];\n        if (i === undefined)\n          i = 0; // expr has no repeats\n        else\n          i = i-1;\n        return { c:e.c, e:e.e, i:i };\n      });\n      const withIndexes = {\n        c: state.c,\n        triples: taken,\n        stack: newStack\n      };\n      thread.matched = thread.matched.concat(withIndexes);\n      state.outs.forEach(o => { // single out if NFA includes epsilons\n        addstate(rbenx, nlist, o, thread);\n      });\n    }\n\n    function addstate (rbenx, list, stateNo, thread, seen) {\n      seen = seen || [];\n      const seenkey = stateString(stateNo, thread.repeats);\n      if (seen.indexOf(seenkey) !== -1)\n        return;\n      seen.push(seenkey);\n\n      const s = rbenx.states[stateNo];\n      if (s.c === Split) {\n        return s.outs.reduce((ret, o, idx) => {\n          return ret.concat(addstate(rbenx, list, o, thread, seen));\n        }, []);\n        // } else if (s.c.type === \"OneOf\" || s.c.type === \"EachOf\") { // don't need Rept\n      } else if (s.c === Rept) {\n        const ret = [];\n        // matched = [matched].concat(\"Rept\" + s.expr);\n        if (!(stateNo in thread.repeats))\n          thread.repeats[stateNo] = 0;\n        const repetitions = thread.repeats[stateNo];\n        // add(r < s.min ? outs[0] : r >= s.min && < s.max ? outs[0], outs[1] : outs[1])\n        if (repetitions < s.max)\n          [].push.apply(ret, addstate(rbenx, list, s.outs[0], incrmRepeat(thread, stateNo), seen)); // outs[0] to repeat\n        if (repetitions >= s.min && repetitions <= s.max)\n          [].push.apply(ret, addstate(rbenx, list, s.outs[1], resetRepeat(thread, stateNo), seen)); // outs[1] when done\n        return ret;\n      } else {\n        // if (stateNo !== rbenx.end || !thread.avail.reduce((r2, avail) => { faster if we trim early??\n        //   return r2 || avail.length > 0;\n        // }, false))\n        return [list.push({ // return [new list element index]\n          state:stateNo,\n          repeats:thread.repeats,\n          avail:thread.avail.map(a => { // copy parent thread's avail vector\n            return a.slice();\n          }),\n          stack:thread.stack,\n          matched:thread.matched,\n          errors: thread.errors\n        }) - 1];\n      }\n    }\n\n    function resetRepeat (thread, repeatedState) {\n      const trimmedRepeats = Object.keys(thread.repeats).reduce((r, k) => {\n        if (parseInt(k) !== repeatedState) // ugh, hash keys are strings\n          r[k] = thread.repeats[k];\n        return r;\n      }, {});\n      return {state:thread.state/*???*/, repeats:trimmedRepeats, matched:thread.matched, avail:thread.avail.slice(), stack:thread.stack};\n    }\n\n    function incrmRepeat (thread, repeatedState) {\n      const incrmedRepeats = Object.keys(thread.repeats).reduce((r, k) => {\n        r[k] = parseInt(k) == repeatedState ? thread.repeats[k] + 1 : thread.repeats[k];\n        return r;\n      }, {});\n      return {state:thread.state/*???*/, repeats:incrmedRepeats, matched:thread.matched, avail:thread.avail.slice(), stack:thread.stack};\n    }\n\n    function stateString (state, repeats) {\n      const rs = Object.keys(repeats).map(rpt => {\n        return rpt+\":\"+repeats[rpt];\n      }).join(\",\");\n      return rs.length ? state + \"-\" + rs : \"\"+state;\n    }\n\n    function matchedToResult (matched, constraintList, constraintToTripleMapping, neighborhood, semActHandler) {\n      let last = [];\n      const errors = [];\n      const skips = [];\n      const ret = matched.reduce((out, m) => {\n        let mis = 0;\n        let ptr = out, t;\n        while (mis < last.length &&\n               m.stack[mis].c === last[mis].c && // constraint\n               m.stack[mis].i === last[mis].i && // iteration number\n               m.stack[mis].e === last[mis].e) { // (dis|con)junction number\n            ptr = ptr.solutions[last[mis].i].expressions[last[mis].e];\n          ++mis;\n        }\n        while (mis < m.stack.length) {\n          if (mis >= last.length) {\n            last.push({});\n          }\n          if (m.stack[mis].c !== last[mis].c) {\n            t = [];\n            ptr.type = m.stack[mis].c.type === \"EachOf\" ? \"EachOfSolutions\" : \"OneOfSolutions\", ptr.solutions = t;\n            if (\"min\" in m.stack[mis].c)\n              ptr.min = m.stack[mis].c.min;\n            if (\"max\" in m.stack[mis].c)\n              ptr.max = m.stack[mis].c.max;\n            if (\"annotations\" in m.stack[mis].c)\n              ptr.annotations = m.stack[mis].c.annotations;\n            if (\"semActs\" in m.stack[mis].c)\n              ptr.semActs = m.stack[mis].c.semActs;\n            ptr = t;\n            last[mis].i = null;\n            // !!! on the way out to call after valueExpr test\n            if (\"semActs\" in m.stack[mis].c) {\n              const errors = semActHandler.dispatchAll(m.stack[mis].c.semActs, \"???\", ptr);\n              if (errors.length)\n                throw errors;\n            }\n            // if (ret && \"semActs\" in expr) { ret.semActs = expr.semActs; }\n          } else {\n            ptr = ptr.solutions;\n          }\n          if (m.stack[mis].i !== last[mis].i) {\n            t = [];\n            ptr[m.stack[mis].i] = {\n              type:m.stack[mis].c.type === \"EachOf\" ? \"EachOfSolution\" : \"OneOfSolution\",\n              expressions: t};\n            ptr = t;\n            last[mis].e = null;\n          } else {\n            ptr = ptr[last[mis].i].expressions;\n          }\n          if (m.stack[mis].e !== last[mis].e) {\n            t = {};\n            ptr[m.stack[mis].e] = t;\n            if (m.stack[mis].e > 0 && ptr[m.stack[mis].e-1] === undefined && skips.indexOf(ptr) === -1)\n              skips.push(ptr);\n            ptr = t;\n            last.length = mis + 1; // chop off last so we create everything underneath\n          } else {\n            throw \"how'd we get here?\"\n            ptr = ptr[last[mis].e];\n          }\n          ++mis;\n        }\n        ptr.type = \"TripleConstraintSolutions\";\n        if (\"min\" in m.c)\n          ptr.min = m.c.min;\n        if (\"max\" in m.c)\n          ptr.max = m.c.max;\n        ptr.predicate = m.c.predicate;\n        if (\"valueExpr\" in m.c)\n          ptr.valueExpr = m.c.valueExpr;\n        if (\"id\" in m.c)\n          ptr.productionLabel = m.c.id;\n        ptr.solutions = m.triples.map(tNo => {\n          const triple = neighborhood[tNo];\n          const ret = {\n            type: \"TestedTriple\",\n            subject: triple.subject,\n            predicate: triple.predicate,\n            object: ldify(triple.object)\n          };\n\n        function ldify (term) {\n          if (term[0] !== \"\\\"\")\n            return term;\n          const ret = { value: ShExTerm.getLiteralValue(term) };\n          const dt = ShExTerm.getLiteralType(term);\n          if (dt &&\n              dt !== \"http://www.w3.org/2001/XMLSchema#string\" &&\n              dt !== \"http://www.w3.org/1999/02/22-rdf-syntax-ns#langString\")\n            ret.type = dt;\n          const lang = ShExTerm.getLiteralLanguage(term)\n          if (lang)\n            ret.language = lang;\n          return ret;\n        }\n          const constraintNo = constraintList.indexOf(m.c);\n                      const hit = constraintToTripleMapping[constraintNo].find(x => x.tNo === tNo);\n                      if (hit.res && Object.keys(hit.res).length > 0)\n                        ret.referenced = hit.res;\n          if (errors.length === 0 && \"semActs\" in m.c)\n            [].push.apply(errors, semActHandler.dispatchAll(m.c.semActs, triple, ret));\n          return ret;\n        })\n        if (\"annotations\" in m.c)\n          ptr.annotations = m.c.annotations;\n        if (\"semActs\" in m.c)\n          ptr.semActs = m.c.semActs;\n        last = m.stack.slice();\n        return out;\n      }, {});\n\n      if (errors.length)\n        return {\n          type: \"SemActFailure\",\n          errors: errors\n        };\n\n      // Clear out the nulls for the expressions with min:0 and no matches.\n      // <S> { (:p .; :q .)?; :r . } \\ { <s> :r 1 } -> i:0, e:1 resulting in null at e=0\n      // Maybe we want these nulls in expressions[] to make it clear that there are holes?\n      skips.forEach(skip => {\n        for (let exprNo = 0; exprNo < skip.length; ++exprNo)\n          if (skip[exprNo] === null || skip[exprNo] === undefined)\n            skip.splice(exprNo--, 1);\n      });\n\n      if (\"semActs\" in shape)\n        ret.semActs = shape.semActs;\n      return ret;\n    }\n  }\n\nfunction extend(base) {\n  if (!base) base = {};\n  for (let i = 1, l = arguments.length, arg; i < l && (arg = arguments[i] || {}); i++)\n    for (let name in arg)\n      base[name] = arg[name];\n  return base;\n}\n\n// ## Exports\n\nreturn exports = {\n  name: \"eval-simple-1err\",\n  description: \"simple regular expression engine with n out states\",\n  compile: compileNFA\n};\n\n})();\n\nif (true)\n  module.exports = EvalSimple1ErrCjsModule;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/@shexjs/eval-simple-1err/eval-simple-1err.js?");

/***/ }),

/***/ "../fhirlib/node_modules/@shexjs/eval-threaded-nerr/eval-threaded-nerr.js":
/*!********************************************************************************!*\
  !*** ../fhirlib/node_modules/@shexjs/eval-threaded-nerr/eval-threaded-nerr.js ***!
  \********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const EvalThreadedNErrCjsModule = (function () {\nconst ShExTerm = __webpack_require__(/*! @shexjs/term */ \"../fhirlib/node_modules/@shexjs/term/shex-term.js\");\nconst UNBOUNDED = -1;\n\nfunction vpEngine (schema, shape, index) {\n    const outerExpression = shape.expression;\n    return {\n      match:match\n    };\n\n    function match (graph, node, constraintList, constraintToTripleMapping, tripleToConstraintMapping, neighborhood, semActHandler, trace) {\n\n      /*\n       * returns: list of passing or failing threads (no heterogeneous lists)\n       */\n      function validateExpr (expr, thread) {\n        if (typeof expr === \"string\") { // Inclusion\n          const included = index.tripleExprs[expr];\n          return validateExpr(included, thread);\n        }\n\n        const constraintNo = constraintList.indexOf(expr);\n        let min = \"min\" in expr ? expr.min : 1;\n        let max = \"max\" in expr ? expr.max === UNBOUNDED ? Infinity : expr.max : 1;\n\n        function validateRept (type, val) {\n          let repeated = 0, errOut = false;\n          let newThreads = [thread];\n          const minmax = {  };\n          if (\"min\" in expr && expr.min !== 1 || \"max\" in expr && expr.max !== 1) {\n            minmax.min = expr.min;\n            minmax.max = expr.max;\n          }\n          if (\"semActs\" in expr)\n            minmax.semActs = expr.semActs;\n          if (\"annotations\" in expr)\n            minmax.annotations = expr.annotations;\n          for (; repeated < max && !errOut; ++repeated) {\n            let inner = [];\n            for (let t = 0; t < newThreads.length; ++t) {\n              const newt = newThreads[t];\n              const sub = val(newt);\n              if (sub.length > 0 && sub[0].errors.length === 0) { // all subs pass or all fail\n                sub.forEach(newThread => {\n                  const solutions =\n                      \"expression\" in newt ? newt.expression.solutions.slice() : [];\n                  if (\"solution\" in newThread)\n                    solutions.push(newThread.solution);\n                  delete newThread.solution;\n                  newThread.expression = extend({\n                    type: type,\n                    solutions: solutions\n                  }, minmax);\n                });\n              }\n              if (sub.length === 0 /* min:0 */ || sub[0].errors.length > 0)\n                return repeated < min ? sub : newThreads;\n              else\n                inner = inner.concat(sub);\n              // newThreads.expressions.push(sub);\n            }\n            newThreads = inner;\n          }\n          if (newThreads.length > 0 && newThreads[0].errors.length === 0 && \"semActs\" in expr) {\n            const passes = [];\n            const failures = [];\n            newThreads.forEach(newThread => {\n              const semActErrors = semActHandler.dispatchAll(expr.semActs, \"???\", newThread)\n              if (semActErrors.length === 0) {\n                passes.push(newThread)\n              } else {\n                [].push.apply(newThread.errors, semActErrors);\n                failures.push(newThread);\n              }\n            });\n            newThreads = passes.length > 0 ? passes : failures;\n          }\n          return newThreads;\n        }\n\n        if (expr.type === \"TripleConstraint\") {\n          const negated = \"negated\" in expr && expr.negated || max === 0;\n          if (negated)\n            min = max = Infinity;\n          if (thread.avail[constraintNo] === undefined)\n            thread.avail[constraintNo] = constraintToTripleMapping[constraintNo].map(pair => pair.tNo);\n          const minmax = {  };\n          if (\"min\" in expr && expr.min !== 1 || \"max\" in expr && expr.max !== 1) {\n            minmax.min = expr.min;\n            minmax.max = expr.max;\n          }\n          if (\"semActs\" in expr)\n            minmax.semActs = expr.semActs;\n          if (\"annotations\" in expr)\n            minmax.annotations = expr.annotations;\n          const taken = thread.avail[constraintNo].splice(0, min);\n          const passed = negated ? taken.length === 0 : taken.length >= min;\n          const ret = [];\n          const matched = thread.matched;\n          if (passed) {\n            do {\n              const passFail = taken.reduce((acc, tripleNo) => {\n                const t = neighborhood[tripleNo]\n                const tested = {\n                  type: \"TestedTriple\",\n                  subject: t.subject,\n                  predicate: t.predicate,\n                  object: ldify(t.object)\n                }\n                const hit = constraintToTripleMapping[constraintNo].find(x => x.tNo === tripleNo);\n                if (hit.res && Object.keys(hit.res).length > 0)\n                  tested.referenced = hit.res;\n                const semActErrors = thread.errors.concat(\n                  \"semActs\" in expr\n                    ? semActHandler.dispatchAll(expr.semActs, tested, tested)\n                    : []\n                )\n                if (semActErrors.length > 0)\n                  acc.fail.push({tripleNo, tested, semActErrors})\n                else\n                  acc.pass.push({tripleNo, tested, semActErrors})\n                return acc\n              }, {pass: [], fail: []})\n\n\n              // return an empty solution if min card was 0\n              if (passFail.fail.length === 0) {\n                // If we didn't take anything, fall back to old errors.\n                // Could do something fancy here with a semAct registration for negative matches.\n                const totalErrors = taken.length === 0 ? thread.errors.slice() : []\n                const myThread = makeThread(passFail.pass, totalErrors)\n                ret.push(myThread);\n              } else {\n                passFail.fail.forEach(\n                  f => ret.push(makeThread([f], f.semActErrors))\n                )\n              }\n\n              function makeThread (tests, errors) {\n                return {\n                  avail: thread.avail.map(a => { // copy parent thread's avail vector\n                    return a.slice();\n                  }),\n                  errors: errors,\n                  matched: matched.concat({\n                    tNos: tests.map(p => p.tripleNo)\n                  }),\n                  expression: extend(\n                    {\n                      type: \"TripleConstraintSolutions\",\n                      predicate: expr.predicate\n                    },\n                    \"valueExpr\" in expr ? { valueExpr: expr.valueExpr } : {},\n                    \"id\" in expr ? { productionLabel: expr.id } : {},\n                    minmax,\n                    {\n                      solutions: tests.map(p => p.tested)\n                    }\n                  )\n                }\n              }\n            } while ((function () {\n              if (thread.avail[constraintNo].length > 0 && taken.length < max) {\n                // build another thread.\n                taken.push(thread.avail[constraintNo].shift());\n                return true;\n              } else {\n                // no more threads\n                return false;\n              }\n            })());\n          } else {\n            let valueExpr = null;\n            if (typeof expr.valueExpr === \"string\") { // ShapeRef\n              valueExpr = expr.valueExpr;\n              if (ShExTerm.isBlank(valueExpr))\n                valueExpr = index.shapeExprs[valueExpr];\n            } else if (expr.valueExpr) {\n              valueExpr = extend({}, expr.valueExpr)\n            }\n            ret.push({\n              avail: thread.avail,\n              errors: thread.errors.concat([\n                extend({\n                  type: negated ? \"NegatedProperty\" : \"MissingProperty\",\n                  property: expr.predicate\n                }, valueExpr ? { valueExpr: valueExpr } : {})\n              ]),\n              matched: matched\n            });\n          }\n\n          return ret;\n        }\n\n        else if (expr.type === \"OneOf\") {\n          return validateRept(\"OneOfSolutions\", (th) => {\n            // const accept = null;\n            const matched = [];\n            const failed = [];\n            expr.expressions.forEach(nested => {\n              const thcopy = {\n                avail: th.avail.map(a => { return a.slice(); }),\n                errors: th.errors,\n                matched: th.matched//.slice() ever needed??\n              };\n              const sub = validateExpr(nested, thcopy);\n              if (sub[0].errors.length === 0) { // all subs pass or all fail\n                [].push.apply(matched, sub);\n                sub.forEach(newThread => {\n                  const expressions =\n                      \"solution\" in thcopy ? thcopy.solution.expressions : [];\n                  if (\"expression\" in newThread) // undefined for no matches on min card:0\n                    expressions.push(newThread.expression);\n                  delete newThread.expression;\n                  newThread.solution = {\n                    type: \"OneOfSolution\",\n                    expressions: expressions\n                  };\n                });\n              } else\n                [].push.apply(failed, sub);\n            });\n            return matched.length > 0 ? matched : failed;\n          });\n        }\n\n        else if (expr.type === \"EachOf\") {\n          return homogenize(validateRept(\"EachOfSolutions\", (th) => {\n            // Iterate through nested expressions, exprThreads starts as [th].\n            return expr.expressions.reduce((exprThreads, nested) => {\n              // Iterate through current thread list composing nextThreads.\n              // Consider e.g.\n              // <S1> { <p1> . | <p2> .; <p3> . } / { <x> <p2> 2; <p3> 3 } (should pass)\n              // <S1> { <p1> .; <p2> . }          / { <s1> <p1> 1 }        (should fail)\n              return homogenize(exprThreads.reduce((nextThreads, exprThread) => {\n                const sub = validateExpr(nested, exprThread);\n                // Move newThread.expression into a hierarchical solution structure.\n                sub.forEach(newThread => {\n                  if (newThread.errors.length === 0) {\n                    const expressions =\n                        \"solution\" in exprThread ? exprThread.solution.expressions.slice() : [];\n                    if (\"expression\" in newThread) // undefined for no matches on min card:0\n                      expressions.push(newThread.expression);\n                    delete newThread.expression;\n                    newThread.solution = {\n                      type: \"EachOfSolution\",\n                      expressions: expressions // exprThread.expression + newThread.expression\n                    };\n                  }\n                });\n                return nextThreads.concat(sub);\n              }, []));\n            }, [th]);\n          }));\n        }\n\n        runtimeError(\"unexpected expr type: \" + expr.type);\n\n        function homogenize (list) {\n          return list.reduce((acc, elt) => {\n            if (elt.errors.length === 0) {\n              if (acc.errors) {\n                return { errors: false, l: [elt] };\n              } else {\n                return { errors: false, l: acc.l.concat(elt) };\n              }\n            } else {\n              if (acc.errors) {\n                return { errors: true, l: acc.l.concat(elt) };\n              } else {\n                return acc; }\n            }\n          }, {errors: true, l: []}).l;\n        }\n      }\n\n      const startingThread = {\n        avail:[],   // triples remaining by constraint number\n        matched:[], // triples matched in this thread\n        errors:[]   // errors encounted\n      };\n      if (!outerExpression)\n        return { }; // vapid match if no expression\n      const ret = validateExpr(outerExpression, startingThread);\n      // console.log(JSON.stringify(ret));\n      // note: don't return if ret.length === 1 because it might fail the unmatchedTriples test.\n      const longerChosen =\n          ret.reduce((ret, elt) => {\n            if (elt.errors.length > 0)\n              return ret;              // early return\n            const unmatchedTriples = {};\n            // Collect triples assigned to some constraint.\n            Object.keys(tripleToConstraintMapping).forEach(k => {\n              if (tripleToConstraintMapping[k] !== \"NO_TRIPLE_CONSTRAINT\")\n                unmatchedTriples[k] = tripleToConstraintMapping[k];\n            });\n            // Removed triples matched in this thread.\n            elt.matched.forEach(m => {\n              m.tNos.forEach(t => {\n                delete unmatchedTriples[t];\n              });\n            });\n            // Remaining triples are unaccounted for.\n            Object.keys(unmatchedTriples).forEach(t => {\n              elt.errors.push({\n                type: \"ExcessTripleViolation\",\n                triple: neighborhood[t],\n                constraint: constraintList[unmatchedTriples[t]]\n              });\n            });\n            return ret !== null ? ret : // keep first solution\n            // Accept thread with no unmatched triples.\n            Object.keys(unmatchedTriples).length > 0 ? null : elt;\n          }, null);\n      return longerChosen !== null ?\n        finish(longerChosen.expression, constraintList,\n               neighborhood, semActHandler) :\n        ret.length > 1 ? {\n          type: \"PossibleErrors\",\n          errors: ret.reduce((all, e) => {\n            return all.concat([e.errors]);\n          }, [])\n        } : ret[0];\n    }\n\n        function ldify (term) {\n          if (term[0] !== \"\\\"\")\n            return term;\n          const ret = { value: ShExTerm.getLiteralValue(term) };\n          const dt = ShExTerm.getLiteralType(term);\n          if (dt &&\n              dt !== \"http://www.w3.org/2001/XMLSchema#string\" &&\n              dt !== \"http://www.w3.org/1999/02/22-rdf-syntax-ns#langString\")\n            ret.type = dt;\n          const lang = ShExTerm.getLiteralLanguage(term)\n          if (lang)\n            ret.language = lang;\n          return ret;\n        }\n\n    function finish (fromValidatePoint, constraintList, neighborhood, semActHandler) {\n      function _dive (solns) {\n        if (solns.type === \"OneOfSolutions\" ||\n            solns.type === \"EachOfSolutions\") {\n          solns.solutions.forEach(s => {\n            s.expressions.forEach(e => {\n              _dive(e);\n            });\n          });\n        } else if (solns.type === \"TripleConstraintSolutions\") {\n          solns.solutions = solns.solutions.map(x => {\n            if (x.type === \"TestedTriple\") // already done\n              return x; // c.f. validation/3circularRef1_pass-open\n            const t = neighborhood[x.tripleNo];\n            const expr = constraintList[x.constraintNo];\n            const ret = {\n              type: \"TestedTriple\", subject: t.subject, predicate: t.predicate, object: ldify(t.object)\n            };\n            function diver (focus, shapeLabel, dive) {\n              const sub = dive(focus, shapeLabel);\n              if (\"errors\" in sub) {\n                // console.dir(sub);\n                const err = {\n                  type: \"ReferenceError\", focus: focus,\n                  shape: shapeLabel\n                };\n                if (typeof shapeLabel === \"string\" && ShExTerm.isBlank(shapeLabel))\n                  err.referencedShape = shape;\n                err.errors = sub;\n                return [err];\n              }\n              if ((\"solution\" in sub || \"solutions\" in sub)&& Object.keys(sub.solution || sub.solutions).length !== 0 ||\n                  sub.type === \"Recursion\")\n                ret.referenced = sub; // !!! needs to aggregate errors and solutions\n              return [];\n            }\n            function diveRecurse (focus, shapeLabel) {\n              return diver(focus, shapeLabel, recurse);\n            }\n            function diveDirect (focus, shapeLabel) {\n              return diver(focus, shapeLabel, direct);\n            }\n            const subErrors = \"valueExpr\" in expr ?\n                checkValueExpr(expr.inverse ? t.subject : t.object, expr.valueExpr, diveRecurse, diveDirect) :\n                [];\n            if (subErrors.length === 0 && \"semActs\" in expr)\n              [].push.apply(subErrors, semActHandler.dispatchAll(expr.semActs, ret, ret))\n            if (subErrors.length > 0) {\n              fromValidatePoint.errors = fromValidatePoint.errors || [];\n              fromValidatePoint.errors = fromValidatePoint.errors.concat(subErrors);\n            }\n            return ret;\n          });\n        } else {\n          throw Error(\"unexpected expr type in \" + JSON.stringify(solns));\n        }\n      }\n      if (Object.keys(fromValidatePoint).length > 0) // guard against {}\n        _dive(fromValidatePoint);\n      if (\"semActs\" in shape)\n        fromValidatePoint.semActs = shape.semActs;\n      return fromValidatePoint;\n    }\n  }\n\n        function ldify (term) {\n          if (term[0] !== \"\\\"\")\n            return term;\n          const ret = { value: N3Util.getLiteralValue(term) };\n          const dt = N3Util.getLiteralType(term);\n          if (dt &&\n              dt !== \"http://www.w3.org/2001/XMLSchema#string\" &&\n              dt !== \"http://www.w3.org/1999/02/22-rdf-syntax-ns#langString\")\n            ret.type = dt;\n          const lang = N3Util.getLiteralLanguage(term)\n          if (lang)\n            ret.language = lang;\n          return ret;\n        }\n\nfunction extend(base) {\n  if (!base) base = {};\n  for (let i = 1, l = arguments.length, arg; i < l && (arg = arguments[i] || {}); i++)\n    for (let name in arg)\n      base[name] = arg[name];\n  return base;\n}\n\nreturn {\n  name: \"eval-threaded-nerr\",\n  description: \"emulation of regular expression engine with error permutations\",\n  compile: vpEngine\n};\n})();\n\nif (true)\n  module.exports = EvalThreadedNErrCjsModule;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/@shexjs/eval-threaded-nerr/eval-threaded-nerr.js?");

/***/ }),

/***/ "../fhirlib/node_modules/@shexjs/term/shex-term.js":
/*!*********************************************************!*\
  !*** ../fhirlib/node_modules/@shexjs/term/shex-term.js ***!
  \*********************************************************/
/***/ ((module) => {

eval("/**\n *\n * isIRI, isBlank, getLiteralType, getLiteralValue\n */\n\nconst ShExTermCjsModule = (function () {\n\n  const absoluteIRI = /^[a-z][a-z0-9+.-]*:/i,\n    schemeAuthority = /^(?:([a-z][a-z0-9+.-]*:))?(?:\\/\\/[^\\/]*)?/i,\n    dotSegments = /(?:^|\\/)\\.\\.?(?:$|[\\/#?])/;\n\n  const RdfLangString = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#langString\";\n  const XsdString = \"http://www.w3.org/2001/XMLSchema#string\";\n\n  // N3.js:lib/N3Parser.js<0.4.5>:576 with\n  //   s/this\\./Parser./g\n  //   s/token/iri/\n  // ### `_resolveIRI` resolves a relative IRI token against the base path,\n  // assuming that a base path has been set and that the IRI is indeed relative.\n  function resolveRelativeIRI (base, iri) {\n\n    if (absoluteIRI.test(iri))\n      return iri\n\n    switch (iri[0]) {\n    // An empty relative IRI indicates the base IRI\n    case undefined: return base;\n    // Resolve relative fragment IRIs against the base IRI\n    case '#': return base + iri;\n    // Resolve relative query string IRIs by replacing the query string\n    case '?': return base.replace(/(?:\\?.*)?$/, iri);\n    // Resolve root-relative IRIs at the root of the base IRI\n    case '/':\n      let m = base.match(schemeAuthority);\n      // Resolve scheme-relative IRIs to the scheme\n      return (iri[1] === '/' ? m[1] : m[0]) + _removeDotSegments(iri);\n    // Resolve all other IRIs at the base IRI's path\n    default: {\n      return _removeDotSegments(base.replace(/[^\\/?]*(?:\\?.*)?$/, '') + iri);\n    }\n    }\n  }\n\n  // ### `_removeDotSegments` resolves './' and '../' path segments in an IRI as per RFC3986.\n  function _removeDotSegments (iri) {\n    // Don't modify the IRI if it does not contain any dot segments\n    if (!dotSegments.test(iri))\n      return iri;\n\n    // Start with an imaginary slash before the IRI in order to resolve trailing './' and '../'\n    const result = '', length = iri.length, i = -1, pathStart = -1, segmentStart = 0, next = '/';\n\n    while (i < length) {\n      switch (next) {\n      // The path starts with the first slash after the authority\n      case ':':\n        if (pathStart < 0) {\n          // Skip two slashes before the authority\n          if (iri[++i] === '/' && iri[++i] === '/')\n            // Skip to slash after the authority\n            while ((pathStart = i + 1) < length && iri[pathStart] !== '/')\n              i = pathStart;\n        }\n        break;\n      // Don't modify a query string or fragment\n      case '?':\n      case '#':\n        i = length;\n        break;\n      // Handle '/.' or '/..' path segments\n      case '/':\n        if (iri[i + 1] === '.') {\n          next = iri[++i + 1];\n          switch (next) {\n          // Remove a '/.' segment\n          case '/':\n            result += iri.substring(segmentStart, i - 1);\n            segmentStart = i + 1;\n            break;\n          // Remove a trailing '/.' segment\n          case undefined:\n          case '?':\n          case '#':\n            return result + iri.substring(segmentStart, i) + iri.substr(i + 1);\n          // Remove a '/..' segment\n          case '.':\n            next = iri[++i + 1];\n            if (next === undefined || next === '/' || next === '?' || next === '#') {\n              result += iri.substring(segmentStart, i - 2);\n              // Try to remove the parent path from result\n              if ((segmentStart = result.lastIndexOf('/')) >= pathStart)\n                result = result.substr(0, segmentStart);\n              // Remove a trailing '/..' segment\n              if (next !== '/')\n                return result + '/' + iri.substr(i + 1);\n              segmentStart = i + 1;\n            }\n          }\n        }\n      }\n      next = iri[++i];\n    }\n    return result + iri.substring(segmentStart);\n  }\n\n  function internalTerm (node) { // !!rdfjsTermToInternal\n    switch (node.termType) {\n    case (\"NamedNode\"):\n      return node.value;\n    case (\"BlankNode\"):\n      return \"_:\" + node.value;\n    case (\"Literal\"):\n      return \"\\\"\" + node.value + \"\\\"\" + (\n        node.datatypeString === RdfLangString\n          ? \"@\" + node.language\n          : node.datatypeString === XsdString\n          ? \"\"\n          : \"^^\" + node.datatypeString\n      );\n    default: throw Error(\"unknown RDFJS node type: \" + JSON.stringify(node))\n    }\n  }\n\n  function internalTriple (triple) { // !!rdfjsTripleToInternal\n    return {\n      subject: internalTerm(triple.subject),\n      predicate: internalTerm(triple.predicate),\n      object: internalTerm(triple.object)\n    };\n  }\n\n  function externalTerm (node, factory) { // !!intermalTermToRdfjs\n    if (isIRI(node)) {\n      return factory.namedNode(node);\n    } else if (isBlank(node)) {\n      return factory.blankNode(node.substr(2));\n    } else if (isLiteral(node)) {\n      let dtOrLang = getLiteralLanguage(node) ||\n          (getLiteralType(node) === XsdString\n           ? null // seems to screw up N3.js\n           : factory.namedNode(getLiteralType(node)))\n      return factory.literal(getLiteralValue(node), dtOrLang)\n    } else {\n      throw Error(\"Unknown internal term type: \" + JSON.stringify(node));\n    }\n  }\n\n  function externalTriple (triple, factory) { // !!rename internalTripleToRdjs\n    return factory.quad(\n      externalTerm(triple.subject, factory),\n      externalTerm(triple.predicate, factory),\n      externalTerm(triple.object, factory)\n    );\n  }\n\n  function intermalTermToTurtle (node, base, prefixes) {\n    if (isIRI(node)) {\n      // if (node === RDF_TYPE) // only valid in Turtle predicates\n      //   return \"a\";\n\n      // Escape special characters\n      if (escape.test(node))\n        node = node.replace(escapeAll, characterReplacer);\n      const pref = Object.keys(prefixes).find(pref => node.startsWith(prefixes[pref]));\n      if (pref) {\n        const rest = node.substr(prefixes[pref].length);\n        if (rest.indexOf(\"\\\\\") === -1) // could also say no more than n of these: [...]\n          return pref + \":\" + rest.replace(/([~!$&'()*+,;=/?#@%])/g, '\\\\' + \"$1\");\n      }\n      if (node.startsWith(base)) {\n        return \"<\" + node.substr(base.length) + \">\";\n      } else {\n        return \"<\" + node + \">\";\n      }\n    } else if (isBlank(node)) {\n      return node;\n    } else if (isLiteral(node)) {\n      const value = getLiteralValue(node);\n      const type = getLiteralType(node);\n      const language = getLiteralLanguage(node);\n      // Escape special characters\n      if (escape.test(value))\n        value = value.replace(escapeAll, characterReplacer);\n      // Write the literal, possibly with type or language\n      if (language)\n        return '\"' + value + '\"@' + language;\n      else if (type && type !== \"http://www.w3.org/2001/XMLSchema#string\")\n        return '\"' + value + '\"^^' + this.intermalTermToTurtle(type, base, prefixes);\n      else\n        return '\"' + value + '\"';\n    } else {\n      throw Error(\"Unknown internal term type: \" + JSON.stringify(node));\n    }\n  }\n\n  // Tests whether the given entity (triple object) represents an IRI in the N3 library\n  function isIRI (entity) {\n    if (typeof entity !== 'string')\n      return false;\n    else if (entity.length === 0)\n      return true;\n    else {\n      const firstChar = entity[0];\n      return firstChar !== '\"' && firstChar !== '_';\n    }\n  }\n\n  // Tests whether the given entity (triple object) represents a literal in the N3 library\n  function isLiteral (entity) {\n    return typeof entity === 'string' && entity[0] === '\"';\n  }\n\n  // Tests whether the given entity (triple object) represents a blank node in the N3 library\n  function isBlank (entity) {\n    return typeof entity === 'string' && entity.substr(0, 2) === '_:';\n  }\n\n  // Tests whether the given entity represents the default graph\n  function isDefaultGraph (entity) {\n    return !entity;\n  }\n\n  // Tests whether the given triple is in the default graph\n  function inDefaultGraph (triple) {\n    return !triple.graph;\n  }\n\n  // Gets the string value of a literal in the N3 library\n  function getLiteralValue (literal) {\n    const match = /^\"([^]*)\"/.exec(literal);\n    if (!match)\n      throw new Error(literal + ' is not a literal');\n    return match[1].replace(/\\\\\"/g, '\"');\n  }\n\n  // Gets the type of a literal in the N3 library\n  function getLiteralType (literal) {\n    const match = /^\"[^]*\"(?:\\^\\^([^\"]+)|(@)[^@\"]+)?$/.exec(literal);\n    if (!match)\n      throw new Error(literal + ' is not a literal');\n    return match[1] || (match[2] ? RdfLangString : XsdString);\n  }\n\n  // Gets the language of a literal in the N3 library\n  function getLiteralLanguage (literal) {\n    const match = /^\"[^]*\"(?:@([^@\"]+)|\\^\\^[^\"]+)?$/.exec(literal);\n    if (!match)\n      throw new Error(literal + ' is not a literal');\n    return match[1] ? match[1].toLowerCase() : '';\n  }\n\n\n// rdf:type predicate (for 'a' abbreviation)\nconst RDF_PREFIX = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n    RDF_TYPE   = RDF_PREFIX + 'type';\n\n// Characters in literals that require escaping\nconst escape    = /[\"\\\\\\t\\n\\r\\b\\f\\u0000-\\u0019\\ud800-\\udbff]/,\n    escapeAll = /[\"\\\\\\t\\n\\r\\b\\f\\u0000-\\u0019]|[\\ud800-\\udbff][\\udc00-\\udfff]/g,\n    escapeReplacements = {\n      '\\\\': '\\\\\\\\', '\"': '\\\\\"', '\\t': '\\\\t',\n      '\\n': '\\\\n', '\\r': '\\\\r', '\\b': '\\\\b', '\\f': '\\\\f',\n    };\n\n  // Replaces a character by its escaped version\n  function characterReplacer (character) {\n    // Replace a single character by its escaped version\n    const result = escapeReplacements[character];\n    if (result === undefined) {\n      // Replace a single character with its 4-bit unicode escape sequence\n      if (character.length === 1) {\n        result = character.charCodeAt(0).toString(16);\n        result = '\\\\u0000'.substr(0, 6 - result.length) + result;\n      }\n      // Replace a surrogate pair with its 8-bit unicode escape sequence\n      else {\n        result = ((character.charCodeAt(0) - 0xD800) * 0x400 +\n                  character.charCodeAt(1) + 0x2400).toString(16);\n        result = '\\\\U00000000'.substr(0, 10 - result.length) + result;\n      }\n    }\n    return result;\n  }\n\n  return {\n    RdfLangString: RdfLangString,\n    XsdString: XsdString,\n    resolveRelativeIRI: resolveRelativeIRI,\n    isIRI: isIRI,\n    isLiteral: isLiteral,\n    isBlank: isBlank,\n    isDefaultGraph: isDefaultGraph,\n    inDefaultGraph: inDefaultGraph,\n    getLiteralValue: getLiteralValue,\n    getLiteralType: getLiteralType,\n    getLiteralLanguage: getLiteralLanguage,\n    internalTerm: internalTerm,\n    internalTriple: internalTriple,\n    externalTerm: externalTerm,\n    externalTriple: externalTriple,\n    intermalTermToTurtle: intermalTermToTurtle,\n  }\n})();\n\nif (true)\n  module.exports = ShExTermCjsModule; // node environment\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/@shexjs/term/shex-term.js?");

/***/ }),

/***/ "../fhirlib/node_modules/@shexjs/util/shex-util.js":
/*!*********************************************************!*\
  !*** ../fhirlib/node_modules/@shexjs/util/shex-util.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// **ShExUtil** provides ShEx utility functions\n\nconst ShExUtilCjsModule = (function () {\nconst ShExTerm = __webpack_require__(/*! @shexjs/term */ \"../fhirlib/node_modules/@shexjs/term/shex-term.js\");\nconst Visitor = __webpack_require__(/*! @shexjs/visitor */ \"../fhirlib/node_modules/@shexjs/visitor/shex-visitor.js\")\nconst Hierarchy = __webpack_require__(/*! hierarchy-closure */ \"../fhirlib/node_modules/hierarchy-closure/hierarchy-closure.js\")\n\nconst SX = {};\nSX._namespace = \"http://www.w3.org/ns/shex#\";\n[\"Schema\", \"@context\", \"imports\", \"startActs\", \"start\", \"shapes\",\n \"ShapeDecl\", \"ShapeOr\", \"ShapeAnd\", \"shapeExprs\", \"nodeKind\",\n \"NodeConstraint\", \"iri\", \"bnode\", \"nonliteral\", \"literal\", \"datatype\", \"length\", \"minlength\", \"maxlength\", \"pattern\", \"flags\", \"mininclusive\", \"minexclusive\", \"maxinclusive\", \"maxexclusive\", \"totaldigits\", \"fractiondigits\", \"values\",\n \"ShapeNot\", \"shapeExpr\",\n \"Shape\", \"abstract\", \"closed\", \"extra\", \"expression\", \"extends\", \"restricts\", \"semActs\",\n \"ShapeRef\", \"reference\", \"ShapeExternal\",\n \"EachOf\", \"OneOf\", \"expressions\", \"min\", \"max\", \"annotation\",\n \"TripleConstraint\", \"inverse\", \"negated\", \"predicate\", \"valueExpr\",\n \"Inclusion\", \"include\", \"Language\", \"languageTag\",\n \"IriStem\", \"LiteralStem\", \"LanguageStem\", \"stem\",\n \"IriStemRange\", \"LiteralStemRange\", \"LanguageStemRange\", \"exclusion\",\n \"Wildcard\", \"SemAct\", \"name\", \"code\",\n \"Annotation\", \"object\"].forEach(p => {\n  SX[p] = SX._namespace+p;\n});\nconst RDF = {};\nRDF._namespace = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\";\n[\"type\", \"first\", \"rest\", \"nil\"].forEach(p => {\n  RDF[p] = RDF._namespace+p;\n});\nconst XSD = {}\nXSD._namespace = \"http://www.w3.org/2001/XMLSchema#\";\n[\"anyURI\"].forEach(p => {\n  XSD[p] = XSD._namespace+p;\n});\nconst OWL = {}\nOWL._namespace = \"http://www.w3.org/2002/07/owl#\";\n[\"Thing\"].forEach(p => {\n  OWL[p] = OWL._namespace+p;\n});\n\nconst Missed = {}; // singleton\nconst UNBOUNDED = -1;\n\nfunction extend (base) {\n  if (!base) base = {};\n  for (let i = 1, l = arguments.length, arg; i < l && (arg = arguments[i] || {}); i++)\n    for (let name in arg)\n      base[name] = arg[name];\n  return base;\n}\n\n    function isTerm (t) {\n      return typeof t !== \"object\" || \"value\" in t && Object.keys(t).reduce((r, k) => {\n        return r === false ? r : [\"value\", \"type\", \"language\"].indexOf(k) !== -1;\n      }, true);\n    }\n\n  function isShapeRef (expr) {\n    return typeof expr === \"string\" // test for JSON-LD @ID\n  }\n  let isInclusion = isShapeRef;\n\n        function ldify (term) {\n          if (term[0] !== \"\\\"\")\n            return term;\n          const ret = { value: ShExTerm.getLiteralValue(term) };\n          const dt = ShExTerm.getLiteralType(term);\n          if (dt &&\n              dt !== \"http://www.w3.org/2001/XMLSchema#string\" &&\n              dt !== \"http://www.w3.org/1999/02/22-rdf-syntax-ns#langString\")\n            ret.type = dt;\n          const lang = ShExTerm.getLiteralLanguage(term)\n          if (lang)\n            ret.language = lang;\n          return ret;\n        }\nconst ShExUtil = {\n\n  SX: SX,\n  RDF: RDF,\n  version: function () {\n    return \"0.5.0\";\n  },\n\n  Visitor: Visitor,\n  index: Visitor.index,\n\n\n  /* getAST - compile a traditional regular expression abstract syntax tree.\n   * Tested but not used at present.\n   */\n  getAST: function (schema) {\n    return {\n      type: \"AST\",\n      shapes: schema.shapes.reduce(function (ret, shape) {\n        ret[shape.id] = {\n          type: \"ASTshape\",\n          expression: _compileShapeToAST(shape.expression, [], schema)\n        };\n        return ret;\n      }, {})\n    };\n\n    /* _compileShapeToAST - compile a shape expression to an abstract syntax tree.\n     *\n     * currently tested but not used.\n     */\n    function _compileShapeToAST (expression, tripleConstraints, schema) {\n\n      function Epsilon () {\n        this.type = \"Epsilon\";\n      }\n\n      function TripleConstraint (ordinal, predicate, inverse, negated, valueExpr) {\n        this.type = \"TripleConstraint\";\n        // this.ordinal = ordinal; @@ does 1card25\n        this.inverse = !!inverse;\n        this.negated = !!negated;\n        this.predicate = predicate;\n        if (valueExpr !== undefined)\n          this.valueExpr = valueExpr;\n      }\n\n      function Choice (disjuncts) {\n        this.type = \"Choice\";\n        this.disjuncts = disjuncts;\n      }\n\n      function EachOf (conjuncts) {\n        this.type = \"EachOf\";\n        this.conjuncts = conjuncts;\n      }\n\n      function SemActs (expression, semActs) {\n        this.type = \"SemActs\";\n        this.expression = expression;\n        this.semActs = semActs;\n      }\n\n      function KleeneStar (expression) {\n        this.type = \"KleeneStar\";\n        this.expression = expression;\n      }\n\n      function _compileExpression (expr, schema) {\n        let repeated, container;\n\n        /* _repeat: map expr with a min and max cardinality to a corresponding AST with Groups and Stars.\n           expr 1 1 => expr\n           expr 0 1 => Choice(expr, Eps)\n           expr 0 3 => Choice(EachOf(expr, Choice(EachOf(expr, Choice(expr, EPS)), Eps)), Eps)\n           expr 2 5 => EachOf(expr, expr, Choice(EachOf(expr, Choice(EachOf(expr, Choice(expr, EPS)), Eps)), Eps))\n           expr 0 * => KleeneStar(expr)\n           expr 1 * => EachOf(expr, KleeneStar(expr))\n           expr 2 * => EachOf(expr, expr, KleeneStar(expr))\n\n           @@TODO: favor Plus over Star if Epsilon not in expr.\n        */\n        function _repeat (expr, min, max) {\n          if (min === undefined) { min = 1; }\n          if (max === undefined) { max = 1; }\n\n          if (min === 1 && max === 1) { return expr; }\n\n          const opts = max === UNBOUNDED ?\n                new KleeneStar(expr) :\n                Array.from(Array(max - min)).reduce(function (ret, elt, ord) {\n                  return ord === 0 ?\n                    new Choice([expr, new Epsilon]) :\n                    new Choice([new EachOf([expr, ret]), new Epsilon]);\n                }, undefined);\n\n          const reqd = min !== 0 ?\n                new EachOf(Array.from(Array(min)).map(function (ret) {\n                  return expr; // @@ something with ret\n                }).concat(opts)) : opts;\n          return reqd;\n        }\n\n        if (typeof expr === \"string\") { // Inclusion\n          const included = schema._index.tripleExprs[expr].expression;\n          return _compileExpression(included, schema);\n        }\n\n        else if (expr.type === \"TripleConstraint\") {\n          // predicate, inverse, negated, valueExpr, annotations, semActs, min, max\n          const valueExpr = \"valueExprRef\" in expr ?\n                schema.valueExprDefns[expr.valueExprRef] :\n                expr.valueExpr;\n          const ordinal = tripleConstraints.push(expr)-1;\n          const tp = new TripleConstraint(ordinal, expr.predicate, expr.inverse, expr.negated, valueExpr);\n          repeated = _repeat(tp, expr.min, expr.max);\n          return expr.semActs ? new SemActs(repeated, expr.semActs) : repeated;\n        }\n\n        else if (expr.type === \"OneOf\") {\n          container = new Choice(expr.expressions.map(function (e) {\n            return _compileExpression(e, schema);\n          }));\n          repeated = _repeat(container, expr.min, expr.max);\n          return expr.semActs ? new SemActs(repeated, expr.semActs) : repeated;\n        }\n\n        else if (expr.type === \"EachOf\") {\n          container = new EachOf(expr.expressions.map(function (e) {\n            return _compileExpression(e, schema);\n          }));\n          repeated = _repeat(container, expr.min, expr.max);\n          return expr.semActs ? new SemActs(repeated, expr.semActs) : repeated;\n        }\n\n        else throw Error(\"unexpected expr type: \" + expr.type);\n      }\n\n      return expression ? _compileExpression(expression, schema) : new Epsilon();\n    }\n  },\n\n  // tests\n  // console.warn(\"HERE:\", ShExJtoAS({\"type\":\"Schema\",\"shapes\":[{\"id\":\"http://all.example/S1\",\"type\":\"Shape\",\"expression\":\n  //  { \"id\":\"http://all.example/S1e\", \"type\":\"EachOf\",\"expressions\":[ ] },\n  // // { \"id\":\"http://all.example/S1e\",\"type\":\"TripleConstraint\",\"predicate\":\"http://all.example/p1\"},\n  // \"extra\":[\"http://all.example/p3\",\"http://all.example/p1\",\"http://all.example/p2\"]\n  // }]}).shapes['http://all.example/S1']);\n\n  ShExJtoAS: function (schema) {\n    const _ShExUtil = this;\n    schema._prefixes = schema._prefixes || {  };\n    schema._index = this.index(schema);\n    return schema;\n  },\n\n  AStoShExJ: function (schema, abbreviate) {\n    schema[\"@context\"] = schema[\"@context\"] || \"http://www.w3.org/ns/shex.jsonld\";\n    delete schema[\"_index\"];\n    delete schema[\"_prefixes\"];\n    return schema;\n  },\n\n  ShExRVisitor: function (knownShapeExprs) {\n    const v = ShExUtil.Visitor();\n    const knownExpressions = {};\n    const oldVisitShapeExpr = v.visitShapeExpr,\n        oldVisitValueExpr = v.visitValueExpr,\n        oldVisitExpression = v.visitExpression;\n    v.keepShapeExpr = oldVisitShapeExpr;\n\n    v.visitShapeExpr = v.visitValueExpr = function (expr, label) {\n      if (typeof expr === \"string\")\n        return expr;\n      if (\"id\" in expr) {\n        if (knownShapeExprs.indexOf(expr.id) !== -1 || Object.keys(expr).length === 1)\n          return expr.id;\n        delete expr.id;\n      }\n      return oldVisitShapeExpr.call(this, expr, label);\n    };\n\n    v.visitExpression = function (expr) {\n      if (typeof expr === \"string\") // shortcut for recursive references e.g. 1Include1 and ../doc/TODO.md\n        return expr;\n      if (\"id\" in expr) {\n        if (expr.id in knownExpressions) {\n          knownExpressions[expr.id].refCount++;\n          return expr.id;\n        }\n      }\n      const ret = oldVisitExpression.call(this, expr);\n      // Everything from RDF has an ID, usually a BNode.\n      knownExpressions[expr.id] = { refCount: 1, expr: ret };\n      return ret;\n    }\n\n    v.cleanIds = function () {\n      for (let k in knownExpressions) {\n        const known = knownExpressions[k];\n        if (known.refCount === 1 && ShExTerm.isBlank(known.expr.id))\n          delete known.expr.id;\n      };\n    }\n\n    return v;\n  },\n\n\n  // tests\n  // const shexr = ShExUtil.ShExRtoShExJ({ \"type\": \"Schema\", \"shapes\": [\n  //   { \"id\": \"http://a.example/S1\", \"type\": \"Shape\",\n  //     \"expression\": {\n  //       \"type\": \"TripleConstraint\", \"predicate\": \"http://a.example/p1\",\n  //       \"valueExpr\": {\n  //         \"type\": \"ShapeAnd\", \"shapeExprs\": [\n  //           { \"type\": \"NodeConstraint\", \"nodeKind\": \"bnode\" },\n  //           { \"id\": \"http://a.example/S2\", \"type\": \"Shape\",\n  //             \"expression\": {\n  //               \"type\": \"TripleConstraint\", \"predicate\": \"http://a.example/p2\" } }\n  //           //            \"http://a.example/S2\"\n  //         ] } } },\n  //   { \"id\": \"http://a.example/S2\", \"type\": \"Shape\",\n  //     \"expression\": {\n  //       \"type\": \"TripleConstraint\", \"predicate\": \"http://a.example/p2\" } }\n  // ] });\n  // console.warn(\"HERE:\", shexr.shapes[0].expression.valueExpr);\n  // ShExUtil.ShExJtoAS(shexr);\n  // console.warn(\"THERE:\", shexr.shapes[\"http://a.example/S1\"].expression.valueExpr);\n\n\n  ShExRtoShExJ: function (schema) {\n    // compile a list of known shapeExprs\n    const knownShapeExprs = [];\n    if (\"shapes\" in schema)\n      [].push.apply(knownShapeExprs, schema.shapes.map(sh => { return sh.id; }));\n\n    // normalize references to those shapeExprs\n    const v = this.ShExRVisitor(knownShapeExprs);\n    if (\"start\" in schema)\n      schema.start = v.visitShapeExpr(schema.start);\n    if (\"shapes\" in schema)\n      schema.shapes = schema.shapes.map(sh => {\n        return sh.type === SX.ShapeDecl ?\n          {\n            type: \"ShapeDecl\",\n            id: sh.id,\n            abstract: sh.abstract,\n            shapeExpr: v.visitShapeExpr(sh.shapeExpr)\n          } :\n          v.keepShapeExpr(sh);\n      });\n\n    // remove extraneous BNode IDs\n    v.cleanIds();\n    return schema;\n  },\n\n  valGrep: function (obj, type, f) {\n    const _ShExUtil = this;\n    const ret = [];\n    for (let i in obj) {\n      const o = obj[i];\n      if (typeof o === \"object\") {\n        if (\"type\" in o && o.type === type)\n          ret.push(f(o));\n        ret.push.apply(ret, _ShExUtil.valGrep(o, type, f));\n      }\n    }\n    return ret;\n  },\n\n  n3jsToTurtle: function (res) {\n    function termToLex (node) {\n      return typeof node === \"object\" ? (\"\\\"\" + node.value + \"\\\"\" + (\n        \"type\" in node ? \"^^<\" + node.type + \">\" :\n          \"language\" in node ? \"@\" + node.language :\n          \"\"\n      )) :\n      ShExTerm.isIRI(node) ? \"<\" + node + \">\" :\n      ShExTerm.isBlank(node) ? node :\n      \"???\";\n    }\n    return this.valGrep(res, \"TestedTriple\", function (t) {\n      return [\"subject\", \"predicate\", \"object\"].map(k => {\n        return termToLex(t[k]);\n      }).join(\" \")+\" .\";\n    });\n  },\n\n  valToN3js: function (res, factory) {\n    return this.valGrep(res, \"TestedTriple\", function (t) {\n      const ret = JSON.parse(JSON.stringify(t));\n      if (typeof t.object === \"object\")\n        ret.object = (\"\\\"\" + t.object.value + \"\\\"\" + (\n          \"type\" in t.object ? \"^^\" + t.object.type :\n            \"language\" in t.object ? \"@\" + t.object.language :\n            \"\"\n        ));\n      return ShExTerm.externalTriple(ret, factory);\n    });\n  },\n\n  n3jsToTurtle: function (n3js) {\n    function termToLex (node) {\n      if (ShExTerm.isIRI(node))\n        return \"<\" + node + \">\";\n      if (ShExTerm.isBlank(node))\n        return node;\n      const t = ShExTerm.getLiteralType(node);\n      if (t && t !== \"http://www.w3.org/2001/XMLSchema#string\")\n        return \"\\\"\" + ShExTerm.getLiteralValue(node) + \"\\\"\" +\n        \"^^<\" + t + \">\";\n      return node;\n    }\n    return n3js.map(function (t) {\n      return [\"subject\", \"predicate\", \"object\"].map(k => {\n        return termToLex(t[k]);\n      }).join(\" \")+\" .\";\n    });\n  },\n\n  /* canonicalize: move all tripleExpression references to their first expression.\n   *\n   */\n  canonicalize: function (schema, trimIRI) {\n    const ret = JSON.parse(JSON.stringify(schema));\n    ret[\"@context\"] = ret[\"@context\"] || \"http://www.w3.org/ns/shex.jsonld\";\n    delete ret._prefixes;\n    delete ret._base;\n    let index = ret._index || this.index(schema);\n    delete ret._index;\n    let sourceMap = ret._sourceMap;\n    delete ret._sourceMap;\n    // Don't delete ret.productions as it's part of the AS.\n    const v = ShExUtil.Visitor();\n    const knownExpressions = [];\n    const oldVisitInclusion = v.visitInclusion, oldVisitExpression = v.visitExpression;\n    v.visitInclusion = function (inclusion) {\n      if (knownExpressions.indexOf(inclusion) === -1 &&\n          inclusion in index.tripleExprs) {\n        knownExpressions.push(inclusion)\n        return oldVisitExpression.call(v, index.tripleExprs[inclusion]);\n      }\n      return oldVisitInclusion.call(v, inclusion);\n    };\n    v.visitExpression = function (expression) {\n      if (typeof expression === \"object\" && \"id\" in expression) {\n        if (knownExpressions.indexOf(expression.id) === -1) {\n          knownExpressions.push(expression.id)\n          return oldVisitExpression.call(v, index.tripleExprs[expression.id]);\n        }\n        return expression.id; // Inclusion\n      }\n      return oldVisitExpression.call(v, expression);\n    };\n    if (trimIRI) {\n      v.visitIRI = function (i) {\n        return i.replace(trimIRI, \"\");\n      }\n      if (\"imports\" in ret)\n        ret.imports = v.visitImports(ret.imports);\n    }\n    if (\"shapes\" in ret) {\n      ret.shapes = Object.keys(index.shapeExprs).sort().map(k => {\n        if (\"extra\" in index.shapeExprs[k])\n          index.shapeExprs[k].extra.sort();\n        return v.visitShapeDecl(index.shapeExprs[k]);\n      });\n    }\n    return ret;\n  },\n\n  BiDiClosure: function () {\n    return {\n      needs: {},\n      neededBy: {},\n      inCycle: [],\n      test: function () {\n        function expect (l, r) { const ls = JSON.stringify(l), rs = JSON.stringify(r); if (ls !== rs) throw Error(ls+\" !== \"+rs); }\n        // this.add(1, 2); expect(this.needs, { 1:[2]                     }); expect(this.neededBy, { 2:[1]                     });\n        // this.add(3, 4); expect(this.needs, { 1:[2], 3:[4]              }); expect(this.neededBy, { 2:[1], 4:[3]              });\n        // this.add(2, 3); expect(this.needs, { 1:[2,3,4], 2:[3,4], 3:[4] }); expect(this.neededBy, { 2:[1], 3:[2,1], 4:[3,2,1] });\n\n        this.add(2, 3); expect(this.needs, { 2:[3]                     }); expect(this.neededBy, { 3:[2]                     });\n        this.add(1, 2); expect(this.needs, { 1:[2,3], 2:[3]            }); expect(this.neededBy, { 3:[2,1], 2:[1]            });\n        this.add(1, 3); expect(this.needs, { 1:[2,3], 2:[3]            }); expect(this.neededBy, { 3:[2,1], 2:[1]            });\n        this.add(3, 4); expect(this.needs, { 1:[2,3,4], 2:[3,4], 3:[4] }); expect(this.neededBy, { 3:[2,1], 2:[1], 4:[3,2,1] });\n        this.add(6, 7); expect(this.needs, { 6:[7]                    , 1:[2,3,4], 2:[3,4], 3:[4] }); expect(this.neededBy, { 7:[6]                    , 3:[2,1], 2:[1], 4:[3,2,1] });\n        this.add(5, 6); expect(this.needs, { 5:[6,7], 6:[7]           , 1:[2,3,4], 2:[3,4], 3:[4] }); expect(this.neededBy, { 7:[6,5], 6:[5]           , 3:[2,1], 2:[1], 4:[3,2,1] });\n        this.add(5, 7); expect(this.needs, { 5:[6,7], 6:[7]           , 1:[2,3,4], 2:[3,4], 3:[4] }); expect(this.neededBy, { 7:[6,5], 6:[5]           , 3:[2,1], 2:[1], 4:[3,2,1] });\n        this.add(7, 8); expect(this.needs, { 5:[6,7,8], 6:[7,8], 7:[8], 1:[2,3,4], 2:[3,4], 3:[4] }); expect(this.neededBy, { 7:[6,5], 6:[5], 8:[7,6,5], 3:[2,1], 2:[1], 4:[3,2,1] });\n        this.add(4, 5);\n        expect(this.needs,    { 1:[2,3,4,5,6,7,8], 2:[3,4,5,6,7,8], 3:[4,5,6,7,8], 4:[5,6,7,8], 5:[6,7,8], 6:[7,8], 7:[8] });\n        expect(this.neededBy, { 2:[1], 3:[2,1], 4:[3,2,1], 5:[4,3,2,1], 6:[5,4,3,2,1], 7:[6,5,4,3,2,1], 8:[7,6,5,4,3,2,1] });\n      },\n      add: function (needer, needie, negated) {\n        const r = this;\n        if (!(needer in r.needs))\n          r.needs[needer] = [];\n        if (!(needie in r.neededBy))\n          r.neededBy[needie] = [];\n\n        // // [].concat.apply(r.needs[needer], [needie], r.needs[needie]). emitted only last element\n        r.needs[needer] = r.needs[needer].concat([needie], r.needs[needie]).\n          filter(function (el, ord, l) { return el !== undefined && l.indexOf(el) === ord; });\n        // // [].concat.apply(r.neededBy[needie], [needer], r.neededBy[needer]). emitted only last element\n        r.neededBy[needie] = r.neededBy[needie].concat([needer], r.neededBy[needer]).\n          filter(function (el, ord, l) { return el !== undefined && l.indexOf(el) === ord; });\n\n        if (needer in this.neededBy) this.neededBy[needer].forEach(function (e) {\n          r.needs[e] = r.needs[e].concat([needie], r.needs[needie]).\n            filter(function (el, ord, l) { return el !== undefined && l.indexOf(el) === ord; });\n        });\n\n        if (needie in this.needs) this.needs[needie].forEach(function (e) {\n          r.neededBy[e] = r.neededBy[e].concat([needer], r.neededBy[needer]).\n            filter(function (el, ord, l) { return el !== undefined && l.indexOf(el) === ord; })\n        });\n        // this.neededBy[needie].push(needer);\n\n        if (r.needs[needer].indexOf(needer) !== -1)\n          r.inCycle = r.inCycle.concat(r.needs[needer]);\n      },\n      trim: function () {\n        function _trim (a) {\n          // filter(function (el, ord, l) { return l.indexOf(el) === ord; })\n          for (let i = a.length-1; i > -1; --i)\n            if (a.indexOf(a[i]) < i)\n              a.splice(i, i+1);\n        }\n        for (k in this.needs)\n          _trim(this.needs[k]);\n        for (k in this.neededBy)\n          _trim(this.neededBy[k]);\n      },\n      foundIn: {},\n      addIn: function (tripleExpr, shapeExpr) {\n        this.foundIn[tripleExpr] = shapeExpr;\n      }\n    }\n  },\n  /** @@TODO tests\n   * options:\n   *   no: don't do anything; just report nestable shapes\n   *   transform: function to change shape labels\n   */\n  nestShapes: function (schema, options = {}) {\n    const _ShExUtil = this;\n    const index = schema._index || this.index(schema);\n    if (!('no' in options)) { options.no = false }\n\n    let shapeLabels = Object.keys(index.shapeExprs || [])\n    let shapeReferences = {}\n    shapeLabels.forEach(label => {\n      let shape = index.shapeExprs[label]\n      noteReference(label, null) // just note the shape so we have a complete list at the end\n      shape = _ShExUtil.skipDecl(shape)\n      if (shape.type === 'Shape') {\n        if ('extends' in shape) {\n          shape.extends.forEach(\n             // !!! assumes simple reference, not e.g. AND\n            parent => noteReference(parent, shape)\n          )\n        }\n        if ('expression' in shape) {\n          (_ShExUtil.simpleTripleConstraints(shape) || []).forEach(tc => {\n            let target = _ShExUtil.getValueType(tc.valueExpr, true)\n            noteReference(target, {type: 'tc', shapeLabel: label, tc: tc})\n          })\n        }\n      } else if (shape.type === 'NodeConstraint') {\n        // can't have any refs to other shapes\n      } else {\n        throw Error('nestShapes currently only supports Shapes and NodeConstraints')\n      }\n    })\n    let nestables = Object.keys(shapeReferences).filter(\n      label => shapeReferences[label].length === 1\n        && shapeReferences[label][0].type === 'tc' // no inheritance support yet\n        && label in index.shapeExprs\n        && _ShExUtil.skipDecl(index.shapeExprs[label]).type === 'Shape' // Don't nest e.g. valuesets for now. @@ needs an option\n        && !index.shapeExprs[label].abstract // shouldn't have a ref to an unEXTENDed ABSTRACT shape anyways.\n    ).filter(\n      nestable => !('noNestPattern' in options)\n        || !nestable.match(RegExp(options.noNestPattern))\n    ).reduce((acc, label) => {\n      acc[label] = {\n        referrer: shapeReferences[label][0].shapeLabel,\n        predicate: shapeReferences[label][0].tc.predicate\n      }\n      return acc\n    }, {})\n    if (!options.no) {\n      let oldToNew = {}\n\n      if (options.rename) {\n        if (!('transform' in options)) {\n          options.transform = (function () {\n            let map = shapeLabels.reduce((acc, k, idx) => {\n              acc[k] = '_:renamed' + idx\n              return acc\n            }, {})\n            return function (id, shapeExpr) {\n              return map[id]\n            }\n          })()\n        }\n        Object.keys(nestables).forEach(oldName => {\n          let shapeExpr = index.shapeExprs[oldName]\n          let newName = options.transform(oldName, shapeExpr)\n          oldToNew[oldName] = shapeExpr.id = newName\n          shapeLabels[shapeLabels.indexOf(oldName)] = newName\n          nestables[newName] = nestables[oldName]\n          nestables[newName].was = oldName\n          delete nestables[oldName]\n\n          // @@ maybe update index when done? \n          index.shapeExprs[newName] = index.shapeExprs[oldName]\n          delete index.shapeExprs[oldName]\n\n          if (shapeReferences[oldName].length !== 1) { throw Error('assertion: ' + oldName + ' doesn\\'t have one reference: [' + shapeReferences[oldName] + ']') }\n          let ref = shapeReferences[oldName][0]\n          if (ref.type === 'tc') {\n            if (typeof ref.tc.valueExpr === 'string') { // ShapeRef\n              ref.tc.valueExpr = newName\n            } else {\n              throw Error('assertion: rename not implemented for TripleConstraint expr: ' + ref.tc.valueExpr)\n              // _ShExUtil.setValueType(ref, newName)\n            }\n          } else if (ref.type === 'Shape') {\n            throw Error('assertion: rename not implemented for Shape: ' + ref)\n          } else {\n            throw Error('assertion: ' + ref.type + ' not TripleConstraint or Shape')\n          }\n        })\n\n        Object.keys(nestables).forEach(k => {\n          let n = nestables[k]\n          if (n.referrer in oldToNew) {\n            n.newReferrer = oldToNew[n.referrer]\n          }\n        })\n\n        // Restore old order for more concise diffs.\n        let shapesCopy = {}\n        shapeLabels.forEach(label => shapesCopy[label] = index.shapeExprs[label])\n        index.shapeExprs = shapesCopy\n      } else {\n        const doomed = []\n        const ids = schema.shapes.map(s => s.id)\n        Object.keys(nestables).forEach(oldName => {\n          const borged = index.shapeExprs[oldName]\n          // In principle, the ShExJ shouldn't have a Decl if the above criteria are met,\n          // but the ShExJ may be generated by something which emits Decls regardless.\n          shapeReferences[oldName][0].tc.valueExpr = _ShExUtil.skipDecl(borged)\n          const delme = ids.indexOf(oldName)\n          if (schema.shapes[delme].id !== oldName)\n            throw Error('assertion: found ' + schema.shapes[delme].id + ' instead of ' + oldName)\n          doomed.push(delme)\n          delete index.shapeExprs[oldName]\n        })\n        doomed.sort((l, r) => r - l).forEach(delme => {\n          const id = schema.shapes[delme].id\n          if (!nestables[id])\n            throw Error('deleting unexpected shape ' + id)\n          delete schema.shapes[delme].id\n          schema.shapes.splice(delme, 1)\n        })\n      }\n    }\n    // console.dir(nestables)\n    // console.dir(shapeReferences)\n    return nestables\n\n    function noteReference (id, reference) {\n      if (!(id in shapeReferences)) {\n        shapeReferences[id] = []\n      }\n      if (reference) {\n        shapeReferences[id].push(reference)\n      }\n    }\n  },\n\n  /** @@TODO tests\n   *\n   */\n  getPredicateUsage: function (schema, untyped = {}) {\n    const _ShExUtil = this;\n\n    // populate shapeHierarchy\n    let shapeHierarchy = Hierarchy.create()\n    Object.keys(schema.shapes).forEach(label => {\n      let shapeExpr = _ShExUtil.skipDecl(schema.shapes[label])\n      if (shapeExpr.type === 'Shape') {\n        (shapeExpr.extends || []).forEach(\n          superShape => shapeHierarchy.add(superShape.reference, label)\n        )\n      }\n    })\n    Object.keys(schema.shapes).forEach(label => {\n      if (!(label in shapeHierarchy.parents))\n        shapeHierarchy.parents[label] = []\n    })\n\n    let predicates = { } // IRI->{ uses: [shapeLabel], commonType: shapeExpr }\n    Object.keys(schema.shapes).forEach(shapeLabel => {\n      let shapeExpr = _ShExUtil.skipDecl(schema.shapes[shapeLabel])\n      if (shapeExpr.type === 'Shape') {\n        let tcs = _ShExUtil.simpleTripleConstraints(shapeExpr) || []\n        tcs.forEach(tc => {\n          let newType = _ShExUtil.getValueType(tc.valueExpr)\n          if (!(tc.predicate in predicates)) {\n            predicates[tc.predicate] = {\n              uses: [shapeLabel],\n              commonType: newType,\n              polymorphic: false\n            }\n            if (typeof newType === 'object') {\n              untyped[tc.predicate] = {\n                shapeLabel,\n                predicate: tc.predicate,\n                newType,\n                references: []\n              }\n            }\n          } else {\n            predicates[tc.predicate].uses.push(shapeLabel)\n            let curType = predicates[tc.predicate].commonType\n            if (typeof curType === 'object' || curType === null) {\n              // another use of a predicate with no commonType\n              // console.warn(`${shapeLabel} ${tc.predicate}:${newType} uses untypable predicate`)\n              untyped[tc.predicate].references.push({ shapeLabel, newType })\n            } else if (typeof newType === 'object') {\n              // first use of a predicate with no detectable commonType\n              predicates[tc.predicate].commonType = null\n              untyped[tc.predicate] = {\n                shapeLabel,\n                predicate: tc.predicate,\n                curType,\n                newType,\n                references: []\n              }\n            } else if (curType === newType) {\n              ; // same type again\n            } else if (shapeHierarchy.parents[curType] && shapeHierarchy.parents[curType].indexOf(newType) !== -1) {\n              predicates[tc.predicate].polymorphic = true; // already covered by current commonType\n            } else {\n              let idx = shapeHierarchy.parents[newType] ? shapeHierarchy.parents[newType].indexOf(curType) : -1\n              if (idx === -1) {\n                let intersection = shapeHierarchy.parents[curType]\n                    ? shapeHierarchy.parents[curType].filter(\n                      lab => -1 !== shapeHierarchy.parents[newType].indexOf(lab)\n                    )\n                    : []\n                if (intersection.length === 0) {\n                  untyped[tc.predicate] = {\n                    shapeLabel,\n                    predicate: tc.predicate,\n                    curType,\n                    newType,\n                    references: []\n                  }\n                  // console.warn(`${shapeLabel} ${tc.predicate} : ${newType} isn\\'t related to ${curType}`)\n                  predicates[tc.predicate].commonType = null\n                } else {\n                  predicates[tc.predicate].commonType = intersection[0]\n                  predicates[tc.predicate].polymorphic = true\n                }\n              } else {\n                predicates[tc.predicate].commonType = shapeHierarchy.parents[newType][idx]\n                predicates[tc.predicate].polymorphic = true\n              }\n            }\n          }\n        })\n      }\n    })\n    return predicates\n  },\n\n  /** @@TODO tests\n   *\n   */\n  simpleTripleConstraints: function (shape) {\n    if (!('expression' in shape)) {\n      return []\n    }\n    if (shape.expression.type === 'TripleConstraint') {\n      return [ shape.expression ]\n    }\n    if (shape.expression.type === 'EachOf' &&\n        !(shape.expression.expressions.find(\n          expr => expr.type !== 'TripleConstraint'\n        ))) {\n          return shape.expression.expressions\n        }\n    throw Error('can\\'t (yet) express ' + JSON.stringify(shape))\n  },\n\n  skipDecl: function (shapeExpr) {\n    return shapeExpr.type === 'ShapeDecl' ? shapeExpr.shapeExpr : shapeExpr\n  },\n\n  getValueType: function (valueExpr) {\n    if (typeof valueExpr === 'string') { return valueExpr }\n    if (valueExpr.reference) { return valueExpr.reference }\n    if (valueExpr.nodeKind === 'iri') { return OWL.Thing } // !! push this test to callers\n    if (valueExpr.datatype) { return valueExpr.datatype }\n    // if (valueExpr.extends && valueExpr.extends.length === 1) { return valueExpr.extends[0] }\n    return valueExpr // throw Error('no value type for ' + JSON.stringify(valueExpr))\n  },\n\n  /** getDependencies: find which shappes depend on other shapes by inheritance\n   * or inclusion.\n   * TODO: rewrite in terms of Visitor.\n   */\n  getDependencies: function (schema, ret) {\n    ret = ret || this.BiDiClosure();\n    (schema.shapes || []).forEach(function (shape) {\n      function _walkShapeExpression (shapeExpr, negated) {\n        if (typeof shapeExpr === \"string\") { // ShapeRef\n          ret.add(shape.id, shapeExpr);\n        } else if (shapeExpr.type === \"ShapeOr\" || shapeExpr.type === \"ShapeAnd\") {\n          shapeExpr.shapeExprs.forEach(function (expr) {\n            _walkShapeExpression(expr, negated);\n          });\n        } else if (shapeExpr.type === \"ShapeNot\") {\n          _walkShapeExpression(shapeExpr.shapeExpr, negated ^ 1); // !!! test negation\n        } else if (shapeExpr.type === \"Shape\") {\n          _walkShape(shapeExpr, negated);\n        } else if (shapeExpr.type === \"NodeConstraint\") {\n          // no impact on dependencies\n        } else if (shapeExpr.type === \"ShapeExternal\") {\n        } else\n          throw Error(\"expected Shape{And,Or,Ref,External} or NodeConstraint in \" + JSON.stringify(shapeExpr));\n      }\n      \n      function _walkShape (shape, negated) {\n        function _walkTripleExpression (tripleExpr, negated) {\n          function _exprGroup (exprs, negated) {\n            exprs.forEach(function (nested) {\n              _walkTripleExpression(nested, negated) // ?? negation allowed?\n            });\n          }\n\n          function _walkTripleConstraint (tc, negated) {\n            if (tc.valueExpr)\n              _walkShapeExpression(tc.valueExpr, negated);\n            if (negated && ret.inCycle.indexOf(shape.id) !== -1) // illDefined/negatedRefCycle.err\n              throw Error(\"Structural error: \" + shape.id + \" appears in negated cycle\");\n          }\n\n          if (typeof tripleExpr === \"string\") { // Inclusion\n            ret.add(shape.id, tripleExpr);\n          } else {\n            if (\"id\" in tripleExpr)\n              ret.addIn(tripleExpr.id, shape.id)\n            if (tripleExpr.type === \"TripleConstraint\") {\n              _walkTripleConstraint(tripleExpr, negated);\n            } else if (tripleExpr.type === \"OneOf\" || tripleExpr.type === \"EachOf\") {\n              _exprGroup(tripleExpr.expressions);\n            } else {\n              throw Error(\"expected {TripleConstraint,OneOf,EachOf,Inclusion} in \" + tripleExpr);\n            }\n          }\n        }\n\n        ([\"extends\", \"restricts\"]).forEach(attr => {\n        if (shape[attr] && shape[attr].length > 0)\n          shape[attr].forEach(function (i) {\n            ret.add(shape.id, i);\n          });\n        })\n        if (shape.expression)\n          _walkTripleExpression(shape.expression, negated);\n      }\n      if (shape.type === \"ShapeDecl\")\n        shape = shape.shapeExpr;\n      _walkShapeExpression(shape, 0); // 0 means false for bitwise XOR\n    });\n    return ret;\n  },\n\n  /** partition: create subset of a schema with only desired shapes and\n   * their dependencies.\n   *\n   * @schema: input schema\n   * @partition: shape name or array of desired shape names\n   * @deps: (optional) dependency tree from getDependencies.\n   *        map(shapeLabel -> [shapeLabel])\n   */\n  partition: function (schema, includes, deps, cantFind) {\n    const inputIndex = schema._index || this.index(schema)\n    const outputIndex = { shapeExprs: new Map(), tripleExprs: new Map() };\n    includes = includes instanceof Array ? includes : [includes];\n\n    // build dependency tree if not passed one\n    deps = deps || this.getDependencies(schema);\n    cantFind = cantFind || function (what, why) {\n      throw new Error(\"Error: can't find shape \" +\n                      (why ?\n                       why + \" dependency \" + what :\n                       what));\n    };\n    const partition = {};\n    for (let k in schema)\n      partition[k] = k === \"shapes\" ? [] : schema[k];\n    includes.forEach(function (i) {\n      if (i in outputIndex.shapeExprs) {\n        // already got it.\n      } else if (i in inputIndex.shapeExprs) {\n        const adding = inputIndex.shapeExprs[i];\n        partition.shapes.push(adding);\n        outputIndex.shapeExprs[adding.id] = adding;\n        if (i in deps.needs)\n          deps.needs[i].forEach(function (n) {\n            // Turn any needed TE into an SE.\n            if (n in deps.foundIn)\n              n = deps.foundIn[n];\n\n            if (n in outputIndex.shapeExprs) {\n            } else if (n in inputIndex.shapeExprs) {\n              const needed = inputIndex.shapeExprs[n];\n              partition.shapes.push(needed);\n              outputIndex.shapeExprs[needed.id] = needed;\n            } else\n              cantFind(n, i);\n          });\n      } else {\n        cantFind(i, \"supplied\");\n      }\n    });\n    return partition;\n  },\n\n\n  /** @@TODO flatten: return copy of input schema with all shape and value class\n   * references substituted by a copy of their referent.\n   *\n   * @schema: input schema\n   */\n  flatten: function (schema, deps, cantFind) {\n    const v = this.Visitor();\n    return v.visitSchema(schema);\n  },\n\n  // @@ put predicateUsage here\n\n  emptySchema: function () {\n    return {\n      type: \"Schema\"\n    };\n  },\n  merge: function (left, right, overwrite, inPlace) {\n    const ret = inPlace ? left : this.emptySchema();\n\n    function mergeArray (attr) {\n      Object.keys(left[attr] || {}).forEach(function (key) {\n        if (!(attr in ret))\n          ret[attr] = {};\n        ret[attr][key] = left[attr][key];\n      });\n      Object.keys(right[attr] || {}).forEach(function (key) {\n        if (!(attr  in left) || !(key in left[attr]) || overwrite) {\n          if (!(attr in ret))\n            ret[attr] = {};\n          ret[attr][key] = right[attr][key];\n        }\n      });\n    }\n\n    function mergeMap (attr) {\n      (left[attr] || new Map()).forEach(function (value, key, map) {\n        if (!(attr in ret))\n          ret[attr] = new Map();\n        ret[attr].set(key, left[attr].get(key));\n      });\n      (right[attr] || new Map()).forEach(function (value, key, map) {\n        if (!(attr  in left) || !(left[attr].has(key)) || overwrite) {\n          if (!(attr in ret))\n            ret[attr] = new Map();\n          ret[attr].set(key, right[attr].get(key));\n        }\n      });\n    }\n\n    // base\n    if (\"_base\" in left)\n      ret._base = left._base;\n    if (\"_base\" in right)\n      if (!(\"_base\" in left) || overwrite)\n        ret._base = right._base;\n\n    mergeArray(\"_prefixes\");\n\n    mergeMap(\"_sourceMap\");\n\n    if (\"imports\" in right)\n      if (!(\"imports\" in left) || overwrite)\n        ret.imports = right.imports;\n\n    // startActs\n    if (\"startActs\" in left)\n      ret.startActs = left.startActs;\n    if (\"startActs\" in right)\n      if (!(\"startActs\" in left) || overwrite)\n        ret.startActs = right.startActs;\n\n    // start\n    if (\"start\" in left)\n      ret.start = left.start;\n    if (\"start\" in right)\n      if (!(\"start\" in left) || overwrite)\n        ret.start = right.start;\n\n    let lindex = left._index || this.index(left);\n\n    // shapes\n    if (!inPlace)\n      (left.shapes || []).forEach(function (lshape) {\n        if (!(\"shapes\" in ret))\n          ret.shapes = [];\n        ret.shapes.push(lshape);\n      });\n    (right.shapes || []).forEach(function (rshape) {\n      if (!(\"shapes\"  in left) || !(rshape.id in lindex.shapeExprs) || overwrite) {\n        if (!(\"shapes\" in ret))\n          ret.shapes = [];\n        ret.shapes.push(rshape)\n      }\n    });\n\n    if (left._index || right._index)\n      ret._index = this.index(ret); // inefficient; could build above\n\n    return ret;\n  },\n\n  absolutizeResults: function (parsed, base) {\n    // !! duplicate of Validation-test.js:84: const referenceResult = parseJSONFile(resultsFile...)\n    function mapFunction (k, obj) {\n      // resolve relative URLs in results file\n      if ([\"shape\", \"reference\", \"node\", \"subject\", \"predicate\", \"object\"].indexOf(k) !== -1 &&\n          ShExTerm.isIRI(obj[k])) {\n        obj[k] = ShExTerm.resolveRelativeIRI(base, obj[k]);\n      }}\n\n    function resolveRelativeURLs (obj) {\n      Object.keys(obj).forEach(function (k) {\n        if (typeof obj[k] === \"object\") {\n          resolveRelativeURLs(obj[k]);\n        }\n        if (mapFunction) {\n          mapFunction(k, obj);\n        }\n      });\n    }\n    resolveRelativeURLs(parsed);\n    return parsed;\n  },\n\n  getProofGraph: function (res, db, dataFactory) {\n    function _dive1 (solns) {\n      if (solns.type === \"NodeConstraintTest\") {\n      } else if (solns.type === \"SolutionList\" ||\n                 solns.type === \"ShapeAndResults\" ||\n                 solns.type === \"ExtensionResults\") {\n        solns.solutions.forEach(s => {\n          if (s.solution) // no .solution for <S> {}\n            _dive1(s.solution);\n        });\n      } else if (solns.type === \"ShapeOrResults\") {\n        _dive1(solns.solution);\n      } else if (solns.type === \"ShapeTest\") {\n        if (\"solution\" in solns)\n          _dive1(solns.solution);\n      } else if (solns.type === \"OneOfSolutions\" ||\n                 solns.type === \"EachOfSolutions\") {\n        solns.solutions.forEach(s => {\n          _dive1(s);\n        });\n      } else if (solns.type === \"OneOfSolution\" ||\n                 solns.type === \"EachOfSolution\") {\n        solns.expressions.forEach(s => {\n          _dive1(s);\n        });\n      } else if (solns.type === \"TripleConstraintSolutions\") {\n        solns.solutions.map(s => {\n          if (s.type !== \"TestedTriple\")\n            throw Error(\"unexpected result type: \" + s.type);\n          const s2 = s;\n          if (typeof s2.object === \"object\")\n            s2.object = \"\\\"\" + s2.object.value.replace(/\"/g, \"\\\\\\\"\") + \"\\\"\"\n            + (s2.object.language ? (\"@\" + s2.object.language) : \n               s2.object.type ? (\"^^\" + s2.object.type) :\n               \"\");\n          db.addQuad(ShExTerm.externalTriple(s2, dataFactory))\n          if (\"referenced\" in s) {\n            _dive1(s.referenced);\n          }\n        });\n      } else if (solns.type === \"ExtendedResults\") {\n        _dive1(solns.extensions);\n        if (\"local\" in solns)\n          _dive1(solns.local);        \n      } else if ([\"ShapeNotResults\", \"Recursion\"].indexOf(solns.type) !== -1) {\n      } else {\n        throw Error(\"unexpected expr type \"+solns.type+\" in \" + JSON.stringify(solns));\n      }\n    }\n    _dive1(res);\n    return db;\n  },\n\n  validateSchema: function (schema) { // obselete, but may need other validations in the future.\n    const _ShExUtil = this;\n    const visitor = this.Visitor();\n    let currentLabel = currentExtra = null;\n    let currentNegated = false;\n    const dependsOn = { };\n    let inTE = false;\n    const oldVisitShape = visitor.visitShape;\n    const negativeDeps = Hierarchy.create();\n    const positiveDeps = Hierarchy.create();\n    let index = schema.index || this.index(schema);\n\n    visitor.visitShape = function (shape, label) {\n      const lastExtra = currentExtra;\n      currentExtra = shape.extra;\n      const ret = oldVisitShape.call(visitor, shape, label);\n      currentExtra = lastExtra;\n      return ret;\n    }\n\n    const oldVisitShapeNot = visitor.visitShapeNot;\n    visitor.visitShapeNot = function (shapeNot, label) {\n      const lastNegated = currentNegated;\n      currentNegated ^= true;\n      const ret = oldVisitShapeNot.call(visitor, shapeNot, label);\n      currentNegated = lastNegated;\n      return ret;\n    }\n\n    const oldVisitTripleConstraint = visitor.visitTripleConstraint;\n    visitor.visitTripleConstraint = function (expr) {\n      const lastNegated = currentNegated;\n      if (currentExtra && currentExtra.indexOf(expr.predicate) !== -1)\n        currentNegated ^= true;\n      inTE = true;\n      const ret = oldVisitTripleConstraint.call(visitor, expr);\n      inTE = false;\n      currentNegated = lastNegated;\n      return ret;\n    };\n\n    const oldVisitShapeRef = visitor.visitShapeRef;\n    visitor.visitShapeRef = function (shapeRef) {\n      if (!(shapeRef in index.shapeExprs))\n        throw firstError(Error(\"Structural error: reference to \" + JSON.stringify(shapeRef) + \" not found in schema shape expressions:\\n\" + dumpKeys(index.shapeExprs) + \".\"), shapeRef);\n      if (!inTE && shapeRef === currentLabel)\n        throw firstError(Error(\"Structural error: circular reference to \" + currentLabel + \".\"), shapeRef);\n      (currentNegated ? negativeDeps : positiveDeps).add(currentLabel, shapeRef)\n      return oldVisitShapeRef.call(visitor, shapeRef);\n    }\n\n    const oldVisitInclusion = visitor.visitInclusion;\n    visitor.visitInclusion = function (inclusion) {\n      let refd;\n      if (!(refd = index.tripleExprs[inclusion]))\n        throw firstError(Error(\"Structural error: included shape \" + inclusion + \" not found in schema triple expressions:\\n\" + dumpKeys(index.tripleExprs) + \".\"), inclusion);\n      // if (refd.type !== \"Shape\")\n      //   throw Error(\"Structural error: \" + inclusion + \" is not a simple shape.\");\n      return oldVisitInclusion.call(visitor, inclusion);\n    };\n\n    (schema.shapes || []).forEach(function (shape) {\n      currentLabel = shape.id;\n      visitor.visitShapeDecl(shape, shape.id);\n    });\n    let circs = Object.keys(negativeDeps.children).filter(\n      k => negativeDeps.children[k].filter(\n        k2 => k2 in negativeDeps.children && negativeDeps.children[k2].indexOf(k) !== -1\n          || k2 in positiveDeps.children && positiveDeps.children[k2].indexOf(k) !== -1\n      ).length > 0\n    );\n    if (circs.length)\n      throw firstError(Error(\"Structural error: circular negative dependencies on \" + circs.join(',') + \".\"), circs[0]);\n\n    function dumpKeys (obj) {\n      return obj ? Object.keys(obj).map(\n        u => u.substr(0, 2) === '_:' ? u : '<' + u + '>'\n      ).join(\"\\n        \") : '- none defined -'\n    }\n\n    function firstError (e, obj) {\n      if (\"_sourceMap\" in schema)\n        e.location = (schema._sourceMap.get(obj) || [undefined])[0];\n      return e;\n    }\n  },\n\n  /** isWellDefined: assert that schema is well-defined.\n   *\n   * @schema: input schema\n   * @@TODO\n   */\n  isWellDefined: function (schema) {\n    this.validateSchema(schema);\n    // const deps = this.getDependencies(schema);\n    return schema;\n  },\n\n  walkVal: function (val, cb) {\n    const _ShExUtil = this;\n    if (typeof val === \"string\") { // ShapeRef\n      return null; // 1NOTRefOR1dot_pass-inOR\n    } else if (val.type === \"SolutionList\") { // dependent_shape\n      return val.solutions.reduce((ret, exp) => {\n        const n = _ShExUtil.walkVal(exp, cb);\n        if (n)\n          Object.keys(n).forEach(k => {\n            if (k in ret)\n              ret[k] = ret[k].concat(n[k]);\n            else\n              ret[k] = n[k];\n          })\n        return ret;\n      }, {});\n    } else if (val.type === \"NodeConstraintTest\") { // 1iri_pass-iri\n      return _ShExUtil.walkVal(val.shapeExpr, cb);\n    } else if (val.type === \"NodeConstraint\") { // 1iri_pass-iri\n      return null;\n    } else if (val.type === \"ShapeTest\") { // 0_empty\n      const vals = [];\n      visitSolution(val, vals); // A ShapeTest is a sort of Solution.\n      const ret = vals.length\n            ? {'http://shex.io/reflex': vals}\n            : {};\n      if (\"solution\" in val)\n        Object.assign(ret, _ShExUtil.walkVal(val.solution, cb))\n      return Object.keys(ret).length ? ret : null;\n    } else if (val.type === \"Shape\") { // 1NOTNOTdot_passIv1\n      return null;\n    } else if (val.type === \"ShapeNotTest\") { // 1NOT_vsANDvs__passIv1\n      return _ShExUtil.walkVal(val.shapeExpr, cb);\n    } else if (val.type === \"ShapeNotResults\") { // NOT1dotOR2dot_pass-empty\n      return _ShExUtil.walkVal(val.solution, cb);\n    } else if (val.type === \"Failure\") { // NOT1dotOR2dot_pass-empty\n      return null; // !!TODO\n    } else if (val.type === \"ShapeNot\") { // 1NOTNOTIRI_passIo1,\n      return _ShExUtil.walkVal(val.shapeExpr, cb);\n    } else if (val.type === \"ShapeOrResults\") { // 1dotRefOR3_passShape1\n      return _ShExUtil.walkVal(val.solution, cb);\n    } else if (val.type === \"ShapeOr\") { // 1NOT_literalORvs__passIo1\n      return val.shapeExprs.reduce((ret, exp) => {\n        const n = _ShExUtil.walkVal(exp, cb);\n        if (n)\n          Object.keys(n).forEach(k => {\n            if (k in ret)\n              ret[k] = ret[k].concat(n[k]);\n            else\n              ret[k] = n[k];\n          })\n        return ret;\n      }, {});\n    } else if (val.type === \"ShapeAndResults\" || // 1iriRef1_pass-iri\n               val.type === \"ExtensionResults\") { // extends-abstract-multi-empty_pass-missingOptRef1\n      return val.solutions.reduce((ret, exp) => {\n        const n = _ShExUtil.walkVal(exp, cb);\n        if (n)\n          Object.keys(n).forEach(k => {\n            if (k in ret)\n              ret[k] = ret[k].concat(n[k]);\n            else\n              ret[k] = n[k];\n          })\n        return ret;\n      }, {});\n    } else if (val.type === \"ShapeAnd\") { // 1NOT_literalANDvs__passIv1\n      return val.shapeExprs.reduce((ret, exp) => {\n        const n = _ShExUtil.walkVal(exp, cb);\n        if (n)\n          Object.keys(n).forEach(k => {\n            if (k in ret)\n              ret[k] = ret[k].concat(n[k]);\n            else\n              ret[k] = n[k];\n          })\n        return ret;\n      }, {});\n    } else if (val.type === \"ExtendedResults\") { // extends-abstract-multi-empty_pass-missingOptRef1\n      return ([\"extensions\", \"local\"]).reduce((ret, exp) => {\n        const n = _ShExUtil.walkVal(exp, cb);\n        if (n)\n          Object.keys(n).forEach(k => {\n            if (k in ret)\n              ret[k] = ret[k].concat(n[k]);\n            else\n              ret[k] = n[k];\n          })\n        return ret;\n      }, {});\n    } else if (val.type === \"EachOfSolutions\" || val.type === \"OneOfSolutions\") {\n      // 1dotOne2dot_pass_p1\n      return val.solutions.reduce((ret, sln) => {\n        sln.expressions.forEach(exp => {\n          const n = _ShExUtil.walkVal(exp, cb);\n          if (n)\n            Object.keys(n).forEach(k => {\n              if (k in ret)\n                ret[k] = ret[k].concat(n[k]);\n              else\n                ret[k] = n[k];\n            })\n        });\n        return ret;\n      }, {});\n    } else if (val.type === \"TripleConstraintSolutions\") { // 1dot_pass-noOthers\n      if (\"solutions\" in val) {\n        const ret = {};\n        const vals = [];\n        ret[val.predicate] = vals;\n        val.solutions.forEach(sln => visitSolution(sln, vals));\n        return vals.length ? ret : null;\n      } else {\n        return null;\n      }\n    } else if (val.type === \"Recursion\") { // 3circRefPlus1_pass-recursiveData\n      return null;\n    } else {\n      // console.log(val);\n      throw Error(\"unknown shapeExpression type in \" + JSON.stringify(val));\n    }\n    return val;\n\n        function visitSolution (sln, vals) {\n          const toAdd = [];\n          if (chaseList(sln.referenced, toAdd)) { // parse 1val1IRIREF.ttl\n            [].push.apply(vals, toAdd);\n          } else { // 1dot_pass-noOthers\n            const newElt = cb(sln) || {};\n            if (\"referenced\" in sln) {\n              const t = _ShExUtil.walkVal(sln.referenced, cb);\n              if (t)\n                newElt.nested = t;\n            }\n            if (Object.keys(newElt).length > 0)\n              vals.push(newElt);\n          }\n          function chaseList (li) {\n            if (!li) return false;\n            if (li.node === RDF.nil) return true;\n            if (\"solution\" in li && \"solutions\" in li.solution &&\n                li.solution.solutions.length === 1 &&\n                \"expressions\" in li.solution.solutions[0] &&\n                li.solution.solutions[0].expressions.length === 2 &&\n                \"predicate\" in li.solution.solutions[0].expressions[0] &&\n                li.solution.solutions[0].expressions[0].predicate === RDF.first &&\n                li.solution.solutions[0].expressions[1].predicate === RDF.rest) {\n              const expressions = li.solution.solutions[0].expressions;\n              const ent = expressions[0];\n              const rest = expressions[1].solutions[0];\n              const member = ent.solutions[0];\n              let newElt = cb(member);\n              if (\"referenced\" in member) {\n                const t = _ShExUtil.walkVal(member.referenced, cb);\n                if (t) {\n                  if (newElt)\n                    newElt.nested = t;\n                  else\n                    newElt = t;\n                }\n              }\n              if (newElt)\n                vals.push(newElt);\n              return rest.object === RDF.nil ?\n                true :\n                chaseList(rest.referenced.type === \"ShapeOrResults\" // heuristic for `nil OR @<list>` idiom\n                          ? rest.referenced.solution\n                          : rest.referenced);\n            }\n          }\n        }\n  },\n\n  /**\n   * Convert val results to a property tree.\n   * @exports\n   * @returns {@code {p1:[{p2: v2},{p3: v3}]}}\n   */\n  valToValues: function (val) {\n    return this.walkVal (val, function (sln) {\n      return \"object\" in sln ? { ldterm: sln.object } : null;\n    });\n  },\n\n  valToExtension: function (val, lookfor) {\n    const map = this.walkVal (val, function (sln) {\n      return \"extensions\" in sln ? { extensions: sln.extensions } : null;\n    });\n    function extensions (obj) {\n      const list = [];\n      let crushed = {};\n      function crush (elt) {\n        if (crushed === null)\n          return elt;\n        if (Array.isArray(elt)) {\n          crushed = null;\n          return elt;\n        }\n        for (k in elt) {\n          if (k in crushed) {\n            crushed = null\n            return elt;\n          }\n          crushed[k] = ldify(elt[k]);\n        }\n        return elt;\n      }\n      for (let k in obj) {\n        if (k === \"extensions\") {\n          if (obj[k])\n            list.push(crush(ldify(obj[k][lookfor])));\n        } else if (k === \"nested\") {\n          const nested = extensions(obj[k]);\n          if (Array.isArray(nested))\n            nested.forEach(crush);\n          else\n            crush(nested);\n          list.push(nested);\n        } else {\n          list.push(crush(extensions(obj[k])));\n        }\n      }\n      return list.length === 1 ? list[0] :\n        crushed ? crushed :\n        list;\n    }\n    return extensions(map);\n  },\n\n  valuesToSchema: function (values) {\n    // console.log(JSON.stringify(values, null, \"  \"));\n    const v = values;\n    const t = values[RDF.type][0].ldterm;\n    if (t === SX.Schema) {\n      /* Schema { \"@context\":\"http://www.w3.org/ns/shex.jsonld\"\n       *           startActs:[SemAct+]? start:(shapeExpr|labeledShapeExpr)?\n       *           shapes:[labeledShapeExpr+]? }\n       */\n      const ret = {\n        \"@context\": \"http://www.w3.org/ns/shex.jsonld\",\n        type: \"Schema\"\n      }\n      if (SX.startActs in v)\n        ret.startActs = v[SX.startActs].map(e => {\n          const ret = {\n            type: \"SemAct\",\n            name: e.nested[SX.name][0].ldterm\n          };\n          if (SX.code in e.nested)\n            ret.code = e.nested[SX.code][0].ldterm.value;\n          return ret;\n        });\n      if (SX.imports in v)\n        ret.imports = v[SX.imports].map(e => {\n          return e.ldterm;\n        });\n      if (values[SX.start])\n        ret.start = extend({id: values[SX.start][0].ldterm}, shapeExpr(values[SX.start][0].nested));\n      const shapes = values[SX.shapes];\n      if (shapes) {\n        ret.shapes = shapes.map(v => { // @@ console.log(v.nested);\n          var t = v.nested[RDF.type][0].ldterm;\n          var obj = t === SX.ShapeDecl ?\n              {\n                type: SX.ShapeDecl,\n                abstract: !!v.nested[SX[\"abstract\"]][0].ldterm.value,\n                shapeExpr: shapeExpr(v.nested[SX.shapeExpr][0].nested)\n              } :\n              shapeExpr(v.nested);\n          return extend({id: v.ldterm}, obj);\n        });\n      }\n      // console.log(ret);\n      return ret;\n    } else {\n      throw Error(\"unknown schema type in \" + JSON.stringify(values));\n    }\n    function findType (v, elts, f) {\n      const t = v[RDF.type][0].ldterm.substr(SX._namespace.length);\n      const elt = elts[t];\n      if (!elt)\n        return Missed;\n      if (elt.nary) {\n        const ret = {\n          type: t,\n        };\n        ret[elt.prop] = v[SX[elt.prop]].map(e => {\n          return valueOf(e);\n        });\n        return ret;\n      } else {\n        const ret = {\n          type: t\n        };\n        if (elt.prop) {\n          ret[elt.prop] = valueOf(v[SX[elt.prop]][0]);\n        }\n        return ret;\n      }\n\n      function valueOf (x) {\n        return elt.expr && \"nested\" in x ? extend({ id: x.ldterm, }, f(x.nested)) : x.ldterm;\n      }\n    }\n    function shapeExpr (v) {\n      // shapeExpr = ShapeOr | ShapeAnd | ShapeNot | NodeConstraint | Shape | ShapeRef | ShapeExternal;\n      const elts = { \"ShapeAnd\"     : { nary: true , expr: true , prop: \"shapeExprs\" },\n                   \"ShapeOr\"      : { nary: true , expr: true , prop: \"shapeExprs\" },\n                   \"ShapeNot\"     : { nary: false, expr: true , prop: \"shapeExpr\"  },\n                   \"ShapeRef\"     : { nary: false, expr: false, prop: \"reference\"  },\n                   \"ShapeExternal\": { nary: false, expr: false, prop: null         } };\n      const ret = findType(v, elts, shapeExpr);\n      if (ret !== Missed)\n        return ret;\n\n      const t = v[RDF.type][0].ldterm;\n      if (t === SX.ShapeDecl) {\n        const ret = { type: \"ShapeDecl\" };\n        [\"abstract\"].forEach(a => {\n          if (SX[a] in v)\n            ret[a] = !!v[SX[a]][0].ldterm.value;\n        });\n        if (SX.shapeExpr in v) {\n          ret.shapeExpr =\n            \"nested\" in v[SX.shapeExpr][0] ?\n            extend({id: v[SX.shapeExpr][0].ldterm}, shapeExpr(v[SX.shapeExpr][0].nested)) :\n            v[SX.shapeExpr][0].ldterm;\n        }\n        return ret;\n      } else if (t === SX.Shape) {\n        const ret = { type: \"Shape\" };\n        [\"closed\"].forEach(a => {\n          if (SX[a] in v)\n            ret[a] = !!v[SX[a]][0].ldterm.value;\n        });\n        [\"extra\", \"extends\", \"restricts\"].forEach(a => {\n          if (SX[a] in v)\n            ret[a] = v[SX[a]].map(e => { return e.ldterm; });\n        });\n        if (SX.expression in v) {\n          ret.expression =\n            \"nested\" in v[SX.expression][0] ?\n            extend({id: v[SX.expression][0].ldterm}, tripleExpr(v[SX.expression][0].nested)) :\n            v[SX.expression][0].ldterm;\n        }\n        if (SX.annotation in v)\n          ret.annotations = v[SX.annotation].map(e => {\n            return {\n              type: \"Annotation\",\n              predicate: e.nested[SX.predicate][0].ldterm,\n              object: e.nested[SX.object][0].ldterm\n            };\n          });\n        if (SX.semActs in v)\n          ret.semActs = v[SX.semActs].map(e => {\n            const ret = {\n              type: \"SemAct\",\n              name: e.nested[SX.name][0].ldterm\n            };\n            if (SX.code in e.nested)\n              ret.code = e.nested[SX.code][0].ldterm.value;\n            return ret;\n          });\n        return ret;\n      } else if (t === SX.NodeConstraint) {\n        const ret = { type: \"NodeConstraint\" };\n        if (SX.values in v)\n          ret.values = v[SX.values].map(v1 => { return objectValue(v1); });\n        if (SX.nodeKind in v)\n          ret.nodeKind = v[SX.nodeKind][0].ldterm.substr(SX._namespace.length);\n        [\"length\", \"minlength\", \"maxlength\", \"mininclusive\", \"maxinclusive\", \"minexclusive\", \"maxexclusive\", \"totaldigits\", \"fractiondigits\"].forEach(a => {\n          if (SX[a] in v)\n            ret[a] = parseFloat(v[SX[a]][0].ldterm.value);\n        });\n        if (SX.pattern in v)\n          ret.pattern = v[SX.pattern][0].ldterm.value;\n        if (SX.flags in v)\n          ret.flags = v[SX.flags][0].ldterm.value;\n        if (SX.datatype in v)\n          ret.datatype = v[SX.datatype][0].ldterm;\n        return ret;\n      } else {\n        throw Error(\"unknown shapeExpr type in \" + JSON.stringify(v));\n      }\n\n    }\n\n    function objectValue (v, expectString) {\n      if (\"nested\" in v) {\n        const t = v.nested[RDF.type][0].ldterm;\n        if ([SX.IriStem, SX.LiteralStem, SX.LanguageStem].indexOf(t) !== -1) {\n          const ldterm = v.nested[SX.stem][0].ldterm.value;\n          return {\n            type: t.substr(SX._namespace.length),\n            stem: ldterm\n          };\n        } else if ([SX.Language].indexOf(t) !== -1) {\n          return {\n            type: \"Language\",\n            languageTag: v.nested[SX.languageTag][0].ldterm.value\n          };\n        } else if ([SX.IriStemRange, SX.LiteralStemRange, SX.LanguageStemRange].indexOf(t) !== -1) {\n          const st = v.nested[SX.stem][0];\n          let stem = st;\n          if (typeof st === \"object\") {\n            if (typeof st.ldterm === \"object\") {\n              stem = st.ldterm;\n            } else if (st.ldterm.startsWith(\"_:\")) {\n              stem = { type: \"Wildcard\" };\n            }\n          }\n          const ret = {\n            type: t.substr(SX._namespace.length),\n            stem: stem.type !== \"Wildcard\" ? stem.value : stem\n          };\n          if (SX.exclusion in v.nested) {\n            // IriStemRange:\n            // * [{\"ldterm\":\"http://a.example/v1\"},{\"ldterm\":\"http://a.example/v3\"}] <-- no value\n            // * [{\"ldterm\":\"_:b836\",\"nested\":{a:[{\"ldterm\":sx:IriStem}],\n            //                                 sx:stem:[{\"ldterm\":{\"value\":\"http://a.example/v1\"}}]}},\n            //    {\"ldterm\":\"_:b838\",\"nested\":{a:[{\"ldterm\":sx:IriStem}],\n            //                                 sx:stem:[{\"ldterm\":{\"value\":\"http://a.example/v3\"}}]}}]\n\n            // LiteralStemRange:\n            // * [{\"ldterm\":{\"value\":\"v1\"}},{\"ldterm\":{\"value\":\"v3\"}}]\n            // * [{\"ldterm\":\"_:b866\",\"nested\":{a:[{\"ldterm\":sx:LiteralStem}],\n            //                                 sx:stem:[{\"ldterm\":{\"value\":\"v1\"}}]}},\n            //    {\"ldterm\":\"_:b868\",\"nested\":{a:[{\"ldterm\":sx:LiteralStem}],\n            //                                 sx:stem:[{\"ldterm\":{\"value\":\"v3\"}}]}}]\n\n            // LanguageStemRange:\n            // * [{\"ldterm\":{\"value\":\"fr-be\"}},{\"ldterm\":{\"value\":\"fr-ch\"}}]\n            // * [{\"ldterm\":\"_:b851\",\"nested\":{a:[{\"ldterm\":sx:LanguageStem}],\n            //                                 sx:stem:[{\"ldterm\":{\"value\":\"fr-be\"}}]}},\n            //    {\"ldterm\":\"_:b853\",\"nested\":{a:[{\"ldterm\":sx:LanguageStem}],\n            //                                 sx:stem:[{\"ldterm\":{\"value\":\"fr-ch\"}}]}}]\n            ret.exclusions = v.nested[SX.exclusion].map(v1 => {\n              return objectValue(v1, t !== SX.IriStemRange);\n            });\n          }\n          return ret;\n        } else {\n          throw Error(\"unknown objectValue type in \" + JSON.stringify(v));\n        }\n      } else {\n        return expectString ? v.ldterm.value : v.ldterm;\n      }\n    }\n\n    function tripleExpr (v) {\n      // tripleExpr = EachOf | OneOf | TripleConstraint | Inclusion ;\n      const elts = { \"EachOf\"   : { nary: true , expr: true , prop: \"expressions\" },\n                   \"OneOf\"    : { nary: true , expr: true , prop: \"expressions\" },\n                   \"Inclusion\": { nary: false, expr: false, prop: \"include\"     } };\n      const ret = findType(v, elts, tripleExpr);\n      if (ret !== Missed) {\n        minMaxAnnotSemActs(v, ret);\n        return ret;\n      }\n\n      const t = v[RDF.type][0].ldterm;\n      if (t === SX.TripleConstraint) {\n        const ret = {\n          type: \"TripleConstraint\",\n          predicate: v[SX.predicate][0].ldterm\n        };\n        [\"inverse\"].forEach(a => {\n          if (SX[a] in v)\n            ret[a] = !!v[SX[a]][0].ldterm.value;\n        });\n        if (SX.valueExpr in v)\n          ret.valueExpr = extend({id: v[SX.valueExpr][0].ldterm}, \"nested\" in v[SX.valueExpr][0] ? shapeExpr(v[SX.valueExpr][0].nested) : {});\n        minMaxAnnotSemActs(v, ret);\n        return ret;\n      } else {\n        throw Error(\"unknown tripleExpr type in \" + JSON.stringify(v));\n      }\n    }\n    function minMaxAnnotSemActs (v, ret) {\n      if (SX.min in v)\n        ret.min = parseInt(v[SX.min][0].ldterm.value);\n      if (SX.max in v) {\n        ret.max = parseInt(v[SX.max][0].ldterm.value);\n        if (isNaN(ret.max))\n          ret.max = UNBOUNDED;\n      }\n      if (SX.annotation in v)\n        ret.annotations = v[SX.annotation].map(e => {\n          return {\n            type: \"Annotation\",\n            predicate: e.nested[SX.predicate][0].ldterm,\n            object: e.nested[SX.object][0].ldterm\n          };\n        });\n      if (SX.semActs in v)\n        ret.semActs = v[SX.semActs].map(e => {\n          const ret = {\n            type: \"SemAct\",\n            name: e.nested[SX.name][0].ldterm\n          };\n          if (SX.code in e.nested)\n            ret.code = e.nested[SX.code][0].ldterm.value;\n          return ret;\n        });\n      return ret;\n    }\n  },\n/* -- deprecated\n  valToSimple: function (val) {\n    const _ShExUtil = this;\n    function _join (list) {\n      return list.reduce((ret, elt) => {\n        Object.keys(elt).forEach(k => {\n          if (k in ret) {\n            ret[k] = Array.from(new Set(ret[k].concat(elt[k])));\n          } else {\n            ret[k] = elt[k];\n          }\n        });\n        return ret;\n      }, {});\n    }\n    if (typeof val === \"string\") {\n      return val\n    } else if (val.type === \"TripleConstraintSolutions\") {\n      if (\"solutions\" in val) {\n        return val.solutions.reduce((ret, sln) => {\n          if (!(\"referenced\" in sln))\n            return {};\n          const toAdd = {};\n          if (chaseList(sln.referenced, toAdd)) {\n            return _join(ret, toAdd);\n          } else {\n            return _join(ret, _ShExUtil.valToSimple(sln.referenced));\n          }\n          function chaseList (li) {\n            if (!li) return false;\n            if (li.node === RDF.nil) return true;\n            if (\"solution\" in li && \"solutions\" in li.solution &&\n                li.solution.solutions.length === 1 &&\n                \"expressions\" in li.solution.solutions[0] &&\n                li.solution.solutions[0].expressions.length === 2 &&\n                \"predicate\" in li.solution.solutions[0].expressions[0] &&\n                li.solution.solutions[0].expressions[0].predicate === RDF.first &&\n                li.solution.solutions[0].expressions[1].predicate === RDF.rest) {\n              const expressions = li.solution.solutions[0].expressions;\n              const ent = expressions[0];\n              const rest = expressions[1].solutions[0];\n              const member = ent.solutions[0];\n              const newElt = { ldterm: member.object };\n              if (\"referenced\" in member) {\n                const t = _ShExUtil.valToSimple(member.referenced);\n                if (t)\n                  newElt.nested = t;\n              }\n              toAdd = _join(toAdd, newElt);\n              return rest.object === RDF.nil ?\n                true :\n                chaseList(rest.referenced.type === \"ShapeOrResults\" // heuristic for `nil  OR @<list>` idiom\n                          ? rest.referenced.solution\n                          : rest.referenced);\n            }\n          }\n        }, []);\n      } else {\n        return [];\n      }\n    } else if ([\"TripleConstraintSolutions\"].indexOf(val.type) !== -1) {\n      return {  };\n    } else if (val.type === \"NodeConstraintTest\") {\n      return _ShExUtil.valToSimple(val.shapeExpr);\n    } else if (val.type === \"NodeConstraint\") {\n      const thisNode = {  };\n      thisNode[n3ify(val.focus)] = [val.shape];\n      return thisNode;\n    } else if (val.type === \"ShapeTest\") {\n      const thisNode = {  };\n      thisNode[n3ify(val.node)] = [val.shape];\n      return \"solution\" in val ? _join([thisNode].concat(_ShExUtil.valToSimple(val.solution))) : thisNode;\n    } else if (val.type === \"Shape\") {\n      const thisNode = {  };\n      thisNode[n3ify(val.node)] = [val.shape];\n      return thisNode;\n    } else if (val.type === \"ShapeNotTest\") {\n      const thisNode = {  };\n      thisNode[n3ify(val.node)] = [val.shape];\n      return _join(['NOT1'].concat(_ShExUtil.valToSimple(val.shapeExpr)));\n    } else if (val.type === \"ShapeNot\") {\n      const thisNode = {  };\n      thisNode[n3ify(val.node)] = [val.shape];\n      return _join(['NOT'].concat(_ShExUtil.valToSimple(val.shapeExpr)));\n    } else if (val.type === \"ShapeAnd\") {\n      return val.shapeExprs.map(shapeExpr => _ShExUtil.valToSimple(shapeExpr)).join ('AND');\n    } else if (val.type === \"ShapeOr\") {\n      return val.shapeExprs.map(shapeExpr => _ShExUtil.valToSimple(shapeExpr)).join ('OR');\n    } else if (val.type === \"Failure\") {\n      return _ShExUtil.errsToSimple(val);\n    } else if (val.type === \"Recursion\") {\n      return {  };\n    } else if (\"solutions\" in val) {\n      // [\"SolutionList\", \"EachOfSolutions\", \"OneOfSolutions\", \"ShapeAndResults\", \"ShapeOrResults\"].indexOf(val.type) !== -1\n      return _join(val.solutions.map(sln => {\n        return _ShExUtil.valToSimple(sln);\n      }));\n    } else if (\"solution\" in val) {\n      // [\"SolutionList\", \"EachOfSolutions\", \"OneOfSolutions\", \"ShapeAndResults\", \"ShapeOrResults\"].indexOf(val.type) !== -1\n      return _ShExUtil.valToSimple(val.solution);\n    } else if (\"expressions\" in val) {\n      return _join(val.expressions.map(sln => {\n        return _ShExUtil.valToSimple(sln);\n      }));\n    } else {\n      // console.log(val);\n      throw Error(\"unknown shapeExpression type in \" + JSON.stringify(val));\n    }\n    return val;\n  },\n*/\n  simpleToShapeMap: function (x) {\n    return Object.keys(x).reduce((ret, k) => {\n      x[k].forEach(s => {\n        ret.push({node: k, shape: s });\n      });\n      return ret;\n    }, []);\n  },\n\n  absolutizeShapeMap: function (parsed, base) {\n    return parsed.map(elt => {\n      return Object.assign(elt, {\n        node: ShExTerm.resolveRelativeIRI(base, elt.node),\n        shape: ShExTerm.resolveRelativeIRI(base, elt.shape)\n      });\n    });\n  },\n\n  errsToSimple: function (val) {\n    const _ShExUtil = this;\n    if (val.type === \"FailureList\") {\n      return val.errors.reduce((ret, e) => {\n        return ret.concat(_ShExUtil.errsToSimple(e));\n      }, []);\n    } else if (val.type === \"Failure\") {\n      return [\"validating \" + val.node + \" as \" + val.shape + \":\"].concat(errorList(val.errors).reduce((ret, e) => {\n        const nested = _ShExUtil.errsToSimple(e).map(s => \"  \" + s);\n        return ret.length > 0 ? ret.concat([\"  OR\"]).concat(nested) : nested.map(s => \"  \" + s);\n      }, []));\n    } else if (val.type === \"TypeMismatch\") {\n      const nested = Array.isArray(val.errors) ?\n          val.errors.reduce((ret, e) => {\n            return ret.concat((typeof e === \"string\" ? [e] : _ShExUtil.errsToSimple(e)).map(s => \"  \" + s));\n          }, []) :\n          \"  \" + (typeof e === \"string\" ? [val.errors] : _ShExUtil.errsToSimple(val.errors));\n      return [\"validating \" + n3ify(val.triple.object) + \":\"].concat(nested);\n    } else if (val.type === \"RestrictionError\") {\n      var nested = val.errors.constructor === Array ?\n          val.errors.reduce((ret, e) => {\n            return ret.concat((typeof e === \"string\" ? [e] : _ShExUtil.errsToSimple(e)).map(s => \"  \" + s));\n          }, []) :\n          \"  \" + (typeof e === \"string\" ? [val.errors] : _ShExUtil.errsToSimple(val.errors));\n      return [\"validating restrictions on \" + n3ify(val.focus) + \":\"].concat(nested);\n    } else if (val.type === \"ShapeAndFailure\") {\n      return Array.isArray(val.errors) ?\n          val.errors.reduce((ret, e) => {\n            return ret.concat((typeof e === \"string\" ? [e] : _ShExUtil.errsToSimple(e)).map(s => \"  \" + s));\n          }, []) :\n          \"  \" + (typeof e === \"string\" ? [val.errors] : _ShExUtil.errsToSimple(val.errors));\n    } else if (val.type === \"ShapeOrFailure\") {\n      return Array.isArray(val.errors) ?\n          val.errors.reduce((ret, e) => {\n            return ret.concat(\" OR \" + (typeof e === \"string\" ? [e] : _ShExUtil.errsToSimple(e)));\n          }, []) :\n          \" OR \" + (typeof e === \"string\" ? [val.errors] : _ShExUtil.errsToSimple(val.errors));\n    } else if (val.type === \"ShapeNotFailure\") {\n      return [\"Node \" + val.errors.node + \" expected to NOT pass \" + val.errors.shape];\n    } else if (val.type === \"ExcessTripleViolation\") {\n      return [\"validating \" + n3ify(val.triple.object) + \": exceeds cardinality\"];\n    } else if (val.type === \"ClosedShapeViolation\") {\n      return [\"Unexpected triple(s): {\"].concat(\n        val.unexpectedTriples.map(t => {\n          return \"  \" + t.subject + \" \" + t.predicate + \" \" + n3ify(t.object) + \" .\"\n        })\n      ).concat([\"}\"]);\n    } else if (val.type === \"NodeConstraintViolation\") {\n      const w = __webpack_require__(/*! @shexjs/writer */ \"../fhirlib/node_modules/@shexjs/writer/shex-writer.js\")();\n      w._write(w._writeNodeConstraint(val.shapeExpr).join(\"\"));\n      let txt;\n      w.end((err, res) => {\n        txt = res;\n      });\n      return [\"NodeConstraintError: expected to match \" + txt];\n    } else if (val.type === \"MissingProperty\") {\n      return [\"Missing property: \" + val.property];\n    } else if (val.type === \"NegatedProperty\") {\n      return [\"Unexpected property: \" + val.property];\n    } else if (val.type === \"AbstractShapeFailure\") {\n      return [\"Abstract Shape: \" + val.shape];\n    } else if (Array.isArray(val)) {\n      return val.reduce((ret, e) => {\n        const nested = _ShExUtil.errsToSimple(e).map(s => \"  \" + s);\n        return ret.length ? ret.concat([\"AND\"]).concat(nested) : nested;\n      }, []);\n    } else if (val.type === \"SemActFailure\") {\n      const nested = Array.isArray(val.errors) ?\n          val.errors.reduce((ret, e) => {\n            return ret.concat((typeof e === \"string\" ? [e] : _ShExUtil.errsToSimple(e)).map(s => \"  \" + s));\n          }, []) :\n          \"  \" + (typeof e === \"string\" ? [val.errors] : _ShExUtil.errsToSimple(val.errors));\n      return [\"rejected by semantic action:\"].concat(nested);\n    } else if (val.type === \"SemActViolation\") {\n      return [val.message];\n    } else if (val.type === \"BooleanSemActFailure\") {\n      return [\"Failed evaluating \" + val.code + \" on context \" + JSON.stringify(val.ctx)];\n    } else {\n      debugger; // console.log(val);\n      throw Error(\"unknown shapeExpression type \\\"\" + val.type + \"\\\" in \" + JSON.stringify(val));\n    }\n    function errorList (errors) {\n      return errors.reduce(function (acc, e) {\n        const attrs = Object.keys(e);\n        return acc.concat(\n          (attrs.length === 1 && attrs[0] === \"errors\")\n            ? errorList(e.errors)\n            : e);\n      }, []);\n    }\n  },\n\n  resolveRelativeIRI: ShExTerm.resolveRelativeIRI,\n\n  resolvePrefixedIRI: function (prefixedIri, prefixes) {\n    const colon = prefixedIri.indexOf(\":\");\n    if (colon === -1)\n      return null;\n    const prefix = prefixes[prefixedIri.substr(0, colon)];\n    return prefix === undefined ? null : prefix + prefixedIri.substr(colon+1);\n  },\n\n  parsePassedNode: function (passedValue, meta, deflt, known, reportUnknown) {\n    if (passedValue === undefined || passedValue.length === 0)\n      return known && known(meta.base) ? meta.base : deflt ? deflt() : this.NotSupplied;\n    if (passedValue[0] === \"_\" && passedValue[1] === \":\")\n      return passedValue;\n    if (passedValue[0] === \"\\\"\") {\n      const m = passedValue.match(/^\"((?:[^\"\\\\]|\\\\\")*)\"(?:@(.+)|\\^\\^(?:<(.*)>|([^:]*):(.*)))?$/);\n      if (!m)\n        throw Error(\"malformed literal: \" + passedValue);\n      const lex = m[1], lang = m[2], rel = m[3], pre = m[4], local = m[5];\n      // Turn the literal into an N3.js atom.\n      const quoted = \"\\\"\"+lex+\"\\\"\";\n      if (lang !== undefined)\n        return quoted + \"@\" + lang;\n      if (pre !== undefined) {\n        if (!(pre in meta.prefixes))\n          throw Error(\"error parsing node \"+passedValue+\" no prefix for \\\"\" + pre + \"\\\"\");\n        return quoted + \"^^\" + meta.prefixes[pre] + local;\n      }\n      if (rel !== undefined)\n        return quoted + \"^^\" + ShExTerm.resolveRelativeIRI(meta.base, rel);\n      return quoted;\n    }\n    if (!meta)\n      return known(passedValue) ? passedValue : this.UnknownIRI;\n    const relIRI = passedValue[0] === \"<\" && passedValue[passedValue.length-1] === \">\";\n    if (relIRI)\n      passedValue = passedValue.substr(1, passedValue.length-2);\n    const t = ShExTerm.resolveRelativeIRI(meta.base || \"\", passedValue); // fall back to base-less mode\n    if (known(t))\n      return t;\n    if (!relIRI) {\n      const t2 = this.resolvePrefixedIRI(passedValue, meta.prefixes);\n      if (t2 !== null && known(t2))\n        return t2;\n    }\n    return reportUnknown ? reportUnknown(t) : this.UnknownIRI;\n  },\n\n  executeQueryPromise: function (query, endpoint) {\n    let rows;\n\n    const queryURL = endpoint + \"?query=\" + encodeURIComponent(query);\n    return fetch(queryURL, {\n      headers: {\n        'Accept': 'application/sparql-results+json'\n      }}).then(resp => resp.json()).then(t => {\n        const selects = t.head.vars;\n        return t.results.bindings.map(row => {\n          return selects.map(sel => {\n            const elt = row[sel];\n            switch (elt.type) {\n            case \"uri\": return elt.value;\n            case \"bnode\": return \"_:\" + elt.value;\n            case \"literal\":\n              const datatype = elt.datatype;\n              const lang = elt[\"xml:lang\"];\n              return \"\\\"\" + elt.value + \"\\\"\" + (\n                datatype ? \"^^\" + datatype :\n                  lang ? \"@\" + lang :\n                  \"\");\n            default: throw \"unknown XML results type: \" + elt.prop(\"tagName\");\n            }\n            return row[sel];\n          })\n        });\n      })// .then(x => new Promise(resolve => setTimeout(() => resolve(x), 1000)));\n  },\n\n  executeQuery: function (query, endpoint) {\n    let rows;\n    const queryURL = endpoint + \"?query=\" + encodeURIComponent(query);\n    const xhr = new XMLHttpRequest();\n    xhr.open(\"GET\", queryURL, false);\n    xhr.setRequestHeader('Accept', 'application/sparql-results+json');\n    xhr.send();\n    // const selectsBlock = query.match(/SELECT\\s*(.*?)\\s*{/)[1];\n    // const selects = selectsBlock.match(/\\?[^\\s?]+/g);\n    const t = JSON.parse(xhr.responseText);\n    const selects = t.head.vars;\n    return t.results.bindings.map(row => {\n      return selects.map(sel => {\n        const elt = row[sel];\n        switch (elt.type) {\n        case \"uri\": return elt.value;\n        case \"bnode\": return \"_:\" + elt.value;\n        case \"literal\":\n          const datatype = elt.datatype;\n          const lang = elt[\"xml:lang\"];\n          return \"\\\"\" + elt.value + \"\\\"\" + (\n            datatype ? \"^^\" + datatype :\n              lang ? \"@\" + lang :\n              \"\");\n        default: throw \"unknown XML results type: \" + elt.prop(\"tagName\");\n        }\n        return row[sel];\n      })\n    });\n\n/* TO ADD? XML results format parsed with jquery:\n        $(data).find(\"sparql > results > result\").\n          each((_, row) => {\n            rows.push($(row).find(\"binding > *:nth-child(1)\").\n              map((idx, elt) => {\n                elt = $(elt);\n                const text = elt.text();\n                switch (elt.prop(\"tagName\")) {\n                case \"uri\": return text;\n                case \"bnode\": return \"_:\" + text;\n                case \"literal\":\n                  const datatype = elt.attr(\"datatype\");\n                  const lang = elt.attr(\"xml:lang\");\n                  return \"\\\"\" + text + \"\\\"\" + (\n                    datatype ? \"^^\" + datatype :\n                    lang ? \"@\" + lang :\n                      \"\");\n                default: throw \"unknown XML results type: \" + elt.prop(\"tagName\");\n                }\n              }).get());\n          });\n*/\n  },\n\n  rdfjsDB: function (db /*:typeof N3Store*/, queryTracker /*:QueryTracker*/) {\n\n    function getSubjects () { return db.getSubjects().map(ShExTerm.internalTerm); }\n    function getPredicates () { return db.getPredicates().map(ShExTerm.internalTerm); }\n    function getObjects () { return db.getObjects().map(ShExTerm.internalTerm); }\n    function getQuads ()/*: Quad[]*/ { return db.getQuads.apply(db, arguments).map(ShExTerm.internalTriple); }\n\n    function getNeighborhood (point/*: string*/, shapeLabel/*: string*//*, shape */) {\n      // I'm guessing a local DB doesn't benefit from shape optimization.\n      let startTime;\n      if (queryTracker) {\n        startTime = new Date();\n        queryTracker.start(false, point, shapeLabel);\n      }\n      const outgoing/*: Quad[]*/ = db.getQuads(point, null, null, null).map(ShExTerm.internalTriple);\n      if (queryTracker) {\n        const time = new Date();\n        queryTracker.end(outgoing, time.valueOf() - startTime.valueOf());\n        startTime = time;\n      }\n      if (queryTracker) {\n        queryTracker.start(true, point, shapeLabel);\n      }\n      const incoming/*: Quad[]*/ = db.getQuads(null, null, point, null).map(ShExTerm.internalTriple);\n      if (queryTracker) {\n        queryTracker.end(incoming, new Date().valueOf() - startTime.valueOf());\n      }\n      return {\n        outgoing: outgoing,\n        incoming: incoming\n      };\n    }\n\n    return {\n      // size: db.size,\n      getNeighborhood: getNeighborhood,\n      getSubjects: getSubjects,\n      getPredicates: getPredicates,\n      getObjects: getObjects,\n      getQuads: getQuads,\n      get size() { return db.size; },\n      // getQuads: function (s, p, o, graph, shapeLabel) {\n      //   // console.log(Error(s + p + o).stack)\n      //   if (queryTracker)\n      //     queryTracker.start(!!s, s ? s : o, shapeLabel);\n      //   const quads = db.getQuads(s, p, o, graph)\n      //   if (queryTracker)\n      //     queryTracker.end(quads, new Date() - startTime);\n      //   return quads;\n      // }\n    }\n  },\n\n  /** Directly construct a DB from triples.\n   */\n  makeTriplesDB: function (queryTracker) {\n    var _ShExUtil = this;\n    var incoming = [];\n    var outgoing = [];\n\n    function getTriplesByIRI(s, p, o, g) {\n      return incoming.concat(outgoing).filter(\n        t =>\n          (!s || s === t.subject) &&\n          (!p || p === t.predicate) &&\n          (!s || s === t.object)\n      );\n    }\n\n    function getNeighborhood (point, shapeLabel, shape) {\n      return {\n        outgoing: outgoing,\n        incoming: incoming\n      };\n    }\n\n    return {\n      getNeighborhood: getNeighborhood,\n      getTriplesByIRI: getTriplesByIRI,\n      getSubjects: function () { return [\"!Triples DB can't index subjects\"] },\n      getPredicates: function () { return [\"!Triples DB can't index predicates\"] },\n      getObjects: function () { return [\"!Triples DB can't index objects\"] },\n      get size() { return undefined; },\n      addIncomingTriples: function (tz) { Array.prototype.push.apply(incoming, tz); },\n      addOutgoingTriples: function (tz) { Array.prototype.push.apply(outgoing, tz); }\n    };\n  },\n\n  NotSupplied: \"-- not supplied --\", UnknownIRI: \"-- not found --\",\n\n  /**\n   * unescape numerics and allowed single-character escapes.\n   * throws: if there are any unallowed sequences\n   */\n  unescapeText: function (string, replacements) {\n    const regex = /\\\\u([a-fA-F0-9]{4})|\\\\U([a-fA-F0-9]{8})|\\\\(.)/g;\n    try {\n      string = string.replace(regex, function (sequence, unicode4, unicode8, escapedChar) {\n        let charCode;\n        if (unicode4) {\n          charCode = parseInt(unicode4, 16);\n          if (isNaN(charCode)) throw new Error(); // can never happen (regex), but helps performance\n          return String.fromCharCode(charCode);\n        }\n        else if (unicode8) {\n          charCode = parseInt(unicode8, 16);\n          if (isNaN(charCode)) throw new Error(); // can never happen (regex), but helps performance\n          if (charCode < 0xFFFF) return String.fromCharCode(charCode);\n          return String.fromCharCode(0xD800 + ((charCode -= 0x10000) >> 10), 0xDC00 + (charCode & 0x3FF));\n        }\n        else {\n          const replacement = replacements[escapedChar];\n          if (!replacement) throw new Error(\"no replacement found for '\" + escapedChar + \"'\");\n          return replacement;\n        }\n      });\n      return string;\n    }\n    catch (error) { console.warn(error); return ''; }\n  },\n\n};\n\nfunction n3ify (ldterm) {\n  if (typeof ldterm !== \"object\")\n    return ldterm;\n  const ret = \"\\\"\" + ldterm.value + \"\\\"\";\n  if (\"language\" in ldterm)\n    return ret + \"@\" + ldterm.language;\n  if (\"type\" in ldterm)\n    return ret + \"^^\" + ldterm.type;\n  return ret;\n}\n\n// Add the ShExUtil functions to the given object or its prototype\nfunction AddShExUtil(parent, toPrototype) {\n  for (let name in ShExUtil)\n    if (!toPrototype)\n      parent[name] = ShExUtil[name];\n    else\n      parent.prototype[name] = ApplyToThis(ShExUtil[name]);\n\n  return parent;\n}\n\n// Returns a function that applies `f` to the `this` object\nfunction ApplyToThis(f) {\n  return function (a) { return f(this, a); };\n}\n\nreturn AddShExUtil(AddShExUtil);\n})();\n\nif (true)\n  module.exports = ShExUtilCjsModule; // node environment\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/@shexjs/util/shex-util.js?");

/***/ }),

/***/ "../fhirlib/node_modules/@shexjs/validator/shex-validator.js":
/*!*******************************************************************!*\
  !*** ../fhirlib/node_modules/@shexjs/validator/shex-validator.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* ShExValidator - javascript module to validate a graph with respect to Shape Expressions\n *\n * Status: 1/2 tested, no known bugs.\n *\n * TODO:\n *   constraint violation reporting.\n */\n\nconst ShExValidatorCjsModule = (function () {\nconst UNBOUNDED = -1;\n\n// interface constants\nconst Start = { term: \"START\" }\nconst InterfaceOptions = {\n  \"coverage\": {\n    \"firstError\": \"fail on first error (usually used with eval-simple-1err)\",\n    \"exhaustive\": \"find as many errors as possible (usually used with eval-threaded-nerr)\"\n  }\n};\n\nconst VERBOSE = false; // \"VERBOSE\" in process.env;\n// **ShExValidator** provides ShEx utility functions\n\nconst ProgramFlowError = { type: \"ProgramFlowError\", errors: [{ type: \"UntrackedError\" }] };\n\nconst ShExTerm = __webpack_require__(/*! @shexjs/term */ \"../fhirlib/node_modules/@shexjs/term/shex-term.js\");\nlet ShExVisitor = __webpack_require__(/*! @shexjs/visitor */ \"../fhirlib/node_modules/@shexjs/visitor/shex-visitor.js\");\nlet ShExUtil = __webpack_require__(/*! @shexjs/util */ \"../fhirlib/node_modules/@shexjs/util/shex-util.js\");\nconst Hierarchy = __webpack_require__(/*! hierarchy-closure */ \"../fhirlib/node_modules/hierarchy-closure/hierarchy-closure.js\")\n\nfunction getLexicalValue (term) {\n  return ShExTerm.isIRI(term) ? term :\n    ShExTerm.isLiteral(term) ? ShExTerm.getLiteralValue(term) :\n    term.substr(2); // bnodes start with \"_:\"\n}\n\n\nconst XSD = \"http://www.w3.org/2001/XMLSchema#\";\nconst integerDatatypes = [\n  XSD + \"integer\",\n  XSD + \"nonPositiveInteger\",\n  XSD + \"negativeInteger\",\n  XSD + \"long\",\n  XSD + \"int\",\n  XSD + \"short\",\n  XSD + \"byte\",\n  XSD + \"nonNegativeInteger\",\n  XSD + \"unsignedLong\",\n  XSD + \"unsignedInt\",\n  XSD + \"unsignedShort\",\n  XSD + \"unsignedByte\",\n  XSD + \"positiveInteger\"\n];\n\nconst decimalDatatypes = [\n  XSD + \"decimal\",\n].concat(integerDatatypes);\n\nconst numericDatatypes = [\n  XSD + \"float\",\n  XSD + \"double\"\n].concat(decimalDatatypes);\n\nconst numericParsers = {};\nnumericParsers[XSD + \"integer\"] = function (label, parseError) {\n  if (!(label.match(/^[+-]?[0-9]+$/))) {\n    parseError(\"illegal integer value '\" + label + \"'\");\n  }\n  return parseInt(label);\n};\nnumericParsers[XSD + \"decimal\"] = function (label, parseError) {\n  if (!(label.match(/^[+-]?(?:[0-9]*\\.[0-9]+|[0-9]+)$/))) { // XSD has no pattern for decimal?\n    parseError(\"illegal decimal value '\" + label + \"'\");\n  }\n  return parseFloat(label);\n};\nconst DECIMAL_REGEX = /^[+\\-]?(?:[0-9]+(?:\\.[0-9]*)?|\\.[0-9]+)(?:[eE][+\\-]?[0-9]+)?$/;\nnumericParsers[XSD + \"float\"  ] = function (label, parseError) {\n  if (label === \"NaN\") return NaN;\n  if (label === \"INF\") return Infinity;\n  if (label === \"-INF\") return -Infinity;\n  if (!(label.match(DECIMAL_REGEX))) { // XSD has no pattern for float?\n    parseError(\"illegal float value '\" + label + \"'\");\n  }\n  return parseFloat(label);\n};\nnumericParsers[XSD + \"double\" ] = function (label, parseError) {\n  if (label === \"NaN\") return NaN;\n  if (label === \"INF\") return Infinity;\n  if (label === \"-INF\") return -Infinity;\n  if (!(label.match(DECIMAL_REGEX))) {\n    parseError(\"illegal double value '\" + label + \"'\");\n  }\n  return Number(label);\n};\n\nfunction testRange (value, datatype, parseError) {\n  const ranges = {\n    //    integer            -1 0 1 +1 | \"\" -1.0 +1.0 1e0 NaN INF\n    //    decimal            -1 0 1 +1 -1.0 +1.0 | \"\" 1e0 NaN INF\n    //    float              -1 0 1 +1 -1.0 +1.0 1e0 1E0 NaN INF -INF | \"\" +INF\n    //    double             -1 0 1 +1 -1.0 +1.0 1e0 1E0 NaN INF -INF | \"\" +INF\n    //    nonPositiveInteger -1 0 +0 -0 | 1 +1 1a a1\n    //    negativeInteger    -1 | 0 +0 -0 1\n    //    long               -1 0 1 +1 |\n    //    int                -1 0 1 +1 |\n    //    short              -32768 0 32767 | -32769 32768\n    //    byte               -128 0 127 | \"\" -129 128\n    //    nonNegativeInteger 0 -0 +0 1 +1 | -1\n    //    unsignedLong       0 1 | -1\n    //    unsignedInt        0 1 | -1\n    //    unsignedShort      0 65535 | -1 65536\n    //    unsignedByte       0 255 | -1 256\n    //    positiveInteger    1 | -1 0\n    //    string             \"\" \"a\" \"0\"\n    //    boolean            true false 0 1 | \"\" TRUE FALSE tRuE fAlSe -1 2 10 01\n    //    dateTime           \"2012-01-02T12:34:56.78Z\" | \"\" \"2012-01-02T\" \"2012-01-02\"\n    integer:            { min: -Infinity           , max: Infinity },\n    decimal:            { min: -Infinity           , max: Infinity },\n    float:              { min: -Infinity           , max: Infinity },\n    double:             { min: -Infinity           , max: Infinity },\n    nonPositiveInteger: { min: -Infinity           , max: 0        },\n    negativeInteger:    { min: -Infinity           , max: -1       },\n    long:               { min: -9223372036854775808, max: 9223372036854775807 },\n    int:                { min: -2147483648         , max: 2147483647 },\n    short:              { min: -32768              , max: 32767    },\n    byte:               { min: -128                , max: 127      },\n    nonNegativeInteger: { min: 0                   , max: Infinity },\n    unsignedLong:       { min: 0                   , max: 18446744073709551615 },\n    unsignedInt:        { min: 0                   , max: 4294967295 },\n    unsignedShort:      { min: 0                   , max: 65535    },\n    unsignedByte:       { min: 0                   , max: 255      },\n    positiveInteger:    { min: 1                   , max: Infinity }\n  }\n  const parms = ranges[datatype.substr(XSD.length)];\n  if (!parms) throw Error(\"unexpected datatype: \" + datatype);\n  if (value < parms.min) {\n    parseError(\"\\\"\" + value + \"\\\"^^<\" + datatype + \"> is less than the min:\", parms.min);\n  } else if (value > parms.max) {\n    parseError(\"\\\"\" + value + \"\\\"^^<\" + datatype + \"> is greater than the max:\", parms.min);\n  }\n};\n\n/*\nfunction intSubType (spec, label, parseError) {\n  const ret = numericParsers[XSD + \"integer\"](label, parseError);\n  if (\"min\" in spec && ret < spec.min)\n    parseError(\"illegal \" + XSD + spec.type + \" value '\" + label + \"' should not be < \" + spec.min);\n  if (\"max\" in spec && ret > spec.max)\n    parseError(\"illegal \" + XSD + spec.type + \" value '\" + label + \"' should not be > \" + spec.max);\n  return ret;\n}\n[{type: \"nonPositiveInteger\", max: 0},\n {type: \"negativeInteger\", max: -1},\n {type: \"long\", min: -9223372036854775808, max: 9223372036854775807}, // beyond IEEE double\n {type: \"int\", min: -2147483648, max: 2147483647},\n {type: \"short\", min: -32768, max: 32767},\n {type: \"byte\", min: -128, max: 127},\n {type: \"nonNegativeInteger\", min: 0},\n {type: \"unsignedLong\", min: 0, max: 18446744073709551615},\n {type: \"unsignedInt\", min: 0, max: 4294967295},\n {type: \"unsignedShort\", min: 0, max: 65535},\n {type: \"unsignedByte\", min: 0, max: 255},\n {type: \"positiveInteger\", min: 1}].forEach(function (i) {\n   numericParsers[XSD + i.type ] = function (label, parseError) {\n     return intSubType(i, label, parseError);\n   };\n });\n*/\n\nconst stringTests = {\n  length   : function (v, l) { return v.length === l; },\n  minlength: function (v, l) { return v.length  >= l; },\n  maxlength: function (v, l) { return v.length  <= l; }\n};\n\nconst numericValueTests = {\n  mininclusive  : function (n, m) { return n >= m; },\n  minexclusive  : function (n, m) { return n >  m; },\n  maxinclusive  : function (n, m) { return n <= m; },\n  maxexclusive  : function (n, m) { return n <  m; }\n};\n\nconst decimalLexicalTests = {\n  totaldigits   : function (v, d) {\n    const m = v.match(/[0-9]/g);\n    return m && m.length <= d;\n  },\n  fractiondigits: function (v, d) {\n    const m = v.match(/^[+-]?[0-9]*\\.?([0-9]*)$/);\n    return m && m[1].length <= d;\n  }\n};\n\n        function ldify (term) {\n          if (term[0] !== \"\\\"\")\n            return term;\n          const ret = { value: ShExTerm.getLiteralValue(term) };\n          const dt = ShExTerm.getLiteralType(term);\n          if (dt &&\n              dt !== \"http://www.w3.org/2001/XMLSchema#string\" &&\n              dt !== \"http://www.w3.org/1999/02/22-rdf-syntax-ns#langString\")\n            ret.type = dt;\n          const lang = ShExTerm.getLiteralLanguage(term)\n          if (lang)\n            ret.language = lang;\n          return ret;\n        }\n\n    function isTerm (t) {\n      return typeof t !== \"object\" || \"value\" in t && Object.keys(t).reduce((r, k) => {\n        return r === false ? r : [\"value\", \"type\", \"language\"].indexOf(k) !== -1;\n      }, true);\n    }\n\n/* ShExValidator_constructor - construct an object for validating a schema.\n *\n * schema: a structure produced by a ShEx parser or equivalent.\n * options: object with controls for\n *   lax(true): boolean: whine about missing types in schema.\n *   diagnose(false): boolean: makde validate return a structure with errors.\n */\nfunction ShExValidator_constructor(schema, db, options) {\n  if (!(this instanceof ShExValidator_constructor))\n    return new ShExValidator_constructor(schema, db, options);\n  let index = schema._index || ShExVisitor.index(schema)\n  this.type = \"ShExValidator\";\n  options = options || {};\n  this.options = options;\n  this.options.coverage = this.options.coverage || \"exhaustive\";\n  if (!(\"noCache\" in options && options.noCache))\n    this.known = {};\n\n  const _ShExValidator = this;\n  this.schema = schema;\n  this._expect = this.options.lax ? noop : expect; // report errors on missing types.\n  this._optimize = {}; // optimizations:\n    // hasRepeatedGroups: whether there are patterns like (:p1 ., :p2 .)*\n  this.reset = function () {  }; // included in case we need it later.\n  // const regexModule = this.options.regexModule || require(\"@shexjs/eval-simple-1err\");\n  const regexModule = this.options.regexModule || __webpack_require__(/*! @shexjs/eval-threaded-nerr */ \"../fhirlib/node_modules/@shexjs/eval-threaded-nerr/eval-threaded-nerr.js\");\n\n  /* indexTripleConstraints - compile regular expression and index triple constraints\n   */\n  this.indexTripleConstraints = function (expression) {\n    // list of triple constraints from (:p1 ., (:p2 . | :p3 .))\n    const tripleConstraints = [];\n\n    if (expression)\n      indexTripleConstraints_dive(expression);\n    return tripleConstraints;\n\n    function indexTripleConstraints_dive (expr) {\n      if (typeof expr === \"string\") // Inclusion\n        return indexTripleConstraints_dive(index.tripleExprs[expr]);\n\n      else if (expr.type === \"TripleConstraint\") {\n        tripleConstraints.push(expr);\n        return [tripleConstraints.length - 1]; // index of expr\n      }\n\n      else if (expr.type === \"OneOf\" || expr.type === \"EachOf\")\n        return expr.expressions.reduce(function (acc, nested) {\n          return acc.concat(indexTripleConstraints_dive(nested));\n        }, []);\n\n      else\n        return runtimeError(\"unexpected expr type: \" + expr.type);\n    };\n  };\n\n  /* emptyTracker - a tracker that does nothing\n   */\n  this.emptyTracker = function () {\n    const noop = x => x;\n    return {\n      recurse: noop,\n      known: noop,\n      enter: function (point, label) { ++this.depth; },\n      exit: function (point, label, ret) { --this.depth; },\n      depth: 0\n    };\n  };\n\n  /* validate - test point in db against the schema for labelOrShape\n   * depth: level of recurssion; for logging.\n   */\n  this.validate = function (point, label, tracker, seen, subGraph) {\n    // default to schema's start shape\n    if (typeof point === \"object\" && \"termType\" in point) {\n      point = ShExTerm.internalTerm(point)\n    }\n    if (typeof point === \"object\") {\n      const shapeMap = point;\n      if (this.options.results === \"api\") {\n        return shapeMap.map(pair => {\n          let time = new Date();\n          const res = this.validate(pair.node, pair.shape, label, tracker); // really tracker and seen\n          time = new Date() - time;\n          return {\n            node: pair.node,\n            shape: pair.shape,\n            status: \"errors\" in res ? \"nonconformant\" : \"conformant\",\n            appinfo: res,\n            elapsed: time\n          };\n        });\n      }\n      const results = shapeMap.reduce((ret, pair) => {\n        const res = this.validate(pair.node, pair.shape, label, tracker, subGraph); // really tracker and seen\n        return \"errors\" in res ?\n          { passes: ret.passes, failures: ret.failures.concat(res) } :\n          { passes: ret.passes.concat(res), failures: ret.failures } ;\n      }, {passes: [], failures: []});\n      if (false) { var _add; }\n      if (results.failures.length > 0) {\n        return results.failures.length !== 1 ?\n          { type: \"FailureList\", errors: results.failures } :\n          results.failures [0];\n      } else {\n        return results.passes.length !== 1 ?\n          { type: \"SolutionList\", solutions: results.passes } :\n          results.passes [0];\n      }\n    }\n\n    const outside = tracker === undefined;\n    // logging stuff\n    if (!tracker)\n      tracker = this.emptyTracker();\n    if (!label || label === Start) {\n      if (!schema.start)\n        runtimeError(\"start production not defined\");\n    }\n\n    let shape = null;\n    if (label == Start) {\n      shape = schema.start;\n    } else if (!(\"shapes\" in this.schema) || this.schema.shapes.length === 0) {\n      runtimeError(\"shape \" + label + \" not found; no shapes in schema\");\n    } else if (label in index.shapeExprs) {\n      shape = index.shapeExprs[label]\n    } else {\n      runtimeError(\"shape \" + label + \" not found in:\\n\" + Object.keys(index.shapeExprs || []).map(s => \"  \" + s).join(\"\\n\"));\n    }\n\n    // if we passed in an expression rather than a label, validate it directly.\n    if (typeof label !== \"string\")\n      return this._validateShapeDecl(point, shape, Start, 0, tracker, seen);\n\n    if (seen === undefined)\n      seen = {};\n    const seenKey = point + \"@\" + (label === Start ? \"_: -start-\" : label);\n    if (!subGraph) { // Don't cache base shape validations as they aren't testing the full neighborhood.\n      if (seenKey in seen)\n        return tracker.recurse({\n          type: \"Recursion\",\n          node: ldify(point),\n          shape: label\n        });\n      if (\"known\" in this && seenKey in this.known)\n        return tracker.known(this.known[seenKey]);\n      seen[seenKey] = { point: point, shape: label };\n      tracker.enter(point, label);\n    }\n    const ret = this._validateDescendants(point, label, 0, tracker, seen, subGraph);\n    if (!subGraph) {\n      tracker.exit(point, label, ret);\n      delete seen[seenKey];\n      if (\"known\" in this)\n        this.known[seenKey] = ret;\n    }\n    if (\"startActs\" in schema && outside) {\n      ret.startActs = schema.startActs;\n    }\n    return ret;\n  }\n\n  this._validateDescendants = function (point, shapeLabel, depth, tracker, seen, subGraph, allowAbstract) {\n    if (subGraph) // Shape inference doesn't apply when validating base shapes.\n      return this._validateShapeDecl(point, index.shapeExprs[shapeLabel], shapeLabel, 0, tracker, seen, subGraph);\n\n    // Find all non-abstract shapeExprs extended with label. \n    let candidates = [shapeLabel];\n    candidates = candidates.concat(indexExtensions(this.schema)[shapeLabel] || []);\n    // Uniquify list.\n    for (let i = candidates.length - 1; i >= 0; --i) {\n      if (candidates.indexOf(candidates[i]) < i)\n        candidates.splice(i, 1);\n    }\n    // Filter out abstract shapes.\n    if (!allowAbstract)\n      candidates = candidates.filter(l => !index.shapeExprs[l].abstract);\n\n    // Aggregate results in a SolutionList or FailureList.\n    const results = candidates.reduce((ret, candidateShapeLabel) => {\n      const shapeExpr = index.shapeExprs[candidateShapeLabel];\n      const res = this._validateShapeDecl(point, shapeExpr, candidateShapeLabel, 0, tracker, seen, subGraph);\n      return \"errors\" in res ?\n        { passes: ret.passes, failures: ret.failures.concat(res) } :\n        { passes: ret.passes.concat(res), failures: ret.failures } ;\n\n    }, {passes: [], failures: []});\n    let ret;\n    if (results.passes.length > 0) {\n      ret = results.passes.length !== 1 ?\n        { type: \"SolutionList\", solutions: results.passes } :\n      results.passes [0];\n    } else if (results.failures.length > 0) {\n      ret = results.failures.length !== 1 ?\n        { type: \"FailureList\", errors: results.failures } :\n      results.failures [0];\n    } else {\n      ret = {\n        type: \"AbstractShapeFailure\",\n        shape: shapeLabel,\n        errors: shapeLabel + \" has no non-abstract children\"\n      };\n    }\n    return ret;\n\n    // @TODO move to Vistior.index\n    function indexExtensions (schema) {\n      const abstractness = {};\n      const extensions = Hierarchy.create();\n      makeSchemaVisitor().visitSchema(schema);\n      return extensions.children;\n\n      function makeSchemaVisitor (schema) {\n        const schemaVisitor = ShExUtil.Visitor();\n        let curLabel;\n        let curAbstract;\n        const oldVisitShapeDecl = schemaVisitor.visitShapeDecl;\n        schemaVisitor.visitShapeDecl = function (decl) {\n          curLabel = decl.id;\n          curAbstract = decl.abstract;\n          abstractness[decl.id] = decl.abstract;\n          return oldVisitShapeDecl.call(schemaVisitor, decl, decl.id);\n        };\n        const oldVisitShape = schemaVisitor.visitShape;\n        schemaVisitor.visitShape = function (shape) {\n          if (\"extends\" in shape) {\n            shape.extends.forEach(ext => {\n              const extendsVisitor = ShExUtil.Visitor();\n              extendsVisitor.visitShapeRef = function (parent) {\n                extensions.add(parent, curLabel);\n                // makeSchemaVisitor().visitSchema(schema);\n                return \"null\";\n              };\n              extendsVisitor.visitShapeExpr(ext);\n            })\n          }\n          return \"null\";\n        };\n        return schemaVisitor;\n      }\n    }\n  }\n\n  this._validateShapeDecl = function (point, shapeExpr, shapeLabel, depth, tracker, seen, subgraph) {\n    const expr = shapeExpr.type === \"ShapeDecl\" ? shapeExpr.shapeExpr : shapeExpr;\n    return this._validateShapeExpr(point, expr, shapeLabel, depth, tracker, seen, subgraph);\n  }\n\n  this._validateShapeExpr = function (point, shapeExpr, shapeLabel, depth, tracker, seen, subgraph) {\n    if (point === \"\")\n      throw Error(\"validation needs a valid focus node\");\n    let ret = null\n    if (typeof shapeExpr === \"string\") { // ShapeRef\n      // ret = this._validateShapeDecl(point, schema._index.shapeExprs[shapeExpr], shapeExpr, depth, tracker, seen, subgraph);\n      ret = this._validateDescendants(point, shapeExpr, depth, tracker, seen, subgraph, true);\n    } else if (shapeExpr.type === \"NodeConstraint\") {\n      const sub = this._errorsMatchingNodeConstraint(point, shapeExpr, null);\n      ret = sub.errors && sub.errors.length ? { // @@ when are both conditionals needed?\n        type: \"Failure\",\n        node: ldify(point),\n        shape: shapeLabel,\n        errors: sub.errors.map(function (error) { // !!! just sub.errors?\n          return {\n            type: \"NodeConstraintViolation\",\n            shapeExpr: shapeExpr,\n            error: error\n          };\n        })\n      } : {\n        type: \"NodeConstraintTest\",\n        node: ldify(point),\n        shape: shapeLabel,\n        shapeExpr: shapeExpr\n      };\n    } else if (shapeExpr.type === \"Shape\") {\n      ret = this._validateShape(point, shapeExpr, shapeLabel, depth, tracker, seen, subgraph);\n    } else if (shapeExpr.type === \"ShapeExternal\") {\n      ret = this.options.validateExtern(point, shapeLabel, tracker, seen);\n    } else if (shapeExpr.type === \"ShapeOr\") {\n      const errors = [];\n      for (let i = 0; i < shapeExpr.shapeExprs.length; ++i) {\n        const nested = shapeExpr.shapeExprs[i];\n        const sub = this._validateShapeExpr(point, nested, shapeLabel, depth, tracker, seen, subgraph);\n        if (\"errors\" in sub)\n          errors.push(sub);\n        else\n          return { type: \"ShapeOrResults\", solution: sub };\n      }\n      ret = { type: \"ShapeOrFailure\", errors: errors };\n    } else if (shapeExpr.type === \"ShapeNot\") {\n      const sub = this._validateShapeExpr(point, shapeExpr.shapeExpr, shapeLabel, depth, tracker, seen, subgraph);\n      if (\"errors\" in sub)\n          ret = { type: \"ShapeNotResults\", solution: sub };\n        else\n          ret = { type: \"ShapeNotFailure\", errors: sub };\n    } else if (shapeExpr.type === \"ShapeAnd\") {\n      const passes = [];\n      const errors = [];\n      for (let i = 0; i < shapeExpr.shapeExprs.length; ++i) {\n        const nested = shapeExpr.shapeExprs[i];\n        const sub = this._validateShapeExpr(point, nested, shapeLabel, depth, tracker, seen, subgraph);\n        if (\"errors\" in sub)\n          errors.push(sub);\n        else\n          passes.push(sub);\n      }\n      if (errors.length > 0)\n        ret = { type: \"ShapeAndFailure\", errors: errors };\n      else\n        ret = { type: \"ShapeAndResults\", solutions: passes };\n    } else {\n      throw Error(\"expected one of Shape{Ref,And,Or} or NodeConstraint, got \" + JSON.stringify(shapeExpr));\n    }\n\n    if (typeof shapeExpr !== \"string\" // ShapeRefs are haneled in the referent.\n        &&  shapeExpr.type !== \"Shape\" // Shapes are handled in the try-everything loop.\n        && !(\"errors\" in ret) && \"semActs\" in shapeExpr) {\n      const semActErrors = this.semActHandler.dispatchAll(shapeExpr.semActs, Object.assign({node: point}, ret), ret)\n      if (semActErrors.length)\n        // some semAct aborted\n        return { type: \"Failure\", node: ldify(point), shape: shapeLabel, errors: semActErrors};\n    }\n    return ret;\n  }\n\n  this._validateShape = function (point, shape, shapeLabel, depth, tracker, seen, subgraph) {\n    const _ShExValidator = this;\n    const valParms = { db, shapeLabel, depth, tracker, seen };\n\n    let ret = null;\n    const startAcionStorage = {}; // !!! need test to see this write to results structure.\n    if (\"startActs\" in schema) {\n      const semActErrors = this.semActHandler.dispatchAll(schema.startActs, null, startAcionStorage)\n      if (semActErrors.length)\n        return {\n          type: \"Failure\",\n          node: ldify(point),\n          shape: shapeLabel,\n          errors: semActErrors\n        }; // some semAct aborted !! return a better error\n    }\n\n    const fromDB  = (subgraph || db).getNeighborhood(point, shapeLabel, shape);\n    const outgoingLength = fromDB.outgoing.length;\n    const neighborhood = fromDB.outgoing.sort(\n      (l, r) => l.predicate.localeCompare(r.predicate) || sparqlOrder(l.object, r.object)\n    ).concat(fromDB.incoming.sort(\n      (l, r) => l.predicate.localeCompare(r.predicate) || sparqlOrder(l.object, r.object)\n    ));\n\n    const localTCs = this.indexTripleConstraints(shape.expression);\n    const extendedTCs = getExtendedTripleConstraints(shape);\n    const constraintList = extendedTCs.map(\n      ext => ext.tripleConstraint\n    ).concat(localTCs);\n    const tripleList = matchByPredicate(constraintList, neighborhood, outgoingLength, point, valParms);\n    const {misses, extras} = whatsMissing(tripleList, neighborhood, outgoingLength, shape.extra || [])\n\n    const xp = crossProduct(tripleList.constraintList, \"NO_TRIPLE_CONSTRAINT\");\n    const partitionErrors = [];\n    const regexEngine = regexModule.compile(schema, shape, index);\n    while (xp.next() && ret === null) {\n      const errors = []\n      const usedTriples = []; // [{s1,p1,o1},{s2,p2,o2}] implicated triples -- used for messages\n      const constraintMatchCount = // [2,1,0,1] how many triples matched a constraint\n            _seq(neighborhood.length).map(function () { return 0; });\n\n      // t2tc - array mapping neighborhood index to TripleConstraint\n      const t2tcForThisShapeAndExtends = xp.get(); // [0,1,0,3] mapping from triple to constraint\n      const t2tcForThisShape = []\n      const tripleToExtends = []\n      const extendsToTriples = _seq((shape.extends || []).length).map(() => [])\n      t2tcForThisShapeAndExtends.forEach((cNo, tNo) => {\n        if (cNo !== \"NO_TRIPLE_CONSTRAINT\" && cNo < extendedTCs.length) {\n          const extNo = extendedTCs[cNo].extendsNo;\n          extendsToTriples[extNo].push(neighborhood[tNo]);\n          tripleToExtends[tNo] = cNo;\n          t2tcForThisShape[tNo] = \"NO_TRIPLE_CONSTRAINT\";\n        } else {\n          tripleToExtends[tNo] = \"NO_EXTENDS\";\n          t2tcForThisShape[tNo] = cNo;\n        }\n      });\n\n      // Triples not mapped to triple constraints are not allowed in closed shapes.\n      if (shape.closed) {\n        const unexpectedTriples = neighborhood.slice(0, outgoingLength).filter((t, i) => {\n          return t2tcForThisShape[i] === \"NO_TRIPLE_CONSTRAINT\" && // didn't match a constraint\n            tripleToExtends[i] === \"NO_EXTENDS\" && // didn't match an EXTENDS\n            extras.indexOf(i) === -1; // wasn't in EXTRAs.\n        });\n        if (unexpectedTriples.length > 0)\n          errors.push({\n            type: \"ClosedShapeViolation\",\n            unexpectedTriples: unexpectedTriples\n          });\n      }\n\n      // Set usedTriples and constraintMatchCount.\n      t2tcForThisShape.forEach(function (tpNumber, ord) {\n        if (tpNumber !== \"NO_TRIPLE_CONSTRAINT\") {\n          usedTriples.push(neighborhood[ord]);\n          ++constraintMatchCount[tpNumber];\n        }\n      });\n      const tc2t = _constraintToTriples(t2tcForThisShape, constraintList, tripleList); // e.g. [[t0, t2], [t1, t3]]\n\n      let results = testExtends(shape, point, extendsToTriples, valParms);\n      if (results === null || !(\"errors\" in results)) {\n        const sub = regexEngine.match(db, point, constraintList, tc2t, t2tcForThisShape, neighborhood, this.semActHandler, null);\n        if (!(\"errors\" in sub) && results) {\n          results = { type: \"ExtendedResults\", extensions: results };\n          if (Object.keys(sub).length > 0) // no empty objects from {}s.\n            results.local = sub;\n        } else {\n          results = sub;\n        }\n      }\n      if (\"errors\" in results)\n        [].push.apply(errors, results.errors);\n\n      const possibleRet = { type: \"ShapeTest\", node: ldify(point), shape: shapeLabel };\n      if (errors.length === 0 && Object.keys(results).length > 0) // only include .solution for non-empty pattern\n        possibleRet.solution = results;\n      if (\"semActs\" in shape) {\n        const semActErrors = this.semActHandler.dispatchAll(shape.semActs, Object.assign({node: point}, results), possibleRet)\n        if (semActErrors.length)\n          // some semAct aborted\n          [].push.apply(errors, semActErrors);\n      }\n\n      partitionErrors.push(errors)\n      if (errors.length === 0)\n        ret = possibleRet\n    }\n    // end of while(xp.next())\n\n    const missErrors = misses.map(function (miss) {\n      const t = neighborhood[miss.tripleNo];\n      return {\n        type: \"TypeMismatch\",\n        triple: {type: \"TestedTriple\", subject: t.subject, predicate: t.predicate, object: ldify(t.object)},\n        constraint: constraintList[miss.constraintNo],\n        errors: miss.errors\n      };\n    });\n\n    // Report only last errors until we have a better idea.\n    const lastErrors = partitionErrors[partitionErrors.length - 1];\n    let errors = missErrors.concat(lastErrors.length === 1 ? lastErrors[0] : lastErrors);\n    if (errors.length > 0)\n      ret = {\n        type: \"Failure\",\n        node: ldify(point),\n        shape: shapeLabel,\n        errors: errors\n      };\n\n    // remove N3jsTripleToString\n    if (VERBOSE)\n      neighborhood.forEach(function (t) {\n        delete t.toString;\n      });\n\n    return addShapeAttributes(shape, ret);\n  };\n\n  function matchByPredicate (constraintList, neighborhood, outgoingLength, point, valParms) {\n    const outgoing = indexNeighborhood(neighborhood.slice(0, outgoingLength));\n    const incoming = indexNeighborhood(neighborhood.slice(outgoingLength));\n    return constraintList.reduce(function (ret, constraint, cNo) {\n\n      // subject and object depend on direction of constraint.\n      const searchSubject = constraint.inverse ? null : point;\n      const searchObject = constraint.inverse ? point : null;\n      const index = constraint.inverse ? incoming : outgoing;\n\n      // get triples matching predciate\n      const matchPredicate = index.byPredicate[constraint.predicate] ||\n            []; // empty list when no triple matches that constraint\n\n      // strip to triples matching value constraints (apart from @<someShape>)\n      const matchConstraints = _ShExValidator._triplesMatchingShapeExpr(\n        matchPredicate, constraint, valParms\n      );\n\n      matchConstraints.hits.forEach(function (evidence) {\n        const tNo = neighborhood.indexOf(evidence.triple);\n        ret.constraintList[tNo].push(cNo);\n        ret.results[cNo][tNo] = evidence.sub;\n      });\n      matchConstraints.misses.forEach(function (evidence) {\n        const tNo = neighborhood.indexOf(evidence.triple);\n        ret.misses[tNo] = {constraintNo: cNo, errors: evidence.errors};\n      });\n      return ret;\n    }, { misses: {}, results: _alist(constraintList.length), constraintList:_alist(neighborhood.length) })\n  }\n\n  function whatsMissing (tripleList, neighborhood, outgoingLength, extras) {\n    const matchedExtras = []; // triples accounted for by EXTRA\n    const misses = tripleList.constraintList.reduce(function (ret, constraints, ord) {\n      if (constraints.length === 0 &&   // matches no constraints\n          ord < outgoingLength &&       // not an incoming triple\n          ord in tripleList.misses) {   // predicate matched some constraint(s)\n        if (extras.indexOf(neighborhood[ord].predicate) !== -1) {\n          matchedExtras.push(ord);\n        } else {                        // not declared extra\n          ret.push({                    // so it's a missed triple.\n            tripleNo: ord,\n            constraintNo: tripleList.misses[ord].constraintNo,\n            errors: tripleList.misses[ord].errors\n          });\n        }\n      }\n      return ret;\n    }, []);\n    return {misses, extras: matchedExtras}\n  }\n\n  function addShapeAttributes (shape, ret) {\n    if (\"annotations\" in shape)\n      ret.annotations = shape.annotations;\n    return ret;\n  }\n\n  // Pivot to triples by constraint.\n  function _constraintToTriples (t2tc, constraintList, tripleList) {\n    return t2tc.slice().\n      reduce(function (ret, cNo, tNo) {\n        if (cNo !== \"NO_TRIPLE_CONSTRAINT\")\n          ret[cNo].push({tNo: tNo, res: tripleList.results[cNo][tNo]});\n        return ret;\n      }, _seq(constraintList.length).map(() => [])); // [length][]\n  }\n\n  function testExtends (expr, point, extendsToTriples, valParms) {\n    if (!(\"extends\" in expr))\n      return null;\n    const passes = [];\n    const errors = [];\n    for (let eNo = 0; eNo < expr.extends.length; ++eNo) {\n      const extend = expr.extends[eNo];\n      const subgraph = ShExUtil.makeTriplesDB(null); // These triples were tracked earlier.\n      extendsToTriples[eNo].forEach(t => subgraph.addOutgoingTriples([t]));\n      const sub = _ShExValidator.validate(point, extend, valParms.tracker, valParms.seen, subgraph)\n      if (\"errors\" in sub)\n        errors.push(sub);\n      else\n        passes.push(sub);\n    }\n    if (errors.length > 0) {\n      return { type: \"ExtensionFailure\", errors: errors };\n    }\n    return { type: \"ExtensionResults\", solutions: passes };\n  }\n\n  /** getExtendedTripleConstraints - walk shape's extends to get all\n   * referenced triple constraints.\n   *\n   * @param {} shape\n   * @returns {}\n   */\n  function getExtendedTripleConstraints (shape) {\n    const ret = []\n    if (\"extends\" in shape) {\n      shape.extends.forEach((se, extendsNo) => {\n        // Index incoming and outgoing arcs by predicate.  Multiple TCs with the\n        // same predicate are aggregated into a single TC with the maximum\n        // cardinality span. (@@Does this actually reduce permutations?)\n        // tests: Extend3G-pass\n        const ins = {}, outs = {};\n        visitTripleConstraints(se, ins, outs);\n\n        [ins, outs].forEach(directionIndex => {\n          Object.keys(directionIndex).forEach(predicate => {\n            let tripleConstraint = directionIndex[predicate]\n            ret.push({tripleConstraint, extendsNo});\n          });\n        });\n      })\n    }\n    return ret;\n\n    /*\n     * @expr - shape expression to walk\n     * @ins - incoming arcs: map from IRI to {min, max, seen}\n     * @outs - outgoing arcs\n     */\n    function visitTripleConstraints (expr, ins, outs) {\n      const visitor = ShExUtil.Visitor();\n      let outerMin = 1;\n      let outerMax = 1;\n      const oldVisitOneOf = visitor.visitOneOf;\n\n      // Override visitShapeRef to follow references.\n      // tests: Extend3G-pass, vitals-RESTRICTS-pass_lie-Vital...\n      visitor.visitShapeRef = function (inclusion) {\n        return visitor.visitShapeDecl(index.shapeExprs[inclusion]);\n      };\n\n      // Visit shape's EXTENDS and expression.\n      visitor.visitShape = function (shape, label) {\n        if (\"extends\" in shape) {\n          shape.extends.forEach( // extension of an extension...\n            se => visitTripleConstraints(se, ins, outs)\n          )\n        }\n        if (\"expression\" in shape) {\n          visitor.visitExpression(shape.expression);\n        }\n        return { type: \"Shape\" }; // NOP\n      }\n\n      // Any TC inside a OneOf implicitly has a min cardinality of 0.\n      visitor.visitOneOf = function (expr) {\n        const oldOuterMin = outerMin;\n        const oldOuterMax = outerMax;\n        outerMin = 0;\n        oldVisitOneOf.call(visitor, expr);\n        outerMin = oldOuterMin;\n        outerMax = oldOuterMax;\n      }\n\n      // Synthesize a TripleConstraint with the implicit cardinality.\n      visitor.visitTripleConstraint = function (expr) {\n        const idx = expr.inverse ? ins : outs; // pick an index\n        let min = \"min\" in expr ? expr.min : 1; min = min * outerMin;\n        let max = \"max\" in expr ? expr.max : 1; max = max * outerMax;\n        idx[expr.predicate] = {\n          type: \"TripleConstraint\",\n          predicate: expr.predicate,\n          min: expr.predicate in idx ? Math.max(idx[expr.predicate].min, min) : min,\n          max: expr.predicate in idx ? Math.min(idx[expr.predicate].max, max) : max,\n          seen: expr.predicate in idx ? idx[expr.predicate].seen + 1 : 1,\n          tcs: expr.predicate in idx ? idx[expr.predicate].tcs.concat([expr]) : [expr]\n        }\n        return expr;\n      };\n\n      // Call constructed visitor on expr.\n      visitor.visitShapeExpr(expr);\n    }\n  }\n\n  this._triplesMatchingShapeExpr = function (triples, constraint, valParms) {\n    const _ShExValidator = this;\n    const misses = [];\n    const hits = [];\n    triples.forEach(function (triple) {\n      const value = constraint.inverse ? triple.subject : triple.object;\n      let sub;\n      const oldBindings = JSON.parse(JSON.stringify(_ShExValidator.semActHandler.results));\n      const errors = constraint.valueExpr === undefined ?\n          undefined :\n          (sub = _ShExValidator._errorsMatchingShapeExpr(value, constraint.valueExpr, valParms)).errors;\n      if (!errors) {\n        hits.push({triple: triple, sub: sub});\n      } else if (hits.indexOf(triple) === -1) {\n        _ShExValidator.semActHandler.results = JSON.parse(JSON.stringify(oldBindings));\n        misses.push({triple: triple, errors: sub});\n      }\n    });\n    return { hits: hits, misses: misses };\n  }\n  this._errorsMatchingShapeExpr = function (value, valueExpr, valParms, subgraph) {\n    const _ShExValidator = this;\n    if (typeof valueExpr === \"string\") { // ShapeRef\n      return _ShExValidator.validate(value, valueExpr, valParms.tracker, valParms.seen, subgraph);\n    } else if (valueExpr.type === \"NodeConstraint\") {\n      return this._errorsMatchingNodeConstraint(value, valueExpr, null);\n    } else if (valueExpr.type === \"Shape\") {\n      return _ShExValidator._validateShapeExpr(value, valueExpr, valParms.shapeLabel, valParms.depth, valParms.tracker, valParms.seen, subgraph)\n    } else if (valueExpr.type === \"ShapeOr\") {\n      const errors = [];\n      for (let i = 0; i < valueExpr.shapeExprs.length; ++i) {\n        const nested = valueExpr.shapeExprs[i];\n        const sub = _ShExValidator._errorsMatchingShapeExpr(value, nested, valParms, subgraph);\n        if (\"errors\" in sub)\n          errors.push(sub);\n        else\n          return { type: \"ShapeOrResults\", solution: sub };\n      }\n      return { type: \"ShapeOrFailure\", errors: errors };\n    } else if (valueExpr.type === \"ShapeAnd\") {\n      const passes = [];\n      for (let i = 0; i < valueExpr.shapeExprs.length; ++i) {\n        const nested = valueExpr.shapeExprs[i];\n        const sub = _ShExValidator._errorsMatchingShapeExpr(value, nested, valParms, subgraph);\n        if (\"errors\" in sub)\n          return { type: \"ShapeAndFailure\", errors: [sub] };\n        else\n          passes.push(sub);\n      }\n      return { type: \"ShapeAndResults\", solutions: passes };\n    } else if (valueExpr.type === \"ShapeNot\") {\n      const sub = _ShExValidator._errorsMatchingShapeExpr(value, valueExpr.shapeExpr, valParms, subgraph);\n      // return sub.errors && sub.errors.length ? {} : {\n      //   errors: [\"Error validating \" + value + \" as \" + JSON.stringify(valueExpr) + \": expected NOT to pass\"] };\n      const ret = Object.assign({\n        type: null,\n        focus: value\n      }, valueExpr);\n      if (sub.errors && sub.errors.length) {\n        ret.type = \"ShapeNotTest\";\n        // ret = {};\n      } else {\n        ret.type = \"ShapeNotFailure\";\n        ret.errors = [\"Error validating \" + value + \" as \" + JSON.stringify(valueExpr) + \": expected NOT to pass\"]\n      }\n      return ret;\n    } else {\n      throw Error(\"unknown value expression type '\" + valueExpr.type + \"'\");\n    }\n  };\n\n  /* _errorsMatchingNodeConstraint - return whether the value matches the value\n   * expression without checking shape references.\n   */\n  this._errorsMatchingNodeConstraint = function (value, valueExpr, recurse) {\n    const errors = [];\n    const label = ShExTerm.isLiteral(value) ? ShExTerm.getLiteralValue(value) :\n      ShExTerm.isBlank(value) ? value.substring(2) :\n      value;\n    const dt = ShExTerm.isLiteral(value) ? ShExTerm.getLiteralType(value) : null;\n    const numeric = integerDatatypes.indexOf(dt) !== -1 ? XSD + \"integer\" : numericDatatypes.indexOf(dt) !== -1 ? dt : undefined;\n\n    function validationError () {\n      const errorStr = Array.prototype.join.call(arguments, \"\");\n      errors.push(\"Error validating \" + value + \" as \" + JSON.stringify(valueExpr) + \": \" + errorStr);\n      return false;\n    }\n    // if (negated) ;\n    if (false) {} else {\n      if (\"nodeKind\" in valueExpr) {\n        if ([\"iri\", \"bnode\", \"literal\", \"nonliteral\"].indexOf(valueExpr.nodeKind) === -1) {\n          validationError(\"unknown node kind '\" + valueExpr.nodeKind + \"'\");\n        }\n        if (ShExTerm.isBlank(value)) {\n          if (valueExpr.nodeKind === \"iri\" || valueExpr.nodeKind === \"literal\") {\n            validationError(\"blank node found when \" + valueExpr.nodeKind + \" expected\");\n          }\n        } else if (ShExTerm.isLiteral(value)) {\n          if (valueExpr.nodeKind !== \"literal\") {\n            validationError(\"literal found when \" + valueExpr.nodeKind + \" expected\");\n          }\n        } else if (valueExpr.nodeKind === \"bnode\" || valueExpr.nodeKind === \"literal\") {\n          validationError(\"iri found when \" + valueExpr.nodeKind + \" expected\");\n        }\n      }\n\n      if (valueExpr.datatype  && valueExpr.values  ) validationError(\"found both datatype and values in \"   +tripleConstraint);\n\n      if (valueExpr.datatype) {\n        if (!ShExTerm.isLiteral(value)) {\n          validationError(\"mismatched datatype: \" + value + \" is not a literal with datatype \" + valueExpr.datatype);\n        }\n        else if (ShExTerm.getLiteralType(value) !== valueExpr.datatype) {\n          validationError(\"mismatched datatype: \" + ShExTerm.getLiteralType(value) + \" !== \" + valueExpr.datatype);\n        }\n        else if (numeric) {\n          testRange(numericParsers[numeric](label, validationError), valueExpr.datatype, validationError);\n        }\n        else if (valueExpr.datatype === XSD + \"boolean\") {\n          if (label !== \"true\" && label !== \"false\" && label !== \"1\" && label !== \"0\")\n            validationError(\"illegal boolean value: \" + label);\n        }\n        else if (valueExpr.datatype === XSD + \"dateTime\") {\n          if (!label.match(/^[+-]?\\d{4}-[01]\\d-[0-3]\\dT[0-5]\\d:[0-5]\\d:[0-5]\\d(\\.\\d+)?([+-][0-2]\\d:[0-5]\\d|Z)?$/))\n            validationError(\"illegal dateTime value: \" + label);\n        }\n      }\n\n      if (valueExpr.values) {\n        if (ShExTerm.isLiteral(value) && valueExpr.values.reduce((ret, v) => {\n          if (ret) return true;\n          const ld = ldify(value);\n          if (v.type === \"Language\") {\n            return v.languageTag === ld.language; // @@ use equals/normalizeTest\n          }\n          if (!(typeof v === \"object\" && \"value\" in v))\n            return false;\n          return v.value === ld.value &&\n            v.type === ld.type &&\n            v.language === ld.language;\n        }, false)) {\n          // literal match\n        } else if (valueExpr.values.indexOf(value) !== -1) {\n          // trivial match\n        } else {\n          if (!(valueExpr.values.some(function (valueConstraint) {\n            if (typeof valueConstraint === \"object\" && !(\"value\" in valueConstraint)) { // isTerm me -- strike \"value\" in\n              if (!(\"type\" in valueConstraint))\n                runtimeError(\"expected \"+JSON.stringify(valueConstraint)+\" to have a 'type' attribute.\");\n              const stemRangeTypes = [\n                \"Language\",\n                \"IriStem\",      \"LiteralStem\",      \"LanguageStem\",\n                \"IriStemRange\", \"LiteralStemRange\", \"LanguageStemRange\"\n              ];\n              if (stemRangeTypes.indexOf(valueConstraint.type) === -1)\n                runtimeError(\"expected type attribute '\"+valueConstraint.type+\"' to be in '\"+stemRangeTypes+\"'.\");\n\n              /* expect N3.js literals with {Literal,Language}StemRange\n               *       or non-literals with IriStemRange\n               */\n              function normalizedTest (val, ref, func) {\n                if (ShExTerm.isLiteral(val)) {\n                  if ([\"LiteralStem\", \"LiteralStemRange\"].indexOf(valueConstraint.type) !== -1) {\n                    return func(ShExTerm.getLiteralValue(val), ref);\n                  } else if ([\"LanguageStem\", \"LanguageStemRange\"].indexOf(valueConstraint.type) !== -1) {\n                    return func(ShExTerm.getLiteralLanguage(val) || null, ref);\n                  } else {\n                    return validationError(\"literal \" + val + \" not comparable with non-literal \" + ref);\n                  }\n                } else {\n                  if ([\"IriStem\", \"IriStemRange\"].indexOf(valueConstraint.type) === -1) {\n                    return validationError(\"nonliteral \" + val + \" not comparable with literal \" + JSON.stringify(ref));\n                  } else {\n                    return func(val, ref);\n                  }\n                }\n              }\n              function startsWith (val, ref) {\n                return normalizedTest(val, ref, (l, r) => {\n                  return (valueConstraint.type === \"LanguageStem\" ||\n                          valueConstraint.type === \"LanguageStemRange\") ?\n                    // rfc4647 basic filtering\n                    l !== null && (l === r || r === \"\" || l[r.length] === \"-\") :\n                    // simple substring\n                    l.startsWith(r);\n                });\n              }\n              function equals (val, ref) {\n                return normalizedTest(val, ref, (l, r) => { return l === r; });\n              }\n\n              if (!isTerm(valueConstraint.stem)) {\n                expect(valueConstraint.stem, \"type\", \"Wildcard\");\n                // match whatever but check exclusions below\n              } else {\n                if (!(startsWith(value, valueConstraint.stem))) {\n                  return false;\n                }\n              }\n              if (valueConstraint.exclusions) {\n                return !valueConstraint.exclusions.some(function (c) {\n                  if (!isTerm(c)) {\n                    if (!(\"type\" in c))\n                      runtimeError(\"expected \"+JSON.stringify(c)+\" to have a 'type' attribute.\");\n                    const stemTypes = [\"IriStem\", \"LiteralStem\", \"LanguageStem\"];\n                    if (stemTypes.indexOf(c.type) === -1)\n                      runtimeError(\"expected type attribute '\"+c.type+\"' to be in '\"+stemTypes+\"'.\");\n                    return startsWith(value, c.stem);\n                  } else {\n                    return equals(value, c);\n                  }\n                });\n              }\n              return true;\n            } else {\n              // ignore -- would have caught it above\n            }\n          }))) {\n            validationError(\"value \" + value + \" not found in set \" + JSON.stringify(valueExpr.values));\n          }\n        }\n      }\n    }\n\n    if (\"pattern\" in valueExpr) {\n      const regexp = \"flags\" in valueExpr ?\n\t  new RegExp(valueExpr.pattern, valueExpr.flags) :\n\t  new RegExp(valueExpr.pattern);\n      if (!(getLexicalValue(value).match(regexp)))\n        validationError(\"value \" + getLexicalValue(value) + \" did not match pattern \" + valueExpr.pattern);\n    }\n\n    Object.keys(stringTests).forEach(function (test) {\n      if (test in valueExpr && !stringTests[test](label, valueExpr[test])) {\n        validationError(\"facet violation: expected \" + test + \" of \" + valueExpr[test] + \" but got \" + value);\n      }\n    });\n\n    Object.keys(numericValueTests).forEach(function (test) {\n      if (test in valueExpr) {\n        if (numeric) {\n          if (!numericValueTests[test](numericParsers[numeric](label, validationError), valueExpr[test])) {\n            validationError(\"facet violation: expected \" + test + \" of \" + valueExpr[test] + \" but got \" + value);\n          }\n        } else {\n          validationError(\"facet violation: numeric facet \" + test + \" can't apply to \" + value);\n        }\n      }\n    });\n\n    Object.keys(decimalLexicalTests).forEach(function (test) {\n      if (test in valueExpr) {\n        if (numeric === XSD + \"integer\" || numeric === XSD + \"decimal\") {\n          if (!decimalLexicalTests[test](\"\"+numericParsers[numeric](label, validationError), valueExpr[test])) {\n            validationError(\"facet violation: expected \" + test + \" of \" + valueExpr[test] + \" but got \" + value);\n          }\n        } else {\n          validationError(\"facet violation: numeric facet \" + test + \" can't apply to \" + value);\n        }\n      }\n    });\n    const ret = {\n      type: null,\n      focus: value,\n      shapeExpr: valueExpr\n    };\n    if (errors.length) {\n      ret.type = \"NodeConstraintViolation\";\n      ret.errors = errors;\n    } else {\n      ret.type = \"NodeConstraintTest\";\n    }\n    return ret;\n  };\n\n  this.semActHandler = {\n    handlers: { },\n    results: { },\n    /**\n     * Store a semantic action handler.\n     *\n     * @param {string} name - semantic action's URL.\n     * @param {object} handler - handler function.\n     *\n     * The handler object has a dispatch function is invoked with:\n     * @param {string} code - text of the semantic action.\n     * @param {object} ctx - matched triple or results subset.\n     * @param {object} extensionStorage - place where the extension writes into the result structure.\n     * @return {bool} false if the extension failed or did not accept the ctx object.\n     */\n    register: function (name, handler) {\n      this.handlers[name] = handler;\n    },\n    /**\n     * Calls all semantic actions, allowing each to write to resultsArtifact.\n     *\n     * @param {array} semActs - list of semantic actions to invoke.\n     * @return {bool} false if any result was false.\n     */\n    dispatchAll: function (semActs, ctx, resultsArtifact) {\n      const _semActHanlder = this;\n      return semActs.reduce(function (ret, semAct) {\n        if (ret.length === 0 && semAct.name in _semActHanlder.handlers) {\n          const code = \"code\" in semAct ? semAct.code : _ShExValidator.options.semActs[semAct.name];\n          const existing = \"extensions\" in resultsArtifact && semAct.name in resultsArtifact.extensions;\n          const extensionStorage = existing ? resultsArtifact.extensions[semAct.name] : {};\n          const response = _semActHanlder.handlers[semAct.name].dispatch(code, ctx, extensionStorage);\n          if (typeof response === 'boolean') {\n            if (!response)\n              ret.push({ type: \"SemActFailure\", errors: [{ type: \"BooleanSemActFailure\", code: code, ctx }] })\n          } else if (typeof response === 'object' && Array.isArray(response)) {\n            if (response.length > 0)\n              ret.push({ type: \"SemActFailure\", errors: response })\n          } else {\n            throw Error(\"unsupported response from semantic action handler: \" + JSON.stringify(response))\n          }\n          if (!existing && Object.keys(extensionStorage).length > 0) {\n            if (!(\"extensions\" in resultsArtifact))\n              resultsArtifact.extensions = {};\n            resultsArtifact.extensions[semAct.name] = extensionStorage;\n          }\n          return ret;\n        }\n        return ret;\n      }, []);\n    }\n  };\n}\n\n// http://stackoverflow.com/questions/9422386/lazy-cartesian-product-of-arrays-arbitrary-nested-loops\nfunction crossProduct(sets, emptyValue) {\n  const n = sets.length, carets = [];\n  let args = null;\n\n  function init() {\n    args = [];\n    for (let i = 0; i < n; i++) {\n      carets[i] = 0;\n      args[i] = sets[i].length > 0 ? sets[i][0] : emptyValue;\n    }\n  }\n\n  function next() {\n\n    // special case: crossProduct([]).next().next() returns false.\n    if (args !== null && args.length === 0)\n      return false;\n\n    if (args === null) {\n      init();\n      return true;\n    }\n    let i = n - 1;\n    carets[i]++;\n    if (carets[i] < sets[i].length) {\n      args[i] = sets[i][carets[i]];\n      return true;\n    }\n    while (carets[i] >= sets[i].length) {\n      if (i == 0) {\n        return false;\n      }\n      carets[i] = 0;\n      args[i] = sets[i].length > 0 ? sets[i][0] : emptyValue;\n      carets[--i]++;\n    }\n    args[i] = sets[i][carets[i]];\n    return true;\n  }\n\n  return {\n    next: next,\n    do: function (block, _context) { // old API\n      return block.apply(_context, args);\n    },\n    // new API because\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/arguments#Description\n    // cautions about functions over arguments.\n    get: function () { return args; }\n  };\n}\n\n/* N3jsTripleToString - simple toString function to make N3.js's triples\n * printable.\n */\nconst N3jsTripleToString = function () {\n  function fmt (n) {\n    return ShExTerm.isLiteral(n) ?\n      [ \"http://www.w3.org/2001/XMLSchema#integer\",\n        \"http://www.w3.org/2001/XMLSchema#float\",\n        \"http://www.w3.org/2001/XMLSchema#double\"\n      ].indexOf(ShExTerm.getLiteralType(n)) !== -1 ?\n      parseInt(ShExTerm.getLiteralValue(n)) :\n      n :\n    ShExTerm.isBlank(n) ?\n      n :\n      \"<\" + n + \">\";\n  }\n  return fmt(this.subject) + \" \" + fmt(this.predicate) + \" \" + fmt(this.object) + \" .\";\n};\n\n/* indexNeighborhood - index triples by predicate\n * returns: {\n *     byPredicate: Object: mapping from predicate to triples containing that\n *                  predicate.\n *\n *     candidates: [[1,3], [0,2]]: mapping from triple to the triple constraints\n *                 it matches.  It is initialized to []. Mappings that remain an\n *                 empty set indicate a triple which didn't matching anything in\n *                 the shape.\n *\n *     misses: list to recieve value constraint failures.\n *   }\n */\nfunction indexNeighborhood (triples) {\n  return {\n    byPredicate: triples.reduce(function (ret, t) {\n      const p = t.predicate;\n      if (!(p in ret))\n        ret[p] = [];\n      ret[p].push(t);\n\n      // If in VERBOSE mode, add a nice toString to N3.js's triple objects.\n      if (VERBOSE)\n        t.toString = N3jsTripleToString;\n\n      return ret;\n    }, {}),\n    candidates: _seq(triples.length).map(function () {\n      return [];\n    }),\n    misses: []\n  };\n}\n\n/* sparqlOrder - sort triples by subject following SPARQL partial ordering.\n */\nfunction sparqlOrder (l, r) {\n  const [lprec, rprec] = [l, r].map(\n    x => ShExTerm.isBlank(x) ? 1 : ShExTerm.isLiteral(x) ? 2 : 3\n  );\n  return lprec === rprec ? l.localeCompare(r) : lprec - rprec;\n}\n\n/* Return a list of n `undefined`s.\n *\n * Note that Array(n) on its own returns a \"sparse array\" so Array(n).map(f)\n * never calls f.\n */\nfunction _seq (n) {\n  return Array.from(Array(n)); // hahaha, javascript, you suck.\n}\n\n/* Expect property p with value v in object o\n */\nfunction expect (o, p, v) {\n  if (!(p in o))\n    runtimeError(\"expected \"+JSON.stringify(o)+\" to have a '\"+p+\"' attribute.\");\n  if (arguments.length > 2 && o[p] !== v)\n    runtimeError(\"expected \"+p+\" attribute '\"+o[p]+\"' to equal '\"+v+\"'.\");\n}\n\nfunction noop () {  }\n\nfunction runtimeError () {\n  const errorStr = Array.prototype.join.call(arguments, \"\");\n  const e = new Error(errorStr);\n  Error.captureStackTrace(e, runtimeError);\n  throw e;\n}\n\n  function _alist (len) {\n    return _seq(len).map(() => [])\n  }\n\n  return {\n    construct: ShExValidator_constructor,\n    start: Start,\n    options: InterfaceOptions\n  };\n})();\n\n// Export the `ShExValidator` class as a whole.\nif (true)\n  module.exports = ShExValidatorCjsModule;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/@shexjs/validator/shex-validator.js?");

/***/ }),

/***/ "../fhirlib/node_modules/@shexjs/visitor/shex-visitor.js":
/*!***************************************************************!*\
  !*** ../fhirlib/node_modules/@shexjs/visitor/shex-visitor.js ***!
  \***************************************************************/
/***/ ((module) => {

eval("\nfunction ShExVisitor () {\n\n    function isTerm (t) {\n      return typeof t !== \"object\" || \"value\" in t && Object.keys(t).reduce((r, k) => {\n        return r === false ? r : [\"value\", \"type\", \"language\"].indexOf(k) !== -1;\n      }, true);\n    }\n\n  function isShapeRef (expr) {\n    return typeof expr === \"string\" // test for JSON-LD @ID\n  }\n  let isInclusion = isShapeRef;\n\n  // function expect (l, r) { const ls = JSON.stringify(l), rs = JSON.stringify(r); if (ls !== rs) throw Error(ls+\" !== \"+rs); }\n  const _ShExUtil = this;\n  function visitMap (map, val) {\n    const ret = {};\n    Object.keys(map).forEach(function (item) {\n      ret[item] = val(map[item]);\n    });\n    return ret;\n  }\n  const r = {\n    runtimeError: function (e) {\n      throw e;\n    },\n\n    visitSchema: function (schema) {\n      const ret = { type: \"Schema\" };\n      _expect(schema, \"type\", \"Schema\");\n      this._maybeSet(schema, ret, \"Schema\",\n                     [\"@context\", \"prefixes\", \"base\", \"imports\", \"startActs\", \"start\", \"shapes\"],\n                     [\"_base\", \"_prefixes\", \"_index\", \"_sourceMap\"]\n                    );\n      return ret;\n    },\n\n    visitPrefixes: function (prefixes) {\n      return prefixes === undefined ?\n        undefined :\n        visitMap(prefixes, function (val) {\n          return val;\n        });\n    },\n\n    visitIRI: function (i) {\n      return i;\n    },\n\n    visitImports: function (imports) {\n      const _Visitor = this;\n      return imports.map(function (imp) {\n        return _Visitor.visitIRI(imp);\n      });\n    },\n\n    visitStartActs: function (startActs) {\n      const _Visitor = this;\n      return startActs === undefined ?\n        undefined :\n        startActs.map(function (act) {\n          return _Visitor.visitSemAct(act);\n        });\n    },\n    visitSemActs: function (semActs) {\n      const _Visitor = this;\n      if (semActs === undefined)\n        return undefined;\n      const ret = []\n      Object.keys(semActs).forEach(function (label) {\n        ret.push(_Visitor.visitSemAct(semActs[label], label));\n      });\n      return ret;\n    },\n    visitSemAct: function (semAct, label) {\n      const ret = { type: \"SemAct\" };\n      _expect(semAct, \"type\", \"SemAct\");\n\n      this._maybeSet(semAct, ret, \"SemAct\",\n                     [\"name\", \"code\"]);\n      return ret;\n    },\n\n    visitShapes: function (shapes) {\n      const _Visitor = this;\n      if (shapes === undefined)\n        return undefined;\n      return shapes.map(\n        shapeExpr =>\n          _Visitor.visitShapeDecl(shapeExpr)\n      );\n    },\n\n    visitProductions999: function (productions) { // !! DELETE\n      const _Visitor = this;\n      if (productions === undefined)\n        return undefined;\n      const ret = {}\n      Object.keys(productions).forEach(function (label) {\n        ret[label] = _Visitor.visitExpression(productions[label], label);\n      });\n      return ret;\n    },\n\n    visitShapeDecl: function (decl, label) {\n      return decl.type === \"ShapeDecl\" ?\n        this._maybeSet(decl, { type: \"ShapeDecl\" }, \"ShapeDecl\",\n                       [\"id\", \"abstract\", \"restricts\", \"shapeExpr\"]) :\n        this.visitShapeExpr(decl, label);\n    },\n\n    visitShapeExpr: function (expr, label) {\n      if (isShapeRef(expr))\n        return this.visitShapeRef(expr)\n      const r =\n          expr.type === \"Shape\" ? this.visitShape(expr, label) :\n          expr.type === \"NodeConstraint\" ? this.visitNodeConstraint(expr, label) :\n          expr.type === \"ShapeAnd\" ? this.visitShapeAnd(expr, label) :\n          expr.type === \"ShapeOr\" ? this.visitShapeOr(expr, label) :\n          expr.type === \"ShapeNot\" ? this.visitShapeNot(expr, label) :\n          expr.type === \"ShapeExternal\" ? this.visitShapeExternal(expr) :\n          null;// if (expr.type === \"ShapeRef\") r = 0; // console.warn(\"visitShapeExpr:\", r);\n      if (r === null)\n        throw Error(\"unexpected shapeExpr type: \" + expr.type);\n      else\n        return r;\n    },\n\n    // _visitShapeGroup: visit a grouping expression (shapeAnd, shapeOr)\n    _visitShapeGroup: function (expr, label) {\n      this._testUnknownAttributes(expr, [\"id\", \"shapeExprs\"], expr.type, this.visitShapeNot)\n      const _Visitor = this;\n      const r = { type: expr.type };\n      if (\"id\" in expr)\n        r.id = expr.id;\n      r.shapeExprs = expr.shapeExprs.map(function (nested) {\n        return _Visitor.visitShapeExpr(nested, label);\n      });\n      return r;\n    },\n\n    // _visitShapeNot: visit negated shape\n    visitShapeNot: function (expr, label) {\n      this._testUnknownAttributes(expr, [\"id\", \"shapeExpr\"], \"ShapeNot\", this.visitShapeNot)\n      const r = { type: expr.type };\n      if (\"id\" in expr)\n        r.id = expr.id;\n      r.shapeExpr = this.visitShapeExpr(expr.shapeExpr, label);\n      return r;\n    },\n\n    // ### `visitNodeConstraint` deep-copies the structure of a shape\n    visitShape: function (shape, label) {\n      const ret = { type: \"Shape\" };\n      _expect(shape, \"type\", \"Shape\");\n\n      this._maybeSet(shape, ret, \"Shape\",\n                     [ \"id\",\n                       \"abstract\", \"extends\",\n                       \"closed\",\n                       \"expression\", \"extra\", \"semActs\", \"annotations\"]);\n      return ret;\n    },\n\n    _visitShapeExprList: function (ext) {\n      const _Visitor = this;\n      return ext.map(function (t) {\n        return _Visitor.visitShapeExpr(t, undefined);\n      });\n    },\n\n    // ### `visitNodeConstraint` deep-copies the structure of a shape\n    visitNodeConstraint: function (shape, label) {\n      const ret = { type: \"NodeConstraint\" };\n      _expect(shape, \"type\", \"NodeConstraint\");\n\n      this._maybeSet(shape, ret, \"NodeConstraint\",\n                     [ \"id\",\n                       // \"abstract\", \"extends\", \"restricts\", -- futureWork\n                       \"nodeKind\", \"datatype\", \"pattern\", \"flags\", \"length\",\n                       \"reference\", \"minlength\", \"maxlength\",\n                       \"mininclusive\", \"minexclusive\", \"maxinclusive\", \"maxexclusive\",\n                       \"totaldigits\", \"fractiondigits\", \"values\", \"annotations\", \"semActs\"]);\n      return ret;\n    },\n\n    visitShapeRef: function (reference) {\n      if (typeof reference !== \"string\") {\n        let ex = Exception(\"visitShapeRef expected a string, not \" + JSON.stringify(reference));\n        console.warn(ex);\n        throw ex;\n      }\n      return reference;\n    },\n\n    visitShapeExternal: function (expr) {\n      this._testUnknownAttributes(expr, [\"id\"], \"ShapeExternal\", this.visitShapeNot)\n      return Object.assign(\"id\" in expr ? { id: expr.id } : {}, { type: \"ShapeExternal\" });\n    },\n\n    // _visitGroup: visit a grouping expression (someOf or eachOf)\n    _visitGroup: function (expr, type) {\n      const _Visitor = this;\n      const r = Object.assign(\n        // pre-declare an id so it sorts to the top\n        \"id\" in expr ? { id: null } : { },\n        { type: expr.type }\n      );\n      r.expressions = expr.expressions.map(function (nested) {\n        return _Visitor.visitExpression(nested);\n      });\n      return this._maybeSet(expr, r, \"expr\",\n                            [\"id\", \"min\", \"max\", \"annotations\", \"semActs\"], [\"expressions\"]);\n    },\n\n    visitTripleConstraint: function (expr) {\n      return this._maybeSet(expr,\n                            Object.assign(\n                              // pre-declare an id so it sorts to the top\n                              \"id\" in expr ? { id: null } : { },\n                              { type: \"TripleConstraint\" }\n                            ),\n                            \"TripleConstraint\",\n                            [\"id\", \"inverse\", \"predicate\", \"valueExpr\",\n                             \"min\", \"max\", \"annotations\", \"semActs\"])\n    },\n\n    visitExpression: function (expr) {\n      if (typeof expr === \"string\")\n        return this.visitInclusion(expr);\n      const r = expr.type === \"TripleConstraint\" ? this.visitTripleConstraint(expr) :\n          expr.type === \"OneOf\" ? this.visitOneOf(expr) :\n          expr.type === \"EachOf\" ? this.visitEachOf(expr) :\n          null;\n      if (r === null)\n        throw Error(\"unexpected expression type: \" + expr.type);\n      else\n        return r;\n    },\n\n    visitValues: function (values) {\n      const _Visitor = this;\n      return values.map(function (t) {\n        return isTerm(t) || t.type === \"Language\" ?\n          t :\n          _Visitor.visitStemRange(t);\n      });\n    },\n\n    visitStemRange: function (t) {\n      const _Visitor = this; // console.log(Error(t.type).stack);\n      // _expect(t, \"type\", \"IriStemRange\");\n      if (!(\"type\" in t))\n        _Visitor.runtimeError(Error(\"expected \"+JSON.stringify(t)+\" to have a 'type' attribute.\"));\n      const stemRangeTypes = [\"IriStem\", \"LiteralStem\", \"LanguageStem\", \"IriStemRange\", \"LiteralStemRange\", \"LanguageStemRange\"];\n      if (stemRangeTypes.indexOf(t.type) === -1)\n        _Visitor.runtimeError(Error(\"expected type attribute '\"+t.type+\"' to be in '\"+stemRangeTypes+\"'.\"));\n      let stem;\n      if (isTerm(t)) {\n        _expect(t.stem, \"type\", \"Wildcard\");\n        stem = { type: t.type, stem: { type: \"Wildcard\" } };\n      } else {\n        stem = { type: t.type, stem: t.stem };\n      }\n      if (t.exclusions) {\n        stem.exclusions = t.exclusions.map(function (c) {\n          return _Visitor.visitExclusion(c);\n        });\n      }\n      return stem;\n    },\n\n    visitExclusion: function (c) {\n      if (!isTerm(c)) {\n        // _expect(c, \"type\", \"IriStem\");\n        if (!(\"type\" in c))\n          _Visitor.runtimeError(Error(\"expected \"+JSON.stringify(c)+\" to have a 'type' attribute.\"));\n        const stemTypes = [\"IriStem\", \"LiteralStem\", \"LanguageStem\"];\n        if (stemTypes.indexOf(c.type) === -1)\n          _Visitor.runtimeError(Error(\"expected type attribute '\"+c.type+\"' to be in '\"+stemTypes+\"'.\"));\n        return { type: c.type, stem: c.stem };\n      } else {\n        return c;\n      }\n    },\n\n    visitInclusion: function (inclusion) {\n      if (typeof inclusion !== \"string\") {\n        let ex = Exception(\"visitInclusion expected a string, not \" + JSON.stringify(inclusion));\n        console.warn(ex);\n        throw ex;\n      }\n      return inclusion;\n    },\n\n    _maybeSet: function (obj, ret, context, members, ignore) {\n      const _Visitor = this;\n      this._testUnknownAttributes(obj, ignore ? members.concat(ignore) : members, context, this._maybeSet)\n      members.forEach(function (member) {\n        const methodName = \"visit\" + member.charAt(0).toUpperCase() + member.slice(1);\n        if (member in obj) {\n          const f = _Visitor[methodName];\n          if (typeof f !== \"function\") {\n            throw Error(methodName + \" not found in Visitor\");\n          }\n          const t = f.call(_Visitor, obj[member]);\n          if (t !== undefined) {\n            ret[member] = t;\n          }\n        }\n      });\n      return ret;\n    },\n    _visitValue: function (v) {\n      return v;\n    },\n    _visitList: function (l) {\n      return l.slice();\n    },\n    _testUnknownAttributes: function (obj, expected, context, captureFrame) {\n      const unknownMembers = Object.keys(obj).reduce(function (ret, k) {\n        return k !== \"type\" && expected.indexOf(k) === -1 ? ret.concat(k) : ret;\n      }, []);\n      if (unknownMembers.length > 0) {\n        const e = Error(\"unknown propert\" + (unknownMembers.length > 1 ? \"ies\" : \"y\") + \": \" +\n                      unknownMembers.map(function (p) {\n                        return \"\\\"\" + p + \"\\\"\";\n                      }).join(\",\") +\n                      \" in \" + context + \": \" + JSON.stringify(obj));\n        Error.captureStackTrace(e, captureFrame);\n        throw e;\n      }\n    }\n\n  };\n  r.visitBase = r.visitStart = r.visitClosed = r[\"visit@context\"] = r._visitValue;\n  r.visitRestricts = r.visitExtends = r._visitShapeExprList;\n  r.visitExtra = r.visitAnnotations = r._visitList;\n  r.visitAbstract = r.visitInverse = r.visitPredicate = r._visitValue;\n  r.visitName = r.visitId = r.visitCode = r.visitMin = r.visitMax = r._visitValue;\n\n  r.visitType = r.visitNodeKind = r.visitDatatype = r.visitPattern = r.visitFlags = r.visitLength = r.visitMinlength = r.visitMaxlength = r.visitMininclusive = r.visitMinexclusive = r.visitMaxinclusive = r.visitMaxexclusive = r.visitTotaldigits = r.visitFractiondigits = r._visitValue;\n  r.visitOneOf = r.visitEachOf = r._visitGroup;\n  r.visitShapeAnd = r.visitShapeOr = r._visitShapeGroup;\n  r.visitInclude = r._visitValue;\n  r.visitValueExpr = r.visitShapeExpr;\n  return r;\n\n  // Expect property p with value v in object o\n  function _expect (o, p, v) {\n    if (!(p in o))\n      _error(\"expected \"+JSON.stringify(o)+\" to have a .\"+p);\n    if (arguments.length > 2 && o[p] !== v)\n      _error(\"expected \"+o[p]+\" to equal \"+v);\n  }\n\n  function _error (str) {\n    throw new Error(str);\n  }\n}\n\n// The ShEx Vistor is here to minimize deps for ShExValidator.\n/** create indexes for schema\n */\nShExVisitor.index = function (schema) {\n  let index = {\n    shapeExprs: {},\n    tripleExprs: {}\n  };\n  let v = ShExVisitor();\n\n  let oldVisitExpression = v.visitExpression;\n  v.visitExpression = function (expression) {\n    if (typeof expression === \"object\" && \"id\" in expression)\n      index.tripleExprs[expression.id] = expression;\n    return oldVisitExpression.call(v, expression);\n  };\n\n  let oldVisitShapeExpr = v.visitShapeExpr;\n  v.visitShapeExpr = v.visitValueExpr = function (shapeExpr, label) {\n    if (typeof shapeExpr === \"object\" && \"id\" in shapeExpr)\n      index.shapeExprs[shapeExpr.id] = shapeExpr;\n    return oldVisitShapeExpr.call(v, shapeExpr, label);\n  };\n\n  let oldVisitShapeDecl = v.visitShapeDecl;\n  v.visitShapeDecl = v.visitValueExpr = function (shapeExpr, label) {\n    if (typeof shapeExpr === \"object\" && \"id\" in shapeExpr)\n      index.shapeExprs[shapeExpr.id] = shapeExpr;\n    return oldVisitShapeDecl.call(v, shapeExpr, label);\n  };\n\n  v.visitSchema(schema);\n  return index;\n}\n\nif (true)\n  module.exports = ShExVisitor;\n\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/@shexjs/visitor/shex-visitor.js?");

/***/ }),

/***/ "../fhirlib/node_modules/@shexjs/writer/shex-writer.js":
/*!*************************************************************!*\
  !*** ../fhirlib/node_modules/@shexjs/writer/shex-writer.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// **ShExWriter** writes ShEx documents.\n\nconst ShExWriterCjsModule = (function () {\nconst RelateUrl = __webpack_require__(/*! relateurl */ \"../fhirlib/node_modules/relateurl/lib/index.js\");\nconst UNBOUNDED = -1;\n\n// Matches a literal as represented in memory by the ShEx library\nconst ShExLiteralMatcher = /^\"([^]*)\"(?:\\^\\^(.+)|@([\\-a-z]+))?$/i;\n\n// rdf:type predicate (for 'a' abbreviation)\nconst RDF_PREFIX = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n    RDF_TYPE   = RDF_PREFIX + 'type';\n\n// Characters in literals that require escaping\nconst ESCAPE_1 = /[\"\\\\\\t\\n\\r\\b\\f\\u0000-\\u0019\\ud800-\\udbff]/,\n    ESCAPE_g = /[\"\\\\\\t\\n\\r\\b\\f\\u0000-\\u0019]|[\\ud800-\\udbff][\\udc00-\\udfff]/g,\n    ESCAPE_replacements = { '\\\\': '\\\\\\\\', '\"': '\\\\\"', '/': '\\\\/', '\\t': '\\\\t',\n                            '\\n': '\\\\n', '\\r': '\\\\r', '\\b': '\\\\b', '\\f': '\\\\f' };\n\nconst nodeKinds = {\n  'iri': \"IRI\",\n  'bnode': \"BNODE\",\n  'literal': \"LITERAL\",\n  'nonliteral': \"NONLITERAL\"\n};\nconst nonLitNodeKinds = {\n  'iri': \"IRI\",\n  'bnode': \"BNODE\",\n  'literal': \"LITERAL\",\n  'nonliteral': \"NONLITERAL\"\n};\n\n// ## Constructor\nfunction ShExWriter (outputStream, options) {\n  if (!(this instanceof ShExWriter))\n    return new ShExWriter(outputStream, options);\n\n  // Shift arguments if the first argument is not a stream\n  if (outputStream && typeof outputStream.write !== 'function')\n    options = outputStream, outputStream = null;\n  options = options || {};\n\n  // If no output stream given, send the output as string through the end callback\n  if (!outputStream) {\n    let output = '';\n    this._outputStream = {\n      write: function (chunk, encoding, done) { output += chunk; done && done(); },\n      end:   function (done) { done && done(null, output); },\n    };\n    this._endStream = true;\n  }\n  else {\n    this._outputStream = outputStream;\n    this._endStream = options.end === undefined ? true : !!options.end;\n  }\n\n  // Initialize writer, depending on the format\n  this._prefixIRIs = Object.create(null);\n  this._baseIRI = options.base || null;\n  options.prefixes && this.addPrefixes(options.prefixes);\n\n  this._error = options.error || _throwError;\n  this.forceParens = !options.simplifyParentheses; // default to false\n  this._expect = options.lax ? noop : expect;\n}\n\nShExWriter.prototype = {\n  // ## Private methods\n\n  // ### `_write` writes the argument to the output stream\n  _write: function (string, callback) {\n    this._outputStream.write(string, 'utf8', callback);\n  },\n\n  // ### `_writeSchema` writes the shape to the output stream\n  _writeSchema: function (schema, done) {\n    const _ShExWriter = this;\n    this._expect(schema, \"type\", \"Schema\");\n    _ShExWriter.addPrefixes(schema._prefixes);\n    if (schema._base)\n      _ShExWriter._baseIRI = schema._base;\n\n    if (_ShExWriter._baseIRI)\n      _ShExWriter._write(\"BASE <\" + _ShExWriter._baseIRI + \">\\n\"); // don't use _encodeIriOrBlankNode()\n\n    if (schema.imports)\n      schema.imports.forEach(function (imp) {\n        _ShExWriter._write(\"IMPORT \" + _ShExWriter._encodeIriOrBlankNode(imp) + \"\\n\");\n      });\n    if (schema.startActs)\n      schema.startActs.forEach(function (act) {\n        _ShExWriter._expect(act, \"type\", \"SemAct\");\n        _ShExWriter._write(\" %\"+\n                           _ShExWriter._encodePredicate(act.name)+\n                           (\"code\" in act ? \"{\"+escapeCode(act.code)+\"%\"+\"}\" : \"%\"));\n      });\n    if (schema.start)\n      _ShExWriter._write(\"start = \" + _ShExWriter._writeShapeExpr(schema.start, done, true, 0).join('') + \"\\n\")\n    if (\"shapes\" in schema)\n      schema.shapes.forEach(function (shapeExpr) {\n        let id = shapeExpr.id;\n        let abstract = \"\";\n        if (shapeExpr.type === \"ShapeDecl\") {\n          if (shapeExpr.abstract)\n            abstract = \"abstract \"\n          shapeExpr = shapeExpr.shapeExpr;\n        }\n        _ShExWriter._write(\n          abstract +\n          _ShExWriter._encodeShapeName(id, false) +\n            \" \" +\n            _ShExWriter._writeShapeExpr(shapeExpr, done, true, 0).join(\"\")+\"\\n\",\n          done\n        );\n      })\n  },\n\n  _writeShapeExpr: function (shapeExpr, done, forceBraces, parentPrec) {\n    const _ShExWriter = this;\n    const pieces = [];\n    if (typeof shapeExpr === \"string\") // ShapeRef\n      pieces.push(\"@\", _ShExWriter._encodeShapeName(shapeExpr));\n    // !!! []s for precedence!\n    else if (shapeExpr.type === \"ShapeDecl\")\n      pieces.push(_ShExWriter._writeShapeExpr(shapeExpr.shapeExpr, done, false, 3));\n    else if (shapeExpr.type === \"ShapeExternal\")\n      pieces.push(\"EXTERNAL\");\n    else if (shapeExpr.type === \"ShapeAnd\") {\n      if (parentPrec >= 3)\n        pieces.push(\"(\");\n      let lastAndElided = false;\n      shapeExpr.shapeExprs.forEach(function (expr, ord) {\n        if (ord > 0) { // && !!! grammar rules too weird here\n          /*\n            shapeAtom:\n                  nonLitNodeConstraint shapeOrRef?\n                | shapeDecl nonLitNodeConstraint?\n\n            nonLitInlineNodeConstraint:\n                  nonLiteralKind stringFacet*\n          */\n          function nonLitNodeConstraint (idx) {\n            let c = shapeExpr.shapeExprs[idx];\n            return c.type !== \"NodeConstraint\"\n              || (\"nodeKind\" in c && c.nodeKind === \"literal\")\n              || \"datatype\" in c\n              || \"values\" in c\n              ? false\n              : true;\n          }\n\n          function shapeOrRef (idx) {\n            let c = shapeExpr.shapeExprs[idx];\n            return c.type === \"Shape\" || c.type === \"ShapeRef\";\n          }\n\n          function shapeDecl (idx) {\n            let c = shapeExpr.shapeExprs[idx];\n            return c.type === \"Shape\";\n          }\n\n          let elideAnd = !lastAndElided\n              && (nonLitNodeConstraint(ord-1) && shapeOrRef(ord)\n                  || shapeDecl(ord-1) && nonLitNodeConstraint(ord))\n          if (!elideAnd || true) { // !! temporary work-around for ShExC parser bug\n            pieces.push(\" AND \");\n          }\n          lastAndElided = elideAnd;\n        }\n        [].push.apply(pieces, _ShExWriter._writeShapeExpr(expr, done, false, 3));\n      });\n      if (parentPrec >= 3)\n        pieces.push(\")\");\n    } else if (shapeExpr.type === \"ShapeOr\") {\n      if (parentPrec >= 2)\n        pieces.push(\"(\");\n      shapeExpr.shapeExprs.forEach(function (expr, ord) {\n        if (ord > 0)\n          pieces.push(\" OR \");\n        [].push.apply(pieces, _ShExWriter._writeShapeExpr(expr, done, forceBraces, 2));\n      });\n      if (parentPrec >= 2)\n        pieces.push(\")\");\n    } else if (shapeExpr.type === \"ShapeNot\") {\n      if (parentPrec >= 4)\n        pieces.push(\"(\");\n      pieces.push(\"NOT \");\n      [].push.apply(pieces, _ShExWriter._writeShapeExpr(shapeExpr.shapeExpr, done, forceBraces, 4));\n      if (parentPrec >= 4)\n        pieces.push(\")\");\n    } else if (shapeExpr.type === \"Shape\") {\n      [].push.apply(pieces, _ShExWriter._writeShape(shapeExpr, done, forceBraces));\n    } else if (shapeExpr.type === \"NodeConstraint\") {\n      [].push.apply(pieces, _ShExWriter._writeNodeConstraint(shapeExpr, done, forceBraces));\n    } else\n      throw Error(\"expected Shape{,And,Or,Ref} or NodeConstraint in \" + JSON.stringify(shapeExpr));\n    return pieces;\n  },\n\n  // ### `_writeShape` writes the shape to the output stream\n  _writeShape: function (shape, done, forceBraces) {\n    const _ShExWriter = this;\n    try {\n      const pieces = []; // guessing push/join is faster than concat\n      this._expect(shape, \"type\", \"Shape\");\n\n      if (shape.closed) pieces.push(\"CLOSED \");\n\n      [{keyword: \"extends\", marker: \"EXTENDS \"}].forEach(pair => {\n         // pieces = pieces.concat(_ShExWriter._writeShapeExpr(expr.valueExpr, done, true, 0));\n         if (shape[pair.keyword] && shape[pair.keyword].length > 0) {\n           shape[pair.keyword].forEach(function (i, ord) {\n             if (ord)\n               pieces.push(\" \")\n             pieces.push(pair.marker);\n             [].push.apply(pieces, _ShExWriter._writeShapeExpr(i, done, true, 0));\n           });\n           pieces.push(\" \");\n         }\n       });\n\n      if (shape.extra && shape.extra.length > 0) {\n        pieces.push(\"EXTRA \");\n        shape.extra.forEach(function (i, ord) {\n          pieces.push(_ShExWriter._encodeShapeName(i, false)+\" \");\n        });\n        pieces.push(\" \");\n      }\n      const empties = [\"values\", \"length\", \"minlength\", \"maxlength\", \"pattern\", \"flags\"];\n      pieces.push(\"{\\n\");\n\n      function _writeShapeActions (semActs) {\n        if (!semActs)\n          return;\n\n        semActs.forEach(function (act) {\n          _ShExWriter._expect(act, \"type\", \"SemAct\");\n          pieces.push(\" %\",\n                      _ShExWriter._encodePredicate(act.name),\n                      (\"code\" in act ? \"{\"+escapeCode(act.code)+\"%\"+\"}\" : \"%\"));\n        });\n      }\n\n      function _writeCardinality (min, max) {\n        if      (min === 0 && max === 1)         pieces.push(\"?\");\n        else if (min === 0 && max === UNBOUNDED) pieces.push(\"*\");\n        else if (min === undefined && max === undefined)                         ;\n        else if (min === 1 && max === UNBOUNDED) pieces.push(\"+\");\n        else\n          pieces.push(\"{\", min, \",\", (max === UNBOUNDED ? \"*\" : max), \"}\"); // by coincidence, both use the same character.\n      }\n\n      function _writeExpression (expr, indent, parentPrecedence) {\n        function _writeExpressionActions (semActs) {\n          if (semActs) {\n\n            semActs.forEach(function (act) {\n              _ShExWriter._expect(act, \"type\", \"SemAct\");\n              pieces.push(\"\\n\"+indent+\"   %\");\n              pieces.push(_ShExWriter._encodeValue(act.name));\n              if (\"code\" in act)\n                pieces.push(\"{\"+escapeCode(act.code)+\"%\"+\"}\");\n              else\n                pieces.push(\"%\");\n            });\n          }\n        }\n\n        function _exprGroup (exprs, separator, precedence, forceParens) {\n          const needsParens = precedence < parentPrecedence || forceParens;\n          if (needsParens) {\n            pieces.push(\"(\");\n          }\n          exprs.forEach(function (nested, ord) {\n            _writeExpression(nested, indent+\"  \", precedence)\n            if (ord < exprs.length - 1)\n              pieces.push(separator);\n          });\n          if (needsParens) {\n            pieces.push(\")\");\n          }\n        }\n\n        if (typeof expr === \"string\") {\n          pieces.push(\"&\");\n          pieces.push(_ShExWriter._encodeShapeName(expr, false));\n        } else {\n\n        if (\"id\" in expr) {\n          pieces.push(\"$\");\n          pieces.push(_ShExWriter._encodeIriOrBlankNode(expr.id, true));\n        }\n\n        if (expr.type === \"TripleConstraint\") {\n          if (expr.inverse)\n            pieces.push(\"^\");\n          if (expr.negated)\n            pieces.push(\"!\");\n          pieces.push(indent,\n                      _ShExWriter._encodePredicate(expr.predicate),\n                      \" \");\n\n          if (\"valueExpr\" in expr)\n            [].push.apply(pieces, _ShExWriter._writeShapeExpr(expr.valueExpr, done, true, 0));\n          else\n            pieces.push(\". \");\n\n          _writeCardinality(expr.min, expr.max);\n          _ShExWriter._annotations(pieces, expr.annotations, indent);\n          _writeExpressionActions(expr.semActs);\n        }\n\n        else if (expr.type === \"OneOf\") {\n          const needsParens = \"id\" in expr || \"min\" in expr || \"max\" in expr || \"annotations\" in expr || \"semActs\" in expr;\n          _exprGroup(expr.expressions, \"\\n\"+indent+\"| \", 1, needsParens || _ShExWriter.forceParens);\n          _writeCardinality(expr.min, expr.max); // t: open1dotclosecardOpt\n          _ShExWriter._annotations(pieces, expr.annotations, indent);\n          _writeExpressionActions(expr.semActs);\n        }\n\n        else if (expr.type === \"EachOf\") {\n          const needsParens = \"id\" in expr || \"min\" in expr || \"max\" in expr || \"annotations\" in expr || \"semActs\" in expr;\n          _exprGroup(expr.expressions, \";\\n\"+indent, 2, needsParens || _ShExWriter.forceParens);\n          _writeCardinality(expr.min, expr.max); // t: open1dotclosecardOpt\n          _ShExWriter._annotations(pieces, expr.annotations, indent);\n          _writeExpressionActions(expr.semActs);\n        }\n\n        else throw Error(\"unexpected expr type: \" + expr.type);\n        }\n      }\n\n      if (shape.expression) // t: 0, 0Extend1\n        _writeExpression(shape.expression, \"  \", 0);\n      pieces.push(\"\\n}\");\n      _writeShapeActions(shape.semActs);\n      _ShExWriter._annotations(pieces, shape.annotations, \"  \");\n\n      return pieces;\n    }\n    catch (error) { done && done(error); }\n  },\n\n  // ### `_writeShape` writes the shape to the output stream\n  _writeNodeConstraint: function (v, done) {\n    const _ShExWriter = this;\n    try {\n      _ShExWriter._expect(v, \"type\", \"NodeConstraint\");\n\n      const pieces = [];\n      if (v.nodeKind in nodeKinds)       pieces.push(nodeKinds[v.nodeKind], \" \");\n      else if (v.nodeKind !== undefined) _ShExWriter._error(\"unexpected nodeKind: \" + v.nodeKind); // !!!!\n\n      this._fillNodeConstraint(pieces, v, done);\n      this._annotations(pieces, v.annotations, \"  \");\n      return pieces;\n    }\n    catch (error) { done && done(error); }\n\n  },\n\n  _annotations: function (pieces, annotations, indent) {\n    const _ShExWriter = this;\n    if (annotations) {\n      annotations.forEach(function (a) {\n        _ShExWriter._expect(a, \"type\", \"Annotation\");\n        pieces.push(\"//\\n\"+indent+\"   \");\n        pieces.push(_ShExWriter._encodeValue(a.predicate));\n        pieces.push(\" \");\n        pieces.push(_ShExWriter._encodeValue(a.object));\n      });\n    }\n  },\n\n  _fillNodeConstraint: function (pieces, v, done) {\n    const _ShExWriter = this;\n    if (v.datatype  && v.values  ) _ShExWriter._error(\"found both datatype and values in \"   +expr);\n    if (v.datatype) {\n      pieces.push(_ShExWriter._encodeShapeName(v.datatype));\n    }\n\n    if (v.values) {\n      pieces.push(\"[\");\n\n      v.values.forEach(function (t, ord) {\n        if (ord > 0)\n          pieces.push(\" \");\n\n        if (!isTerm(t)) {\n//          expect(t, \"type\", \"IriStemRange\");\n              if (!(\"type\" in t))\n                runtimeError(\"expected \"+JSON.stringify(t)+\" to have a 'type' attribute.\");\n          const stemRangeTypes = [\"Language\", \"IriStem\", \"LiteralStem\", \"LanguageStem\", \"IriStemRange\", \"LiteralStemRange\", \"LanguageStemRange\"];\n              if (stemRangeTypes.indexOf(t.type) === -1)\n                runtimeError(\"expected type attribute '\"+t.type+\"' to be in '\"+stemRangeTypes+\"'.\");\n          if (t.type === \"Language\") {\n            pieces.push(\"@\" + t.languageTag);\n          } else if (!isTerm(t.stem)) {\n            expect(t.stem, \"type\", \"Wildcard\");\n            pieces.push(\".\");\n          } else {\n            pieces.push(langOrLiteral(t, t.stem) + \"~\");\n          }\n          if (t.exclusions) {\n            t.exclusions.forEach(function (c) {\n              pieces.push(\" - \");\n              if (!isTerm(c)) {\n//                expect(c, \"type\", \"IriStem\");\n                    if (!(\"type\" in c))\n                      runtimeError(\"expected \"+JSON.stringify(c)+\" to have a 'type' attribute.\");\n                    const stemTypes = [\"IriStem\", \"LiteralStem\", \"LanguageStem\"];\n                    if (stemTypes.indexOf(c.type) === -1)\n                      runtimeError(\"expected type attribute '\"+c.type+\"' to be in '\"+stemTypes+\"'.\");\n                pieces.push(langOrLiteral(t, c.stem) + \"~\");\n              } else {\n                pieces.push(langOrLiteral(t, c));\n              }\n            });\n          }\n          function langOrLiteral (t, c) {\n            return [\"LanguageStem\", \"LanguageStemRange\"].indexOf(t.type) !== -1 ? \"@\" + c :\n              [\"LiteralStem\", \"LiteralStemRange\"].indexOf(t.type) !== -1 ? '\"' + c.replace(ESCAPE_g, c) + '\"' :\n              _ShExWriter._encodeValue(c)\n          }\n        } else {\n          pieces.push(_ShExWriter._encodeValue(t));\n        }\n      });\n\n      pieces.push(\"]\");\n    }\n\n    if ('pattern' in v) {\n      const pattern = v.pattern.\n          replace(/\\//g, \"\\\\/\");\n      // if (ESCAPE_1.test(pattern))\n      //   pattern = pattern.replace(ESCAPE_g, characterReplacer);\n      const flags = 'flags' in v ? v.flags : \"\";\n      pieces.push(\"/\" + pattern + \"/\" + flags + \" \");\n    }\n    ['length', 'minlength', 'maxlength',\n     'mininclusive', 'minexclusive', 'maxinclusive', 'maxexclusive',\n     'totaldigits', 'fractiondigits'\n    ].forEach(function (a) {\n      if (v[a])\n        pieces.push(\" \", a, \" \", v[a]);\n    });\n    return pieces;\n\n    function isTerm (t) {\n      return typeof t !== \"object\" || \"value\" in t && Object.keys(t).reduce((r, k) => {\n        return r === false ? r : [\"value\", \"type\", \"language\"].indexOf(k) !== -1;\n      }, true);\n    }\n  },\n\n  // ### `_encodeIriOrBlankNode` represents an IRI or blank node\n  _encodeIriOrBlankNode: function (iri, trailingSpace) {\n    trailingSpace = trailingSpace ? ' ' : '';\n    // A blank node is represented as-is\n    if (iri[0] === '_' && iri[1] === ':') return iri;\n    // Escape special characters\n    if (ESCAPE_1.test(iri))\n      iri = iri.replace(ESCAPE_g, characterReplacer);\n    // Try to represent the IRI as prefixed name\n    const prefixMatch = this._prefixRegex.exec(iri);\n    return !prefixMatch\n      ? this._relateUrl(iri)\n      : (!prefixMatch[1]\n         ? iri\n         : this._prefixIRIs[prefixMatch[1]] + prefixMatch[2])\n      + trailingSpace;\n  },\n\n  // ### ``\n  _relateUrl: function (iri) {\n    const base = this._baseIRI;\n    try {\n      if (base && new URL(base).host === new URL(iri).host) // https://github.com/stevenvachon/relateurl/issues/28\n        iri = RelateUrl.relate(base, iri, { output: RelateUrl.ROOT_PATH_RELATIVE });\n    } catch (e) {\n      // invalid URL for e.g. already relative IMPORTs\n    }\n    return '<' + iri + '>';\n  },\n\n  // ### `_encodeLiteral` represents a literal\n  _encodeLiteral: function (value, type, language) {\n    // Escape special characters\n    if (ESCAPE_1.test(value))\n      value = value.replace(ESCAPE_g, characterReplacer);\n    // Write the literal, possibly with type or language\n    if (language) {\n      return '\"' + value + '\"@' + language;\n    } else if (type) { // && type !== \"http://www.w3.org/2001/XMLSchema#integer\" is implied by the parsing rules.\n      if (type === \"http://www.w3.org/2001/XMLSchema#integer\" && value.match(/^[+-]?[0-9]+$/)) {\n        return value;\n      } else if (type === \"http://www.w3.org/2001/XMLSchema#decimal\" && value.match(/^[+-]?[0-9]*\\.[0-9]+$/)) {\n        return value;\n      } else if (type === \"http://www.w3.org/2001/XMLSchema#double\" && value.match(/^[+-]?([0-9]+\\.[0-9]*[eE][+-]?[0-9]+|\\.?[0-9]+[eE][+-]?[0-9]+)$/)) {\n        return value;\n      } else {\n        return '\"' + value + '\"^^' + this._encodeIriOrBlankNode(type);\n      }\n    } else {\n      return '\"' + value + '\"';\n    }\n  },\n\n  // ### `_encodeShapeName` represents a subject\n  _encodeShapeName: function (subject, trailingSpace) {\n    if (subject[0] === '\"')\n      throw new Error('A literal as subject is not allowed: ' + subject);\n    return this._encodeIriOrBlankNode(subject, trailingSpace);\n  },\n\n  // ### `_encodePredicate` represents a predicate\n  _encodePredicate: function (predicate) {\n    if (predicate[0] === '\"')\n      throw new Error('A literal as predicate is not allowed: ' + predicate);\n    return predicate === RDF_TYPE ? 'a' : this._encodeIriOrBlankNode(predicate);\n  },\n\n  // ### `_encodeValue` represents an object\n  _encodeValue: function (object) {\n    // Represent an IRI or blank node\n    if (typeof object !== \"object\")\n      return this._encodeIriOrBlankNode(object);\n    // Represent a literal\n    return this._encodeLiteral(object.value, object.type, object.language);\n  },\n\n  // ### `_blockedWrite` replaces `_write` after the writer has been closed\n  _blockedWrite: function () {\n    throw new Error('Cannot write because the writer has been closed.');\n  },\n\n  writeSchema: function (shape, done) {\n    this._writeSchema(shape, done);\n    this.end(done);\n  },\n\n  // ### `addShape` adds the shape to the output stream\n  addShape: function (shape, name, done) {\n    this._write(\n      _ShExWriter._encodeShapeName(name, false) +\n        \" \" +\n        _ShExWriter._writeShapeExpr(shape, done, true, 0).join(\"\"),\n      done\n    );\n  },\n\n  // ### `addShapes` adds the shapes to the output stream\n  addShapes: function (shapes) {\n    for (let i = 0; i < shapes.length; i++)\n      this.addShape(shapes[i]);\n  },\n\n  // ### `addPrefix` adds the prefix to the output stream\n  addPrefix: function (prefix, iri, done) {\n    const prefixes = {};\n    prefixes[prefix] = iri;\n    this.addPrefixes(prefixes, done);\n  },\n\n  // ### `addPrefixes` adds the prefixes to the output stream\n  addPrefixes: function (prefixes, done) {\n    // Add all useful prefixes\n    const prefixIRIs = this._prefixIRIs;\n    let hasPrefixes = false;\n    for (let prefix in prefixes) {\n      // Verify whether the prefix can be used and does not exist yet\n      const iri = prefixes[prefix];\n      if (// @@ /[#\\/]$/.test(iri) && !! what was that?\n          prefixIRIs[iri] !== (prefix += ':')) {\n        hasPrefixes = true;\n        prefixIRIs[iri] = prefix;\n        // Write prefix\n        this._write('PREFIX ' + prefix + ' <' + iri + '>\\n');\n      }\n    }\n    // Recreate the prefix matcher\n    if (hasPrefixes) {\n      let IRIlist = '', prefixList = '';\n      for (let prefixIRI in prefixIRIs) {\n        IRIlist += IRIlist ? '|' + prefixIRI : prefixIRI;\n        prefixList += (prefixList ? '|' : '') + prefixIRIs[prefixIRI];\n      }\n      IRIlist = IRIlist.replace(/[\\]\\/\\(\\)\\*\\+\\?\\.\\\\\\$]/g, '\\\\$&');\n      this._prefixRegex = new RegExp('^(?:' + prefixList + ')[^\\/]*$|' +\n                                     '^(' + IRIlist + ')([a-zA-Z][\\\\-_a-zA-Z0-9]*)$');\n    }\n    // End a prefix block with a newline\n    this._write(hasPrefixes ? '\\n' : '', done);\n  },\n\n  // ### `_prefixRegex` matches a prefixed name or IRI that begins with one of the added prefixes\n  _prefixRegex: /$0^/,\n\n  // ### `end` signals the end of the output stream\n  end: function (done) {\n    // Disallow further writing\n    this._write = this._blockedWrite;\n\n    // Try to end the underlying stream, ensuring done is called exactly one time\n    let singleDone = done && function (error, result) { singleDone = null, done(error, result); };\n    if (this._endStream) {\n      try { return this._outputStream.end(singleDone); }\n      catch (error) { /* error closing stream */ }\n    }\n    singleDone && singleDone();\n  },\n};\n\n// Replaces a character by its escaped version\nfunction characterReplacer(character) {\n  // Replace a single character by its escaped version\n  let result = ESCAPE_replacements[character];\n  if (result === undefined) {\n    // Replace a single character with its 4-bit unicode escape sequence\n    if (character.length === 1) {\n      result = character.charCodeAt(0).toString(16);\n      result = '\\\\u0000'.substr(0, 6 - result.length) + result;\n    }\n    // Replace a surrogate pair with its 8-bit unicode escape sequence\n    else {\n      result = ((character.charCodeAt(0) - 0xD800) * 0x400 +\n                 character.charCodeAt(1) + 0x2400).toString(16);\n      result = '\\\\U00000000'.substr(0, 10 - result.length) + result;\n    }\n  }\n  return result;\n}\n\nfunction escapeCode (code) {\n  return code.replace(/\\\\/g, \"\\\\\\\\\").replace(/%/g, \"\\\\%\")\n}\n\n/** _throwError: overridable function to throw Errors().\n *\n * @param func (optional): function at which to truncate stack trace\n * @param str: error message\n */\nfunction _throwError (func, str) {\n  if (typeof func !== \"function\") {\n    str = func;\n    func = _throwError;\n  }\n  const e = new Error(str);\n  Error.captureStackTrace(e, func);\n  throw e;\n}\n\n// Expect property p with value v in object o\nfunction expect (o, p, v) {\n  if (!(p in o))\n    this._error(expect, \"expected \"+o+\" to have a .\"+p);\n  if (arguments.length > 2 && o[p] !== v)\n    this._error(expect, \"expected \"+o[o]+\" to equal .\"+v);\n}\n\n// The empty function\nfunction noop () {}\n\nreturn ShExWriter;\n})();\n\n// Export the `ShExWriter` class as a whole.\nif (true)\n  module.exports = ShExWriterCjsModule; // node environment\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/@shexjs/writer/shex-writer.js?");

/***/ }),

/***/ "../fhirlib/node_modules/hierarchy-closure/hierarchy-closure.js":
/*!**********************************************************************!*\
  !*** ../fhirlib/node_modules/hierarchy-closure/hierarchy-closure.js ***!
  \**********************************************************************/
/***/ ((module) => {

eval("var HierarchyClosure = (function () {\n  /** create a hierarchy object\n   * This object keeps track of direct children and parents as well as transitive children and parents.\n   */\n  function makeHierarchy () {\n    let roots = {}\n    let parents = {}\n    let children = {}\n    let holders = {}\n    return {\n      add: function (parent, child) {\n        if (// test if this is a novel entry.\n          (parent in children && children[parent].indexOf(child) !== -1)) {\n          return\n        }\n        let target = parent in holders\n          ? getNode(parent)\n          : (roots[parent] = getNode(parent)) // add new parents to roots.\n        let value = getNode(child)\n\n        target[child] = value\n        delete roots[child]\n\n        // // maintain hierarchy (direct and confusing)\n        // children[parent] = children[parent].concat(child, children[child])\n        // children[child].forEach(c => parents[c] = parents[c].concat(parent, parents[parent]))\n        // parents[child] = parents[child].concat(parent, parents[parent])\n        // parents[parent].forEach(p => children[p] = children[p].concat(child, children[child]))\n\n        // maintain hierarchy (generic and confusing)\n        updateClosure(children, parents, child, parent)\n        updateClosure(parents, children, parent, child)\n        function updateClosure (container, members, near, far) {\n          container[far] = container[far].filter(\n            e => /* e !== near && */ container[near].indexOf(e) === -1\n          ).concat(container[near].indexOf(near) === -1 ? [near] : [], container[near])\n          container[near].forEach(\n            n => (members[n] = members[n].filter(\n              e => e !== far && members[far].indexOf(e) === -1\n            ).concat(members[far].indexOf(far) === -1 ? [far] : [], members[far]))\n          )\n        }\n\n        function getNode (node) {\n          if (!(node in holders)) {\n            parents[node] = []\n            children[node] = []\n            holders[node] = {}\n          }\n          return holders[node]\n        }\n      },\n      roots: roots,\n      parents: parents,\n      children: children\n    }\n  }\n\n  function depthFirst (n, f, p) {\n    return Object.keys(n).reduce((ret, k) => {\n      return ret.concat(\n        depthFirst(n[k], f, k),\n        p ? f(k, p) : []) // outer invocation can have null parent\n    }, [])\n  }\n\n  return { create: makeHierarchy, depthFirst }\n})()\n\n/* istanbul ignore next */\nif (true) {\n  module.exports = HierarchyClosure\n}\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/hierarchy-closure/hierarchy-closure.js?");

/***/ }),

/***/ "../fhirlib/node_modules/inherits/inherits_browser.js":
/*!************************************************************!*\
  !*** ../fhirlib/node_modules/inherits/inherits_browser.js ***!
  \************************************************************/
/***/ ((module) => {

eval("if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/inherits/inherits_browser.js?");

/***/ }),

/***/ "../fhirlib/node_modules/n3/lib/IRIs.js":
/*!**********************************************!*\
  !*** ../fhirlib/node_modules/n3/lib/IRIs.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\nconst RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n      XSD = 'http://www.w3.org/2001/XMLSchema#',\n      SWAP = 'http://www.w3.org/2000/10/swap/';\nvar _default = {\n  xsd: {\n    decimal: `${XSD}decimal`,\n    boolean: `${XSD}boolean`,\n    double: `${XSD}double`,\n    integer: `${XSD}integer`,\n    string: `${XSD}string`\n  },\n  rdf: {\n    type: `${RDF}type`,\n    nil: `${RDF}nil`,\n    first: `${RDF}first`,\n    rest: `${RDF}rest`,\n    langString: `${RDF}langString`\n  },\n  owl: {\n    sameAs: 'http://www.w3.org/2002/07/owl#sameAs'\n  },\n  r: {\n    forSome: `${SWAP}reify#forSome`,\n    forAll: `${SWAP}reify#forAll`\n  },\n  log: {\n    implies: `${SWAP}log#implies`\n  }\n};\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/n3/lib/IRIs.js?");

/***/ }),

/***/ "../fhirlib/node_modules/n3/lib/N3DataFactory.js":
/*!*******************************************************!*\
  !*** ../fhirlib/node_modules/n3/lib/N3DataFactory.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = exports.Variable = exports.Triple = exports.Term = exports.Quad = exports.NamedNode = exports.Literal = exports.DefaultGraph = exports.BlankNode = void 0;\nexports.escapeQuotes = escapeQuotes;\nexports.termFromId = termFromId;\nexports.termToId = termToId;\nexports.unescapeQuotes = unescapeQuotes;\n\nvar _IRIs = _interopRequireDefault(__webpack_require__(/*! ./IRIs */ \"../fhirlib/node_modules/n3/lib/IRIs.js\"));\n\nvar _N3Util = __webpack_require__(/*! ./N3Util */ \"../fhirlib/node_modules/n3/lib/N3Util.js\");\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// N3.js implementations of the RDF/JS core data types\n// See https://github.com/rdfjs/representation-task-force/blob/master/interface-spec.md\nconst {\n  rdf,\n  xsd\n} = _IRIs.default; // eslint-disable-next-line prefer-const\n\nlet DEFAULTGRAPH;\nlet _blankNodeCounter = 0;\nconst escapedLiteral = /^\"(.*\".*)(?=\"[^\"]*$)/;\nconst quadId = /^<<(\"(?:\"\"|[^\"])*\"[^ ]*|[^ ]+) (\"(?:\"\"|[^\"])*\"[^ ]*|[^ ]+) (\"(?:\"\"|[^\"])*\"[^ ]*|[^ ]+) ?(\"(?:\"\"|[^\"])*\"[^ ]*|[^ ]+)?>>$/; // ## DataFactory singleton\n\nconst DataFactory = {\n  namedNode,\n  blankNode,\n  variable,\n  literal,\n  defaultGraph,\n  quad,\n  triple: quad\n};\nvar _default = DataFactory; // ## Term constructor\n\nexports[\"default\"] = _default;\n\nclass Term {\n  constructor(id) {\n    this.id = id;\n  } // ### The value of this term\n\n\n  get value() {\n    return this.id;\n  } // ### Returns whether this object represents the same term as the other\n\n\n  equals(other) {\n    // If both terms were created by this library,\n    // equality can be computed through ids\n    if (other instanceof Term) return this.id === other.id; // Otherwise, compare term type and value\n\n    return !!other && this.termType === other.termType && this.value === other.value;\n  } // ### Returns a plain object representation of this term\n\n\n  toJSON() {\n    return {\n      termType: this.termType,\n      value: this.value\n    };\n  }\n\n} // ## NamedNode constructor\n\n\nexports.Term = Term;\n\nclass NamedNode extends Term {\n  // ### The term type of this term\n  get termType() {\n    return 'NamedNode';\n  }\n\n} // ## Literal constructor\n\n\nexports.NamedNode = NamedNode;\n\nclass Literal extends Term {\n  // ### The term type of this term\n  get termType() {\n    return 'Literal';\n  } // ### The text value of this literal\n\n\n  get value() {\n    return this.id.substring(1, this.id.lastIndexOf('\"'));\n  } // ### The language of this literal\n\n\n  get language() {\n    // Find the last quotation mark (e.g., '\"abc\"@en-us')\n    const id = this.id;\n    let atPos = id.lastIndexOf('\"') + 1; // If \"@\" it follows, return the remaining substring; empty otherwise\n\n    return atPos < id.length && id[atPos++] === '@' ? id.substr(atPos).toLowerCase() : '';\n  } // ### The datatype IRI of this literal\n\n\n  get datatype() {\n    return new NamedNode(this.datatypeString);\n  } // ### The datatype string of this literal\n\n\n  get datatypeString() {\n    // Find the last quotation mark (e.g., '\"abc\"^^http://ex.org/types#t')\n    const id = this.id,\n          dtPos = id.lastIndexOf('\"') + 1;\n    const char = dtPos < id.length ? id[dtPos] : ''; // If \"^\" it follows, return the remaining substring\n\n    return char === '^' ? id.substr(dtPos + 2) : // If \"@\" follows, return rdf:langString; xsd:string otherwise\n    char !== '@' ? xsd.string : rdf.langString;\n  } // ### Returns whether this object represents the same term as the other\n\n\n  equals(other) {\n    // If both literals were created by this library,\n    // equality can be computed through ids\n    if (other instanceof Literal) return this.id === other.id; // Otherwise, compare term type, value, language, and datatype\n\n    return !!other && !!other.datatype && this.termType === other.termType && this.value === other.value && this.language === other.language && this.datatype.value === other.datatype.value;\n  }\n\n  toJSON() {\n    return {\n      termType: this.termType,\n      value: this.value,\n      language: this.language,\n      datatype: {\n        termType: 'NamedNode',\n        value: this.datatypeString\n      }\n    };\n  }\n\n} // ## BlankNode constructor\n\n\nexports.Literal = Literal;\n\nclass BlankNode extends Term {\n  constructor(name) {\n    super(`_:${name}`);\n  } // ### The term type of this term\n\n\n  get termType() {\n    return 'BlankNode';\n  } // ### The name of this blank node\n\n\n  get value() {\n    return this.id.substr(2);\n  }\n\n}\n\nexports.BlankNode = BlankNode;\n\nclass Variable extends Term {\n  constructor(name) {\n    super(`?${name}`);\n  } // ### The term type of this term\n\n\n  get termType() {\n    return 'Variable';\n  } // ### The name of this variable\n\n\n  get value() {\n    return this.id.substr(1);\n  }\n\n} // ## DefaultGraph constructor\n\n\nexports.Variable = Variable;\n\nclass DefaultGraph extends Term {\n  constructor() {\n    super('');\n    return DEFAULTGRAPH || this;\n  } // ### The term type of this term\n\n\n  get termType() {\n    return 'DefaultGraph';\n  } // ### Returns whether this object represents the same term as the other\n\n\n  equals(other) {\n    // If both terms were created by this library,\n    // equality can be computed through strict equality;\n    // otherwise, compare term types.\n    return this === other || !!other && this.termType === other.termType;\n  }\n\n} // ## DefaultGraph singleton\n\n\nexports.DefaultGraph = DefaultGraph;\nDEFAULTGRAPH = new DefaultGraph(); // ### Constructs a term from the given internal string ID\n\nfunction termFromId(id, factory) {\n  factory = factory || DataFactory; // Falsy value or empty string indicate the default graph\n\n  if (!id) return factory.defaultGraph(); // Identify the term type based on the first character\n\n  switch (id[0]) {\n    case '?':\n      return factory.variable(id.substr(1));\n\n    case '_':\n      return factory.blankNode(id.substr(2));\n\n    case '\"':\n      // Shortcut for internal literals\n      if (factory === DataFactory) return new Literal(id); // Literal without datatype or language\n\n      if (id[id.length - 1] === '\"') return factory.literal(id.substr(1, id.length - 2)); // Literal with datatype or language\n\n      const endPos = id.lastIndexOf('\"', id.length - 1);\n      return factory.literal(id.substr(1, endPos - 1), id[endPos + 1] === '@' ? id.substr(endPos + 2) : factory.namedNode(id.substr(endPos + 3)));\n\n    case '<':\n      const components = quadId.exec(id);\n      return factory.quad(termFromId(unescapeQuotes(components[1]), factory), termFromId(unescapeQuotes(components[2]), factory), termFromId(unescapeQuotes(components[3]), factory), components[4] && termFromId(unescapeQuotes(components[4]), factory));\n\n    default:\n      return factory.namedNode(id);\n  }\n} // ### Constructs an internal string ID from the given term or ID string\n\n\nfunction termToId(term) {\n  if (typeof term === 'string') return term;\n  if (term instanceof Term && term.termType !== 'Quad') return term.id;\n  if (!term) return DEFAULTGRAPH.id; // Term instantiated with another library\n\n  switch (term.termType) {\n    case 'NamedNode':\n      return term.value;\n\n    case 'BlankNode':\n      return `_:${term.value}`;\n\n    case 'Variable':\n      return `?${term.value}`;\n\n    case 'DefaultGraph':\n      return '';\n\n    case 'Literal':\n      return `\"${term.value}\"${term.language ? `@${term.language}` : term.datatype && term.datatype.value !== xsd.string ? `^^${term.datatype.value}` : ''}`;\n\n    case 'Quad':\n      // To identify RDF* quad components, we escape quotes by doubling them.\n      // This avoids the overhead of backslash parsing of Turtle-like syntaxes.\n      return `<<${escapeQuotes(termToId(term.subject))} ${escapeQuotes(termToId(term.predicate))} ${escapeQuotes(termToId(term.object))}${(0, _N3Util.isDefaultGraph)(term.graph) ? '' : ` ${termToId(term.graph)}`}>>`;\n\n    default:\n      throw new Error(`Unexpected termType: ${term.termType}`);\n  }\n} // ## Quad constructor\n\n\nclass Quad extends Term {\n  constructor(subject, predicate, object, graph) {\n    super('');\n    this._subject = subject;\n    this._predicate = predicate;\n    this._object = object;\n    this._graph = graph || DEFAULTGRAPH;\n  } // ### The term type of this term\n\n\n  get termType() {\n    return 'Quad';\n  }\n\n  get subject() {\n    return this._subject;\n  }\n\n  get predicate() {\n    return this._predicate;\n  }\n\n  get object() {\n    return this._object;\n  }\n\n  get graph() {\n    return this._graph;\n  } // ### Returns a plain object representation of this quad\n\n\n  toJSON() {\n    return {\n      termType: this.termType,\n      subject: this._subject.toJSON(),\n      predicate: this._predicate.toJSON(),\n      object: this._object.toJSON(),\n      graph: this._graph.toJSON()\n    };\n  } // ### Returns whether this object represents the same quad as the other\n\n\n  equals(other) {\n    return !!other && this._subject.equals(other.subject) && this._predicate.equals(other.predicate) && this._object.equals(other.object) && this._graph.equals(other.graph);\n  }\n\n}\n\nexports.Triple = exports.Quad = Quad;\n\n// ### Escapes the quotes within the given literal\nfunction escapeQuotes(id) {\n  return id.replace(escapedLiteral, (_, quoted) => `\"${quoted.replace(/\"/g, '\"\"')}`);\n} // ### Unescapes the quotes within the given literal\n\n\nfunction unescapeQuotes(id) {\n  return id.replace(escapedLiteral, (_, quoted) => `\"${quoted.replace(/\"\"/g, '\"')}`);\n} // ### Creates an IRI\n\n\nfunction namedNode(iri) {\n  return new NamedNode(iri);\n} // ### Creates a blank node\n\n\nfunction blankNode(name) {\n  return new BlankNode(name || `n3-${_blankNodeCounter++}`);\n} // ### Creates a literal\n\n\nfunction literal(value, languageOrDataType) {\n  // Create a language-tagged string\n  if (typeof languageOrDataType === 'string') return new Literal(`\"${value}\"@${languageOrDataType.toLowerCase()}`); // Automatically determine datatype for booleans and numbers\n\n  let datatype = languageOrDataType ? languageOrDataType.value : '';\n\n  if (datatype === '') {\n    // Convert a boolean\n    if (typeof value === 'boolean') datatype = xsd.boolean; // Convert an integer or double\n    else if (typeof value === 'number') {\n      if (Number.isFinite(value)) datatype = Number.isInteger(value) ? xsd.integer : xsd.double;else {\n        datatype = xsd.double;\n        if (!Number.isNaN(value)) value = value > 0 ? 'INF' : '-INF';\n      }\n    }\n  } // Create a datatyped literal\n\n\n  return datatype === '' || datatype === xsd.string ? new Literal(`\"${value}\"`) : new Literal(`\"${value}\"^^${datatype}`);\n} // ### Creates a variable\n\n\nfunction variable(name) {\n  return new Variable(name);\n} // ### Returns the default graph\n\n\nfunction defaultGraph() {\n  return DEFAULTGRAPH;\n} // ### Creates a quad\n\n\nfunction quad(subject, predicate, object, graph) {\n  return new Quad(subject, predicate, object, graph);\n}\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/n3/lib/N3DataFactory.js?");

/***/ }),

/***/ "../fhirlib/node_modules/n3/lib/N3Store.js":
/*!*************************************************!*\
  !*** ../fhirlib/node_modules/n3/lib/N3Store.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nvar _N3DataFactory = _interopRequireWildcard(__webpack_require__(/*! ./N3DataFactory */ \"../fhirlib/node_modules/n3/lib/N3DataFactory.js\"));\n\nvar _readableStream = __webpack_require__(/*! readable-stream */ \"../fhirlib/node_modules/readable-stream/readable-browser.js\");\n\nvar _IRIs = _interopRequireDefault(__webpack_require__(/*! ./IRIs */ \"../fhirlib/node_modules/n3/lib/IRIs.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _getRequireWildcardCache(nodeInterop) { if (typeof WeakMap !== \"function\") return null; var cacheBabelInterop = new WeakMap(); var cacheNodeInterop = new WeakMap(); return (_getRequireWildcardCache = function (nodeInterop) { return nodeInterop ? cacheNodeInterop : cacheBabelInterop; })(nodeInterop); }\n\nfunction _interopRequireWildcard(obj, nodeInterop) { if (!nodeInterop && obj && obj.__esModule) { return obj; } if (obj === null || typeof obj !== \"object\" && typeof obj !== \"function\") { return { default: obj }; } var cache = _getRequireWildcardCache(nodeInterop); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (key !== \"default\" && Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }\n\n// **N3Store** objects store N3 quads by graph in memory.\n// ## Constructor\nclass N3Store {\n  constructor(quads, options) {\n    // The number of quads is initially zero\n    this._size = 0; // `_graphs` contains subject, predicate, and object indexes per graph\n\n    this._graphs = Object.create(null); // `_ids` maps entities such as `http://xmlns.com/foaf/0.1/name` to numbers,\n    // saving memory by using only numbers as keys in `_graphs`\n\n    this._id = 0;\n    this._ids = Object.create(null);\n    this._ids['><'] = 0; // dummy entry, so the first actual key is non-zero\n\n    this._entities = Object.create(null); // inverse of `_ids`\n    // `_blankNodeIndex` is the index of the last automatically named blank node\n\n    this._blankNodeIndex = 0; // Shift parameters if `quads` is not given\n\n    if (!options && quads && !quads[0]) options = quads, quads = null;\n    options = options || {};\n    this._factory = options.factory || _N3DataFactory.default; // Add quads if passed\n\n    if (quads) this.addQuads(quads);\n  } // ## Public properties\n  // ### `size` returns the number of quads in the store\n\n\n  get size() {\n    // Return the quad count if if was cached\n    let size = this._size;\n    if (size !== null) return size; // Calculate the number of quads by counting to the deepest level\n\n    size = 0;\n    const graphs = this._graphs;\n    let subjects, subject;\n\n    for (const graphKey in graphs) for (const subjectKey in subjects = graphs[graphKey].subjects) for (const predicateKey in subject = subjects[subjectKey]) size += Object.keys(subject[predicateKey]).length;\n\n    return this._size = size;\n  } // ## Private methods\n  // ### `_addToIndex` adds a quad to a three-layered index.\n  // Returns if the index has changed, if the entry did not already exist.\n\n\n  _addToIndex(index0, key0, key1, key2) {\n    // Create layers as necessary\n    const index1 = index0[key0] || (index0[key0] = {});\n    const index2 = index1[key1] || (index1[key1] = {}); // Setting the key to _any_ value signals the presence of the quad\n\n    const existed = (key2 in index2);\n    if (!existed) index2[key2] = null;\n    return !existed;\n  } // ### `_removeFromIndex` removes a quad from a three-layered index\n\n\n  _removeFromIndex(index0, key0, key1, key2) {\n    // Remove the quad from the index\n    const index1 = index0[key0],\n          index2 = index1[key1];\n    delete index2[key2]; // Remove intermediary index layers if they are empty\n\n    for (const key in index2) return;\n\n    delete index1[key1];\n\n    for (const key in index1) return;\n\n    delete index0[key0];\n  } // ### `_findInIndex` finds a set of quads in a three-layered index.\n  // The index base is `index0` and the keys at each level are `key0`, `key1`, and `key2`.\n  // Any of these keys can be undefined, which is interpreted as a wildcard.\n  // `name0`, `name1`, and `name2` are the names of the keys at each level,\n  // used when reconstructing the resulting quad\n  // (for instance: _subject_, _predicate_, and _object_).\n  // Finally, `graph` will be the graph of the created quads.\n  // If `callback` is given, each result is passed through it\n  // and iteration halts when it returns truthy for any quad.\n  // If instead `array` is given, each result is added to the array.\n\n\n  _findInIndex(index0, key0, key1, key2, name0, name1, name2, graph, callback, array) {\n    let tmp, index1, index2; // Depending on the number of variables, keys or reverse index are faster\n\n    const varCount = !key0 + !key1 + !key2,\n          entityKeys = varCount > 1 ? Object.keys(this._ids) : this._entities; // If a key is specified, use only that part of index 0.\n\n    if (key0) (tmp = index0, index0 = {})[key0] = tmp[key0];\n\n    for (const value0 in index0) {\n      const entity0 = entityKeys[value0];\n\n      if (index1 = index0[value0]) {\n        // If a key is specified, use only that part of index 1.\n        if (key1) (tmp = index1, index1 = {})[key1] = tmp[key1];\n\n        for (const value1 in index1) {\n          const entity1 = entityKeys[value1];\n\n          if (index2 = index1[value1]) {\n            // If a key is specified, use only that part of index 2, if it exists.\n            const values = key2 ? key2 in index2 ? [key2] : [] : Object.keys(index2); // Create quads for all items found in index 2.\n\n            for (let l = 0; l < values.length; l++) {\n              const parts = {\n                subject: null,\n                predicate: null,\n                object: null\n              };\n              parts[name0] = (0, _N3DataFactory.termFromId)(entity0, this._factory);\n              parts[name1] = (0, _N3DataFactory.termFromId)(entity1, this._factory);\n              parts[name2] = (0, _N3DataFactory.termFromId)(entityKeys[values[l]], this._factory);\n\n              const quad = this._factory.quad(parts.subject, parts.predicate, parts.object, (0, _N3DataFactory.termFromId)(graph, this._factory));\n\n              if (array) array.push(quad);else if (callback(quad)) return true;\n            }\n          }\n        }\n      }\n    }\n\n    return array;\n  } // ### `_loop` executes the callback on all keys of index 0\n\n\n  _loop(index0, callback) {\n    for (const key0 in index0) callback(key0);\n  } // ### `_loopByKey0` executes the callback on all keys of a certain entry in index 0\n\n\n  _loopByKey0(index0, key0, callback) {\n    let index1, key1;\n\n    if (index1 = index0[key0]) {\n      for (key1 in index1) callback(key1);\n    }\n  } // ### `_loopByKey1` executes the callback on given keys of all entries in index 0\n\n\n  _loopByKey1(index0, key1, callback) {\n    let key0, index1;\n\n    for (key0 in index0) {\n      index1 = index0[key0];\n      if (index1[key1]) callback(key0);\n    }\n  } // ### `_loopBy2Keys` executes the callback on given keys of certain entries in index 2\n\n\n  _loopBy2Keys(index0, key0, key1, callback) {\n    let index1, index2, key2;\n\n    if ((index1 = index0[key0]) && (index2 = index1[key1])) {\n      for (key2 in index2) callback(key2);\n    }\n  } // ### `_countInIndex` counts matching quads in a three-layered index.\n  // The index base is `index0` and the keys at each level are `key0`, `key1`, and `key2`.\n  // Any of these keys can be undefined, which is interpreted as a wildcard.\n\n\n  _countInIndex(index0, key0, key1, key2) {\n    let count = 0,\n        tmp,\n        index1,\n        index2; // If a key is specified, count only that part of index 0\n\n    if (key0) (tmp = index0, index0 = {})[key0] = tmp[key0];\n\n    for (const value0 in index0) {\n      if (index1 = index0[value0]) {\n        // If a key is specified, count only that part of index 1\n        if (key1) (tmp = index1, index1 = {})[key1] = tmp[key1];\n\n        for (const value1 in index1) {\n          if (index2 = index1[value1]) {\n            // If a key is specified, count the quad if it exists\n            if (key2) key2 in index2 && count++; // Otherwise, count all quads\n            else count += Object.keys(index2).length;\n          }\n        }\n      }\n    }\n\n    return count;\n  } // ### `_getGraphs` returns an array with the given graph,\n  // or all graphs if the argument is null or undefined.\n\n\n  _getGraphs(graph) {\n    if (!isString(graph)) return this._graphs;\n    const graphs = {};\n    graphs[graph] = this._graphs[graph];\n    return graphs;\n  } // ### `_uniqueEntities` returns a function that accepts an entity ID\n  // and passes the corresponding entity to callback if it hasn't occurred before.\n\n\n  _uniqueEntities(callback) {\n    const uniqueIds = Object.create(null);\n    return id => {\n      if (!(id in uniqueIds)) {\n        uniqueIds[id] = true;\n        callback((0, _N3DataFactory.termFromId)(this._entities[id], this._factory));\n      }\n    };\n  } // ## Public methods\n  // ### `add` adds the specified quad to the dataset.\n  // Returns the dataset instance it was called on.\n  // Existing quads, as defined in Quad.equals, will be ignored.\n\n\n  add(quad) {\n    this.addQuad(quad);\n    return this;\n  } // ### `addQuad` adds a new quad to the store.\n  // Returns if the quad index has changed, if the quad did not already exist.\n\n\n  addQuad(subject, predicate, object, graph) {\n    // Shift arguments if a quad object is given instead of components\n    if (!predicate) graph = subject.graph, object = subject.object, predicate = subject.predicate, subject = subject.subject; // Convert terms to internal string representation\n\n    subject = (0, _N3DataFactory.termToId)(subject);\n    predicate = (0, _N3DataFactory.termToId)(predicate);\n    object = (0, _N3DataFactory.termToId)(object);\n    graph = (0, _N3DataFactory.termToId)(graph); // Find the graph that will contain the triple\n\n    let graphItem = this._graphs[graph]; // Create the graph if it doesn't exist yet\n\n    if (!graphItem) {\n      graphItem = this._graphs[graph] = {\n        subjects: {},\n        predicates: {},\n        objects: {}\n      }; // Freezing a graph helps subsequent `add` performance,\n      // and properties will never be modified anyway\n\n      Object.freeze(graphItem);\n    } // Since entities can often be long IRIs, we avoid storing them in every index.\n    // Instead, we have a separate index that maps entities to numbers,\n    // which are then used as keys in the other indexes.\n\n\n    const ids = this._ids;\n    const entities = this._entities;\n    subject = ids[subject] || (ids[entities[++this._id] = subject] = this._id);\n    predicate = ids[predicate] || (ids[entities[++this._id] = predicate] = this._id);\n    object = ids[object] || (ids[entities[++this._id] = object] = this._id);\n\n    const changed = this._addToIndex(graphItem.subjects, subject, predicate, object);\n\n    this._addToIndex(graphItem.predicates, predicate, object, subject);\n\n    this._addToIndex(graphItem.objects, object, subject, predicate); // The cached quad count is now invalid\n\n\n    this._size = null;\n    return changed;\n  } // ### `addQuads` adds multiple quads to the store\n\n\n  addQuads(quads) {\n    for (let i = 0; i < quads.length; i++) this.addQuad(quads[i]);\n  } // ### `delete` removes the specified quad from the dataset.\n  // Returns the dataset instance it was called on.\n\n\n  delete(quad) {\n    this.removeQuad(quad);\n    return this;\n  } // ### `has` determines whether a dataset includes a certain quad.\n  // Returns true or false as appropriate.\n\n\n  has(quad) {\n    const quads = this.getQuads(quad.subject, quad.predicate, quad.object, quad.graph);\n    return quads.length !== 0;\n  } // ### `import` adds a stream of quads to the store\n\n\n  import(stream) {\n    stream.on('data', quad => {\n      this.addQuad(quad);\n    });\n    return stream;\n  } // ### `removeQuad` removes a quad from the store if it exists\n\n\n  removeQuad(subject, predicate, object, graph) {\n    // Shift arguments if a quad object is given instead of components\n    if (!predicate) graph = subject.graph, object = subject.object, predicate = subject.predicate, subject = subject.subject; // Convert terms to internal string representation\n\n    subject = (0, _N3DataFactory.termToId)(subject);\n    predicate = (0, _N3DataFactory.termToId)(predicate);\n    object = (0, _N3DataFactory.termToId)(object);\n    graph = (0, _N3DataFactory.termToId)(graph); // Find internal identifiers for all components\n    // and verify the quad exists.\n\n    const ids = this._ids,\n          graphs = this._graphs;\n    let graphItem, subjects, predicates;\n    if (!(subject = ids[subject]) || !(predicate = ids[predicate]) || !(object = ids[object]) || !(graphItem = graphs[graph]) || !(subjects = graphItem.subjects[subject]) || !(predicates = subjects[predicate]) || !(object in predicates)) return false; // Remove it from all indexes\n\n    this._removeFromIndex(graphItem.subjects, subject, predicate, object);\n\n    this._removeFromIndex(graphItem.predicates, predicate, object, subject);\n\n    this._removeFromIndex(graphItem.objects, object, subject, predicate);\n\n    if (this._size !== null) this._size--; // Remove the graph if it is empty\n\n    for (subject in graphItem.subjects) return true;\n\n    delete graphs[graph];\n    return true;\n  } // ### `removeQuads` removes multiple quads from the store\n\n\n  removeQuads(quads) {\n    for (let i = 0; i < quads.length; i++) this.removeQuad(quads[i]);\n  } // ### `remove` removes a stream of quads from the store\n\n\n  remove(stream) {\n    stream.on('data', quad => {\n      this.removeQuad(quad);\n    });\n    return stream;\n  } // ### `removeMatches` removes all matching quads from the store\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  removeMatches(subject, predicate, object, graph) {\n    const stream = new _readableStream.Readable({\n      objectMode: true\n    });\n\n    stream._read = () => {\n      for (const quad of this.getQuads(subject, predicate, object, graph)) stream.push(quad);\n\n      stream.push(null);\n    };\n\n    return this.remove(stream);\n  } // ### `deleteGraph` removes all triples with the given graph from the store\n\n\n  deleteGraph(graph) {\n    return this.removeMatches(null, null, null, graph);\n  } // ### `getQuads` returns an array of quads matching a pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  getQuads(subject, predicate, object, graph) {\n    // Convert terms to internal string representation\n    subject = subject && (0, _N3DataFactory.termToId)(subject);\n    predicate = predicate && (0, _N3DataFactory.termToId)(predicate);\n    object = object && (0, _N3DataFactory.termToId)(object);\n    graph = graph && (0, _N3DataFactory.termToId)(graph);\n\n    const quads = [],\n          graphs = this._getGraphs(graph),\n          ids = this._ids;\n\n    let content, subjectId, predicateId, objectId; // Translate IRIs to internal index keys.\n\n    if (isString(subject) && !(subjectId = ids[subject]) || isString(predicate) && !(predicateId = ids[predicate]) || isString(object) && !(objectId = ids[object])) return quads;\n\n    for (const graphId in graphs) {\n      // Only if the specified graph contains triples, there can be results\n      if (content = graphs[graphId]) {\n        // Choose the optimal index, based on what fields are present\n        if (subjectId) {\n          if (objectId) // If subject and object are given, the object index will be the fastest\n            this._findInIndex(content.objects, objectId, subjectId, predicateId, 'object', 'subject', 'predicate', graphId, null, quads);else // If only subject and possibly predicate are given, the subject index will be the fastest\n            this._findInIndex(content.subjects, subjectId, predicateId, null, 'subject', 'predicate', 'object', graphId, null, quads);\n        } else if (predicateId) // If only predicate and possibly object are given, the predicate index will be the fastest\n          this._findInIndex(content.predicates, predicateId, objectId, null, 'predicate', 'object', 'subject', graphId, null, quads);else if (objectId) // If only object is given, the object index will be the fastest\n          this._findInIndex(content.objects, objectId, null, null, 'object', 'subject', 'predicate', graphId, null, quads);else // If nothing is given, iterate subjects and predicates first\n          this._findInIndex(content.subjects, null, null, null, 'subject', 'predicate', 'object', graphId, null, quads);\n      }\n    }\n\n    return quads;\n  } // ### `match` returns a new dataset that is comprised of all quads in the current instance matching the given arguments.\n  // The logic described in Quad Matching is applied for each quad in this dataset to check if it should be included in the output dataset.\n  // Note: This method always returns a new DatasetCore, even if that dataset contains no quads.\n  // Note: Since a DatasetCore is an unordered set, the order of the quads within the returned sequence is arbitrary.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n  // For backwards compatibility, the object return also implements the Readable stream interface.\n\n\n  match(subject, predicate, object, graph) {\n    return new DatasetCoreAndReadableStream(this, subject, predicate, object, graph);\n  } // ### `countQuads` returns the number of quads matching a pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  countQuads(subject, predicate, object, graph) {\n    // Convert terms to internal string representation\n    subject = subject && (0, _N3DataFactory.termToId)(subject);\n    predicate = predicate && (0, _N3DataFactory.termToId)(predicate);\n    object = object && (0, _N3DataFactory.termToId)(object);\n    graph = graph && (0, _N3DataFactory.termToId)(graph);\n\n    const graphs = this._getGraphs(graph),\n          ids = this._ids;\n\n    let count = 0,\n        content,\n        subjectId,\n        predicateId,\n        objectId; // Translate IRIs to internal index keys.\n\n    if (isString(subject) && !(subjectId = ids[subject]) || isString(predicate) && !(predicateId = ids[predicate]) || isString(object) && !(objectId = ids[object])) return 0;\n\n    for (const graphId in graphs) {\n      // Only if the specified graph contains triples, there can be results\n      if (content = graphs[graphId]) {\n        // Choose the optimal index, based on what fields are present\n        if (subject) {\n          if (object) // If subject and object are given, the object index will be the fastest\n            count += this._countInIndex(content.objects, objectId, subjectId, predicateId);else // If only subject and possibly predicate are given, the subject index will be the fastest\n            count += this._countInIndex(content.subjects, subjectId, predicateId, objectId);\n        } else if (predicate) {\n          // If only predicate and possibly object are given, the predicate index will be the fastest\n          count += this._countInIndex(content.predicates, predicateId, objectId, subjectId);\n        } else {\n          // If only object is possibly given, the object index will be the fastest\n          count += this._countInIndex(content.objects, objectId, subjectId, predicateId);\n        }\n      }\n    }\n\n    return count;\n  } // ### `forEach` executes the callback on all quads.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  forEach(callback, subject, predicate, object, graph) {\n    this.some(quad => {\n      callback(quad);\n      return false;\n    }, subject, predicate, object, graph);\n  } // ### `every` executes the callback on all quads,\n  // and returns `true` if it returns truthy for all them.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  every(callback, subject, predicate, object, graph) {\n    let some = false;\n    const every = !this.some(quad => {\n      some = true;\n      return !callback(quad);\n    }, subject, predicate, object, graph);\n    return some && every;\n  } // ### `some` executes the callback on all quads,\n  // and returns `true` if it returns truthy for any of them.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  some(callback, subject, predicate, object, graph) {\n    // Convert terms to internal string representation\n    subject = subject && (0, _N3DataFactory.termToId)(subject);\n    predicate = predicate && (0, _N3DataFactory.termToId)(predicate);\n    object = object && (0, _N3DataFactory.termToId)(object);\n    graph = graph && (0, _N3DataFactory.termToId)(graph);\n\n    const graphs = this._getGraphs(graph),\n          ids = this._ids;\n\n    let content, subjectId, predicateId, objectId; // Translate IRIs to internal index keys.\n\n    if (isString(subject) && !(subjectId = ids[subject]) || isString(predicate) && !(predicateId = ids[predicate]) || isString(object) && !(objectId = ids[object])) return false;\n\n    for (const graphId in graphs) {\n      // Only if the specified graph contains triples, there can be results\n      if (content = graphs[graphId]) {\n        // Choose the optimal index, based on what fields are present\n        if (subjectId) {\n          if (objectId) {\n            // If subject and object are given, the object index will be the fastest\n            if (this._findInIndex(content.objects, objectId, subjectId, predicateId, 'object', 'subject', 'predicate', graphId, callback, null)) return true;\n          } else // If only subject and possibly predicate are given, the subject index will be the fastest\n            if (this._findInIndex(content.subjects, subjectId, predicateId, null, 'subject', 'predicate', 'object', graphId, callback, null)) return true;\n        } else if (predicateId) {\n          // If only predicate and possibly object are given, the predicate index will be the fastest\n          if (this._findInIndex(content.predicates, predicateId, objectId, null, 'predicate', 'object', 'subject', graphId, callback, null)) {\n            return true;\n          }\n        } else if (objectId) {\n          // If only object is given, the object index will be the fastest\n          if (this._findInIndex(content.objects, objectId, null, null, 'object', 'subject', 'predicate', graphId, callback, null)) {\n            return true;\n          }\n        } else // If nothing is given, iterate subjects and predicates first\n          if (this._findInIndex(content.subjects, null, null, null, 'subject', 'predicate', 'object', graphId, callback, null)) {\n            return true;\n          }\n      }\n    }\n\n    return false;\n  } // ### `getSubjects` returns all subjects that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  getSubjects(predicate, object, graph) {\n    const results = [];\n    this.forSubjects(s => {\n      results.push(s);\n    }, predicate, object, graph);\n    return results;\n  } // ### `forSubjects` executes the callback on all subjects that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  forSubjects(callback, predicate, object, graph) {\n    // Convert terms to internal string representation\n    predicate = predicate && (0, _N3DataFactory.termToId)(predicate);\n    object = object && (0, _N3DataFactory.termToId)(object);\n    graph = graph && (0, _N3DataFactory.termToId)(graph);\n\n    const ids = this._ids,\n          graphs = this._getGraphs(graph);\n\n    let content, predicateId, objectId;\n    callback = this._uniqueEntities(callback); // Translate IRIs to internal index keys.\n\n    if (isString(predicate) && !(predicateId = ids[predicate]) || isString(object) && !(objectId = ids[object])) return;\n\n    for (graph in graphs) {\n      // Only if the specified graph contains triples, there can be results\n      if (content = graphs[graph]) {\n        // Choose optimal index based on which fields are wildcards\n        if (predicateId) {\n          if (objectId) // If predicate and object are given, the POS index is best.\n            this._loopBy2Keys(content.predicates, predicateId, objectId, callback);else // If only predicate is given, the SPO index is best.\n            this._loopByKey1(content.subjects, predicateId, callback);\n        } else if (objectId) // If only object is given, the OSP index is best.\n          this._loopByKey0(content.objects, objectId, callback);else // If no params given, iterate all the subjects\n          this._loop(content.subjects, callback);\n      }\n    }\n  } // ### `getPredicates` returns all predicates that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  getPredicates(subject, object, graph) {\n    const results = [];\n    this.forPredicates(p => {\n      results.push(p);\n    }, subject, object, graph);\n    return results;\n  } // ### `forPredicates` executes the callback on all predicates that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  forPredicates(callback, subject, object, graph) {\n    // Convert terms to internal string representation\n    subject = subject && (0, _N3DataFactory.termToId)(subject);\n    object = object && (0, _N3DataFactory.termToId)(object);\n    graph = graph && (0, _N3DataFactory.termToId)(graph);\n\n    const ids = this._ids,\n          graphs = this._getGraphs(graph);\n\n    let content, subjectId, objectId;\n    callback = this._uniqueEntities(callback); // Translate IRIs to internal index keys.\n\n    if (isString(subject) && !(subjectId = ids[subject]) || isString(object) && !(objectId = ids[object])) return;\n\n    for (graph in graphs) {\n      // Only if the specified graph contains triples, there can be results\n      if (content = graphs[graph]) {\n        // Choose optimal index based on which fields are wildcards\n        if (subjectId) {\n          if (objectId) // If subject and object are given, the OSP index is best.\n            this._loopBy2Keys(content.objects, objectId, subjectId, callback);else // If only subject is given, the SPO index is best.\n            this._loopByKey0(content.subjects, subjectId, callback);\n        } else if (objectId) // If only object is given, the POS index is best.\n          this._loopByKey1(content.predicates, objectId, callback);else // If no params given, iterate all the predicates.\n          this._loop(content.predicates, callback);\n      }\n    }\n  } // ### `getObjects` returns all objects that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  getObjects(subject, predicate, graph) {\n    const results = [];\n    this.forObjects(o => {\n      results.push(o);\n    }, subject, predicate, graph);\n    return results;\n  } // ### `forObjects` executes the callback on all objects that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  forObjects(callback, subject, predicate, graph) {\n    // Convert terms to internal string representation\n    subject = subject && (0, _N3DataFactory.termToId)(subject);\n    predicate = predicate && (0, _N3DataFactory.termToId)(predicate);\n    graph = graph && (0, _N3DataFactory.termToId)(graph);\n\n    const ids = this._ids,\n          graphs = this._getGraphs(graph);\n\n    let content, subjectId, predicateId;\n    callback = this._uniqueEntities(callback); // Translate IRIs to internal index keys.\n\n    if (isString(subject) && !(subjectId = ids[subject]) || isString(predicate) && !(predicateId = ids[predicate])) return;\n\n    for (graph in graphs) {\n      // Only if the specified graph contains triples, there can be results\n      if (content = graphs[graph]) {\n        // Choose optimal index based on which fields are wildcards\n        if (subjectId) {\n          if (predicateId) // If subject and predicate are given, the SPO index is best.\n            this._loopBy2Keys(content.subjects, subjectId, predicateId, callback);else // If only subject is given, the OSP index is best.\n            this._loopByKey1(content.objects, subjectId, callback);\n        } else if (predicateId) // If only predicate is given, the POS index is best.\n          this._loopByKey0(content.predicates, predicateId, callback);else // If no params given, iterate all the objects.\n          this._loop(content.objects, callback);\n      }\n    }\n  } // ### `getGraphs` returns all graphs that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  getGraphs(subject, predicate, object) {\n    const results = [];\n    this.forGraphs(g => {\n      results.push(g);\n    }, subject, predicate, object);\n    return results;\n  } // ### `forGraphs` executes the callback on all graphs that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  forGraphs(callback, subject, predicate, object) {\n    for (const graph in this._graphs) {\n      this.some(quad => {\n        callback(quad.graph);\n        return true; // Halt iteration of some()\n      }, subject, predicate, object, graph);\n    }\n  } // ### `createBlankNode` creates a new blank node, returning its name\n\n\n  createBlankNode(suggestedName) {\n    let name, index; // Generate a name based on the suggested name\n\n    if (suggestedName) {\n      name = suggestedName = `_:${suggestedName}`, index = 1;\n\n      while (this._ids[name]) name = suggestedName + index++;\n    } // Generate a generic blank node name\n    else {\n      do {\n        name = `_:b${this._blankNodeIndex++}`;\n      } while (this._ids[name]);\n    } // Add the blank node to the entities, avoiding the generation of duplicates\n\n\n    this._ids[name] = ++this._id;\n    this._entities[this._id] = name;\n    return this._factory.blankNode(name.substr(2));\n  } // ### `extractLists` finds and removes all list triples\n  // and returns the items per list.\n\n\n  extractLists({\n    remove = false,\n    ignoreErrors = false\n  } = {}) {\n    const lists = {}; // has scalar keys so could be a simple Object\n\n    const onError = ignoreErrors ? () => true : (node, message) => {\n      throw new Error(`${node.value} ${message}`);\n    }; // Traverse each list from its tail\n\n    const tails = this.getQuads(null, _IRIs.default.rdf.rest, _IRIs.default.rdf.nil, null);\n    const toRemove = remove ? [...tails] : [];\n    tails.forEach(tailQuad => {\n      const items = []; // the members found as objects of rdf:first quads\n\n      let malformed = false; // signals whether the current list is malformed\n\n      let head; // the head of the list (_:b1 in above example)\n\n      let headPos; // set to subject or object when head is set\n\n      const graph = tailQuad.graph; // make sure list is in exactly one graph\n      // Traverse the list from tail to end\n\n      let current = tailQuad.subject;\n\n      while (current && !malformed) {\n        const objectQuads = this.getQuads(null, null, current, null);\n        const subjectQuads = this.getQuads(current, null, null, null);\n        let quad,\n            first = null,\n            rest = null,\n            parent = null; // Find the first and rest of this list node\n\n        for (let i = 0; i < subjectQuads.length && !malformed; i++) {\n          quad = subjectQuads[i];\n          if (!quad.graph.equals(graph)) malformed = onError(current, 'not confined to single graph');else if (head) malformed = onError(current, 'has non-list arcs out'); // one rdf:first\n          else if (quad.predicate.value === _IRIs.default.rdf.first) {\n            if (first) malformed = onError(current, 'has multiple rdf:first arcs');else toRemove.push(first = quad);\n          } // one rdf:rest\n          else if (quad.predicate.value === _IRIs.default.rdf.rest) {\n            if (rest) malformed = onError(current, 'has multiple rdf:rest arcs');else toRemove.push(rest = quad);\n          } // alien triple\n          else if (objectQuads.length) malformed = onError(current, 'can\\'t be subject and object');else {\n            head = quad; // e.g. { (1 2 3) :p :o }\n\n            headPos = 'subject';\n          }\n        } // { :s :p (1 2) } arrives here with no head\n        // { (1 2) :p :o } arrives here with head set to the list.\n\n\n        for (let i = 0; i < objectQuads.length && !malformed; ++i) {\n          quad = objectQuads[i];\n          if (head) malformed = onError(current, 'can\\'t have coreferences'); // one rdf:rest\n          else if (quad.predicate.value === _IRIs.default.rdf.rest) {\n            if (parent) malformed = onError(current, 'has incoming rdf:rest arcs');else parent = quad;\n          } else {\n            head = quad; // e.g. { :s :p (1 2) }\n\n            headPos = 'object';\n          }\n        } // Store the list item and continue with parent\n\n\n        if (!first) malformed = onError(current, 'has no list head');else items.unshift(first.object);\n        current = parent && parent.subject;\n      } // Don't remove any quads if the list is malformed\n\n\n      if (malformed) remove = false; // Store the list under the value of its head\n      else if (head) lists[head[headPos].value] = items;\n    }); // Remove list quads if requested\n\n    if (remove) this.removeQuads(toRemove);\n    return lists;\n  } // ### Store is an iterable.\n  // Can be used where iterables are expected: for...of loops, array spread operator,\n  // `yield*`, and destructuring assignment (order is not guaranteed).\n\n\n  *[Symbol.iterator]() {\n    yield* this.getQuads();\n  }\n\n} // Determines whether the argument is a string\n\n\nexports[\"default\"] = N3Store;\n\nfunction isString(s) {\n  return typeof s === 'string' || s instanceof String;\n}\n/**\n * A class that implements both DatasetCore and Readable.\n */\n\n\nclass DatasetCoreAndReadableStream extends _readableStream.Readable {\n  constructor(n3Store, subject, predicate, object, graph) {\n    super({\n      objectMode: true\n    });\n    Object.assign(this, {\n      n3Store,\n      subject,\n      predicate,\n      object,\n      graph\n    });\n  }\n\n  get filtered() {\n    if (!this._filtered) {\n      const {\n        n3Store,\n        graph,\n        object,\n        predicate,\n        subject\n      } = this;\n      const quads = n3Store.getQuads(subject, predicate, object, graph);\n      this._filtered = new N3Store(quads, {\n        factory: n3Store._factory\n      });\n    }\n\n    return this._filtered;\n  }\n\n  get size() {\n    return this.filtered.size;\n  }\n\n  _read() {\n    for (const quad of this.filtered.getQuads()) this.push(quad);\n\n    this.push(null);\n  }\n\n  add(quad) {\n    return this.filtered.add(quad);\n  }\n\n  delete(quad) {\n    return this.filtered.delete(quad);\n  }\n\n  has(quad) {\n    return this.filtered.has(quad);\n  }\n\n  match(subject, predicate, object, graph) {\n    return new DatasetCoreAndReadableStream(this.filtered, subject, predicate, object, graph);\n  }\n\n  *[Symbol.iterator]() {\n    yield* this.filtered.getQuads();\n  }\n\n}\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/n3/lib/N3Store.js?");

/***/ }),

/***/ "../fhirlib/node_modules/n3/lib/N3Util.js":
/*!************************************************!*\
  !*** ../fhirlib/node_modules/n3/lib/N3Util.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports.inDefaultGraph = inDefaultGraph;\nexports.isBlankNode = isBlankNode;\nexports.isDefaultGraph = isDefaultGraph;\nexports.isLiteral = isLiteral;\nexports.isNamedNode = isNamedNode;\nexports.isVariable = isVariable;\nexports.prefix = prefix;\nexports.prefixes = prefixes;\n\nvar _N3DataFactory = _interopRequireDefault(__webpack_require__(/*! ./N3DataFactory */ \"../fhirlib/node_modules/n3/lib/N3DataFactory.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// **N3Util** provides N3 utility functions.\n// Tests whether the given term represents an IRI\nfunction isNamedNode(term) {\n  return !!term && term.termType === 'NamedNode';\n} // Tests whether the given term represents a blank node\n\n\nfunction isBlankNode(term) {\n  return !!term && term.termType === 'BlankNode';\n} // Tests whether the given term represents a literal\n\n\nfunction isLiteral(term) {\n  return !!term && term.termType === 'Literal';\n} // Tests whether the given term represents a variable\n\n\nfunction isVariable(term) {\n  return !!term && term.termType === 'Variable';\n} // Tests whether the given term represents the default graph\n\n\nfunction isDefaultGraph(term) {\n  return !!term && term.termType === 'DefaultGraph';\n} // Tests whether the given quad is in the default graph\n\n\nfunction inDefaultGraph(quad) {\n  return isDefaultGraph(quad.graph);\n} // Creates a function that prepends the given IRI to a local name\n\n\nfunction prefix(iri, factory) {\n  return prefixes({\n    '': iri\n  }, factory)('');\n} // Creates a function that allows registering and expanding prefixes\n\n\nfunction prefixes(defaultPrefixes, factory) {\n  // Add all of the default prefixes\n  const prefixes = Object.create(null);\n\n  for (const prefix in defaultPrefixes) processPrefix(prefix, defaultPrefixes[prefix]); // Set the default factory if none was specified\n\n\n  factory = factory || _N3DataFactory.default; // Registers a new prefix (if an IRI was specified)\n  // or retrieves a function that expands an existing prefix (if no IRI was specified)\n\n  function processPrefix(prefix, iri) {\n    // Create a new prefix if an IRI is specified or the prefix doesn't exist\n    if (typeof iri === 'string') {\n      // Create a function that expands the prefix\n      const cache = Object.create(null);\n\n      prefixes[prefix] = local => {\n        return cache[local] || (cache[local] = factory.namedNode(iri + local));\n      };\n    } else if (!(prefix in prefixes)) {\n      throw new Error(`Unknown prefix: ${prefix}`);\n    }\n\n    return prefixes[prefix];\n  }\n\n  return processPrefix;\n}\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/n3/lib/N3Util.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/errors-browser.js":
/*!*****************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/errors-browser.js ***!
  \*****************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\n\nvar codes = {};\n\nfunction createErrorType(code, message, Base) {\n  if (!Base) {\n    Base = Error;\n  }\n\n  function getMessage(arg1, arg2, arg3) {\n    if (typeof message === 'string') {\n      return message;\n    } else {\n      return message(arg1, arg2, arg3);\n    }\n  }\n\n  var NodeError =\n  /*#__PURE__*/\n  function (_Base) {\n    _inheritsLoose(NodeError, _Base);\n\n    function NodeError(arg1, arg2, arg3) {\n      return _Base.call(this, getMessage(arg1, arg2, arg3)) || this;\n    }\n\n    return NodeError;\n  }(Base);\n\n  NodeError.prototype.name = Base.name;\n  NodeError.prototype.code = code;\n  codes[code] = NodeError;\n} // https://github.com/nodejs/node/blob/v10.8.0/lib/internal/errors.js\n\n\nfunction oneOf(expected, thing) {\n  if (Array.isArray(expected)) {\n    var len = expected.length;\n    expected = expected.map(function (i) {\n      return String(i);\n    });\n\n    if (len > 2) {\n      return \"one of \".concat(thing, \" \").concat(expected.slice(0, len - 1).join(', '), \", or \") + expected[len - 1];\n    } else if (len === 2) {\n      return \"one of \".concat(thing, \" \").concat(expected[0], \" or \").concat(expected[1]);\n    } else {\n      return \"of \".concat(thing, \" \").concat(expected[0]);\n    }\n  } else {\n    return \"of \".concat(thing, \" \").concat(String(expected));\n  }\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith\n\n\nfunction startsWith(str, search, pos) {\n  return str.substr(!pos || pos < 0 ? 0 : +pos, search.length) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith\n\n\nfunction endsWith(str, search, this_len) {\n  if (this_len === undefined || this_len > str.length) {\n    this_len = str.length;\n  }\n\n  return str.substring(this_len - search.length, this_len) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes\n\n\nfunction includes(str, search, start) {\n  if (typeof start !== 'number') {\n    start = 0;\n  }\n\n  if (start + search.length > str.length) {\n    return false;\n  } else {\n    return str.indexOf(search, start) !== -1;\n  }\n}\n\ncreateErrorType('ERR_INVALID_OPT_VALUE', function (name, value) {\n  return 'The value \"' + value + '\" is invalid for option \"' + name + '\"';\n}, TypeError);\ncreateErrorType('ERR_INVALID_ARG_TYPE', function (name, expected, actual) {\n  // determiner: 'must be' or 'must not be'\n  var determiner;\n\n  if (typeof expected === 'string' && startsWith(expected, 'not ')) {\n    determiner = 'must not be';\n    expected = expected.replace(/^not /, '');\n  } else {\n    determiner = 'must be';\n  }\n\n  var msg;\n\n  if (endsWith(name, ' argument')) {\n    // For cases like 'first argument'\n    msg = \"The \".concat(name, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  } else {\n    var type = includes(name, '.') ? 'property' : 'argument';\n    msg = \"The \\\"\".concat(name, \"\\\" \").concat(type, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  }\n\n  msg += \". Received type \".concat(typeof actual);\n  return msg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF');\ncreateErrorType('ERR_METHOD_NOT_IMPLEMENTED', function (name) {\n  return 'The ' + name + ' method is not implemented';\n});\ncreateErrorType('ERR_STREAM_PREMATURE_CLOSE', 'Premature close');\ncreateErrorType('ERR_STREAM_DESTROYED', function (name) {\n  return 'Cannot call ' + name + ' after a stream was destroyed';\n});\ncreateErrorType('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times');\ncreateErrorType('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable');\ncreateErrorType('ERR_STREAM_WRITE_AFTER_END', 'write after end');\ncreateErrorType('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);\ncreateErrorType('ERR_UNKNOWN_ENCODING', function (arg) {\n  return 'Unknown encoding: ' + arg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event');\nmodule.exports.codes = codes;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/errors-browser.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/lib/_stream_duplex.js":
/*!*********************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/lib/_stream_duplex.js ***!
  \*********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n/*<replacement>*/\n\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n\n  for (var key in obj) {\n    keys.push(key);\n  }\n\n  return keys;\n};\n/*</replacement>*/\n\n\nmodule.exports = Duplex;\n\nvar Readable = __webpack_require__(/*! ./_stream_readable */ \"../fhirlib/node_modules/readable-stream/lib/_stream_readable.js\");\n\nvar Writable = __webpack_require__(/*! ./_stream_writable */ \"../fhirlib/node_modules/readable-stream/lib/_stream_writable.js\");\n\n__webpack_require__(/*! inherits */ \"../fhirlib/node_modules/inherits/inherits_browser.js\")(Duplex, Readable);\n\n{\n  // Allow the keys array to be GC'ed.\n  var keys = objectKeys(Writable.prototype);\n\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n  Readable.call(this, options);\n  Writable.call(this, options);\n  this.allowHalfOpen = true;\n\n  if (options) {\n    if (options.readable === false) this.readable = false;\n    if (options.writable === false) this.writable = false;\n\n    if (options.allowHalfOpen === false) {\n      this.allowHalfOpen = false;\n      this.once('end', onend);\n    }\n  }\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n}); // the no-half-open enforcer\n\nfunction onend() {\n  // If the writable side ended, then we're ok.\n  if (this._writableState.ended) return; // no more data can be written.\n  // But allow more writes to happen in this tick.\n\n  process.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/lib/_stream_duplex.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/lib/_stream_passthrough.js":
/*!**************************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/lib/_stream_passthrough.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n\nmodule.exports = PassThrough;\n\nvar Transform = __webpack_require__(/*! ./_stream_transform */ \"../fhirlib/node_modules/readable-stream/lib/_stream_transform.js\");\n\n__webpack_require__(/*! inherits */ \"../fhirlib/node_modules/inherits/inherits_browser.js\")(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/lib/_stream_passthrough.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/lib/_stream_readable.js":
/*!***********************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/lib/_stream_readable.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\nmodule.exports = Readable;\n/*<replacement>*/\n\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n/*<replacement>*/\n\nvar EE = (__webpack_require__(/*! events */ \"?5ee0\").EventEmitter);\n\nvar EElistenerCount = function EElistenerCount(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\n\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"../fhirlib/node_modules/readable-stream/lib/internal/streams/stream-browser.js\");\n/*</replacement>*/\n\n\nvar Buffer = (__webpack_require__(/*! buffer */ \"?463b\").Buffer);\n\nvar OurUint8Array = __webpack_require__.g.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n/*<replacement>*/\n\n\nvar debugUtil = __webpack_require__(/*! util */ \"?910f\");\n\nvar debug;\n\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function debug() {};\n}\n/*</replacement>*/\n\n\nvar BufferList = __webpack_require__(/*! ./internal/streams/buffer_list */ \"../fhirlib/node_modules/readable-stream/lib/internal/streams/buffer_list.js\");\n\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"../fhirlib/node_modules/readable-stream/lib/internal/streams/destroy.js\");\n\nvar _require = __webpack_require__(/*! ./internal/streams/state */ \"../fhirlib/node_modules/readable-stream/lib/internal/streams/state.js\"),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = (__webpack_require__(/*! ../errors */ \"../fhirlib/node_modules/readable-stream/errors-browser.js\").codes),\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT; // Lazy loaded to improve the startup performance.\n\n\nvar StringDecoder;\nvar createReadableStreamAsyncIterator;\nvar from;\n\n__webpack_require__(/*! inherits */ \"../fhirlib/node_modules/inherits/inherits_browser.js\")(Readable, Stream);\n\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn); // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream, isDuplex) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"../fhirlib/node_modules/readable-stream/lib/_stream_duplex.js\");\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode; // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n\n  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex); // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false; // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n\n  this.sync = true; // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n  this.paused = true; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'end' (and potentially 'finish')\n\n  this.autoDestroy = !!options.autoDestroy; // has it been destroyed\n\n  this.destroyed = false; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // the number of writers that are awaiting a drain event in .pipe()s\n\n  this.awaitDrain = 0; // if true, a maybeReadMore has been scheduled\n\n  this.readingMore = false;\n  this.decoder = null;\n  this.encoding = null;\n\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = (__webpack_require__(/*! string_decoder/ */ \"../fhirlib/node_modules/string_decoder/lib/string_decoder.js\").StringDecoder);\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"../fhirlib/node_modules/readable-stream/lib/_stream_duplex.js\");\n  if (!(this instanceof Readable)) return new Readable(options); // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the ReadableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  this._readableState = new ReadableState(options, this, isDuplex); // legacy\n\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n  }\n});\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\n\nReadable.prototype._destroy = function (err, cb) {\n  cb(err);\n}; // Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\n\n\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n}; // Unshift should *always* be something directly out of read()\n\n\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  debug('readableAddChunk', chunk);\n  var state = stream._readableState;\n\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n\n    if (er) {\n      errorOrDestroy(stream, er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());\n      } else if (state.destroyed) {\n        return false;\n      } else {\n        state.reading = false;\n\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n      maybeReadMore(stream, state);\n    }\n  } // We can push more data if we are below the highWaterMark.\n  // Also, if we have no data yet, we can stand some more bytes.\n  // This is to work around cases where hwm=0, such as the repl.\n\n\n  return !state.ended && (state.length < state.highWaterMark || state.length === 0);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    state.awaitDrain = 0;\n    stream.emit('data', chunk);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n    if (state.needReadable) emitReadable(stream);\n  }\n\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);\n  }\n\n  return er;\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n}; // backwards compatibility.\n\n\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = (__webpack_require__(/*! string_decoder/ */ \"../fhirlib/node_modules/string_decoder/lib/string_decoder.js\").StringDecoder);\n  var decoder = new StringDecoder(enc);\n  this._readableState.decoder = decoder; // If setEncoding(null), decoder.encoding equals utf8\n\n  this._readableState.encoding = this._readableState.decoder.encoding; // Iterate over current buffer to convert already stored Buffers:\n\n  var p = this._readableState.buffer.head;\n  var content = '';\n\n  while (p !== null) {\n    content += decoder.write(p.data);\n    p = p.next;\n  }\n\n  this._readableState.buffer.clear();\n\n  if (content !== '') this._readableState.buffer.push(content);\n  this._readableState.length = content.length;\n  return this;\n}; // Don't raise the hwm > 1GB\n\n\nvar MAX_HWM = 0x40000000;\n\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n\n  return n;\n} // This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\n\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  } // If we're asking for more than the current hwm, then raise the hwm.\n\n\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n; // Don't have enough\n\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n\n  return state.length;\n} // you can override either this method, or the async _read(n) below.\n\n\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n  if (n !== 0) state.emittedReadable = false; // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n\n  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state); // if we've ended, and we're now clear, then finish it up.\n\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  } // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n  // if we need a readable event, then we need to do some reading.\n\n\n  var doRead = state.needReadable;\n  debug('need readable', doRead); // if we currently have less than the highWaterMark, then also read some\n\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  } // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n\n\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true; // if the length is currently zero, then we *need* a readable event.\n\n    if (state.length === 0) state.needReadable = true; // call internal read method\n\n    this._read(state.highWaterMark);\n\n    state.sync = false; // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = state.length <= state.highWaterMark;\n    n = 0;\n  } else {\n    state.length -= n;\n    state.awaitDrain = 0;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true; // If we tried to read() past the EOF, then emit end on the next tick.\n\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  debug('onEofChunk');\n  if (state.ended) return;\n\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n\n  state.ended = true;\n\n  if (state.sync) {\n    // if we are sync, wait until next tick to emit the data.\n    // Otherwise we risk emitting data in the flow()\n    // the readable code triggers during a read() call\n    emitReadable(stream);\n  } else {\n    // emit 'readable' now to make sure it gets picked up.\n    state.needReadable = false;\n\n    if (!state.emittedReadable) {\n      state.emittedReadable = true;\n      emitReadable_(stream);\n    }\n  }\n} // Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\n\n\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  debug('emitReadable', state.needReadable, state.emittedReadable);\n  state.needReadable = false;\n\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    process.nextTick(emitReadable_, stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  var state = stream._readableState;\n  debug('emitReadable_', state.destroyed, state.length, state.ended);\n\n  if (!state.destroyed && (state.length || state.ended)) {\n    stream.emit('readable');\n    state.emittedReadable = false;\n  } // The stream needs another readable event if\n  // 1. It is not flowing, as the flow mechanism will take\n  //    care of it.\n  // 2. It is not ended.\n  // 3. It is below the highWaterMark, so we can schedule\n  //    another readable later.\n\n\n  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;\n  flow(stream);\n} // at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\n\n\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  // Attempt to read more data if we should.\n  //\n  // The conditions for reading more data are (one of):\n  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n  //   is responsible for filling the buffer with enough data if such data\n  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n  //   we should _not_ attempt to buffer any extra data. We'll get more data\n  //   when the stream consumer calls read() instead.\n  // - No data in the buffer, and the stream is in flowing mode. In this mode\n  //   the loop below is responsible for ensuring read() is called. Failing to\n  //   call read here would abort the flow and there's no other mechanism for\n  //   continuing the flow if the stream consumer has just subscribed to the\n  //   'data' event.\n  //\n  // In addition to the above conditions to keep reading data, the following\n  // conditions prevent the data from being read:\n  // - The stream has ended (state.ended).\n  // - There is already a pending 'read' operation (state.reading). This is a\n  //   case where the the stream has called the implementation defined _read()\n  //   method, but they are processing the call asynchronously and have _not_\n  //   called push() with new data. In this case we skip performing more\n  //   read()s. The execution ends in this method again after the _read() ends\n  //   up calling push() with more data.\n  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {\n    var len = state.length;\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length) // didn't get any data, stop spinning.\n      break;\n  }\n\n  state.readingMore = false;\n} // abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\n\n\nReadable.prototype._read = function (n) {\n  errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);\n  dest.on('unpipe', onunpipe);\n\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  } // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n\n\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n  var cleanedUp = false;\n\n  function cleanup() {\n    debug('cleanup'); // cleanup event handlers once the pipe is broken\n\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n    cleanedUp = true; // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  src.on('data', ondata);\n\n  function ondata(chunk) {\n    debug('ondata');\n    var ret = dest.write(chunk);\n    debug('dest.write', ret);\n\n    if (ret === false) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', state.awaitDrain);\n        state.awaitDrain++;\n      }\n\n      src.pause();\n    }\n  } // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n\n\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) errorOrDestroy(dest, er);\n  } // Make sure our error handler is attached before userland ones.\n\n\n  prependListener(dest, 'error', onerror); // Both close and finish should trigger unpipe, but only once.\n\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n\n  dest.once('close', onclose);\n\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  } // tell the dest that it's being piped to\n\n\n  dest.emit('pipe', src); // start the flow if it hasn't been started already.\n\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function pipeOnDrainFunctionResult() {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = {\n    hasUnpiped: false\n  }; // if we're not piping anywhere, then do nothing.\n\n  if (state.pipesCount === 0) return this; // just one destination.  most common case.\n\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n    if (!dest) dest = state.pipes; // got a match.\n\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  } // slow case. multiple pipe destinations.\n\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, {\n        hasUnpiped: false\n      });\n    }\n\n    return this;\n  } // try to find the right one.\n\n\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n  dest.emit('unpipe', this, unpipeInfo);\n  return this;\n}; // set up data events if they are asked for\n// Ensure readable listeners eventually get something\n\n\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n  var state = this._readableState;\n\n  if (ev === 'data') {\n    // update readableListening so that resume() may be a no-op\n    // a few lines down. This is needed to support once('readable').\n    state.readableListening = this.listenerCount('readable') > 0; // Try start flowing on next tick if stream isn't explicitly paused\n\n    if (state.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.flowing = false;\n      state.emittedReadable = false;\n      debug('on readable', state.length, state.reading);\n\n      if (state.length) {\n        emitReadable(this);\n      } else if (!state.reading) {\n        process.nextTick(nReadingNextTick, this);\n      }\n    }\n  }\n\n  return res;\n};\n\nReadable.prototype.addListener = Readable.prototype.on;\n\nReadable.prototype.removeListener = function (ev, fn) {\n  var res = Stream.prototype.removeListener.call(this, ev, fn);\n\n  if (ev === 'readable') {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nReadable.prototype.removeAllListeners = function (ev) {\n  var res = Stream.prototype.removeAllListeners.apply(this, arguments);\n\n  if (ev === 'readable' || ev === undefined) {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nfunction updateReadableListening(self) {\n  var state = self._readableState;\n  state.readableListening = self.listenerCount('readable') > 0;\n\n  if (state.resumeScheduled && !state.paused) {\n    // flowing needs to be set to true now, otherwise\n    // the upcoming resume will not flow.\n    state.flowing = true; // crude way to check if we should resume\n  } else if (self.listenerCount('data') > 0) {\n    self.resume();\n  }\n}\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n} // pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\n\n\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n\n  if (!state.flowing) {\n    debug('resume'); // we flow only if there is no one listening\n    // for readable, but we still have to call\n    // resume()\n\n    state.flowing = !state.readableListening;\n    resume(this, state);\n  }\n\n  state.paused = false;\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    process.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  debug('resume', state.reading);\n\n  if (!state.reading) {\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n\n  if (this._readableState.flowing !== false) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n\n  this._readableState.paused = true;\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n\n  while (state.flowing && stream.read() !== null) {\n    ;\n  }\n} // wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\n\n\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n  stream.on('end', function () {\n    debug('wrapped end');\n\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk); // don't skip over falsy values in objectMode\n\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  }); // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function methodWrap(method) {\n        return function methodWrapReturnFunction() {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  } // proxy certain important events.\n\n\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  } // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n\n\n  this._read = function (n) {\n    debug('wrapped _read', n);\n\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nif (typeof Symbol === 'function') {\n  Readable.prototype[Symbol.asyncIterator] = function () {\n    if (createReadableStreamAsyncIterator === undefined) {\n      createReadableStreamAsyncIterator = __webpack_require__(/*! ./internal/streams/async_iterator */ \"../fhirlib/node_modules/readable-stream/lib/internal/streams/async_iterator.js\");\n    }\n\n    return createReadableStreamAsyncIterator(this);\n  };\n}\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.highWaterMark;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState && this._readableState.buffer;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableFlowing', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.flowing;\n  },\n  set: function set(state) {\n    if (this._readableState) {\n      this._readableState.flowing = state;\n    }\n  }\n}); // exposed for testing purposes only.\n\nReadable._fromList = fromList;\nObject.defineProperty(Readable.prototype, 'readableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.length;\n  }\n}); // Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = state.buffer.consume(n, state.decoder);\n  }\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n  debug('endReadable', state.endEmitted);\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    process.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  debug('endReadableNT', state.endEmitted, state.length); // Check that we didn't get one last unshift.\n\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n\n    if (state.autoDestroy) {\n      // In case of duplex streams we need a way to detect\n      // if the writable side is ready for autoDestroy as well\n      var wState = stream._writableState;\n\n      if (!wState || wState.autoDestroy && wState.finished) {\n        stream.destroy();\n      }\n    }\n  }\n}\n\nif (typeof Symbol === 'function') {\n  Readable.from = function (iterable, opts) {\n    if (from === undefined) {\n      from = __webpack_require__(/*! ./internal/streams/from */ \"../fhirlib/node_modules/readable-stream/lib/internal/streams/from-browser.js\");\n    }\n\n    return from(Readable, iterable, opts);\n  };\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n\n  return -1;\n}\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/lib/_stream_readable.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/lib/_stream_transform.js":
/*!************************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/lib/_stream_transform.js ***!
  \************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n\nmodule.exports = Transform;\n\nvar _require$codes = (__webpack_require__(/*! ../errors */ \"../fhirlib/node_modules/readable-stream/errors-browser.js\").codes),\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n    ERR_TRANSFORM_ALREADY_TRANSFORMING = _require$codes.ERR_TRANSFORM_ALREADY_TRANSFORMING,\n    ERR_TRANSFORM_WITH_LENGTH_0 = _require$codes.ERR_TRANSFORM_WITH_LENGTH_0;\n\nvar Duplex = __webpack_require__(/*! ./_stream_duplex */ \"../fhirlib/node_modules/readable-stream/lib/_stream_duplex.js\");\n\n__webpack_require__(/*! inherits */ \"../fhirlib/node_modules/inherits/inherits_browser.js\")(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n  var cb = ts.writecb;\n\n  if (cb === null) {\n    return this.emit('error', new ERR_MULTIPLE_CALLBACK());\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n  cb(er);\n  var rs = this._readableState;\n  rs.reading = false;\n\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n  Duplex.call(this, options);\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  }; // start out asking for a readable event once data is transformed.\n\n  this._readableState.needReadable = true; // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  } // When the writable side finishes, then flush out anything remaining.\n\n\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function' && !this._readableState.destroyed) {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n}; // This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\n\n\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_transform()'));\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n}; // Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\n\n\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && !ts.transforming) {\n    ts.transforming = true;\n\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data); // TODO(BridgeAR): Write a test for these two error cases\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n\n  if (stream._writableState.length) throw new ERR_TRANSFORM_WITH_LENGTH_0();\n  if (stream._transformState.transforming) throw new ERR_TRANSFORM_ALREADY_TRANSFORMING();\n  return stream.push(null);\n}\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/lib/_stream_transform.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/lib/_stream_writable.js":
/*!***********************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/lib/_stream_writable.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n\nmodule.exports = Writable;\n/* <replacement> */\n\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n} // It seems a linked list but it is not\n// there will be only 2 of these for each stream\n\n\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\n\n\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n/*<replacement>*/\n\nvar internalUtil = {\n  deprecate: __webpack_require__(/*! util-deprecate */ \"../fhirlib/node_modules/util-deprecate/browser.js\")\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"../fhirlib/node_modules/readable-stream/lib/internal/streams/stream-browser.js\");\n/*</replacement>*/\n\n\nvar Buffer = (__webpack_require__(/*! buffer */ \"?463b\").Buffer);\n\nvar OurUint8Array = __webpack_require__.g.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"../fhirlib/node_modules/readable-stream/lib/internal/streams/destroy.js\");\n\nvar _require = __webpack_require__(/*! ./internal/streams/state */ \"../fhirlib/node_modules/readable-stream/lib/internal/streams/state.js\"),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = (__webpack_require__(/*! ../errors */ \"../fhirlib/node_modules/readable-stream/errors-browser.js\").codes),\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n    ERR_STREAM_CANNOT_PIPE = _require$codes.ERR_STREAM_CANNOT_PIPE,\n    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED,\n    ERR_STREAM_NULL_VALUES = _require$codes.ERR_STREAM_NULL_VALUES,\n    ERR_STREAM_WRITE_AFTER_END = _require$codes.ERR_STREAM_WRITE_AFTER_END,\n    ERR_UNKNOWN_ENCODING = _require$codes.ERR_UNKNOWN_ENCODING;\n\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\n\n__webpack_require__(/*! inherits */ \"../fhirlib/node_modules/inherits/inherits_browser.js\")(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream, isDuplex) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"../fhirlib/node_modules/readable-stream/lib/_stream_duplex.js\");\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream,\n  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode; // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n\n  this.highWaterMark = getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex); // if _final has been called\n\n  this.finalCalled = false; // drain event flag.\n\n  this.needDrain = false; // at the start of calling end()\n\n  this.ending = false; // when end() has been called, and returned\n\n  this.ended = false; // when 'finish' is emitted\n\n  this.finished = false; // has it been destroyed\n\n  this.destroyed = false; // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n\n  this.length = 0; // a flag to see when we're in the middle of a write.\n\n  this.writing = false; // when true all writes will be buffered until .uncork() call\n\n  this.corked = 0; // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n\n  this.sync = true; // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n\n  this.bufferProcessing = false; // the callback that's passed to _write(chunk,cb)\n\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  }; // the callback that the user supplies to write(chunk,encoding,cb)\n\n\n  this.writecb = null; // the amount that is being written when _write is called.\n\n  this.writelen = 0;\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null; // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n\n  this.pendingcb = 0; // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n\n  this.prefinished = false; // True if the error was already emitted and should not be thrown again\n\n  this.errorEmitted = false; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'finish' (and potentially 'end')\n\n  this.autoDestroy = !!options.autoDestroy; // count buffered requests\n\n  this.bufferedRequestCount = 0; // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function writableStateBufferGetter() {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})(); // Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\n\n\nvar realHasInstance;\n\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function value(object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function realHasInstance(object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"../fhirlib/node_modules/readable-stream/lib/_stream_duplex.js\"); // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the WritableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  if (!isDuplex && !realHasInstance.call(Writable, this)) return new Writable(options);\n  this._writableState = new WritableState(options, this, isDuplex); // legacy.\n\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n    if (typeof options.writev === 'function') this._writev = options.writev;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n} // Otherwise people can pipe Writable streams, which is just wrong.\n\n\nWritable.prototype.pipe = function () {\n  errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE());\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new ERR_STREAM_WRITE_AFTER_END(); // TODO: defer error events consistently everywhere, not just the cb\n\n  errorOrDestroy(stream, er);\n  process.nextTick(cb, er);\n} // Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\n\n\nfunction validChunk(stream, state, chunk, cb) {\n  var er;\n\n  if (chunk === null) {\n    er = new ERR_STREAM_NULL_VALUES();\n  } else if (typeof chunk !== 'string' && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer'], chunk);\n  }\n\n  if (er) {\n    errorOrDestroy(stream, er);\n    process.nextTick(cb, er);\n    return false;\n  }\n\n  return true;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n  if (typeof cb !== 'function') cb = nop;\n  if (state.ending) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  this._writableState.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n    if (!state.writing && !state.corked && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new ERR_UNKNOWN_ENCODING(encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nObject.defineProperty(Writable.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n}); // if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\n\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n\n  var len = state.objectMode ? 1 : chunk.length;\n  state.length += len;\n  var ret = state.length < state.highWaterMark; // we must ensure that previous needDrain will not be reset to false.\n\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'));else if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    process.nextTick(cb, er); // this can emit finish, and it will always happen\n    // after error\n\n    process.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er); // this can emit finish, but finish must\n    // always follow error\n\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n  if (typeof cb !== 'function') throw new ERR_MULTIPLE_CALLBACK();\n  onwriteStateUpdate(state);\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state) || stream.destroyed;\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      process.nextTick(afterWrite, stream, state, finished, cb);\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n} // Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\n\n\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n} // if there's something in the buffer waiting, then process it\n\n\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n    var count = 0;\n    var allBuffers = true;\n\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n\n    buffer.allBuffers = allBuffers;\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish); // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--; // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_write()'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding); // .end() fully uncorks\n\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  } // ignore unnecessary end() calls.\n\n\n  if (!state.ending) endWritable(this, state, cb);\n  return this;\n};\n\nObject.defineProperty(Writable.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n});\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\n\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n\n    if (err) {\n      errorOrDestroy(stream, err);\n    }\n\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\n\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function' && !state.destroyed) {\n      state.pendingcb++;\n      state.finalCalled = true;\n      process.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n\n  if (need) {\n    prefinish(stream, state);\n\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n\n      if (state.autoDestroy) {\n        // In case of duplex streams we need a way to detect\n        // if the readable side is ready for autoDestroy as well\n        var rState = stream._readableState;\n\n        if (!rState || rState.autoDestroy && rState.endEmitted) {\n          stream.destroy();\n        }\n      }\n    }\n  }\n\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n\n  if (cb) {\n    if (state.finished) process.nextTick(cb);else stream.once('finish', cb);\n  }\n\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  } // reuse the free corkReq.\n\n\n  state.corkedRequestsFree.next = corkReq;\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._writableState === undefined) {\n      return false;\n    }\n\n    return this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._writableState.destroyed = value;\n  }\n});\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\n\nWritable.prototype._destroy = function (err, cb) {\n  cb(err);\n};\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/lib/_stream_writable.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/lib/internal/streams/async_iterator.js":
/*!**************************************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/lib/internal/streams/async_iterator.js ***!
  \**************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar _Object$setPrototypeO;\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nvar finished = __webpack_require__(/*! ./end-of-stream */ \"../fhirlib/node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\n\nvar kLastResolve = Symbol('lastResolve');\nvar kLastReject = Symbol('lastReject');\nvar kError = Symbol('error');\nvar kEnded = Symbol('ended');\nvar kLastPromise = Symbol('lastPromise');\nvar kHandlePromise = Symbol('handlePromise');\nvar kStream = Symbol('stream');\n\nfunction createIterResult(value, done) {\n  return {\n    value: value,\n    done: done\n  };\n}\n\nfunction readAndResolve(iter) {\n  var resolve = iter[kLastResolve];\n\n  if (resolve !== null) {\n    var data = iter[kStream].read(); // we defer if data is null\n    // we can be expecting either 'end' or\n    // 'error'\n\n    if (data !== null) {\n      iter[kLastPromise] = null;\n      iter[kLastResolve] = null;\n      iter[kLastReject] = null;\n      resolve(createIterResult(data, false));\n    }\n  }\n}\n\nfunction onReadable(iter) {\n  // we wait for the next tick, because it might\n  // emit an error with process.nextTick\n  process.nextTick(readAndResolve, iter);\n}\n\nfunction wrapForNext(lastPromise, iter) {\n  return function (resolve, reject) {\n    lastPromise.then(function () {\n      if (iter[kEnded]) {\n        resolve(createIterResult(undefined, true));\n        return;\n      }\n\n      iter[kHandlePromise](resolve, reject);\n    }, reject);\n  };\n}\n\nvar AsyncIteratorPrototype = Object.getPrototypeOf(function () {});\nvar ReadableStreamAsyncIteratorPrototype = Object.setPrototypeOf((_Object$setPrototypeO = {\n  get stream() {\n    return this[kStream];\n  },\n\n  next: function next() {\n    var _this = this;\n\n    // if we have detected an error in the meanwhile\n    // reject straight away\n    var error = this[kError];\n\n    if (error !== null) {\n      return Promise.reject(error);\n    }\n\n    if (this[kEnded]) {\n      return Promise.resolve(createIterResult(undefined, true));\n    }\n\n    if (this[kStream].destroyed) {\n      // We need to defer via nextTick because if .destroy(err) is\n      // called, the error will be emitted via nextTick, and\n      // we cannot guarantee that there is no error lingering around\n      // waiting to be emitted.\n      return new Promise(function (resolve, reject) {\n        process.nextTick(function () {\n          if (_this[kError]) {\n            reject(_this[kError]);\n          } else {\n            resolve(createIterResult(undefined, true));\n          }\n        });\n      });\n    } // if we have multiple next() calls\n    // we will wait for the previous Promise to finish\n    // this logic is optimized to support for await loops,\n    // where next() is only called once at a time\n\n\n    var lastPromise = this[kLastPromise];\n    var promise;\n\n    if (lastPromise) {\n      promise = new Promise(wrapForNext(lastPromise, this));\n    } else {\n      // fast path needed to support multiple this.push()\n      // without triggering the next() queue\n      var data = this[kStream].read();\n\n      if (data !== null) {\n        return Promise.resolve(createIterResult(data, false));\n      }\n\n      promise = new Promise(this[kHandlePromise]);\n    }\n\n    this[kLastPromise] = promise;\n    return promise;\n  }\n}, _defineProperty(_Object$setPrototypeO, Symbol.asyncIterator, function () {\n  return this;\n}), _defineProperty(_Object$setPrototypeO, \"return\", function _return() {\n  var _this2 = this;\n\n  // destroy(err, cb) is a private API\n  // we can guarantee we have that here, because we control the\n  // Readable class this is attached to\n  return new Promise(function (resolve, reject) {\n    _this2[kStream].destroy(null, function (err) {\n      if (err) {\n        reject(err);\n        return;\n      }\n\n      resolve(createIterResult(undefined, true));\n    });\n  });\n}), _Object$setPrototypeO), AsyncIteratorPrototype);\n\nvar createReadableStreamAsyncIterator = function createReadableStreamAsyncIterator(stream) {\n  var _Object$create;\n\n  var iterator = Object.create(ReadableStreamAsyncIteratorPrototype, (_Object$create = {}, _defineProperty(_Object$create, kStream, {\n    value: stream,\n    writable: true\n  }), _defineProperty(_Object$create, kLastResolve, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kLastReject, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kError, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kEnded, {\n    value: stream._readableState.endEmitted,\n    writable: true\n  }), _defineProperty(_Object$create, kHandlePromise, {\n    value: function value(resolve, reject) {\n      var data = iterator[kStream].read();\n\n      if (data) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        resolve(createIterResult(data, false));\n      } else {\n        iterator[kLastResolve] = resolve;\n        iterator[kLastReject] = reject;\n      }\n    },\n    writable: true\n  }), _Object$create));\n  iterator[kLastPromise] = null;\n  finished(stream, function (err) {\n    if (err && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {\n      var reject = iterator[kLastReject]; // reject if we are waiting for data in the Promise\n      // returned by next() and store the error\n\n      if (reject !== null) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        reject(err);\n      }\n\n      iterator[kError] = err;\n      return;\n    }\n\n    var resolve = iterator[kLastResolve];\n\n    if (resolve !== null) {\n      iterator[kLastPromise] = null;\n      iterator[kLastResolve] = null;\n      iterator[kLastReject] = null;\n      resolve(createIterResult(undefined, true));\n    }\n\n    iterator[kEnded] = true;\n  });\n  stream.on('readable', onReadable.bind(null, iterator));\n  return iterator;\n};\n\nmodule.exports = createReadableStreamAsyncIterator;\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/lib/internal/streams/async_iterator.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/lib/internal/streams/buffer_list.js":
/*!***********************************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/lib/internal/streams/buffer_list.js ***!
  \***********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nvar _require = __webpack_require__(/*! buffer */ \"?1214\"),\n    Buffer = _require.Buffer;\n\nvar _require2 = __webpack_require__(/*! util */ \"?bf66\"),\n    inspect = _require2.inspect;\n\nvar custom = inspect && inspect.custom || 'inspect';\n\nfunction copyBuffer(src, target, offset) {\n  Buffer.prototype.copy.call(src, target, offset);\n}\n\nmodule.exports =\n/*#__PURE__*/\nfunction () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  _createClass(BufferList, [{\n    key: \"push\",\n    value: function push(v) {\n      var entry = {\n        data: v,\n        next: null\n      };\n      if (this.length > 0) this.tail.next = entry;else this.head = entry;\n      this.tail = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"unshift\",\n    value: function unshift(v) {\n      var entry = {\n        data: v,\n        next: this.head\n      };\n      if (this.length === 0) this.tail = entry;\n      this.head = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"shift\",\n    value: function shift() {\n      if (this.length === 0) return;\n      var ret = this.head.data;\n      if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n      --this.length;\n      return ret;\n    }\n  }, {\n    key: \"clear\",\n    value: function clear() {\n      this.head = this.tail = null;\n      this.length = 0;\n    }\n  }, {\n    key: \"join\",\n    value: function join(s) {\n      if (this.length === 0) return '';\n      var p = this.head;\n      var ret = '' + p.data;\n\n      while (p = p.next) {\n        ret += s + p.data;\n      }\n\n      return ret;\n    }\n  }, {\n    key: \"concat\",\n    value: function concat(n) {\n      if (this.length === 0) return Buffer.alloc(0);\n      var ret = Buffer.allocUnsafe(n >>> 0);\n      var p = this.head;\n      var i = 0;\n\n      while (p) {\n        copyBuffer(p.data, ret, i);\n        i += p.data.length;\n        p = p.next;\n      }\n\n      return ret;\n    } // Consumes a specified amount of bytes or characters from the buffered data.\n\n  }, {\n    key: \"consume\",\n    value: function consume(n, hasStrings) {\n      var ret;\n\n      if (n < this.head.data.length) {\n        // `slice` is the same for buffers and strings.\n        ret = this.head.data.slice(0, n);\n        this.head.data = this.head.data.slice(n);\n      } else if (n === this.head.data.length) {\n        // First chunk is a perfect match.\n        ret = this.shift();\n      } else {\n        // Result spans more than one buffer.\n        ret = hasStrings ? this._getString(n) : this._getBuffer(n);\n      }\n\n      return ret;\n    }\n  }, {\n    key: \"first\",\n    value: function first() {\n      return this.head.data;\n    } // Consumes a specified amount of characters from the buffered data.\n\n  }, {\n    key: \"_getString\",\n    value: function _getString(n) {\n      var p = this.head;\n      var c = 1;\n      var ret = p.data;\n      n -= ret.length;\n\n      while (p = p.next) {\n        var str = p.data;\n        var nb = n > str.length ? str.length : n;\n        if (nb === str.length) ret += str;else ret += str.slice(0, n);\n        n -= nb;\n\n        if (n === 0) {\n          if (nb === str.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = str.slice(nb);\n          }\n\n          break;\n        }\n\n        ++c;\n      }\n\n      this.length -= c;\n      return ret;\n    } // Consumes a specified amount of bytes from the buffered data.\n\n  }, {\n    key: \"_getBuffer\",\n    value: function _getBuffer(n) {\n      var ret = Buffer.allocUnsafe(n);\n      var p = this.head;\n      var c = 1;\n      p.data.copy(ret);\n      n -= p.data.length;\n\n      while (p = p.next) {\n        var buf = p.data;\n        var nb = n > buf.length ? buf.length : n;\n        buf.copy(ret, ret.length - n, 0, nb);\n        n -= nb;\n\n        if (n === 0) {\n          if (nb === buf.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = buf.slice(nb);\n          }\n\n          break;\n        }\n\n        ++c;\n      }\n\n      this.length -= c;\n      return ret;\n    } // Make sure the linked list only shows the minimal necessary information.\n\n  }, {\n    key: custom,\n    value: function value(_, options) {\n      return inspect(this, _objectSpread({}, options, {\n        // Only inspect one level.\n        depth: 0,\n        // It should not recurse.\n        customInspect: false\n      }));\n    }\n  }]);\n\n  return BufferList;\n}();\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/lib/internal/streams/buffer_list.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/lib/internal/streams/destroy.js":
/*!*******************************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/lib/internal/streams/destroy.js ***!
  \*******************************************************************************/
/***/ ((module) => {

"use strict";
eval(" // undocumented cb() API, needed for core, not for public API\n\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err) {\n      if (!this._writableState) {\n        process.nextTick(emitErrorNT, this, err);\n      } else if (!this._writableState.errorEmitted) {\n        this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorNT, this, err);\n      }\n    }\n\n    return this;\n  } // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  } // if this is a duplex stream mark the writable part as destroyed as well\n\n\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      if (!_this._writableState) {\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else if (!_this._writableState.errorEmitted) {\n        _this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else {\n        process.nextTick(emitCloseNT, _this);\n      }\n    } else if (cb) {\n      process.nextTick(emitCloseNT, _this);\n      cb(err);\n    } else {\n      process.nextTick(emitCloseNT, _this);\n    }\n  });\n\n  return this;\n}\n\nfunction emitErrorAndCloseNT(self, err) {\n  emitErrorNT(self, err);\n  emitCloseNT(self);\n}\n\nfunction emitCloseNT(self) {\n  if (self._writableState && !self._writableState.emitClose) return;\n  if (self._readableState && !self._readableState.emitClose) return;\n  self.emit('close');\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finalCalled = false;\n    this._writableState.prefinished = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nfunction errorOrDestroy(stream, err) {\n  // We have tests that rely on errors being emitted\n  // in the same tick, so changing this is semver major.\n  // For now when you opt-in to autoDestroy we allow\n  // the error to be emitted nextTick. In a future\n  // semver major update we should change the default to this.\n  var rState = stream._readableState;\n  var wState = stream._writableState;\n  if (rState && rState.autoDestroy || wState && wState.autoDestroy) stream.destroy(err);else stream.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy,\n  errorOrDestroy: errorOrDestroy\n};\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/lib/internal/streams/destroy.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/lib/internal/streams/end-of-stream.js":
/*!*************************************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/lib/internal/streams/end-of-stream.js ***!
  \*************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Ported from https://github.com/mafintosh/end-of-stream with\n// permission from the author, Mathias Buus (@mafintosh).\n\n\nvar ERR_STREAM_PREMATURE_CLOSE = (__webpack_require__(/*! ../../../errors */ \"../fhirlib/node_modules/readable-stream/errors-browser.js\").codes.ERR_STREAM_PREMATURE_CLOSE);\n\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    callback.apply(this, args);\n  };\n}\n\nfunction noop() {}\n\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\n\nfunction eos(stream, opts, callback) {\n  if (typeof opts === 'function') return eos(stream, null, opts);\n  if (!opts) opts = {};\n  callback = once(callback || noop);\n  var readable = opts.readable || opts.readable !== false && stream.readable;\n  var writable = opts.writable || opts.writable !== false && stream.writable;\n\n  var onlegacyfinish = function onlegacyfinish() {\n    if (!stream.writable) onfinish();\n  };\n\n  var writableEnded = stream._writableState && stream._writableState.finished;\n\n  var onfinish = function onfinish() {\n    writable = false;\n    writableEnded = true;\n    if (!readable) callback.call(stream);\n  };\n\n  var readableEnded = stream._readableState && stream._readableState.endEmitted;\n\n  var onend = function onend() {\n    readable = false;\n    readableEnded = true;\n    if (!writable) callback.call(stream);\n  };\n\n  var onerror = function onerror(err) {\n    callback.call(stream, err);\n  };\n\n  var onclose = function onclose() {\n    var err;\n\n    if (readable && !readableEnded) {\n      if (!stream._readableState || !stream._readableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n\n    if (writable && !writableEnded) {\n      if (!stream._writableState || !stream._writableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n  };\n\n  var onrequest = function onrequest() {\n    stream.req.on('finish', onfinish);\n  };\n\n  if (isRequest(stream)) {\n    stream.on('complete', onfinish);\n    stream.on('abort', onclose);\n    if (stream.req) onrequest();else stream.on('request', onrequest);\n  } else if (writable && !stream._writableState) {\n    // legacy streams\n    stream.on('end', onlegacyfinish);\n    stream.on('close', onlegacyfinish);\n  }\n\n  stream.on('end', onend);\n  stream.on('finish', onfinish);\n  if (opts.error !== false) stream.on('error', onerror);\n  stream.on('close', onclose);\n  return function () {\n    stream.removeListener('complete', onfinish);\n    stream.removeListener('abort', onclose);\n    stream.removeListener('request', onrequest);\n    if (stream.req) stream.req.removeListener('finish', onfinish);\n    stream.removeListener('end', onlegacyfinish);\n    stream.removeListener('close', onlegacyfinish);\n    stream.removeListener('finish', onfinish);\n    stream.removeListener('end', onend);\n    stream.removeListener('error', onerror);\n    stream.removeListener('close', onclose);\n  };\n}\n\nmodule.exports = eos;\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/lib/internal/streams/end-of-stream.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/lib/internal/streams/from-browser.js":
/*!************************************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/lib/internal/streams/from-browser.js ***!
  \************************************************************************************/
/***/ ((module) => {

eval("module.exports = function () {\n  throw new Error('Readable.from is not available in the browser')\n};\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/lib/internal/streams/from-browser.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/lib/internal/streams/pipeline.js":
/*!********************************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/lib/internal/streams/pipeline.js ***!
  \********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Ported from https://github.com/mafintosh/pump with\n// permission from the author, Mathias Buus (@mafintosh).\n\n\nvar eos;\n\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n    callback.apply(void 0, arguments);\n  };\n}\n\nvar _require$codes = (__webpack_require__(/*! ../../../errors */ \"../fhirlib/node_modules/readable-stream/errors-browser.js\").codes),\n    ERR_MISSING_ARGS = _require$codes.ERR_MISSING_ARGS,\n    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED;\n\nfunction noop(err) {\n  // Rethrow the error if it exists to avoid swallowing it\n  if (err) throw err;\n}\n\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\n\nfunction destroyer(stream, reading, writing, callback) {\n  callback = once(callback);\n  var closed = false;\n  stream.on('close', function () {\n    closed = true;\n  });\n  if (eos === undefined) eos = __webpack_require__(/*! ./end-of-stream */ \"../fhirlib/node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\n  eos(stream, {\n    readable: reading,\n    writable: writing\n  }, function (err) {\n    if (err) return callback(err);\n    closed = true;\n    callback();\n  });\n  var destroyed = false;\n  return function (err) {\n    if (closed) return;\n    if (destroyed) return;\n    destroyed = true; // request.destroy just do .end - .abort is what we want\n\n    if (isRequest(stream)) return stream.abort();\n    if (typeof stream.destroy === 'function') return stream.destroy();\n    callback(err || new ERR_STREAM_DESTROYED('pipe'));\n  };\n}\n\nfunction call(fn) {\n  fn();\n}\n\nfunction pipe(from, to) {\n  return from.pipe(to);\n}\n\nfunction popCallback(streams) {\n  if (!streams.length) return noop;\n  if (typeof streams[streams.length - 1] !== 'function') return noop;\n  return streams.pop();\n}\n\nfunction pipeline() {\n  for (var _len = arguments.length, streams = new Array(_len), _key = 0; _key < _len; _key++) {\n    streams[_key] = arguments[_key];\n  }\n\n  var callback = popCallback(streams);\n  if (Array.isArray(streams[0])) streams = streams[0];\n\n  if (streams.length < 2) {\n    throw new ERR_MISSING_ARGS('streams');\n  }\n\n  var error;\n  var destroys = streams.map(function (stream, i) {\n    var reading = i < streams.length - 1;\n    var writing = i > 0;\n    return destroyer(stream, reading, writing, function (err) {\n      if (!error) error = err;\n      if (err) destroys.forEach(call);\n      if (reading) return;\n      destroys.forEach(call);\n      callback(error);\n    });\n  });\n  return streams.reduce(pipe);\n}\n\nmodule.exports = pipeline;\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/lib/internal/streams/pipeline.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/lib/internal/streams/state.js":
/*!*****************************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/lib/internal/streams/state.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar ERR_INVALID_OPT_VALUE = (__webpack_require__(/*! ../../../errors */ \"../fhirlib/node_modules/readable-stream/errors-browser.js\").codes.ERR_INVALID_OPT_VALUE);\n\nfunction highWaterMarkFrom(options, isDuplex, duplexKey) {\n  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null;\n}\n\nfunction getHighWaterMark(state, options, duplexKey, isDuplex) {\n  var hwm = highWaterMarkFrom(options, isDuplex, duplexKey);\n\n  if (hwm != null) {\n    if (!(isFinite(hwm) && Math.floor(hwm) === hwm) || hwm < 0) {\n      var name = isDuplex ? duplexKey : 'highWaterMark';\n      throw new ERR_INVALID_OPT_VALUE(name, hwm);\n    }\n\n    return Math.floor(hwm);\n  } // Default value\n\n\n  return state.objectMode ? 16 : 16 * 1024;\n}\n\nmodule.exports = {\n  getHighWaterMark: getHighWaterMark\n};\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/lib/internal/streams/state.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/lib/internal/streams/stream-browser.js":
/*!**************************************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/lib/internal/streams/stream-browser.js ***!
  \**************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = __webpack_require__(/*! events */ \"?883b\").EventEmitter;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/lib/internal/streams/stream-browser.js?");

/***/ }),

/***/ "../fhirlib/node_modules/readable-stream/readable-browser.js":
/*!*******************************************************************!*\
  !*** ../fhirlib/node_modules/readable-stream/readable-browser.js ***!
  \*******************************************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("exports = module.exports = __webpack_require__(/*! ./lib/_stream_readable.js */ \"../fhirlib/node_modules/readable-stream/lib/_stream_readable.js\");\nexports.Stream = exports;\nexports.Readable = exports;\nexports.Writable = __webpack_require__(/*! ./lib/_stream_writable.js */ \"../fhirlib/node_modules/readable-stream/lib/_stream_writable.js\");\nexports.Duplex = __webpack_require__(/*! ./lib/_stream_duplex.js */ \"../fhirlib/node_modules/readable-stream/lib/_stream_duplex.js\");\nexports.Transform = __webpack_require__(/*! ./lib/_stream_transform.js */ \"../fhirlib/node_modules/readable-stream/lib/_stream_transform.js\");\nexports.PassThrough = __webpack_require__(/*! ./lib/_stream_passthrough.js */ \"../fhirlib/node_modules/readable-stream/lib/_stream_passthrough.js\");\nexports.finished = __webpack_require__(/*! ./lib/internal/streams/end-of-stream.js */ \"../fhirlib/node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\nexports.pipeline = __webpack_require__(/*! ./lib/internal/streams/pipeline.js */ \"../fhirlib/node_modules/readable-stream/lib/internal/streams/pipeline.js\");\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/readable-stream/readable-browser.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/constants.js":
/*!**********************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/constants.js ***!
  \**********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports =\n{\n\t// Output\n\tABSOLUTE:      \"absolute\",\n\tPATH_RELATIVE: \"pathRelative\",\n\tROOT_RELATIVE: \"rootRelative\",\n\tSHORTEST:      \"shortest\"\n};\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/constants.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/format.js":
/*!*******************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/format.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar constants = __webpack_require__(/*! ./constants */ \"../fhirlib/node_modules/relateurl/lib/constants.js\");\n\n\n\nfunction formatAuth(urlObj, options)\n{\n\tif (urlObj.auth && !options.removeAuth && (urlObj.extra.relation.maximumHost || options.output===constants.ABSOLUTE))\n\t{\n\t\treturn urlObj.auth + \"@\";\n\t}\n\t\n\treturn \"\";\n}\n\n\n\nfunction formatHash(urlObj, options)\n{\n\treturn urlObj.hash ? urlObj.hash : \"\";\n}\n\n\n\nfunction formatHost(urlObj, options)\n{\n\tif (urlObj.host.full && (urlObj.extra.relation.maximumAuth || options.output===constants.ABSOLUTE))\n\t{\n\t\treturn urlObj.host.full;\n\t}\n\t\n\treturn \"\";\n}\n\n\n\nfunction formatPath(urlObj, options)\n{\n\tvar str = \"\";\n\t\n\tvar absolutePath = urlObj.path.absolute.string;\n\tvar relativePath = urlObj.path.relative.string;\n\tvar resource = showResource(urlObj, options);\n\t\n\tif (urlObj.extra.relation.maximumHost || options.output===constants.ABSOLUTE || options.output===constants.ROOT_RELATIVE)\n\t{\n\t\tstr = absolutePath;\n\t}\n\telse if (relativePath.length<=absolutePath.length && options.output===constants.SHORTEST || options.output===constants.PATH_RELATIVE)\n\t{\n\t\tstr = relativePath;\n\t\t\n\t\tif (str === \"\")\n\t\t{\n\t\t\tvar query = showQuery(urlObj,options) && !!getQuery(urlObj,options);\n\t\t\t\n\t\t\tif (urlObj.extra.relation.maximumPath && !resource)\n\t\t\t{\n\t\t\t\tstr = \"./\";\n\t\t\t}\n\t\t\telse if (urlObj.extra.relation.overridesQuery && !resource && !query)\n\t\t\t{\n\t\t\t\tstr = \"./\";\n\t\t\t}\n\t\t}\n\t}\n\telse\n\t{\n\t\tstr = absolutePath;\n\t}\n\t\n\tif ( str===\"/\" && !resource && options.removeRootTrailingSlash && (!urlObj.extra.relation.minimumPort || options.output===constants.ABSOLUTE) )\n\t{\n\t\tstr = \"\";\n\t}\n\t\n\treturn str;\n}\n\n\n\nfunction formatPort(urlObj, options)\n{\n\tif (urlObj.port && !urlObj.extra.portIsDefault && urlObj.extra.relation.maximumHost)\n\t{\n\t\treturn \":\" + urlObj.port;\n\t}\n\t\n\treturn \"\";\n}\n\n\n\nfunction formatQuery(urlObj, options)\n{\n\treturn showQuery(urlObj,options) ? getQuery(urlObj, options) : \"\";\n}\n\n\n\nfunction formatResource(urlObj, options)\n{\n\treturn showResource(urlObj,options) ? urlObj.resource : \"\";\n}\n\n\n\nfunction formatScheme(urlObj, options)\n{\n\tvar str = \"\";\n\t\n\tif (urlObj.extra.relation.maximumHost || options.output===constants.ABSOLUTE)\n\t{\n\t\tif (!urlObj.extra.relation.minimumScheme || !options.schemeRelative || options.output===constants.ABSOLUTE)\n\t\t{\n\t\t\tstr += urlObj.scheme + \"://\";\n\t\t}\n\t\telse\n\t\t{\n\t\t\tstr += \"//\";\n\t\t}\n\t}\n\t\n\treturn str;\n}\n\n\n\nfunction formatUrl(urlObj, options)\n{\n\tvar url = \"\";\n\t\n\turl += formatScheme(urlObj, options);\n\turl += formatAuth(urlObj, options);\n\turl += formatHost(urlObj, options);\n\turl += formatPort(urlObj, options);\n\turl += formatPath(urlObj, options);\n\turl += formatResource(urlObj, options);\n\turl += formatQuery(urlObj, options);\n\turl += formatHash(urlObj, options);\n\t\n\treturn url;\n}\n\n\n\nfunction getQuery(urlObj, options)\n{\n\tvar stripQuery = options.removeEmptyQueries && urlObj.extra.relation.minimumPort;\n\t\n\treturn urlObj.query.string[ stripQuery ? \"stripped\" : \"full\" ];\n}\n\n\n\nfunction showQuery(urlObj, options)\n{\n\treturn !urlObj.extra.relation.minimumQuery || options.output===constants.ABSOLUTE || options.output===constants.ROOT_RELATIVE;\n}\n\n\n\nfunction showResource(urlObj, options)\n{\n\tvar removeIndex = options.removeDirectoryIndexes && urlObj.extra.resourceIsIndex;\n\tvar removeMatchingResource = urlObj.extra.relation.minimumResource && options.output!==constants.ABSOLUTE && options.output!==constants.ROOT_RELATIVE;\n\t\n\treturn !!urlObj.resource && !removeMatchingResource && !removeIndex;\n}\n\n\n\nmodule.exports = formatUrl;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/format.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/index.js":
/*!******************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/index.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar constants  = __webpack_require__(/*! ./constants */ \"../fhirlib/node_modules/relateurl/lib/constants.js\");\nvar formatUrl  = __webpack_require__(/*! ./format */ \"../fhirlib/node_modules/relateurl/lib/format.js\");\nvar getOptions = __webpack_require__(/*! ./options */ \"../fhirlib/node_modules/relateurl/lib/options.js\");\nvar objUtils   = __webpack_require__(/*! ./util/object */ \"../fhirlib/node_modules/relateurl/lib/util/object.js\");\nvar parseUrl   = __webpack_require__(/*! ./parse */ \"../fhirlib/node_modules/relateurl/lib/parse/index.js\");\nvar relateUrl  = __webpack_require__(/*! ./relate */ \"../fhirlib/node_modules/relateurl/lib/relate/index.js\");\n\n\n\nfunction RelateUrl(from, options)\n{\n\tthis.options = getOptions(options,\n\t{\n\t\tdefaultPorts: {ftp:21, http:80, https:443},\n\t\tdirectoryIndexes: [\"index.html\"],\n\t\tignore_www: false,\n\t\toutput: RelateUrl.SHORTEST,\n\t\trejectedSchemes: [\"data\",\"javascript\",\"mailto\"],\n\t\tremoveAuth: false,\n\t\tremoveDirectoryIndexes: true,\n\t\tremoveEmptyQueries: false,\n\t\tremoveRootTrailingSlash: true,\n\t\tschemeRelative: true,\n\t\tsite: undefined,\n\t\tslashesDenoteHost: true\n\t});\n\t\n\tthis.from = parseUrl.from(from, this.options, null);\n}\n\n\n\n/*\n\tUsage: instance=new RelateUrl(); instance.relate();\n*/\nRelateUrl.prototype.relate = function(from, to, options)\n{\n\t// relate(to,options)\n\tif ( objUtils.isPlainObject(to) )\n\t{\n\t\toptions = to;\n\t\tto = from;\n\t\tfrom = null;\n\t}\n\t// relate(to)\n\telse if (!to)\n\t{\n\t\tto = from;\n\t\tfrom = null;\n\t}\n\t\n\toptions = getOptions(options, this.options);\n\tfrom = from || options.site;\n\tfrom = parseUrl.from(from, options, this.from);\n\t\n\tif (!from || !from.href)\n\t{\n\t\tthrow new Error(\"from value not defined.\");\n\t}\n\telse if (from.extra.hrefInfo.minimumPathOnly)\n\t{\n\t\tthrow new Error(\"from value supplied is not absolute: \"+from.href);\n\t}\n\t\n\tto = parseUrl.to(to, options);\n\t\n\tif (to.valid===false) return to.href;\n\t\n\tto = relateUrl(from, to, options);\n\tto = formatUrl(to, options);\n\t\n\treturn to;\n}\n\n\n\n/*\n\tUsage: RelateUrl.relate();\n*/\nRelateUrl.relate = function(from, to, options)\n{\n\treturn new RelateUrl().relate(from, to, options);\n}\n\n\n\n// Make constants accessible from API\nobjUtils.shallowMerge(RelateUrl, constants);\n\n\n\nmodule.exports = RelateUrl;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/index.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/options.js":
/*!********************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/options.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar objUtils = __webpack_require__(/*! ./util/object */ \"../fhirlib/node_modules/relateurl/lib/util/object.js\");\n\n\n\nfunction getOptions(options, defaults)\n{\n\tif ( objUtils.isPlainObject(options) )\n\t{\n\t\tvar newOptions = {};\n\t\t\n\t\tfor (var i in defaults)\n\t\t{\n\t\t\tif ( defaults.hasOwnProperty(i) )\n\t\t\t{\n\t\t\t\tif (options[i] !== undefined)\n\t\t\t\t{\n\t\t\t\t\tnewOptions[i] = mergeOption(options[i], defaults[i]);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tnewOptions[i] = defaults[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn newOptions;\n\t}\n\telse\n\t{\n\t\treturn defaults;\n\t}\n}\n\n\n\nfunction mergeOption(newValues, defaultValues)\n{\n\tif (defaultValues instanceof Object && newValues instanceof Object)\n\t{\n\t\tif (defaultValues instanceof Array && newValues instanceof Array)\n\t\t{\n\t\t\treturn defaultValues.concat(newValues);\n\t\t}\n\t\telse\n\t\t{\n\t\t\treturn objUtils.shallowMerge(newValues, defaultValues);\n\t\t}\n\t}\n\t\n\treturn newValues;\n}\n\n\n\nmodule.exports = getOptions;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/options.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/parse/host.js":
/*!***********************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/parse/host.js ***!
  \***********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction parseHost(urlObj, options)\n{\n\t// TWEAK :: condition only for speed optimization\n\tif (options.ignore_www)\n\t{\n\t\tvar host = urlObj.host.full;\n\t\t\n\t\tif (host)\n\t\t{\n\t\t\tvar stripped = host;\n\t\t\t\n\t\t\tif (host.indexOf(\"www.\") === 0)\n\t\t\t{\n\t\t\t\tstripped = host.substr(4);\n\t\t\t}\n\t\t\t\n\t\t\turlObj.host.stripped = stripped;\n\t\t}\n\t}\n}\n\n\n\nmodule.exports = parseHost;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/parse/host.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/parse/hrefInfo.js":
/*!***************************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/parse/hrefInfo.js ***!
  \***************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction hrefInfo(urlObj)\n{\n\tvar minimumPathOnly     = (!urlObj.scheme && !urlObj.auth && !urlObj.host.full && !urlObj.port);\n\tvar minimumResourceOnly = (minimumPathOnly && !urlObj.path.absolute.string);\n\tvar minimumQueryOnly    = (minimumResourceOnly && !urlObj.resource);\n\tvar minimumHashOnly     = (minimumQueryOnly && !urlObj.query.string.full.length);\n\tvar empty               = (minimumHashOnly && !urlObj.hash);\n\t\n\turlObj.extra.hrefInfo.minimumPathOnly     = minimumPathOnly;\n\turlObj.extra.hrefInfo.minimumResourceOnly = minimumResourceOnly;\n\turlObj.extra.hrefInfo.minimumQueryOnly    = minimumQueryOnly;\n\turlObj.extra.hrefInfo.minimumHashOnly     = minimumHashOnly;\n\turlObj.extra.hrefInfo.empty = empty;\n}\n\n\n\nmodule.exports = hrefInfo;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/parse/hrefInfo.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/parse/index.js":
/*!************************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/parse/index.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar hrefInfo   = __webpack_require__(/*! ./hrefInfo */ \"../fhirlib/node_modules/relateurl/lib/parse/hrefInfo.js\");\nvar parseHost  = __webpack_require__(/*! ./host */ \"../fhirlib/node_modules/relateurl/lib/parse/host.js\");\nvar parsePath  = __webpack_require__(/*! ./path */ \"../fhirlib/node_modules/relateurl/lib/parse/path.js\");\nvar parsePort  = __webpack_require__(/*! ./port */ \"../fhirlib/node_modules/relateurl/lib/parse/port.js\");\nvar parseQuery = __webpack_require__(/*! ./query */ \"../fhirlib/node_modules/relateurl/lib/parse/query.js\");\nvar parseUrlString = __webpack_require__(/*! ./urlstring */ \"../fhirlib/node_modules/relateurl/lib/parse/urlstring.js\");\nvar pathUtils      = __webpack_require__(/*! ../util/path */ \"../fhirlib/node_modules/relateurl/lib/util/path.js\");\n\n\n\nfunction parseFromUrl(url, options, fallback)\n{\n\tif (url)\n\t{\n\t\tvar urlObj = parseUrl(url, options);\n\t\t\n\t\t// Because the following occurs in the relate stage for \"to\" URLs,\n\t\t// such had to be mostly duplicated here\n\t\t\n\t\tvar pathArray = pathUtils.resolveDotSegments(urlObj.path.absolute.array);\n\t\t\n\t\turlObj.path.absolute.array  = pathArray;\n\t\turlObj.path.absolute.string = \"/\" + pathUtils.join(pathArray);\n\t\t\n\t\treturn urlObj;\n\t}\n\telse\n\t{\n\t\treturn fallback;\n\t}\n}\n\n\n\nfunction parseUrl(url, options)\n{\n\tvar urlObj = parseUrlString(url, options);\n\t\n\tif (urlObj.valid===false) return urlObj;\n\t\n\tparseHost(urlObj, options);\n\tparsePort(urlObj, options);\n\tparsePath(urlObj, options);\n\tparseQuery(urlObj, options);\n\threfInfo(urlObj);\n\t\n\treturn urlObj;\n}\n\n\n\nmodule.exports =\n{\n\tfrom: parseFromUrl,\n\tto:   parseUrl\n};\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/parse/index.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/parse/path.js":
/*!***********************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/parse/path.js ***!
  \***********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction isDirectoryIndex(resource, options)\n{\n\tvar verdict = false;\n\t\n\toptions.directoryIndexes.every( function(index)\n\t{\n\t\tif (index === resource)\n\t\t{\n\t\t\tverdict = true;\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\treturn true;\n\t});\n\t\n\treturn verdict;\n}\n\n\n\nfunction parsePath(urlObj, options)\n{\n\tvar path = urlObj.path.absolute.string;\n\t\n\tif (path)\n\t{\n\t\tvar lastSlash = path.lastIndexOf(\"/\");\n\t\t\n\t\tif (lastSlash > -1)\n\t\t{\n\t\t\tif (++lastSlash < path.length)\n\t\t\t{\n\t\t\t\tvar resource = path.substr(lastSlash);\n\t\t\t\t\n\t\t\t\tif (resource!==\".\" && resource!==\"..\")\n\t\t\t\t{\n\t\t\t\t\turlObj.resource = resource;\n\t\t\t\t\tpath = path.substr(0, lastSlash);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tpath += \"/\";\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\turlObj.path.absolute.string = path;\n\t\t\turlObj.path.absolute.array = splitPath(path);\n\t\t}\n\t\telse if (path===\".\" || path===\"..\")\n\t\t{\n\t\t\t// \"..?var\", \"..#anchor\", etc ... not \"..index.html\"\n\t\t\tpath += \"/\";\n\t\t\t\n\t\t\turlObj.path.absolute.string = path;\n\t\t\turlObj.path.absolute.array = splitPath(path);\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Resource-only\n\t\t\turlObj.resource = path;\n\t\t\turlObj.path.absolute.string = null;\n\t\t}\n\t\t\n\t\turlObj.extra.resourceIsIndex = isDirectoryIndex(urlObj.resource, options);\n\t}\n\t// Else: query/hash-only or empty\n}\n\n\n\nfunction splitPath(path)\n{\n\t// TWEAK :: condition only for speed optimization\n\tif (path !== \"/\")\n\t{\n\t\tvar cleaned = [];\n\t\t\n\t\tpath.split(\"/\").forEach( function(dir)\n\t\t{\n\t\t\t// Cleanup -- splitting \"/dir/\" becomes [\"\",\"dir\",\"\"]\n\t\t\tif (dir !== \"\")\n\t\t\t{\n\t\t\t\tcleaned.push(dir);\n\t\t\t}\n\t\t});\n\t\t\n\t\treturn cleaned;\n\t}\n\telse\n\t{\n\t\t// Faster to skip the above block and just create an array\n\t\treturn [];\n\t}\n}\n\n\n\nmodule.exports = parsePath;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/parse/path.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/parse/port.js":
/*!***********************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/parse/port.js ***!
  \***********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction parsePort(urlObj, options)\n{\n\tvar defaultPort = -1;\n\t\n\tfor (var i in options.defaultPorts)\n\t{\n\t\tif ( i===urlObj.scheme && options.defaultPorts.hasOwnProperty(i) )\n\t\t{\n\t\t\tdefaultPort = options.defaultPorts[i];\n\t\t\tbreak;\n\t\t}\n\t}\n\t\n\tif (defaultPort > -1)\n\t{\n\t\t// Force same type as urlObj.port\n\t\tdefaultPort = defaultPort.toString();\n\t\t\n\t\tif (urlObj.port === null)\n\t\t{\n\t\t\turlObj.port = defaultPort;\n\t\t}\n\t\t\n\t\turlObj.extra.portIsDefault = (urlObj.port === defaultPort);\n\t}\n}\n\n\n\nmodule.exports = parsePort;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/parse/port.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/parse/query.js":
/*!************************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/parse/query.js ***!
  \************************************************************/
/***/ ((module) => {

"use strict";
eval("\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\n\n\n\nfunction parseQuery(urlObj, options)\n{\n\turlObj.query.string.full = stringify(urlObj.query.object, false);\n\t\n\t// TWEAK :: condition only for speed optimization\n\tif (options.removeEmptyQueries)\n\t{\n\t\turlObj.query.string.stripped = stringify(urlObj.query.object, true);\n\t}\n}\n\n\n\nfunction stringify(queryObj, removeEmptyQueries)\n{\n\tvar count = 0;\n\tvar str = \"\";\n\t\n\tfor (var i in queryObj)\n\t{\n\t\tif ( i!==\"\" && hasOwnProperty.call(queryObj, i)===true )\n\t\t{\n\t\t\tvar value = queryObj[i];\n\t\t\t\n\t\t\tif (value !== \"\" || !removeEmptyQueries)\n\t\t\t{\n\t\t\t\tstr += (++count===1) ? \"?\" : \"&\";\n\t\t\t\t\n\t\t\t\ti = encodeURIComponent(i);\n\t\t\t\t\n\t\t\t\tif (value !== \"\")\n\t\t\t\t{\n\t\t\t\t\tstr += i +\"=\"+ encodeURIComponent(value).replace(/%20/g,\"+\");\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tstr += i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn str;\n}\n\n\n\nmodule.exports = parseQuery;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/parse/query.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/parse/urlstring.js":
/*!****************************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/parse/urlstring.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar _parseUrl = (__webpack_require__(/*! url */ \"./node_modules/url/url.js\").parse);\n\n\n\n/*\n\tCustomize the URL object that Node generates\n\tbecause:\n\t\n\t* necessary data for later\n\t* urlObj.host is useless\n\t* urlObj.hostname is too long\n\t* urlObj.path is useless\n\t* urlObj.pathname is too long\n\t* urlObj.protocol is inaccurate; should be called \"scheme\"\n\t* urlObj.search is mostly useless\n*/\nfunction clean(urlObj)\n{\n\tvar scheme = urlObj.protocol;\n\t\n\tif (scheme)\n\t{\n\t\t// Remove \":\" suffix\n\t\tif (scheme.indexOf(\":\") === scheme.length-1)\n\t\t{\n\t\t\tscheme = scheme.substr(0, scheme.length-1);\n\t\t}\n\t}\n\t\n\turlObj.host =\n\t{\n\t\t// TODO :: unescape(encodeURIComponent(s)) ? ... http://ecmanaut.blogspot.ca/2006/07/encoding-decoding-utf8-in-javascript.html\n\t\tfull: urlObj.hostname,\n\t\tstripped: null\n\t};\n\t\n\turlObj.path =\n\t{\n\t\tabsolute:\n\t\t{\n\t\t\tarray: null,\n\t\t\tstring: urlObj.pathname\n\t\t},\n\t\trelative:\n\t\t{\n\t\t\tarray: null,\n\t\t\tstring: null\n\t\t}\n\t};\n\t\n\turlObj.query =\n\t{\n\t\tobject: urlObj.query,\n\t\tstring:\n\t\t{\n\t\t\tfull: null,\n\t\t\tstripped: null\n\t\t}\n\t};\n\t\n\turlObj.extra =\n\t{\n\t\threfInfo:\n\t\t{\n\t\t\tminimumPathOnly: null,\n\t\t\tminimumResourceOnly: null,\n\t\t\tminimumQueryOnly: null,\n\t\t\tminimumHashOnly: null,\n\t\t\tempty: null,\n\t\t\t\n\t\t\tseparatorOnlyQuery: urlObj.search===\"?\"\n\t\t},\n\t\tportIsDefault: null,\n\t\trelation:\n\t\t{\n\t\t\tmaximumScheme: null,\n\t\t\tmaximumAuth: null,\n\t\t\tmaximumHost: null,\n\t\t\tmaximumPort: null,\n\t\t\tmaximumPath: null,\n\t\t\tmaximumResource: null,\n\t\t\tmaximumQuery: null,\n\t\t\tmaximumHash: null,\n\t\t\t\n\t\t\tminimumScheme: null,\n\t\t\tminimumAuth: null,\n\t\t\tminimumHost: null,\n\t\t\tminimumPort: null,\n\t\t\tminimumPath: null,\n\t\t\tminimumResource: null,\n\t\t\tminimumQuery: null,\n\t\t\tminimumHash: null,\n\t\t\t\n\t\t\toverridesQuery: null\n\t\t},\n\t\tresourceIsIndex: null,\n\t\tslashes: urlObj.slashes\n\t};\n\t\n\turlObj.resource = null;\n\turlObj.scheme = scheme;\n\tdelete urlObj.hostname;\n\tdelete urlObj.pathname;\n\tdelete urlObj.protocol;\n\tdelete urlObj.search;\n\tdelete urlObj.slashes;\n\t\n\treturn urlObj;\n}\n\n\n\nfunction validScheme(url, options)\n{\n\tvar valid = true;\n\t\n\toptions.rejectedSchemes.every( function(rejectedScheme)\n\t{\n\t\tvalid = !(url.indexOf(rejectedScheme+\":\") === 0);\n\t\t\n\t\t// Break loop\n\t\treturn valid;\n\t});\n\t\n\treturn valid;\n}\n\n\n\nfunction parseUrlString(url, options)\n{\n\tif ( validScheme(url,options) )\n\t{\n\t\treturn clean( _parseUrl(url, true, options.slashesDenoteHost) );\n\t}\n\telse\n\t{\n\t\treturn {href:url, valid:false};\n\t}\n}\n\n\n\nmodule.exports = parseUrlString;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/parse/urlstring.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/relate/absolutize.js":
/*!******************************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/relate/absolutize.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar findRelation = __webpack_require__(/*! ./findRelation */ \"../fhirlib/node_modules/relateurl/lib/relate/findRelation.js\");\nvar objUtils     = __webpack_require__(/*! ../util/object */ \"../fhirlib/node_modules/relateurl/lib/util/object.js\");\nvar pathUtils    = __webpack_require__(/*! ../util/path */ \"../fhirlib/node_modules/relateurl/lib/util/path.js\");\n\n\n\nfunction absolutize(urlObj, siteUrlObj, options)\n{\n\tfindRelation.upToPath(urlObj, siteUrlObj, options);\n\t\n\t// Fill in relative URLs\n\tif (urlObj.extra.relation.minimumScheme) urlObj.scheme = siteUrlObj.scheme;\n\tif (urlObj.extra.relation.minimumAuth)   urlObj.auth   = siteUrlObj.auth;\n\tif (urlObj.extra.relation.minimumHost)   urlObj.host   = objUtils.clone(siteUrlObj.host);\n\tif (urlObj.extra.relation.minimumPort)   copyPort(urlObj, siteUrlObj);\n\tif (urlObj.extra.relation.minimumScheme) copyPath(urlObj, siteUrlObj);\n\t\n\t// Check remaining relativeness now that path has been copied and/or resolved\n\tfindRelation.pathOn(urlObj, siteUrlObj, options);\n\t\n\t// Fill in relative URLs\n\tif (urlObj.extra.relation.minimumResource) copyResource(urlObj, siteUrlObj);\n\tif (urlObj.extra.relation.minimumQuery)    urlObj.query = objUtils.clone(siteUrlObj.query);\n\tif (urlObj.extra.relation.minimumHash)     urlObj.hash  = siteUrlObj.hash;\n}\n\n\n\n/*\n\tGet an absolute path that's relative to site url.\n*/\nfunction copyPath(urlObj, siteUrlObj)\n{\n\tif (urlObj.extra.relation.maximumHost || !urlObj.extra.hrefInfo.minimumResourceOnly)\n\t{\n\t\tvar pathArray = urlObj.path.absolute.array;\n\t\tvar pathString = \"/\";\n\t\t\n\t\t// If not erroneous URL\n\t\tif (pathArray)\n\t\t{\n\t\t\t// If is relative path\n\t\t\tif (urlObj.extra.hrefInfo.minimumPathOnly && urlObj.path.absolute.string.indexOf(\"/\")!==0)\n\t\t\t{\n\t\t\t\t// Append path to site path\n\t\t\t\tpathArray = siteUrlObj.path.absolute.array.concat(pathArray);\n\t\t\t}\n\t\t\t\n\t\t\tpathArray   = pathUtils.resolveDotSegments(pathArray);\n\t\t\tpathString += pathUtils.join(pathArray);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tpathArray = [];\n\t\t}\n\t\t\n\t\turlObj.path.absolute.array  = pathArray;\n\t\turlObj.path.absolute.string = pathString;\n\t}\n\telse\n\t{\n\t\t// Resource-, query- or hash-only or empty\n\t\turlObj.path = objUtils.clone(siteUrlObj.path);\n\t}\n}\n\n\n\nfunction copyPort(urlObj, siteUrlObj)\n{\n\turlObj.port = siteUrlObj.port;\n\t\n\turlObj.extra.portIsDefault = siteUrlObj.extra.portIsDefault;\n}\n\n\n\nfunction copyResource(urlObj, siteUrlObj)\n{\n\turlObj.resource = siteUrlObj.resource;\n\t\n\turlObj.extra.resourceIsIndex = siteUrlObj.extra.resourceIsIndex;\n}\n\n\n\nmodule.exports = absolutize;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/relate/absolutize.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/relate/findRelation.js":
/*!********************************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/relate/findRelation.js ***!
  \********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction findRelation_upToPath(urlObj, siteUrlObj, options)\n{\n\t// Path- or root-relative URL\n\tvar pathOnly = urlObj.extra.hrefInfo.minimumPathOnly;\n\t\n\t// Matching scheme, scheme-relative or path-only\n\tvar minimumScheme = (urlObj.scheme===siteUrlObj.scheme || !urlObj.scheme);\n\t\n\t// Matching auth, ignoring auth or path-only\n\tvar minimumAuth = minimumScheme && (urlObj.auth===siteUrlObj.auth || options.removeAuth || pathOnly);\n\t\n\t// Matching host or path-only\n\tvar www = options.ignore_www ? \"stripped\" : \"full\";\n\tvar minimumHost = minimumAuth && (urlObj.host[www]===siteUrlObj.host[www] || pathOnly);\n\t\n\t// Matching port or path-only\n\tvar minimumPort = minimumHost && (urlObj.port===siteUrlObj.port || pathOnly);\n\t\n\turlObj.extra.relation.minimumScheme = minimumScheme;\n\turlObj.extra.relation.minimumAuth   = minimumAuth;\n\turlObj.extra.relation.minimumHost   = minimumHost;\n\turlObj.extra.relation.minimumPort   = minimumPort;\n\t\n\turlObj.extra.relation.maximumScheme = !minimumScheme || minimumScheme && !minimumAuth;\n\turlObj.extra.relation.maximumAuth   = !minimumScheme || minimumScheme && !minimumHost;\n\turlObj.extra.relation.maximumHost   = !minimumScheme || minimumScheme && !minimumPort;\n}\n\n\n\nfunction findRelation_pathOn(urlObj, siteUrlObj, options)\n{\n\tvar queryOnly = urlObj.extra.hrefInfo.minimumQueryOnly;\n\tvar hashOnly  = urlObj.extra.hrefInfo.minimumHashOnly;\n\tvar empty     = urlObj.extra.hrefInfo.empty;\t// not required, but self-documenting\n\t\n\t// From upToPath()\n\tvar minimumPort   = urlObj.extra.relation.minimumPort;\n\tvar minimumScheme = urlObj.extra.relation.minimumScheme;\n\t\n\t// Matching port and path\n\tvar minimumPath = minimumPort && urlObj.path.absolute.string===siteUrlObj.path.absolute.string;\n\t\n\t// Matching resource or query/hash-only or empty\n\tvar matchingResource = (urlObj.resource===siteUrlObj.resource || !urlObj.resource && siteUrlObj.extra.resourceIsIndex) || (options.removeDirectoryIndexes && urlObj.extra.resourceIsIndex && !siteUrlObj.resource);\n\tvar minimumResource = minimumPath && (matchingResource || queryOnly || hashOnly || empty);\n\t\n\t// Matching query or hash-only/empty\n\tvar query = options.removeEmptyQueries ? \"stripped\" : \"full\";\n\tvar urlQuery = urlObj.query.string[query];\n\tvar siteUrlQuery = siteUrlObj.query.string[query];\n\tvar minimumQuery = (minimumResource && !!urlQuery && urlQuery===siteUrlQuery) || ((hashOnly || empty) && !urlObj.extra.hrefInfo.separatorOnlyQuery);\n\t\n\tvar minimumHash = minimumQuery && urlObj.hash===siteUrlObj.hash;\n\t\n\turlObj.extra.relation.minimumPath     = minimumPath;\n\turlObj.extra.relation.minimumResource = minimumResource;\n\turlObj.extra.relation.minimumQuery    = minimumQuery;\n\turlObj.extra.relation.minimumHash     = minimumHash;\n\t\n\turlObj.extra.relation.maximumPort     = !minimumScheme || minimumScheme && !minimumPath;\n\turlObj.extra.relation.maximumPath     = !minimumScheme || minimumScheme && !minimumResource;\n\turlObj.extra.relation.maximumResource = !minimumScheme || minimumScheme && !minimumQuery;\n\turlObj.extra.relation.maximumQuery    = !minimumScheme || minimumScheme && !minimumHash;\n\turlObj.extra.relation.maximumHash     = !minimumScheme || minimumScheme && !minimumHash;\t// there's nothing after hash, so it's the same as maximumQuery\n\t\n\t// Matching path and/or resource with existing but non-matching site query\n\turlObj.extra.relation.overridesQuery  = minimumPath && urlObj.extra.relation.maximumResource && !minimumQuery && !!siteUrlQuery;\n}\n\n\n\nmodule.exports =\n{\n\tpathOn:   findRelation_pathOn,\n\tupToPath: findRelation_upToPath\n};\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/relate/findRelation.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/relate/index.js":
/*!*************************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/relate/index.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar absolutize = __webpack_require__(/*! ./absolutize */ \"../fhirlib/node_modules/relateurl/lib/relate/absolutize.js\");\nvar relativize = __webpack_require__(/*! ./relativize */ \"../fhirlib/node_modules/relateurl/lib/relate/relativize.js\");\n\n\n\nfunction relateUrl(siteUrlObj, urlObj, options)\n{\n\tabsolutize(urlObj, siteUrlObj, options);\n\trelativize(urlObj, siteUrlObj, options);\n\t\n\treturn urlObj;\n}\n\n\n\nmodule.exports = relateUrl;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/relate/index.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/relate/relativize.js":
/*!******************************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/relate/relativize.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar pathUtils = __webpack_require__(/*! ../util/path */ \"../fhirlib/node_modules/relateurl/lib/util/path.js\");\n\n\n\n/*\n\tGet a path relative to the site path.\n*/\nfunction relatePath(absolutePath, siteAbsolutePath)\n{\n\tvar relativePath = [];\n\t\n\t// At this point, it's related to the host/port\n\tvar related = true;\n\tvar parentIndex = -1;\n\t\n\t// Find parents\n\tsiteAbsolutePath.forEach( function(siteAbsoluteDir, i)\n\t{\n\t\tif (related)\n\t\t{\n\t\t\tif (absolutePath[i] !== siteAbsoluteDir)\n\t\t\t{\n\t\t\t\trelated = false;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tparentIndex = i;\n\t\t\t}\n\t\t}\n\t\t\n\t\tif (!related)\n\t\t{\n\t\t\t// Up one level\n\t\t\trelativePath.push(\"..\");\n\t\t}\n\t});\n\t\n\t// Form path\n\tabsolutePath.forEach( function(dir, i)\n\t{\n\t\tif (i > parentIndex)\n\t\t{\n\t\t\trelativePath.push(dir);\n\t\t}\n\t});\n\t\n\treturn relativePath;\n}\n\n\n\nfunction relativize(urlObj, siteUrlObj, options)\n{\n\tif (urlObj.extra.relation.minimumScheme)\n\t{\n\t\tvar pathArray = relatePath(urlObj.path.absolute.array, siteUrlObj.path.absolute.array);\n\t\t\n\t\turlObj.path.relative.array  = pathArray;\n\t\turlObj.path.relative.string = pathUtils.join(pathArray);\n\t}\n}\n\n\n\nmodule.exports = relativize;\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/relate/relativize.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/util/object.js":
/*!************************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/util/object.js ***!
  \************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*\n\tDeep-clone an object.\n*/\nfunction clone(obj)\n{\n\tif (obj instanceof Object)\n\t{\n\t\tvar clonedObj = (obj instanceof Array) ? [] : {};\n\t\t\n\t\tfor (var i in obj)\n\t\t{\n\t\t\tif ( obj.hasOwnProperty(i) )\n\t\t\t{\n\t\t\t\tclonedObj[i] = clone( obj[i] );\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn clonedObj;\n\t}\n\t\n\treturn obj;\n}\n\n\n\n/*\n\thttps://github.com/jonschlinkert/is-plain-object\n*/\nfunction isPlainObject(obj)\n{\n\treturn !!obj && typeof obj===\"object\" && obj.constructor===Object;\n}\n\n\n\n/*\n\tShallow-merge two objects.\n*/\nfunction shallowMerge(target, source)\n{\n\tif (target instanceof Object && source instanceof Object)\n\t{\n\t\tfor (var i in source)\n\t\t{\n\t\t\tif ( source.hasOwnProperty(i) )\n\t\t\t{\n\t\t\t\ttarget[i] = source[i];\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn target;\n}\n\n\n\nmodule.exports =\n{\n\tclone: clone,\n\tisPlainObject: isPlainObject,\n\tshallowMerge: shallowMerge\n};\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/util/object.js?");

/***/ }),

/***/ "../fhirlib/node_modules/relateurl/lib/util/path.js":
/*!**********************************************************!*\
  !*** ../fhirlib/node_modules/relateurl/lib/util/path.js ***!
  \**********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction joinPath(pathArray)\n{\n\tif (pathArray.length > 0)\n\t{\n\t\treturn pathArray.join(\"/\") + \"/\";\n\t}\n\telse\n\t{\n\t\treturn \"\";\n\t}\n}\n\n\n\nfunction resolveDotSegments(pathArray)\n{\n\tvar pathAbsolute = [];\n\t\n\tpathArray.forEach( function(dir)\n\t{\n\t\tif (dir !== \"..\")\n\t\t{\n\t\t\tif (dir !== \".\")\n\t\t\t{\n\t\t\t\tpathAbsolute.push(dir);\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Remove parent\n\t\t\tif (pathAbsolute.length > 0)\n\t\t\t{\n\t\t\t\tpathAbsolute.splice(pathAbsolute.length-1, 1);\n\t\t\t}\n\t\t}\n\t});\n\t\n\treturn pathAbsolute;\n}\n\n\n\nmodule.exports =\n{\n\tjoin: joinPath,\n\tresolveDotSegments: resolveDotSegments\n};\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/relateurl/lib/util/path.js?");

/***/ }),

/***/ "../fhirlib/node_modules/string_decoder/lib/string_decoder.js":
/*!********************************************************************!*\
  !*** ../fhirlib/node_modules/string_decoder/lib/string_decoder.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar Buffer = (__webpack_require__(/*! safe-buffer */ \"../fhirlib/node_modules/string_decoder/node_modules/safe-buffer/index.js\").Buffer);\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/string_decoder/lib/string_decoder.js?");

/***/ }),

/***/ "../fhirlib/node_modules/string_decoder/node_modules/safe-buffer/index.js":
/*!********************************************************************************!*\
  !*** ../fhirlib/node_modules/string_decoder/node_modules/safe-buffer/index.js ***!
  \********************************************************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */\n/* eslint-disable node/no-deprecated-api */\nvar buffer = __webpack_require__(/*! buffer */ \"?57ce\")\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.prototype = Object.create(Buffer.prototype)\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/string_decoder/node_modules/safe-buffer/index.js?");

/***/ }),

/***/ "../fhirlib/node_modules/util-deprecate/browser.js":
/*!*********************************************************!*\
  !*** ../fhirlib/node_modules/util-deprecate/browser.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("\n/**\n * Module exports.\n */\n\nmodule.exports = deprecate;\n\n/**\n * Mark that a method should not be used.\n * Returns a modified function which warns once by default.\n *\n * If `localStorage.noDeprecation = true` is set, then it is a no-op.\n *\n * If `localStorage.throwDeprecation = true` is set, then deprecated functions\n * will throw an Error when invoked.\n *\n * If `localStorage.traceDeprecation = true` is set, then deprecated functions\n * will invoke `console.trace()` instead of `console.error()`.\n *\n * @param {Function} fn - the function to deprecate\n * @param {String} msg - the string to print to the console when `fn` is invoked\n * @returns {Function} a new \"deprecated\" version of `fn`\n * @api public\n */\n\nfunction deprecate (fn, msg) {\n  if (config('noDeprecation')) {\n    return fn;\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (config('throwDeprecation')) {\n        throw new Error(msg);\n      } else if (config('traceDeprecation')) {\n        console.trace(msg);\n      } else {\n        console.warn(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n}\n\n/**\n * Checks `localStorage` for boolean values for the given `name`.\n *\n * @param {String} name\n * @returns {Boolean}\n * @api private\n */\n\nfunction config (name) {\n  // accessing global.localStorage can trigger a DOMException in sandboxed iframes\n  try {\n    if (!__webpack_require__.g.localStorage) return false;\n  } catch (_) {\n    return false;\n  }\n  var val = __webpack_require__.g.localStorage[name];\n  if (null == val) return false;\n  return String(val).toLowerCase() === 'true';\n}\n\n\n//# sourceURL=webpack://playground/../fhirlib/node_modules/util-deprecate/browser.js?");

/***/ }),

/***/ "./fhircat-addons.js":
/*!***************************!*\
  !*** ./fhircat-addons.js ***!
  \***************************/
/***/ ((__unused_webpack_module, __unused_webpack_exports, __webpack_require__) => {

eval("globalThis.N3 = {\n  Factory: (__webpack_require__(/*! n3/lib/N3DataFactory */ \"./node_modules/n3/lib/N3DataFactory.js\")[\"default\"]),\n  Parser: (__webpack_require__(/*! n3/lib/N3Parser */ \"./node_modules/n3/lib/N3Parser.js\")[\"default\"]),\n  Writer: (__webpack_require__(/*! n3/lib/N3Writer */ \"./node_modules/n3/lib/N3Writer.js\")[\"default\"]),\n  Store: (__webpack_require__(/*! n3/lib/N3Store */ \"./node_modules/n3/lib/N3Store.js\")[\"default\"]),\n};\nglobalThis.ShExUtil = __webpack_require__(/*! @shexjs/util */ \"./node_modules/@shexjs/util/shex-util.js\");\nglobalThis.StructureError = (__webpack_require__(/*! ../fhirlib/errors */ \"../fhirlib/errors.js\").StructureError);\nglobalThis.FhirJsonLdContextGenerator = __webpack_require__(/*! ../fhirlib/FhirJsonLdContextGenerator */ \"../fhirlib/FhirJsonLdContextGenerator.js\");\nglobalThis.BundleDefinitionLoader = (__webpack_require__(/*! ../fhirlib/BundleDefinitionLoader */ \"../fhirlib/BundleDefinitionLoader.js\").BundleDefinitionLoader);\nglobalThis.FhirShExJGenerator = __webpack_require__(/*! ../fhirlib/FhirShExJGenerator */ \"../fhirlib/FhirShExJGenerator.js\");\nglobalThis.FhirTurtleSerializer = __webpack_require__(/*! ../fhirlib/FhirTurtleSerializer */ \"../fhirlib/FhirTurtleSerializer.js\");\nglobalThis.NestedWriter = __webpack_require__(/*! ../fhirlib/NestedWriter */ \"../fhirlib/NestedWriter.js\");\nglobalThis.P = __webpack_require__(/*! ../fhirlib/Prefixes */ \"../fhirlib/Prefixes.js\");\n\nglobalThis.setImmediate = function (f) { return f(); }\n\nconst preprocs = __webpack_require__(/*! ../fhirlib/FhirPreprocessors */ \"../fhirlib/FhirPreprocessors.js\");\nglobalThis.FhirPreprocessor = {\n  R4: preprocs.FhirR4Preprocessor,\n  R5: preprocs.FhirR5Preprocessor,\n}\n\n\n//# sourceURL=webpack://playground/./fhircat-addons.js?");

/***/ }),

/***/ "./node_modules/@shexjs/term/shex-term.js":
/*!************************************************!*\
  !*** ./node_modules/@shexjs/term/shex-term.js ***!
  \************************************************/
/***/ ((module) => {

eval("/**\n *\n * isIRI, isBlank, getLiteralType, getLiteralValue\n */\n\nconst ShExTermCjsModule = (function () {\n\n  const absoluteIRI = /^[a-z][a-z0-9+.-]*:/i,\n    schemeAuthority = /^(?:([a-z][a-z0-9+.-]*:))?(?:\\/\\/[^\\/]*)?/i,\n    dotSegments = /(?:^|\\/)\\.\\.?(?:$|[\\/#?])/;\n\n  const RdfLangString = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#langString\";\n  const XsdString = \"http://www.w3.org/2001/XMLSchema#string\";\n\n  // N3.js:lib/N3Parser.js<0.4.5>:576 with\n  //   s/this\\./Parser./g\n  //   s/token/iri/\n  // ### `_resolveIRI` resolves a relative IRI token against the base path,\n  // assuming that a base path has been set and that the IRI is indeed relative.\n  function resolveRelativeIRI (base, iri) {\n\n    if (absoluteIRI.test(iri))\n      return iri\n\n    switch (iri[0]) {\n    // An empty relative IRI indicates the base IRI\n    case undefined: return base;\n    // Resolve relative fragment IRIs against the base IRI\n    case '#': return base + iri;\n    // Resolve relative query string IRIs by replacing the query string\n    case '?': return base.replace(/(?:\\?.*)?$/, iri);\n    // Resolve root-relative IRIs at the root of the base IRI\n    case '/':\n      let m = base.match(schemeAuthority);\n      // Resolve scheme-relative IRIs to the scheme\n      return (iri[1] === '/' ? m[1] : m[0]) + _removeDotSegments(iri);\n    // Resolve all other IRIs at the base IRI's path\n    default: {\n      return _removeDotSegments(base.replace(/[^\\/?]*(?:\\?.*)?$/, '') + iri);\n    }\n    }\n  }\n\n  // ### `_removeDotSegments` resolves './' and '../' path segments in an IRI as per RFC3986.\n  function _removeDotSegments (iri) {\n    // Don't modify the IRI if it does not contain any dot segments\n    if (!dotSegments.test(iri))\n      return iri;\n\n    // Start with an imaginary slash before the IRI in order to resolve trailing './' and '../'\n    const result = '', length = iri.length, i = -1, pathStart = -1, segmentStart = 0, next = '/';\n\n    while (i < length) {\n      switch (next) {\n      // The path starts with the first slash after the authority\n      case ':':\n        if (pathStart < 0) {\n          // Skip two slashes before the authority\n          if (iri[++i] === '/' && iri[++i] === '/')\n            // Skip to slash after the authority\n            while ((pathStart = i + 1) < length && iri[pathStart] !== '/')\n              i = pathStart;\n        }\n        break;\n      // Don't modify a query string or fragment\n      case '?':\n      case '#':\n        i = length;\n        break;\n      // Handle '/.' or '/..' path segments\n      case '/':\n        if (iri[i + 1] === '.') {\n          next = iri[++i + 1];\n          switch (next) {\n          // Remove a '/.' segment\n          case '/':\n            result += iri.substring(segmentStart, i - 1);\n            segmentStart = i + 1;\n            break;\n          // Remove a trailing '/.' segment\n          case undefined:\n          case '?':\n          case '#':\n            return result + iri.substring(segmentStart, i) + iri.substr(i + 1);\n          // Remove a '/..' segment\n          case '.':\n            next = iri[++i + 1];\n            if (next === undefined || next === '/' || next === '?' || next === '#') {\n              result += iri.substring(segmentStart, i - 2);\n              // Try to remove the parent path from result\n              if ((segmentStart = result.lastIndexOf('/')) >= pathStart)\n                result = result.substr(0, segmentStart);\n              // Remove a trailing '/..' segment\n              if (next !== '/')\n                return result + '/' + iri.substr(i + 1);\n              segmentStart = i + 1;\n            }\n          }\n        }\n      }\n      next = iri[++i];\n    }\n    return result + iri.substring(segmentStart);\n  }\n\n  function internalTerm (node) { // !!rdfjsTermToInternal\n    switch (node.termType) {\n    case (\"NamedNode\"):\n      return node.value;\n    case (\"BlankNode\"):\n      return \"_:\" + node.value;\n    case (\"Literal\"):\n      return \"\\\"\" + node.value + \"\\\"\" + (\n        node.datatypeString === RdfLangString\n          ? \"@\" + node.language\n          : node.datatypeString === XsdString\n          ? \"\"\n          : \"^^\" + node.datatypeString\n      );\n    default: throw Error(\"unknown RDFJS node type: \" + JSON.stringify(node))\n    }\n  }\n\n  function internalTriple (triple) { // !!rdfjsTripleToInternal\n    return {\n      subject: internalTerm(triple.subject),\n      predicate: internalTerm(triple.predicate),\n      object: internalTerm(triple.object)\n    };\n  }\n\n  function externalTerm (node, factory) { // !!intermalTermToRdfjs\n    if (isIRI(node)) {\n      return factory.namedNode(node);\n    } else if (isBlank(node)) {\n      return factory.blankNode(node.substr(2));\n    } else if (isLiteral(node)) {\n      let dtOrLang = getLiteralLanguage(node) ||\n          (getLiteralType(node) === XsdString\n           ? null // seems to screw up N3.js\n           : factory.namedNode(getLiteralType(node)))\n      return factory.literal(getLiteralValue(node), dtOrLang)\n    } else {\n      throw Error(\"Unknown internal term type: \" + JSON.stringify(node));\n    }\n  }\n\n  function externalTriple (triple, factory) { // !!rename internalTripleToRdjs\n    return factory.quad(\n      externalTerm(triple.subject, factory),\n      externalTerm(triple.predicate, factory),\n      externalTerm(triple.object, factory)\n    );\n  }\n\n  function intermalTermToTurtle (node, base, prefixes) {\n    if (isIRI(node)) {\n      // if (node === RDF_TYPE) // only valid in Turtle predicates\n      //   return \"a\";\n\n      // Escape special characters\n      if (escape.test(node))\n        node = node.replace(escapeAll, characterReplacer);\n      const pref = Object.keys(prefixes).find(pref => node.startsWith(prefixes[pref]));\n      if (pref) {\n        const rest = node.substr(prefixes[pref].length);\n        if (rest.indexOf(\"\\\\\") === -1) // could also say no more than n of these: [...]\n          return pref + \":\" + rest.replace(/([~!$&'()*+,;=/?#@%])/g, '\\\\' + \"$1\");\n      }\n      if (node.startsWith(base)) {\n        return \"<\" + node.substr(base.length) + \">\";\n      } else {\n        return \"<\" + node + \">\";\n      }\n    } else if (isBlank(node)) {\n      return node;\n    } else if (isLiteral(node)) {\n      const value = getLiteralValue(node);\n      const type = getLiteralType(node);\n      const language = getLiteralLanguage(node);\n      // Escape special characters\n      if (escape.test(value))\n        value = value.replace(escapeAll, characterReplacer);\n      // Write the literal, possibly with type or language\n      if (language)\n        return '\"' + value + '\"@' + language;\n      else if (type && type !== \"http://www.w3.org/2001/XMLSchema#string\")\n        return '\"' + value + '\"^^' + this.intermalTermToTurtle(type, base, prefixes);\n      else\n        return '\"' + value + '\"';\n    } else {\n      throw Error(\"Unknown internal term type: \" + JSON.stringify(node));\n    }\n  }\n\n  // Tests whether the given entity (triple object) represents an IRI in the N3 library\n  function isIRI (entity) {\n    if (typeof entity !== 'string')\n      return false;\n    else if (entity.length === 0)\n      return true;\n    else {\n      const firstChar = entity[0];\n      return firstChar !== '\"' && firstChar !== '_';\n    }\n  }\n\n  // Tests whether the given entity (triple object) represents a literal in the N3 library\n  function isLiteral (entity) {\n    return typeof entity === 'string' && entity[0] === '\"';\n  }\n\n  // Tests whether the given entity (triple object) represents a blank node in the N3 library\n  function isBlank (entity) {\n    return typeof entity === 'string' && entity.substr(0, 2) === '_:';\n  }\n\n  // Tests whether the given entity represents the default graph\n  function isDefaultGraph (entity) {\n    return !entity;\n  }\n\n  // Tests whether the given triple is in the default graph\n  function inDefaultGraph (triple) {\n    return !triple.graph;\n  }\n\n  // Gets the string value of a literal in the N3 library\n  function getLiteralValue (literal) {\n    const match = /^\"([^]*)\"/.exec(literal);\n    if (!match)\n      throw new Error(literal + ' is not a literal');\n    return match[1];\n  }\n\n  // Gets the type of a literal in the N3 library\n  function getLiteralType (literal) {\n    const match = /^\"[^]*\"(?:\\^\\^([^\"]+)|(@)[^@\"]+)?$/.exec(literal);\n    if (!match)\n      throw new Error(literal + ' is not a literal');\n    return match[1] || (match[2] ? RdfLangString : XsdString);\n  }\n\n  // Gets the language of a literal in the N3 library\n  function getLiteralLanguage (literal) {\n    const match = /^\"[^]*\"(?:@([^@\"]+)|\\^\\^[^\"]+)?$/.exec(literal);\n    if (!match)\n      throw new Error(literal + ' is not a literal');\n    return match[1] ? match[1].toLowerCase() : '';\n  }\n\n\n// rdf:type predicate (for 'a' abbreviation)\nconst RDF_PREFIX = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n    RDF_TYPE   = RDF_PREFIX + 'type';\n\n// Characters in literals that require escaping\nconst escape    = /[\"\\\\\\t\\n\\r\\b\\f\\u0000-\\u0019\\ud800-\\udbff]/,\n    escapeAll = /[\"\\\\\\t\\n\\r\\b\\f\\u0000-\\u0019]|[\\ud800-\\udbff][\\udc00-\\udfff]/g,\n    escapeReplacements = {\n      '\\\\': '\\\\\\\\', '\"': '\\\\\"', '\\t': '\\\\t',\n      '\\n': '\\\\n', '\\r': '\\\\r', '\\b': '\\\\b', '\\f': '\\\\f',\n    };\n\n  // Replaces a character by its escaped version\n  function characterReplacer (character) {\n    // Replace a single character by its escaped version\n    const result = escapeReplacements[character];\n    if (result === undefined) {\n      // Replace a single character with its 4-bit unicode escape sequence\n      if (character.length === 1) {\n        result = character.charCodeAt(0).toString(16);\n        result = '\\\\u0000'.substr(0, 6 - result.length) + result;\n      }\n      // Replace a surrogate pair with its 8-bit unicode escape sequence\n      else {\n        result = ((character.charCodeAt(0) - 0xD800) * 0x400 +\n                  character.charCodeAt(1) + 0x2400).toString(16);\n        result = '\\\\U00000000'.substr(0, 10 - result.length) + result;\n      }\n    }\n    return result;\n  }\n\n  return {\n    RdfLangString: RdfLangString,\n    XsdString: XsdString,\n    resolveRelativeIRI: resolveRelativeIRI,\n    isIRI: isIRI,\n    isLiteral: isLiteral,\n    isBlank: isBlank,\n    isDefaultGraph: isDefaultGraph,\n    inDefaultGraph: inDefaultGraph,\n    getLiteralValue: getLiteralValue,\n    getLiteralType: getLiteralType,\n    getLiteralLanguage: getLiteralLanguage,\n    internalTerm: internalTerm,\n    internalTriple: internalTriple,\n    externalTerm: externalTerm,\n    externalTriple: externalTriple,\n    intermalTermToTurtle: intermalTermToTurtle,\n  }\n})();\n\nif (true)\n  module.exports = ShExTermCjsModule; // node environment\n\n\n//# sourceURL=webpack://playground/./node_modules/@shexjs/term/shex-term.js?");

/***/ }),

/***/ "./node_modules/@shexjs/util/shex-util.js":
/*!************************************************!*\
  !*** ./node_modules/@shexjs/util/shex-util.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// **ShExUtil** provides ShEx utility functions\n\nconst ShExUtilCjsModule = (function () {\nconst ShExTerm = __webpack_require__(/*! @shexjs/term */ \"./node_modules/@shexjs/term/shex-term.js\");\nconst Visitor = __webpack_require__(/*! @shexjs/visitor */ \"./node_modules/@shexjs/visitor/shex-visitor.js\")\nconst Hierarchy = __webpack_require__(/*! hierarchy-closure */ \"./node_modules/hierarchy-closure/hierarchy-closure.js\")\n\nconst SX = {};\nSX._namespace = \"http://www.w3.org/ns/shex#\";\n[\"Schema\", \"@context\", \"imports\", \"startActs\", \"start\", \"shapes\",\n \"ShapeDecl\", \"ShapeOr\", \"ShapeAnd\", \"shapeExprs\", \"nodeKind\",\n \"NodeConstraint\", \"iri\", \"bnode\", \"nonliteral\", \"literal\", \"datatype\", \"length\", \"minlength\", \"maxlength\", \"pattern\", \"flags\", \"mininclusive\", \"minexclusive\", \"maxinclusive\", \"maxexclusive\", \"totaldigits\", \"fractiondigits\", \"values\",\n \"ShapeNot\", \"shapeExpr\",\n \"Shape\", \"abstract\", \"closed\", \"extra\", \"expression\", \"extends\", \"restricts\", \"semActs\",\n \"ShapeRef\", \"reference\", \"ShapeExternal\",\n \"EachOf\", \"OneOf\", \"expressions\", \"min\", \"max\", \"annotation\",\n \"TripleConstraint\", \"inverse\", \"negated\", \"predicate\", \"valueExpr\",\n \"Inclusion\", \"include\", \"Language\", \"languageTag\",\n \"IriStem\", \"LiteralStem\", \"LanguageStem\", \"stem\",\n \"IriStemRange\", \"LiteralStemRange\", \"LanguageStemRange\", \"exclusion\",\n \"Wildcard\", \"SemAct\", \"name\", \"code\",\n \"Annotation\", \"object\"].forEach(p => {\n  SX[p] = SX._namespace+p;\n});\nconst RDF = {};\nRDF._namespace = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\";\n[\"type\", \"first\", \"rest\", \"nil\"].forEach(p => {\n  RDF[p] = RDF._namespace+p;\n});\nconst XSD = {}\nXSD._namespace = \"http://www.w3.org/2001/XMLSchema#\";\n[\"anyURI\"].forEach(p => {\n  XSD[p] = XSD._namespace+p;\n});\nconst OWL = {}\nOWL._namespace = \"http://www.w3.org/2002/07/owl#\";\n[\"Thing\"].forEach(p => {\n  OWL[p] = OWL._namespace+p;\n});\n\nconst Missed = {}; // singleton\nconst UNBOUNDED = -1;\n\nfunction extend (base) {\n  if (!base) base = {};\n  for (let i = 1, l = arguments.length, arg; i < l && (arg = arguments[i] || {}); i++)\n    for (let name in arg)\n      base[name] = arg[name];\n  return base;\n}\n\n    function isTerm (t) {\n      return typeof t !== \"object\" || \"value\" in t && Object.keys(t).reduce((r, k) => {\n        return r === false ? r : [\"value\", \"type\", \"language\"].indexOf(k) !== -1;\n      }, true);\n    }\n\n  function isShapeRef (expr) {\n    return typeof expr === \"string\" // test for JSON-LD @ID\n  }\n  let isInclusion = isShapeRef;\n\n        function ldify (term) {\n          if (term[0] !== \"\\\"\")\n            return term;\n          const ret = { value: ShExTerm.getLiteralValue(term) };\n          const dt = ShExTerm.getLiteralType(term);\n          if (dt &&\n              dt !== \"http://www.w3.org/2001/XMLSchema#string\" &&\n              dt !== \"http://www.w3.org/1999/02/22-rdf-syntax-ns#langString\")\n            ret.type = dt;\n          const lang = ShExTerm.getLiteralLanguage(term)\n          if (lang)\n            ret.language = lang;\n          return ret;\n        }\nconst ShExUtil = {\n\n  SX: SX,\n  RDF: RDF,\n  version: function () {\n    return \"0.5.0\";\n  },\n\n  Visitor: Visitor,\n  index: Visitor.index,\n\n\n  /* getAST - compile a traditional regular expression abstract syntax tree.\n   * Tested but not used at present.\n   */\n  getAST: function (schema) {\n    return {\n      type: \"AST\",\n      shapes: schema.shapes.reduce(function (ret, shape) {\n        ret[shape.id] = {\n          type: \"ASTshape\",\n          expression: _compileShapeToAST(shape.expression, [], schema)\n        };\n        return ret;\n      }, {})\n    };\n\n    /* _compileShapeToAST - compile a shape expression to an abstract syntax tree.\n     *\n     * currently tested but not used.\n     */\n    function _compileShapeToAST (expression, tripleConstraints, schema) {\n\n      function Epsilon () {\n        this.type = \"Epsilon\";\n      }\n\n      function TripleConstraint (ordinal, predicate, inverse, negated, valueExpr) {\n        this.type = \"TripleConstraint\";\n        // this.ordinal = ordinal; @@ does 1card25\n        this.inverse = !!inverse;\n        this.negated = !!negated;\n        this.predicate = predicate;\n        if (valueExpr !== undefined)\n          this.valueExpr = valueExpr;\n      }\n\n      function Choice (disjuncts) {\n        this.type = \"Choice\";\n        this.disjuncts = disjuncts;\n      }\n\n      function EachOf (conjuncts) {\n        this.type = \"EachOf\";\n        this.conjuncts = conjuncts;\n      }\n\n      function SemActs (expression, semActs) {\n        this.type = \"SemActs\";\n        this.expression = expression;\n        this.semActs = semActs;\n      }\n\n      function KleeneStar (expression) {\n        this.type = \"KleeneStar\";\n        this.expression = expression;\n      }\n\n      function _compileExpression (expr, schema) {\n        let repeated, container;\n\n        /* _repeat: map expr with a min and max cardinality to a corresponding AST with Groups and Stars.\n           expr 1 1 => expr\n           expr 0 1 => Choice(expr, Eps)\n           expr 0 3 => Choice(EachOf(expr, Choice(EachOf(expr, Choice(expr, EPS)), Eps)), Eps)\n           expr 2 5 => EachOf(expr, expr, Choice(EachOf(expr, Choice(EachOf(expr, Choice(expr, EPS)), Eps)), Eps))\n           expr 0 * => KleeneStar(expr)\n           expr 1 * => EachOf(expr, KleeneStar(expr))\n           expr 2 * => EachOf(expr, expr, KleeneStar(expr))\n\n           @@TODO: favor Plus over Star if Epsilon not in expr.\n        */\n        function _repeat (expr, min, max) {\n          if (min === undefined) { min = 1; }\n          if (max === undefined) { max = 1; }\n\n          if (min === 1 && max === 1) { return expr; }\n\n          const opts = max === UNBOUNDED ?\n                new KleeneStar(expr) :\n                Array.from(Array(max - min)).reduce(function (ret, elt, ord) {\n                  return ord === 0 ?\n                    new Choice([expr, new Epsilon]) :\n                    new Choice([new EachOf([expr, ret]), new Epsilon]);\n                }, undefined);\n\n          const reqd = min !== 0 ?\n                new EachOf(Array.from(Array(min)).map(function (ret) {\n                  return expr; // @@ something with ret\n                }).concat(opts)) : opts;\n          return reqd;\n        }\n\n        if (typeof expr === \"string\") { // Inclusion\n          const included = schema._index.tripleExprs[expr].expression;\n          return _compileExpression(included, schema);\n        }\n\n        else if (expr.type === \"TripleConstraint\") {\n          // predicate, inverse, negated, valueExpr, annotations, semActs, min, max\n          const valueExpr = \"valueExprRef\" in expr ?\n                schema.valueExprDefns[expr.valueExprRef] :\n                expr.valueExpr;\n          const ordinal = tripleConstraints.push(expr)-1;\n          const tp = new TripleConstraint(ordinal, expr.predicate, expr.inverse, expr.negated, valueExpr);\n          repeated = _repeat(tp, expr.min, expr.max);\n          return expr.semActs ? new SemActs(repeated, expr.semActs) : repeated;\n        }\n\n        else if (expr.type === \"OneOf\") {\n          container = new Choice(expr.expressions.map(function (e) {\n            return _compileExpression(e, schema);\n          }));\n          repeated = _repeat(container, expr.min, expr.max);\n          return expr.semActs ? new SemActs(repeated, expr.semActs) : repeated;\n        }\n\n        else if (expr.type === \"EachOf\") {\n          container = new EachOf(expr.expressions.map(function (e) {\n            return _compileExpression(e, schema);\n          }));\n          repeated = _repeat(container, expr.min, expr.max);\n          return expr.semActs ? new SemActs(repeated, expr.semActs) : repeated;\n        }\n\n        else throw Error(\"unexpected expr type: \" + expr.type);\n      }\n\n      return expression ? _compileExpression(expression, schema) : new Epsilon();\n    }\n  },\n\n  // tests\n  // console.warn(\"HERE:\", ShExJtoAS({\"type\":\"Schema\",\"shapes\":[{\"id\":\"http://all.example/S1\",\"type\":\"Shape\",\"expression\":\n  //  { \"id\":\"http://all.example/S1e\", \"type\":\"EachOf\",\"expressions\":[ ] },\n  // // { \"id\":\"http://all.example/S1e\",\"type\":\"TripleConstraint\",\"predicate\":\"http://all.example/p1\"},\n  // \"extra\":[\"http://all.example/p3\",\"http://all.example/p1\",\"http://all.example/p2\"]\n  // }]}).shapes['http://all.example/S1']);\n\n  ShExJtoAS: function (schema) {\n    const _ShExUtil = this;\n    schema._prefixes = schema._prefixes || {  };\n    schema._index = this.index(schema);\n    return schema;\n  },\n\n  AStoShExJ: function (schema, abbreviate) {\n    schema[\"@context\"] = schema[\"@context\"] || \"http://www.w3.org/ns/shex.jsonld\";\n    delete schema[\"_index\"];\n    delete schema[\"_prefixes\"];\n    return schema;\n  },\n\n  ShExRVisitor: function (knownShapeExprs) {\n    const v = ShExUtil.Visitor();\n    const knownExpressions = {};\n    const oldVisitShapeExpr = v.visitShapeExpr,\n        oldVisitValueExpr = v.visitValueExpr,\n        oldVisitExpression = v.visitExpression;\n    v.keepShapeExpr = oldVisitShapeExpr;\n\n    v.visitShapeExpr = v.visitValueExpr = function (expr, label) {\n      if (typeof expr === \"string\")\n        return expr;\n      if (\"id\" in expr) {\n        if (knownShapeExprs.indexOf(expr.id) !== -1 || Object.keys(expr).length === 1)\n          return expr.id;\n        delete expr.id;\n      }\n      return oldVisitShapeExpr.call(this, expr, label);\n    };\n\n    v.visitExpression = function (expr) {\n      if (typeof expr === \"string\") // shortcut for recursive references e.g. 1Include1 and ../doc/TODO.md\n        return expr;\n      if (\"id\" in expr) {\n        if (expr.id in knownExpressions) {\n          knownExpressions[expr.id].refCount++;\n          return expr.id;\n        }\n      }\n      const ret = oldVisitExpression.call(this, expr);\n      // Everything from RDF has an ID, usually a BNode.\n      knownExpressions[expr.id] = { refCount: 1, expr: ret };\n      return ret;\n    }\n\n    v.cleanIds = function () {\n      for (let k in knownExpressions) {\n        const known = knownExpressions[k];\n        if (known.refCount === 1 && ShExTerm.isBlank(known.expr.id))\n          delete known.expr.id;\n      };\n    }\n\n    return v;\n  },\n\n\n  // tests\n  // const shexr = ShExUtil.ShExRtoShExJ({ \"type\": \"Schema\", \"shapes\": [\n  //   { \"id\": \"http://a.example/S1\", \"type\": \"Shape\",\n  //     \"expression\": {\n  //       \"type\": \"TripleConstraint\", \"predicate\": \"http://a.example/p1\",\n  //       \"valueExpr\": {\n  //         \"type\": \"ShapeAnd\", \"shapeExprs\": [\n  //           { \"type\": \"NodeConstraint\", \"nodeKind\": \"bnode\" },\n  //           { \"id\": \"http://a.example/S2\", \"type\": \"Shape\",\n  //             \"expression\": {\n  //               \"type\": \"TripleConstraint\", \"predicate\": \"http://a.example/p2\" } }\n  //           //            \"http://a.example/S2\"\n  //         ] } } },\n  //   { \"id\": \"http://a.example/S2\", \"type\": \"Shape\",\n  //     \"expression\": {\n  //       \"type\": \"TripleConstraint\", \"predicate\": \"http://a.example/p2\" } }\n  // ] });\n  // console.warn(\"HERE:\", shexr.shapes[0].expression.valueExpr);\n  // ShExUtil.ShExJtoAS(shexr);\n  // console.warn(\"THERE:\", shexr.shapes[\"http://a.example/S1\"].expression.valueExpr);\n\n\n  ShExRtoShExJ: function (schema) {\n    // compile a list of known shapeExprs\n    const knownShapeExprs = [];\n    if (\"shapes\" in schema)\n      [].push.apply(knownShapeExprs, schema.shapes.map(sh => { return sh.id; }));\n\n    // normalize references to those shapeExprs\n    const v = this.ShExRVisitor(knownShapeExprs);\n    if (\"start\" in schema)\n      schema.start = v.visitShapeExpr(schema.start);\n    if (\"shapes\" in schema)\n      schema.shapes = schema.shapes.map(sh => {\n        return sh.type === SX.ShapeDecl ?\n          {\n            type: \"ShapeDecl\",\n            id: sh.id,\n            abstract: sh.abstract,\n            shapeExpr: v.visitShapeExpr(sh.shapeExpr)\n          } :\n          v.keepShapeExpr(sh);\n      });\n\n    // remove extraneous BNode IDs\n    v.cleanIds();\n    return schema;\n  },\n\n  valGrep: function (obj, type, f) {\n    const _ShExUtil = this;\n    const ret = [];\n    for (let i in obj) {\n      const o = obj[i];\n      if (typeof o === \"object\") {\n        if (\"type\" in o && o.type === type)\n          ret.push(f(o));\n        ret.push.apply(ret, _ShExUtil.valGrep(o, type, f));\n      }\n    }\n    return ret;\n  },\n\n  n3jsToTurtle: function (res) {\n    function termToLex (node) {\n      return typeof node === \"object\" ? (\"\\\"\" + node.value + \"\\\"\" + (\n        \"type\" in node ? \"^^<\" + node.type + \">\" :\n          \"language\" in node ? \"@\" + node.language :\n          \"\"\n      )) :\n      ShExTerm.isIRI(node) ? \"<\" + node + \">\" :\n      ShExTerm.isBlank(node) ? node :\n      \"???\";\n    }\n    return this.valGrep(res, \"TestedTriple\", function (t) {\n      return [\"subject\", \"predicate\", \"object\"].map(k => {\n        return termToLex(t[k]);\n      }).join(\" \")+\" .\";\n    });\n  },\n\n  valToN3js: function (res, factory) {\n    return this.valGrep(res, \"TestedTriple\", function (t) {\n      const ret = JSON.parse(JSON.stringify(t));\n      if (typeof t.object === \"object\")\n        ret.object = (\"\\\"\" + t.object.value + \"\\\"\" + (\n          \"type\" in t.object ? \"^^\" + t.object.type :\n            \"language\" in t.object ? \"@\" + t.object.language :\n            \"\"\n        ));\n      return ShExTerm.externalTriple(ret, factory);\n    });\n  },\n\n  n3jsToTurtle: function (n3js) {\n    function termToLex (node) {\n      if (ShExTerm.isIRI(node))\n        return \"<\" + node + \">\";\n      if (ShExTerm.isBlank(node))\n        return node;\n      const t = ShExTerm.getLiteralType(node);\n      if (t && t !== \"http://www.w3.org/2001/XMLSchema#string\")\n        return \"\\\"\" + ShExTerm.getLiteralValue(node) + \"\\\"\" +\n        \"^^<\" + t + \">\";\n      return node;\n    }\n    return n3js.map(function (t) {\n      return [\"subject\", \"predicate\", \"object\"].map(k => {\n        return termToLex(t[k]);\n      }).join(\" \")+\" .\";\n    });\n  },\n\n  /* canonicalize: move all tripleExpression references to their first expression.\n   *\n   */\n  canonicalize: function (schema, trimIRI) {\n    const ret = JSON.parse(JSON.stringify(schema));\n    ret[\"@context\"] = ret[\"@context\"] || \"http://www.w3.org/ns/shex.jsonld\";\n    delete ret._prefixes;\n    delete ret._base;\n    let index = ret._index || this.index(schema);\n    delete ret._index;\n    let sourceMap = ret._sourceMap;\n    delete ret._sourceMap;\n    // Don't delete ret.productions as it's part of the AS.\n    const v = ShExUtil.Visitor();\n    const knownExpressions = [];\n    const oldVisitInclusion = v.visitInclusion, oldVisitExpression = v.visitExpression;\n    v.visitInclusion = function (inclusion) {\n      if (knownExpressions.indexOf(inclusion) === -1 &&\n          inclusion in index.tripleExprs) {\n        knownExpressions.push(inclusion)\n        return oldVisitExpression.call(v, index.tripleExprs[inclusion]);\n      }\n      return oldVisitInclusion.call(v, inclusion);\n    };\n    v.visitExpression = function (expression) {\n      if (typeof expression === \"object\" && \"id\" in expression) {\n        if (knownExpressions.indexOf(expression.id) === -1) {\n          knownExpressions.push(expression.id)\n          return oldVisitExpression.call(v, index.tripleExprs[expression.id]);\n        }\n        return expression.id; // Inclusion\n      }\n      return oldVisitExpression.call(v, expression);\n    };\n    if (trimIRI) {\n      v.visitIRI = function (i) {\n        return i.replace(trimIRI, \"\");\n      }\n      if (\"imports\" in ret)\n        ret.imports = v.visitImports(ret.imports);\n    }\n    if (\"shapes\" in ret) {\n      ret.shapes = Object.keys(index.shapeExprs).sort().map(k => {\n        if (\"extra\" in index.shapeExprs[k])\n          index.shapeExprs[k].extra.sort();\n        return v.visitShapeDecl(index.shapeExprs[k]);\n      });\n    }\n    return ret;\n  },\n\n  BiDiClosure: function () {\n    return {\n      needs: {},\n      neededBy: {},\n      inCycle: [],\n      test: function () {\n        function expect (l, r) { const ls = JSON.stringify(l), rs = JSON.stringify(r); if (ls !== rs) throw Error(ls+\" !== \"+rs); }\n        // this.add(1, 2); expect(this.needs, { 1:[2]                     }); expect(this.neededBy, { 2:[1]                     });\n        // this.add(3, 4); expect(this.needs, { 1:[2], 3:[4]              }); expect(this.neededBy, { 2:[1], 4:[3]              });\n        // this.add(2, 3); expect(this.needs, { 1:[2,3,4], 2:[3,4], 3:[4] }); expect(this.neededBy, { 2:[1], 3:[2,1], 4:[3,2,1] });\n\n        this.add(2, 3); expect(this.needs, { 2:[3]                     }); expect(this.neededBy, { 3:[2]                     });\n        this.add(1, 2); expect(this.needs, { 1:[2,3], 2:[3]            }); expect(this.neededBy, { 3:[2,1], 2:[1]            });\n        this.add(1, 3); expect(this.needs, { 1:[2,3], 2:[3]            }); expect(this.neededBy, { 3:[2,1], 2:[1]            });\n        this.add(3, 4); expect(this.needs, { 1:[2,3,4], 2:[3,4], 3:[4] }); expect(this.neededBy, { 3:[2,1], 2:[1], 4:[3,2,1] });\n        this.add(6, 7); expect(this.needs, { 6:[7]                    , 1:[2,3,4], 2:[3,4], 3:[4] }); expect(this.neededBy, { 7:[6]                    , 3:[2,1], 2:[1], 4:[3,2,1] });\n        this.add(5, 6); expect(this.needs, { 5:[6,7], 6:[7]           , 1:[2,3,4], 2:[3,4], 3:[4] }); expect(this.neededBy, { 7:[6,5], 6:[5]           , 3:[2,1], 2:[1], 4:[3,2,1] });\n        this.add(5, 7); expect(this.needs, { 5:[6,7], 6:[7]           , 1:[2,3,4], 2:[3,4], 3:[4] }); expect(this.neededBy, { 7:[6,5], 6:[5]           , 3:[2,1], 2:[1], 4:[3,2,1] });\n        this.add(7, 8); expect(this.needs, { 5:[6,7,8], 6:[7,8], 7:[8], 1:[2,3,4], 2:[3,4], 3:[4] }); expect(this.neededBy, { 7:[6,5], 6:[5], 8:[7,6,5], 3:[2,1], 2:[1], 4:[3,2,1] });\n        this.add(4, 5);\n        expect(this.needs,    { 1:[2,3,4,5,6,7,8], 2:[3,4,5,6,7,8], 3:[4,5,6,7,8], 4:[5,6,7,8], 5:[6,7,8], 6:[7,8], 7:[8] });\n        expect(this.neededBy, { 2:[1], 3:[2,1], 4:[3,2,1], 5:[4,3,2,1], 6:[5,4,3,2,1], 7:[6,5,4,3,2,1], 8:[7,6,5,4,3,2,1] });\n      },\n      add: function (needer, needie, negated) {\n        const r = this;\n        if (!(needer in r.needs))\n          r.needs[needer] = [];\n        if (!(needie in r.neededBy))\n          r.neededBy[needie] = [];\n\n        // // [].concat.apply(r.needs[needer], [needie], r.needs[needie]). emitted only last element\n        r.needs[needer] = r.needs[needer].concat([needie], r.needs[needie]).\n          filter(function (el, ord, l) { return el !== undefined && l.indexOf(el) === ord; });\n        // // [].concat.apply(r.neededBy[needie], [needer], r.neededBy[needer]). emitted only last element\n        r.neededBy[needie] = r.neededBy[needie].concat([needer], r.neededBy[needer]).\n          filter(function (el, ord, l) { return el !== undefined && l.indexOf(el) === ord; });\n\n        if (needer in this.neededBy) this.neededBy[needer].forEach(function (e) {\n          r.needs[e] = r.needs[e].concat([needie], r.needs[needie]).\n            filter(function (el, ord, l) { return el !== undefined && l.indexOf(el) === ord; });\n        });\n\n        if (needie in this.needs) this.needs[needie].forEach(function (e) {\n          r.neededBy[e] = r.neededBy[e].concat([needer], r.neededBy[needer]).\n            filter(function (el, ord, l) { return el !== undefined && l.indexOf(el) === ord; })\n        });\n        // this.neededBy[needie].push(needer);\n\n        if (r.needs[needer].indexOf(needer) !== -1)\n          r.inCycle = r.inCycle.concat(r.needs[needer]);\n      },\n      trim: function () {\n        function _trim (a) {\n          // filter(function (el, ord, l) { return l.indexOf(el) === ord; })\n          for (let i = a.length-1; i > -1; --i)\n            if (a.indexOf(a[i]) < i)\n              a.splice(i, i+1);\n        }\n        for (k in this.needs)\n          _trim(this.needs[k]);\n        for (k in this.neededBy)\n          _trim(this.neededBy[k]);\n      },\n      foundIn: {},\n      addIn: function (tripleExpr, shapeExpr) {\n        this.foundIn[tripleExpr] = shapeExpr;\n      }\n    }\n  },\n  /** @@TODO tests\n   * options:\n   *   no: don't do anything; just report nestable shapes\n   *   transform: function to change shape labels\n   */\n  nestShapes: function (schema, options = {}) {\n    const _ShExUtil = this;\n    const index = schema._index || this.index(schema);\n    if (!('no' in options)) { options.no = false }\n\n    let shapeLabels = Object.keys(index.shapeExprs || [])\n    let shapeReferences = {}\n    shapeLabels.forEach(label => {\n      let shape = index.shapeExprs[label]\n      noteReference(label, null) // just note the shape so we have a complete list at the end\n      shape = _ShExUtil.skipDecl(shape)\n      if (shape.type === 'Shape') {\n        if ('extends' in shape) {\n          shape.extends.forEach(\n             // !!! assumes simple reference, not e.g. AND\n            parent => noteReference(parent, shape)\n          )\n        }\n        if ('expression' in shape) {\n          (_ShExUtil.simpleTripleConstraints(shape) || []).forEach(tc => {\n            let target = _ShExUtil.getValueType(tc.valueExpr, true)\n            noteReference(target, {type: 'tc', shapeLabel: label, tc: tc})\n          })\n        }\n      } else if (shape.type === 'NodeConstraint') {\n        // can't have any refs to other shapes\n      } else {\n        throw Error('nestShapes currently only supports Shapes and NodeConstraints')\n      }\n    })\n    let nestables = Object.keys(shapeReferences).filter(\n      label => shapeReferences[label].length === 1\n        && shapeReferences[label][0].type === 'tc' // no inheritance support yet\n        && label in index.shapeExprs\n        && _ShExUtil.skipDecl(index.shapeExprs[label]).type === 'Shape' // Don't nest e.g. valuesets for now. @@ needs an option\n        && !index.shapeExprs[label].abstract // shouldn't have a ref to an unEXTENDed ABSTRACT shape anyways.\n    ).filter(\n      nestable => !('noNestPattern' in options)\n        || !nestable.match(RegExp(options.noNestPattern))\n    ).reduce((acc, label) => {\n      acc[label] = {\n        referrer: shapeReferences[label][0].shapeLabel,\n        predicate: shapeReferences[label][0].tc.predicate\n      }\n      return acc\n    }, {})\n    if (!options.no) {\n      let oldToNew = {}\n\n      if (options.rename) {\n        if (!('transform' in options)) {\n          options.transform = (function () {\n            let map = shapeLabels.reduce((acc, k, idx) => {\n              acc[k] = '_:renamed' + idx\n              return acc\n            }, {})\n            return function (id, shapeExpr) {\n              return map[id]\n            }\n          })()\n        }\n        Object.keys(nestables).forEach(oldName => {\n          let shapeExpr = index.shapeExprs[oldName]\n          let newName = options.transform(oldName, shapeExpr)\n          oldToNew[oldName] = shapeExpr.id = newName\n          shapeLabels[shapeLabels.indexOf(oldName)] = newName\n          nestables[newName] = nestables[oldName]\n          nestables[newName].was = oldName\n          delete nestables[oldName]\n\n          // @@ maybe update index when done? \n          index.shapeExprs[newName] = index.shapeExprs[oldName]\n          delete index.shapeExprs[oldName]\n\n          if (shapeReferences[oldName].length !== 1) { throw Error('assertion: ' + oldName + ' doesn\\'t have one reference: [' + shapeReferences[oldName] + ']') }\n          let ref = shapeReferences[oldName][0]\n          if (ref.type === 'tc') {\n            if (typeof ref.tc.valueExpr === 'string') { // ShapeRef\n              ref.tc.valueExpr = newName\n            } else {\n              throw Error('assertion: rename not implemented for TripleConstraint expr: ' + ref.tc.valueExpr)\n              // _ShExUtil.setValueType(ref, newName)\n            }\n          } else if (ref.type === 'Shape') {\n            throw Error('assertion: rename not implemented for Shape: ' + ref)\n          } else {\n            throw Error('assertion: ' + ref.type + ' not TripleConstraint or Shape')\n          }\n        })\n\n        Object.keys(nestables).forEach(k => {\n          let n = nestables[k]\n          if (n.referrer in oldToNew) {\n            n.newReferrer = oldToNew[n.referrer]\n          }\n        })\n\n        // Restore old order for more concise diffs.\n        let shapesCopy = {}\n        shapeLabels.forEach(label => shapesCopy[label] = index.shapeExprs[label])\n        index.shapeExprs = shapesCopy\n      } else {\n        const doomed = []\n        const ids = schema.shapes.map(s => s.id)\n        Object.keys(nestables).forEach(oldName => {\n          const borged = index.shapeExprs[oldName]\n          // In principle, the ShExJ shouldn't have a Decl if the above criteria are met,\n          // but the ShExJ may be generated by something which emits Decls regardless.\n          shapeReferences[oldName][0].tc.valueExpr = _ShExUtil.skipDecl(borged)\n          const delme = ids.indexOf(oldName)\n          if (schema.shapes[delme].id !== oldName)\n            throw Error('assertion: found ' + schema.shapes[delme].id + ' instead of ' + oldName)\n          doomed.push(delme)\n          delete index.shapeExprs[oldName]\n        })\n        doomed.sort((l, r) => r - l).forEach(delme => {\n          const id = schema.shapes[delme].id\n          if (!nestables[id])\n            throw Error('deleting unexpected shape ' + id)\n          delete schema.shapes[delme].id\n          schema.shapes.splice(delme, 1)\n        })\n      }\n    }\n    // console.dir(nestables)\n    // console.dir(shapeReferences)\n    return nestables\n\n    function noteReference (id, reference) {\n      if (!(id in shapeReferences)) {\n        shapeReferences[id] = []\n      }\n      if (reference) {\n        shapeReferences[id].push(reference)\n      }\n    }\n  },\n\n  /** @@TODO tests\n   *\n   */\n  getPredicateUsage: function (schema, untyped = {}) {\n    const _ShExUtil = this;\n\n    // populate shapeHierarchy\n    let shapeHierarchy = Hierarchy.create()\n    Object.keys(schema.shapes).forEach(label => {\n      let shapeExpr = _ShExUtil.skipDecl(schema.shapes[label])\n      if (shapeExpr.type === 'Shape') {\n        (shapeExpr.extends || []).forEach(\n          superShape => shapeHierarchy.add(superShape.reference, label)\n        )\n      }\n    })\n    Object.keys(schema.shapes).forEach(label => {\n      if (!(label in shapeHierarchy.parents))\n        shapeHierarchy.parents[label] = []\n    })\n\n    let predicates = { } // IRI->{ uses: [shapeLabel], commonType: shapeExpr }\n    Object.keys(schema.shapes).forEach(shapeLabel => {\n      let shapeExpr = _ShExUtil.skipDecl(schema.shapes[shapeLabel])\n      if (shapeExpr.type === 'Shape') {\n        let tcs = _ShExUtil.simpleTripleConstraints(shapeExpr) || []\n        tcs.forEach(tc => {\n          let newType = _ShExUtil.getValueType(tc.valueExpr)\n          if (!(tc.predicate in predicates)) {\n            predicates[tc.predicate] = {\n              uses: [shapeLabel],\n              commonType: newType,\n              polymorphic: false\n            }\n            if (typeof newType === 'object') {\n              untyped[tc.predicate] = {\n                shapeLabel,\n                predicate: tc.predicate,\n                newType,\n                references: []\n              }\n            }\n          } else {\n            predicates[tc.predicate].uses.push(shapeLabel)\n            let curType = predicates[tc.predicate].commonType\n            if (typeof curType === 'object' || curType === null) {\n              // another use of a predicate with no commonType\n              // console.warn(`${shapeLabel} ${tc.predicate}:${newType} uses untypable predicate`)\n              untyped[tc.predicate].references.push({ shapeLabel, newType })\n            } else if (typeof newType === 'object') {\n              // first use of a predicate with no detectable commonType\n              predicates[tc.predicate].commonType = null\n              untyped[tc.predicate] = {\n                shapeLabel,\n                predicate: tc.predicate,\n                curType,\n                newType,\n                references: []\n              }\n            } else if (curType === newType) {\n              ; // same type again\n            } else if (shapeHierarchy.parents[curType] && shapeHierarchy.parents[curType].indexOf(newType) !== -1) {\n              predicates[tc.predicate].polymorphic = true; // already covered by current commonType\n            } else {\n              let idx = shapeHierarchy.parents[newType] ? shapeHierarchy.parents[newType].indexOf(curType) : -1\n              if (idx === -1) {\n                let intersection = shapeHierarchy.parents[curType]\n                    ? shapeHierarchy.parents[curType].filter(\n                      lab => -1 !== shapeHierarchy.parents[newType].indexOf(lab)\n                    )\n                    : []\n                if (intersection.length === 0) {\n                  untyped[tc.predicate] = {\n                    shapeLabel,\n                    predicate: tc.predicate,\n                    curType,\n                    newType,\n                    references: []\n                  }\n                  // console.warn(`${shapeLabel} ${tc.predicate} : ${newType} isn\\'t related to ${curType}`)\n                  predicates[tc.predicate].commonType = null\n                } else {\n                  predicates[tc.predicate].commonType = intersection[0]\n                  predicates[tc.predicate].polymorphic = true\n                }\n              } else {\n                predicates[tc.predicate].commonType = shapeHierarchy.parents[newType][idx]\n                predicates[tc.predicate].polymorphic = true\n              }\n            }\n          }\n        })\n      }\n    })\n    return predicates\n  },\n\n  /** @@TODO tests\n   *\n   */\n  simpleTripleConstraints: function (shape) {\n    if (!('expression' in shape)) {\n      return []\n    }\n    if (shape.expression.type === 'TripleConstraint') {\n      return [ shape.expression ]\n    }\n    if (shape.expression.type === 'EachOf' &&\n        !(shape.expression.expressions.find(\n          expr => expr.type !== 'TripleConstraint'\n        ))) {\n          return shape.expression.expressions\n        }\n    throw Error('can\\'t (yet) express ' + JSON.stringify(shape))\n  },\n\n  skipDecl: function (shapeExpr) {\n    return shapeExpr.type === 'ShapeDecl' ? shapeExpr.shapeExpr : shapeExpr\n  },\n\n  getValueType: function (valueExpr) {\n    if (typeof valueExpr === 'string') { return valueExpr }\n    if (valueExpr.reference) { return valueExpr.reference }\n    if (valueExpr.nodeKind === 'iri') { return OWL.Thing } // !! push this test to callers\n    if (valueExpr.datatype) { return valueExpr.datatype }\n    // if (valueExpr.extends && valueExpr.extends.length === 1) { return valueExpr.extends[0] }\n    return valueExpr // throw Error('no value type for ' + JSON.stringify(valueExpr))\n  },\n\n  /** getDependencies: find which shappes depend on other shapes by inheritance\n   * or inclusion.\n   * TODO: rewrite in terms of Visitor.\n   */\n  getDependencies: function (schema, ret) {\n    ret = ret || this.BiDiClosure();\n    (schema.shapes || []).forEach(function (shape) {\n      function _walkShapeExpression (shapeExpr, negated) {\n        if (typeof shapeExpr === \"string\") { // ShapeRef\n          ret.add(shape.id, shapeExpr);\n        } else if (shapeExpr.type === \"ShapeOr\" || shapeExpr.type === \"ShapeAnd\") {\n          shapeExpr.shapeExprs.forEach(function (expr) {\n            _walkShapeExpression(expr, negated);\n          });\n        } else if (shapeExpr.type === \"ShapeNot\") {\n          _walkShapeExpression(shapeExpr.shapeExpr, negated ^ 1); // !!! test negation\n        } else if (shapeExpr.type === \"Shape\") {\n          _walkShape(shapeExpr, negated);\n        } else if (shapeExpr.type === \"NodeConstraint\") {\n          // no impact on dependencies\n        } else if (shapeExpr.type === \"ShapeExternal\") {\n        } else\n          throw Error(\"expected Shape{And,Or,Ref,External} or NodeConstraint in \" + JSON.stringify(shapeExpr));\n      }\n      \n      function _walkShape (shape, negated) {\n        function _walkTripleExpression (tripleExpr, negated) {\n          function _exprGroup (exprs, negated) {\n            exprs.forEach(function (nested) {\n              _walkTripleExpression(nested, negated) // ?? negation allowed?\n            });\n          }\n\n          function _walkTripleConstraint (tc, negated) {\n            if (tc.valueExpr)\n              _walkShapeExpression(tc.valueExpr, negated);\n            if (negated && ret.inCycle.indexOf(shape.id) !== -1) // illDefined/negatedRefCycle.err\n              throw Error(\"Structural error: \" + shape.id + \" appears in negated cycle\");\n          }\n\n          if (typeof tripleExpr === \"string\") { // Inclusion\n            ret.add(shape.id, tripleExpr);\n          } else {\n            if (\"id\" in tripleExpr)\n              ret.addIn(tripleExpr.id, shape.id)\n            if (tripleExpr.type === \"TripleConstraint\") {\n              _walkTripleConstraint(tripleExpr, negated);\n            } else if (tripleExpr.type === \"OneOf\" || tripleExpr.type === \"EachOf\") {\n              _exprGroup(tripleExpr.expressions);\n            } else {\n              throw Error(\"expected {TripleConstraint,OneOf,EachOf,Inclusion} in \" + tripleExpr);\n            }\n          }\n        }\n\n        ([\"extends\", \"restricts\"]).forEach(attr => {\n        if (shape[attr] && shape[attr].length > 0)\n          shape[attr].forEach(function (i) {\n            ret.add(shape.id, i);\n          });\n        })\n        if (shape.expression)\n          _walkTripleExpression(shape.expression, negated);\n      }\n      if (shape.type === \"ShapeDecl\")\n        shape = shape.shapeExpr;\n      _walkShapeExpression(shape, 0); // 0 means false for bitwise XOR\n    });\n    return ret;\n  },\n\n  /** partition: create subset of a schema with only desired shapes and\n   * their dependencies.\n   *\n   * @schema: input schema\n   * @partition: shape name or array of desired shape names\n   * @deps: (optional) dependency tree from getDependencies.\n   *        map(shapeLabel -> [shapeLabel])\n   */\n  partition: function (schema, includes, deps, cantFind) {\n    const inputIndex = schema._index || this.index(schema)\n    const outputIndex = { shapeExprs: new Map(), tripleExprs: new Map() };\n    includes = includes instanceof Array ? includes : [includes];\n\n    // build dependency tree if not passed one\n    deps = deps || this.getDependencies(schema);\n    cantFind = cantFind || function (what, why) {\n      throw new Error(\"Error: can't find shape \" +\n                      (why ?\n                       why + \" dependency \" + what :\n                       what));\n    };\n    const partition = {};\n    for (let k in schema)\n      partition[k] = k === \"shapes\" ? [] : schema[k];\n    includes.forEach(function (i) {\n      if (i in outputIndex.shapeExprs) {\n        // already got it.\n      } else if (i in inputIndex.shapeExprs) {\n        const adding = inputIndex.shapeExprs[i];\n        partition.shapes.push(adding);\n        outputIndex.shapeExprs[adding.id] = adding;\n        if (i in deps.needs)\n          deps.needs[i].forEach(function (n) {\n            // Turn any needed TE into an SE.\n            if (n in deps.foundIn)\n              n = deps.foundIn[n];\n\n            if (n in outputIndex.shapeExprs) {\n            } else if (n in inputIndex.shapeExprs) {\n              const needed = inputIndex.shapeExprs[n];\n              partition.shapes.push(needed);\n              outputIndex.shapeExprs[needed.id] = needed;\n            } else\n              cantFind(n, i);\n          });\n      } else {\n        cantFind(i, \"supplied\");\n      }\n    });\n    return partition;\n  },\n\n\n  /** @@TODO flatten: return copy of input schema with all shape and value class\n   * references substituted by a copy of their referent.\n   *\n   * @schema: input schema\n   */\n  flatten: function (schema, deps, cantFind) {\n    const v = this.Visitor();\n    return v.visitSchema(schema);\n  },\n\n  // @@ put predicateUsage here\n\n  emptySchema: function () {\n    return {\n      type: \"Schema\"\n    };\n  },\n  merge: function (left, right, overwrite, inPlace) {\n    const ret = inPlace ? left : this.emptySchema();\n\n    function mergeArray (attr) {\n      Object.keys(left[attr] || {}).forEach(function (key) {\n        if (!(attr in ret))\n          ret[attr] = {};\n        ret[attr][key] = left[attr][key];\n      });\n      Object.keys(right[attr] || {}).forEach(function (key) {\n        if (!(attr  in left) || !(key in left[attr]) || overwrite) {\n          if (!(attr in ret))\n            ret[attr] = {};\n          ret[attr][key] = right[attr][key];\n        }\n      });\n    }\n\n    function mergeMap (attr) {\n      (left[attr] || new Map()).forEach(function (value, key, map) {\n        if (!(attr in ret))\n          ret[attr] = new Map();\n        ret[attr].set(key, left[attr].get(key));\n      });\n      (right[attr] || new Map()).forEach(function (value, key, map) {\n        if (!(attr  in left) || !(left[attr].has(key)) || overwrite) {\n          if (!(attr in ret))\n            ret[attr] = new Map();\n          ret[attr].set(key, right[attr].get(key));\n        }\n      });\n    }\n\n    // base\n    if (\"_base\" in left)\n      ret._base = left._base;\n    if (\"_base\" in right)\n      if (!(\"_base\" in left) || overwrite)\n        ret._base = right._base;\n\n    mergeArray(\"_prefixes\");\n\n    mergeMap(\"_sourceMap\");\n\n    if (\"imports\" in right)\n      if (!(\"imports\" in left) || overwrite)\n        ret.imports = right.imports;\n\n    // startActs\n    if (\"startActs\" in left)\n      ret.startActs = left.startActs;\n    if (\"startActs\" in right)\n      if (!(\"startActs\" in left) || overwrite)\n        ret.startActs = right.startActs;\n\n    // start\n    if (\"start\" in left)\n      ret.start = left.start;\n    if (\"start\" in right)\n      if (!(\"start\" in left) || overwrite)\n        ret.start = right.start;\n\n    let lindex = left._index || this.index(left);\n\n    // shapes\n    if (!inPlace)\n      (left.shapes || []).forEach(function (lshape) {\n        if (!(\"shapes\" in ret))\n          ret.shapes = [];\n        ret.shapes.push(lshape);\n      });\n    (right.shapes || []).forEach(function (rshape) {\n      if (!(\"shapes\"  in left) || !(rshape.id in lindex.shapeExprs) || overwrite) {\n        if (!(\"shapes\" in ret))\n          ret.shapes = [];\n        ret.shapes.push(rshape)\n      }\n    });\n\n    if (left._index || right._index)\n      ret._index = this.index(ret); // inefficient; could build above\n\n    return ret;\n  },\n\n  absolutizeResults: function (parsed, base) {\n    // !! duplicate of Validation-test.js:84: const referenceResult = parseJSONFile(resultsFile...)\n    function mapFunction (k, obj) {\n      // resolve relative URLs in results file\n      if ([\"shape\", \"reference\", \"node\", \"subject\", \"predicate\", \"object\"].indexOf(k) !== -1 &&\n          ShExTerm.isIRI(obj[k])) {\n        obj[k] = ShExTerm.resolveRelativeIRI(base, obj[k]);\n      }}\n\n    function resolveRelativeURLs (obj) {\n      Object.keys(obj).forEach(function (k) {\n        if (typeof obj[k] === \"object\") {\n          resolveRelativeURLs(obj[k]);\n        }\n        if (mapFunction) {\n          mapFunction(k, obj);\n        }\n      });\n    }\n    resolveRelativeURLs(parsed);\n    return parsed;\n  },\n\n  getProofGraph: function (res, db, dataFactory) {\n    function _dive1 (solns) {\n      if (solns.type === \"NodeConstraintTest\") {\n      } else if (solns.type === \"SolutionList\" ||\n                 solns.type === \"ShapeAndResults\" ||\n                 solns.type === \"ExtensionResults\") {\n        solns.solutions.forEach(s => {\n          if (s.solution) // no .solution for <S> {}\n            _dive1(s.solution);\n        });\n      } else if (solns.type === \"ShapeOrResults\") {\n        _dive1(solns.solution);\n      } else if (solns.type === \"ShapeTest\") {\n        if (\"solution\" in solns)\n          _dive1(solns.solution);\n      } else if (solns.type === \"OneOfSolutions\" ||\n                 solns.type === \"EachOfSolutions\") {\n        solns.solutions.forEach(s => {\n          _dive1(s);\n        });\n      } else if (solns.type === \"OneOfSolution\" ||\n                 solns.type === \"EachOfSolution\") {\n        solns.expressions.forEach(s => {\n          _dive1(s);\n        });\n      } else if (solns.type === \"TripleConstraintSolutions\") {\n        solns.solutions.map(s => {\n          if (s.type !== \"TestedTriple\")\n            throw Error(\"unexpected result type: \" + s.type);\n          const s2 = s;\n          if (typeof s2.object === \"object\")\n            s2.object = \"\\\"\" + s2.object.value.replace(/\"/g, \"\\\\\\\"\") + \"\\\"\"\n            + (s2.object.language ? (\"@\" + s2.object.language) : \n               s2.object.type ? (\"^^\" + s2.object.type) :\n               \"\");\n          db.addQuad(ShExTerm.externalTriple(s2, dataFactory))\n          if (\"referenced\" in s) {\n            _dive1(s.referenced);\n          }\n        });\n      } else if (solns.type === \"ExtendedResults\") {\n        _dive1(solns.extensions);\n        if (\"local\" in solns)\n          _dive1(solns.local);        \n      } else if (solns.type === \"Recursion\") {        \n      } else {\n        throw Error(\"unexpected expr type \"+solns.type+\" in \" + JSON.stringify(solns));\n      }\n    }\n    _dive1(res);\n    return db;\n  },\n\n  validateSchema: function (schema) { // obselete, but may need other validations in the future.\n    const _ShExUtil = this;\n    const visitor = this.Visitor();\n    let currentLabel = currentExtra = null;\n    let currentNegated = false;\n    const dependsOn = { };\n    let inTE = false;\n    const oldVisitShape = visitor.visitShape;\n    const negativeDeps = Hierarchy.create();\n    const positiveDeps = Hierarchy.create();\n    let index = schema.index || this.index(schema);\n\n    visitor.visitShape = function (shape, label) {\n      const lastExtra = currentExtra;\n      currentExtra = shape.extra;\n      const ret = oldVisitShape.call(visitor, shape, label);\n      currentExtra = lastExtra;\n      return ret;\n    }\n\n    const oldVisitShapeNot = visitor.visitShapeNot;\n    visitor.visitShapeNot = function (shapeNot, label) {\n      const lastNegated = currentNegated;\n      currentNegated ^= true;\n      const ret = oldVisitShapeNot.call(visitor, shapeNot, label);\n      currentNegated = lastNegated;\n      return ret;\n    }\n\n    const oldVisitTripleConstraint = visitor.visitTripleConstraint;\n    visitor.visitTripleConstraint = function (expr) {\n      const lastNegated = currentNegated;\n      if (currentExtra && currentExtra.indexOf(expr.predicate) !== -1)\n        currentNegated ^= true;\n      inTE = true;\n      const ret = oldVisitTripleConstraint.call(visitor, expr);\n      inTE = false;\n      currentNegated = lastNegated;\n      return ret;\n    };\n\n    const oldVisitShapeRef = visitor.visitShapeRef;\n    visitor.visitShapeRef = function (shapeRef) {\n      if (!(shapeRef in index.shapeExprs))\n        throw firstError(Error(\"Structural error: reference to \" + JSON.stringify(shapeRef) + \" not found in schema shape expressions:\\n\" + dumpKeys(index.shapeExprs) + \".\"), shapeRef);\n      if (!inTE && shapeRef === currentLabel)\n        throw firstError(Error(\"Structural error: circular reference to \" + currentLabel + \".\"), shapeRef);\n      (currentNegated ? negativeDeps : positiveDeps).add(currentLabel, shapeRef)\n      return oldVisitShapeRef.call(visitor, shapeRef);\n    }\n\n    const oldVisitInclusion = visitor.visitInclusion;\n    visitor.visitInclusion = function (inclusion) {\n      let refd;\n      if (!(refd = index.tripleExprs[inclusion]))\n        throw firstError(Error(\"Structural error: included shape \" + inclusion + \" not found in schema triple expressions:\\n\" + dumpKeys(index.tripleExprs) + \".\"), inclusion);\n      // if (refd.type !== \"Shape\")\n      //   throw Error(\"Structural error: \" + inclusion + \" is not a simple shape.\");\n      return oldVisitInclusion.call(visitor, inclusion);\n    };\n\n    (schema.shapes || []).forEach(function (shape) {\n      currentLabel = shape.id;\n      visitor.visitShapeDecl(shape, shape.id);\n    });\n    let circs = Object.keys(negativeDeps.children).filter(\n      k => negativeDeps.children[k].filter(\n        k2 => k2 in negativeDeps.children && negativeDeps.children[k2].indexOf(k) !== -1\n          || k2 in positiveDeps.children && positiveDeps.children[k2].indexOf(k) !== -1\n      ).length > 0\n    );\n    if (circs.length)\n      throw firstError(Error(\"Structural error: circular negative dependencies on \" + circs.join(',') + \".\"), circs[0]);\n\n    function dumpKeys (obj) {\n      return obj ? Object.keys(obj).map(\n        u => u.substr(0, 2) === '_:' ? u : '<' + u + '>'\n      ).join(\"\\n        \") : '- none defined -'\n    }\n\n    function firstError (e, obj) {\n      if (\"_sourceMap\" in schema)\n        e.location = (schema._sourceMap.get(obj) || [undefined])[0];\n      return e;\n    }\n  },\n\n  /** isWellDefined: assert that schema is well-defined.\n   *\n   * @schema: input schema\n   * @@TODO\n   */\n  isWellDefined: function (schema) {\n    this.validateSchema(schema);\n    // const deps = this.getDependencies(schema);\n    return schema;\n  },\n\n  walkVal: function (val, cb) {\n    const _ShExUtil = this;\n    if (typeof val === \"string\") { // ShapeRef\n      return null; // 1NOTRefOR1dot_pass-inOR\n    } else if (val.type === \"SolutionList\") { // dependent_shape\n      return val.solutions.reduce((ret, exp) => {\n        const n = _ShExUtil.walkVal(exp, cb);\n        if (n)\n          Object.keys(n).forEach(k => {\n            if (k in ret)\n              ret[k] = ret[k].concat(n[k]);\n            else\n              ret[k] = n[k];\n          })\n        return ret;\n      }, {});\n    } else if (val.type === \"NodeConstraintTest\") { // 1iri_pass-iri\n      return _ShExUtil.walkVal(val.shapeExpr, cb);\n    } else if (val.type === \"NodeConstraint\") { // 1iri_pass-iri\n      return null;\n    } else if (val.type === \"ShapeTest\") { // 0_empty\n      const vals = [];\n      visitSolution(val, vals); // A ShapeTest is a sort of Solution.\n      const ret = vals.length\n            ? {'http://shex.io/reflex': vals}\n            : {};\n      if (\"solution\" in val)\n        Object.assign(ret, _ShExUtil.walkVal(val.solution, cb))\n      return Object.keys(ret).length ? ret : null;\n    } else if (val.type === \"Shape\") { // 1NOTNOTdot_passIv1\n      return null;\n    } else if (val.type === \"ShapeNotTest\") { // 1NOT_vsANDvs__passIv1\n      return _ShExUtil.walkVal(val.shapeExpr, cb);\n    } else if (val.type === \"ShapeNotResults\") { // NOT1dotOR2dot_pass-empty\n      return _ShExUtil.walkVal(val.solution, cb);\n    } else if (val.type === \"Failure\") { // NOT1dotOR2dot_pass-empty\n      return null; // !!TODO\n    } else if (val.type === \"ShapeNot\") { // 1NOTNOTIRI_passIo1,\n      return _ShExUtil.walkVal(val.shapeExpr, cb);\n    } else if (val.type === \"ShapeOrResults\") { // 1dotRefOR3_passShape1\n      return _ShExUtil.walkVal(val.solution, cb);\n    } else if (val.type === \"ShapeOr\") { // 1NOT_literalORvs__passIo1\n      return val.shapeExprs.reduce((ret, exp) => {\n        const n = _ShExUtil.walkVal(exp, cb);\n        if (n)\n          Object.keys(n).forEach(k => {\n            if (k in ret)\n              ret[k] = ret[k].concat(n[k]);\n            else\n              ret[k] = n[k];\n          })\n        return ret;\n      }, {});\n    } else if (val.type === \"ShapeAndResults\" || // 1iriRef1_pass-iri\n               val.type === \"ExtensionResults\") { // extends-abstract-multi-empty_pass-missingOptRef1\n      return val.solutions.reduce((ret, exp) => {\n        const n = _ShExUtil.walkVal(exp, cb);\n        if (n)\n          Object.keys(n).forEach(k => {\n            if (k in ret)\n              ret[k] = ret[k].concat(n[k]);\n            else\n              ret[k] = n[k];\n          })\n        return ret;\n      }, {});\n    } else if (val.type === \"ShapeAnd\") { // 1NOT_literalANDvs__passIv1\n      return val.shapeExprs.reduce((ret, exp) => {\n        const n = _ShExUtil.walkVal(exp, cb);\n        if (n)\n          Object.keys(n).forEach(k => {\n            if (k in ret)\n              ret[k] = ret[k].concat(n[k]);\n            else\n              ret[k] = n[k];\n          })\n        return ret;\n      }, {});\n    } else if (val.type === \"ExtendedResults\") { // extends-abstract-multi-empty_pass-missingOptRef1\n      return ([\"extensions\", \"local\"]).reduce((ret, exp) => {\n        const n = _ShExUtil.walkVal(exp, cb);\n        if (n)\n          Object.keys(n).forEach(k => {\n            if (k in ret)\n              ret[k] = ret[k].concat(n[k]);\n            else\n              ret[k] = n[k];\n          })\n        return ret;\n      }, {});\n    } else if (val.type === \"EachOfSolutions\" || val.type === \"OneOfSolutions\") {\n      // 1dotOne2dot_pass_p1\n      return val.solutions.reduce((ret, sln) => {\n        sln.expressions.forEach(exp => {\n          const n = _ShExUtil.walkVal(exp, cb);\n          if (n)\n            Object.keys(n).forEach(k => {\n              if (k in ret)\n                ret[k] = ret[k].concat(n[k]);\n              else\n                ret[k] = n[k];\n            })\n        });\n        return ret;\n      }, {});\n    } else if (val.type === \"TripleConstraintSolutions\") { // 1dot_pass-noOthers\n      if (\"solutions\" in val) {\n        const ret = {};\n        const vals = [];\n        ret[val.predicate] = vals;\n        val.solutions.forEach(sln => visitSolution(sln, vals));\n        return vals.length ? ret : null;\n      } else {\n        return null;\n      }\n    } else if (val.type === \"Recursion\") { // 3circRefPlus1_pass-recursiveData\n      return null;\n    } else {\n      // console.log(val);\n      throw Error(\"unknown shapeExpression type in \" + JSON.stringify(val));\n    }\n    return val;\n\n        function visitSolution (sln, vals) {\n          const toAdd = [];\n          if (chaseList(sln.referenced, toAdd)) { // parse 1val1IRIREF.ttl\n            [].push.apply(vals, toAdd);\n          } else { // 1dot_pass-noOthers\n            const newElt = cb(sln) || {};\n            if (\"referenced\" in sln) {\n              const t = _ShExUtil.walkVal(sln.referenced, cb);\n              if (t)\n                newElt.nested = t;\n            }\n            if (Object.keys(newElt).length > 0)\n              vals.push(newElt);\n          }\n          function chaseList (li) {\n            if (!li) return false;\n            if (li.node === RDF.nil) return true;\n            if (\"solution\" in li && \"solutions\" in li.solution &&\n                li.solution.solutions.length === 1 &&\n                \"expressions\" in li.solution.solutions[0] &&\n                li.solution.solutions[0].expressions.length === 2 &&\n                \"predicate\" in li.solution.solutions[0].expressions[0] &&\n                li.solution.solutions[0].expressions[0].predicate === RDF.first &&\n                li.solution.solutions[0].expressions[1].predicate === RDF.rest) {\n              const expressions = li.solution.solutions[0].expressions;\n              const ent = expressions[0];\n              const rest = expressions[1].solutions[0];\n              const member = ent.solutions[0];\n              let newElt = cb(member);\n              if (\"referenced\" in member) {\n                const t = _ShExUtil.walkVal(member.referenced, cb);\n                if (t) {\n                  if (newElt)\n                    newElt.nested = t;\n                  else\n                    newElt = t;\n                }\n              }\n              if (newElt)\n                vals.push(newElt);\n              return rest.object === RDF.nil ?\n                true :\n                chaseList(rest.referenced.type === \"ShapeOrResults\" // heuristic for `nil OR @<list>` idiom\n                          ? rest.referenced.solution\n                          : rest.referenced);\n            }\n          }\n        }\n  },\n\n  /**\n   * Convert val results to a property tree.\n   * @exports\n   * @returns {@code {p1:[{p2: v2},{p3: v3}]}}\n   */\n  valToValues: function (val) {\n    return this.walkVal (val, function (sln) {\n      return \"object\" in sln ? { ldterm: sln.object } : null;\n    });\n  },\n\n  valToExtension: function (val, lookfor) {\n    const map = this.walkVal (val, function (sln) {\n      return \"extensions\" in sln ? { extensions: sln.extensions } : null;\n    });\n    function extensions (obj) {\n      const list = [];\n      let crushed = {};\n      function crush (elt) {\n        if (crushed === null)\n          return elt;\n        if (Array.isArray(elt)) {\n          crushed = null;\n          return elt;\n        }\n        for (k in elt) {\n          if (k in crushed) {\n            crushed = null\n            return elt;\n          }\n          crushed[k] = ldify(elt[k]);\n        }\n        return elt;\n      }\n      for (let k in obj) {\n        if (k === \"extensions\") {\n          if (obj[k])\n            list.push(crush(ldify(obj[k][lookfor])));\n        } else if (k === \"nested\") {\n          const nested = extensions(obj[k]);\n          if (Array.isArray(nested))\n            nested.forEach(crush);\n          else\n            crush(nested);\n          list.push(nested);\n        } else {\n          list.push(crush(extensions(obj[k])));\n        }\n      }\n      return list.length === 1 ? list[0] :\n        crushed ? crushed :\n        list;\n    }\n    return extensions(map);\n  },\n\n  valuesToSchema: function (values) {\n    // console.log(JSON.stringify(values, null, \"  \"));\n    const v = values;\n    const t = values[RDF.type][0].ldterm;\n    if (t === SX.Schema) {\n      /* Schema { \"@context\":\"http://www.w3.org/ns/shex.jsonld\"\n       *           startActs:[SemAct+]? start:(shapeExpr|labeledShapeExpr)?\n       *           shapes:[labeledShapeExpr+]? }\n       */\n      const ret = {\n        \"@context\": \"http://www.w3.org/ns/shex.jsonld\",\n        type: \"Schema\"\n      }\n      if (SX.startActs in v)\n        ret.startActs = v[SX.startActs].map(e => {\n          const ret = {\n            type: \"SemAct\",\n            name: e.nested[SX.name][0].ldterm\n          };\n          if (SX.code in e.nested)\n            ret.code = e.nested[SX.code][0].ldterm.value;\n          return ret;\n        });\n      if (SX.imports in v)\n        ret.imports = v[SX.imports].map(e => {\n          return e.ldterm;\n        });\n      if (values[SX.start])\n        ret.start = extend({id: values[SX.start][0].ldterm}, shapeExpr(values[SX.start][0].nested));\n      const shapes = values[SX.shapes];\n      if (shapes) {\n        ret.shapes = shapes.map(v => { // @@ console.log(v.nested);\n          var t = v.nested[RDF.type][0].ldterm;\n          var obj = t === SX.ShapeDecl ?\n              {\n                type: SX.ShapeDecl,\n                abstract: !!v.nested[SX[\"abstract\"]][0].ldterm.value,\n                shapeExpr: shapeExpr(v.nested[SX.shapeExpr][0].nested)\n              } :\n              shapeExpr(v.nested);\n          return extend({id: v.ldterm}, obj);\n        });\n      }\n      // console.log(ret);\n      return ret;\n    } else {\n      throw Error(\"unknown schema type in \" + JSON.stringify(values));\n    }\n    function findType (v, elts, f) {\n      const t = v[RDF.type][0].ldterm.substr(SX._namespace.length);\n      const elt = elts[t];\n      if (!elt)\n        return Missed;\n      if (elt.nary) {\n        const ret = {\n          type: t,\n        };\n        ret[elt.prop] = v[SX[elt.prop]].map(e => {\n          return valueOf(e);\n        });\n        return ret;\n      } else {\n        const ret = {\n          type: t\n        };\n        if (elt.prop) {\n          ret[elt.prop] = valueOf(v[SX[elt.prop]][0]);\n        }\n        return ret;\n      }\n\n      function valueOf (x) {\n        return elt.expr && \"nested\" in x ? extend({ id: x.ldterm, }, f(x.nested)) : x.ldterm;\n      }\n    }\n    function shapeExpr (v) {\n      // shapeExpr = ShapeOr | ShapeAnd | ShapeNot | NodeConstraint | Shape | ShapeRef | ShapeExternal;\n      const elts = { \"ShapeAnd\"     : { nary: true , expr: true , prop: \"shapeExprs\" },\n                   \"ShapeOr\"      : { nary: true , expr: true , prop: \"shapeExprs\" },\n                   \"ShapeNot\"     : { nary: false, expr: true , prop: \"shapeExpr\"  },\n                   \"ShapeRef\"     : { nary: false, expr: false, prop: \"reference\"  },\n                   \"ShapeExternal\": { nary: false, expr: false, prop: null         } };\n      const ret = findType(v, elts, shapeExpr);\n      if (ret !== Missed)\n        return ret;\n\n      const t = v[RDF.type][0].ldterm;\n      if (t === SX.ShapeDecl) {\n        const ret = { type: \"ShapeDecl\" };\n        [\"abstract\"].forEach(a => {\n          if (SX[a] in v)\n            ret[a] = !!v[SX[a]][0].ldterm.value;\n        });\n        if (SX.shapeExpr in v) {\n          ret.shapeExpr =\n            \"nested\" in v[SX.shapeExpr][0] ?\n            extend({id: v[SX.shapeExpr][0].ldterm}, shapeExpr(v[SX.shapeExpr][0].nested)) :\n            v[SX.shapeExpr][0].ldterm;\n        }\n        return ret;\n      } else if (t === SX.Shape) {\n        const ret = { type: \"Shape\" };\n        [\"closed\"].forEach(a => {\n          if (SX[a] in v)\n            ret[a] = !!v[SX[a]][0].ldterm.value;\n        });\n        [\"extra\", \"extends\", \"restricts\"].forEach(a => {\n          if (SX[a] in v)\n            ret[a] = v[SX[a]].map(e => { return e.ldterm; });\n        });\n        if (SX.expression in v) {\n          ret.expression =\n            \"nested\" in v[SX.expression][0] ?\n            extend({id: v[SX.expression][0].ldterm}, tripleExpr(v[SX.expression][0].nested)) :\n            v[SX.expression][0].ldterm;\n        }\n        if (SX.annotation in v)\n          ret.annotations = v[SX.annotation].map(e => {\n            return {\n              type: \"Annotation\",\n              predicate: e.nested[SX.predicate][0].ldterm,\n              object: e.nested[SX.object][0].ldterm\n            };\n          });\n        if (SX.semActs in v)\n          ret.semActs = v[SX.semActs].map(e => {\n            const ret = {\n              type: \"SemAct\",\n              name: e.nested[SX.name][0].ldterm\n            };\n            if (SX.code in e.nested)\n              ret.code = e.nested[SX.code][0].ldterm.value;\n            return ret;\n          });\n        return ret;\n      } else if (t === SX.NodeConstraint) {\n        const ret = { type: \"NodeConstraint\" };\n        if (SX.values in v)\n          ret.values = v[SX.values].map(v1 => { return objectValue(v1); });\n        if (SX.nodeKind in v)\n          ret.nodeKind = v[SX.nodeKind][0].ldterm.substr(SX._namespace.length);\n        [\"length\", \"minlength\", \"maxlength\", \"mininclusive\", \"maxinclusive\", \"minexclusive\", \"maxexclusive\", \"totaldigits\", \"fractiondigits\"].forEach(a => {\n          if (SX[a] in v)\n            ret[a] = parseFloat(v[SX[a]][0].ldterm.value);\n        });\n        if (SX.pattern in v)\n          ret.pattern = v[SX.pattern][0].ldterm.value;\n        if (SX.flags in v)\n          ret.flags = v[SX.flags][0].ldterm.value;\n        if (SX.datatype in v)\n          ret.datatype = v[SX.datatype][0].ldterm;\n        return ret;\n      } else {\n        throw Error(\"unknown shapeExpr type in \" + JSON.stringify(v));\n      }\n\n    }\n\n    function objectValue (v, expectString) {\n      if (\"nested\" in v) {\n        const t = v.nested[RDF.type][0].ldterm;\n        if ([SX.IriStem, SX.LiteralStem, SX.LanguageStem].indexOf(t) !== -1) {\n          const ldterm = v.nested[SX.stem][0].ldterm.value;\n          return {\n            type: t.substr(SX._namespace.length),\n            stem: ldterm\n          };\n        } else if ([SX.Language].indexOf(t) !== -1) {\n          return {\n            type: \"Language\",\n            languageTag: v.nested[SX.languageTag][0].ldterm.value\n          };\n        } else if ([SX.IriStemRange, SX.LiteralStemRange, SX.LanguageStemRange].indexOf(t) !== -1) {\n          const st = v.nested[SX.stem][0];\n          let stem = st;\n          if (typeof st === \"object\") {\n            if (typeof st.ldterm === \"object\") {\n              stem = st.ldterm;\n            } else if (st.ldterm.startsWith(\"_:\")) {\n              stem = { type: \"Wildcard\" };\n            }\n          }\n          const ret = {\n            type: t.substr(SX._namespace.length),\n            stem: stem.type !== \"Wildcard\" ? stem.value : stem\n          };\n          if (SX.exclusion in v.nested) {\n            // IriStemRange:\n            // * [{\"ldterm\":\"http://a.example/v1\"},{\"ldterm\":\"http://a.example/v3\"}] <-- no value\n            // * [{\"ldterm\":\"_:b836\",\"nested\":{a:[{\"ldterm\":sx:IriStem}],\n            //                                 sx:stem:[{\"ldterm\":{\"value\":\"http://a.example/v1\"}}]}},\n            //    {\"ldterm\":\"_:b838\",\"nested\":{a:[{\"ldterm\":sx:IriStem}],\n            //                                 sx:stem:[{\"ldterm\":{\"value\":\"http://a.example/v3\"}}]}}]\n\n            // LiteralStemRange:\n            // * [{\"ldterm\":{\"value\":\"v1\"}},{\"ldterm\":{\"value\":\"v3\"}}]\n            // * [{\"ldterm\":\"_:b866\",\"nested\":{a:[{\"ldterm\":sx:LiteralStem}],\n            //                                 sx:stem:[{\"ldterm\":{\"value\":\"v1\"}}]}},\n            //    {\"ldterm\":\"_:b868\",\"nested\":{a:[{\"ldterm\":sx:LiteralStem}],\n            //                                 sx:stem:[{\"ldterm\":{\"value\":\"v3\"}}]}}]\n\n            // LanguageStemRange:\n            // * [{\"ldterm\":{\"value\":\"fr-be\"}},{\"ldterm\":{\"value\":\"fr-ch\"}}]\n            // * [{\"ldterm\":\"_:b851\",\"nested\":{a:[{\"ldterm\":sx:LanguageStem}],\n            //                                 sx:stem:[{\"ldterm\":{\"value\":\"fr-be\"}}]}},\n            //    {\"ldterm\":\"_:b853\",\"nested\":{a:[{\"ldterm\":sx:LanguageStem}],\n            //                                 sx:stem:[{\"ldterm\":{\"value\":\"fr-ch\"}}]}}]\n            ret.exclusions = v.nested[SX.exclusion].map(v1 => {\n              return objectValue(v1, t !== SX.IriStemRange);\n            });\n          }\n          return ret;\n        } else {\n          throw Error(\"unknown objectValue type in \" + JSON.stringify(v));\n        }\n      } else {\n        return expectString ? v.ldterm.value : v.ldterm;\n      }\n    }\n\n    function tripleExpr (v) {\n      // tripleExpr = EachOf | OneOf | TripleConstraint | Inclusion ;\n      const elts = { \"EachOf\"   : { nary: true , expr: true , prop: \"expressions\" },\n                   \"OneOf\"    : { nary: true , expr: true , prop: \"expressions\" },\n                   \"Inclusion\": { nary: false, expr: false, prop: \"include\"     } };\n      const ret = findType(v, elts, tripleExpr);\n      if (ret !== Missed) {\n        minMaxAnnotSemActs(v, ret);\n        return ret;\n      }\n\n      const t = v[RDF.type][0].ldterm;\n      if (t === SX.TripleConstraint) {\n        const ret = {\n          type: \"TripleConstraint\",\n          predicate: v[SX.predicate][0].ldterm\n        };\n        [\"inverse\"].forEach(a => {\n          if (SX[a] in v)\n            ret[a] = !!v[SX[a]][0].ldterm.value;\n        });\n        if (SX.valueExpr in v)\n          ret.valueExpr = extend({id: v[SX.valueExpr][0].ldterm}, \"nested\" in v[SX.valueExpr][0] ? shapeExpr(v[SX.valueExpr][0].nested) : {});\n        minMaxAnnotSemActs(v, ret);\n        return ret;\n      } else {\n        throw Error(\"unknown tripleExpr type in \" + JSON.stringify(v));\n      }\n    }\n    function minMaxAnnotSemActs (v, ret) {\n      if (SX.min in v)\n        ret.min = parseInt(v[SX.min][0].ldterm.value);\n      if (SX.max in v) {\n        ret.max = parseInt(v[SX.max][0].ldterm.value);\n        if (isNaN(ret.max))\n          ret.max = UNBOUNDED;\n      }\n      if (SX.annotation in v)\n        ret.annotations = v[SX.annotation].map(e => {\n          return {\n            type: \"Annotation\",\n            predicate: e.nested[SX.predicate][0].ldterm,\n            object: e.nested[SX.object][0].ldterm\n          };\n        });\n      if (SX.semActs in v)\n        ret.semActs = v[SX.semActs].map(e => {\n          const ret = {\n            type: \"SemAct\",\n            name: e.nested[SX.name][0].ldterm\n          };\n          if (SX.code in e.nested)\n            ret.code = e.nested[SX.code][0].ldterm.value;\n          return ret;\n        });\n      return ret;\n    }\n  },\n/* -- deprecated\n  valToSimple: function (val) {\n    const _ShExUtil = this;\n    function _join (list) {\n      return list.reduce((ret, elt) => {\n        Object.keys(elt).forEach(k => {\n          if (k in ret) {\n            ret[k] = Array.from(new Set(ret[k].concat(elt[k])));\n          } else {\n            ret[k] = elt[k];\n          }\n        });\n        return ret;\n      }, {});\n    }\n    if (typeof val === \"string\") {\n      return val\n    } else if (val.type === \"TripleConstraintSolutions\") {\n      if (\"solutions\" in val) {\n        return val.solutions.reduce((ret, sln) => {\n          if (!(\"referenced\" in sln))\n            return {};\n          const toAdd = {};\n          if (chaseList(sln.referenced, toAdd)) {\n            return _join(ret, toAdd);\n          } else {\n            return _join(ret, _ShExUtil.valToSimple(sln.referenced));\n          }\n          function chaseList (li) {\n            if (!li) return false;\n            if (li.node === RDF.nil) return true;\n            if (\"solution\" in li && \"solutions\" in li.solution &&\n                li.solution.solutions.length === 1 &&\n                \"expressions\" in li.solution.solutions[0] &&\n                li.solution.solutions[0].expressions.length === 2 &&\n                \"predicate\" in li.solution.solutions[0].expressions[0] &&\n                li.solution.solutions[0].expressions[0].predicate === RDF.first &&\n                li.solution.solutions[0].expressions[1].predicate === RDF.rest) {\n              const expressions = li.solution.solutions[0].expressions;\n              const ent = expressions[0];\n              const rest = expressions[1].solutions[0];\n              const member = ent.solutions[0];\n              const newElt = { ldterm: member.object };\n              if (\"referenced\" in member) {\n                const t = _ShExUtil.valToSimple(member.referenced);\n                if (t)\n                  newElt.nested = t;\n              }\n              toAdd = _join(toAdd, newElt);\n              return rest.object === RDF.nil ?\n                true :\n                chaseList(rest.referenced.type === \"ShapeOrResults\" // heuristic for `nil  OR @<list>` idiom\n                          ? rest.referenced.solution\n                          : rest.referenced);\n            }\n          }\n        }, []);\n      } else {\n        return [];\n      }\n    } else if ([\"TripleConstraintSolutions\"].indexOf(val.type) !== -1) {\n      return {  };\n    } else if (val.type === \"NodeConstraintTest\") {\n      return _ShExUtil.valToSimple(val.shapeExpr);\n    } else if (val.type === \"NodeConstraint\") {\n      const thisNode = {  };\n      thisNode[n3ify(val.focus)] = [val.shape];\n      return thisNode;\n    } else if (val.type === \"ShapeTest\") {\n      const thisNode = {  };\n      thisNode[n3ify(val.node)] = [val.shape];\n      return \"solution\" in val ? _join([thisNode].concat(_ShExUtil.valToSimple(val.solution))) : thisNode;\n    } else if (val.type === \"Shape\") {\n      const thisNode = {  };\n      thisNode[n3ify(val.node)] = [val.shape];\n      return thisNode;\n    } else if (val.type === \"ShapeNotTest\") {\n      const thisNode = {  };\n      thisNode[n3ify(val.node)] = [val.shape];\n      return _join(['NOT1'].concat(_ShExUtil.valToSimple(val.shapeExpr)));\n    } else if (val.type === \"ShapeNot\") {\n      const thisNode = {  };\n      thisNode[n3ify(val.node)] = [val.shape];\n      return _join(['NOT'].concat(_ShExUtil.valToSimple(val.shapeExpr)));\n    } else if (val.type === \"ShapeAnd\") {\n      return val.shapeExprs.map(shapeExpr => _ShExUtil.valToSimple(shapeExpr)).join ('AND');\n    } else if (val.type === \"ShapeOr\") {\n      return val.shapeExprs.map(shapeExpr => _ShExUtil.valToSimple(shapeExpr)).join ('OR');\n    } else if (val.type === \"Failure\") {\n      return _ShExUtil.errsToSimple(val);\n    } else if (val.type === \"Recursion\") {\n      return {  };\n    } else if (\"solutions\" in val) {\n      // [\"SolutionList\", \"EachOfSolutions\", \"OneOfSolutions\", \"ShapeAndResults\", \"ShapeOrResults\"].indexOf(val.type) !== -1\n      return _join(val.solutions.map(sln => {\n        return _ShExUtil.valToSimple(sln);\n      }));\n    } else if (\"solution\" in val) {\n      // [\"SolutionList\", \"EachOfSolutions\", \"OneOfSolutions\", \"ShapeAndResults\", \"ShapeOrResults\"].indexOf(val.type) !== -1\n      return _ShExUtil.valToSimple(val.solution);\n    } else if (\"expressions\" in val) {\n      return _join(val.expressions.map(sln => {\n        return _ShExUtil.valToSimple(sln);\n      }));\n    } else {\n      // console.log(val);\n      throw Error(\"unknown shapeExpression type in \" + JSON.stringify(val));\n    }\n    return val;\n  },\n*/\n  simpleToShapeMap: function (x) {\n    return Object.keys(x).reduce((ret, k) => {\n      x[k].forEach(s => {\n        ret.push({node: k, shape: s });\n      });\n      return ret;\n    }, []);\n  },\n\n  absolutizeShapeMap: function (parsed, base) {\n    return parsed.map(elt => {\n      return Object.assign(elt, {\n        node: ShExTerm.resolveRelativeIRI(base, elt.node),\n        shape: ShExTerm.resolveRelativeIRI(base, elt.shape)\n      });\n    });\n  },\n\n  errsToSimple: function (val) {\n    const _ShExUtil = this;\n    if (val.type === \"FailureList\") {\n      return val.errors.reduce((ret, e) => {\n        return ret.concat(_ShExUtil.errsToSimple(e));\n      }, []);\n    } else if (val.type === \"Failure\") {\n      return [\"validating \" + val.node + \" as \" + val.shape + \":\"].concat(errorList(val.errors).reduce((ret, e) => {\n        const nested = _ShExUtil.errsToSimple(e).map(s => \"  \" + s);\n        return ret.length > 0 ? ret.concat([\"  OR\"]).concat(nested) : nested.map(s => \"  \" + s);\n      }, []));\n    } else if (val.type === \"TypeMismatch\") {\n      const nested = Array.isArray(val.errors) ?\n          val.errors.reduce((ret, e) => {\n            return ret.concat((typeof e === \"string\" ? [e] : _ShExUtil.errsToSimple(e)).map(s => \"  \" + s));\n          }, []) :\n          \"  \" + (typeof e === \"string\" ? [val.errors] : _ShExUtil.errsToSimple(val.errors));\n      return [\"validating \" + n3ify(val.triple.object) + \":\"].concat(nested);\n    } else if (val.type === \"RestrictionError\") {\n      var nested = val.errors.constructor === Array ?\n          val.errors.reduce((ret, e) => {\n            return ret.concat((typeof e === \"string\" ? [e] : _ShExUtil.errsToSimple(e)).map(s => \"  \" + s));\n          }, []) :\n          \"  \" + (typeof e === \"string\" ? [val.errors] : _ShExUtil.errsToSimple(val.errors));\n      return [\"validating restrictions on \" + n3ify(val.focus) + \":\"].concat(nested);\n    } else if (val.type === \"ShapeAndFailure\") {\n      return Array.isArray(val.errors) ?\n          val.errors.reduce((ret, e) => {\n            return ret.concat((typeof e === \"string\" ? [e] : _ShExUtil.errsToSimple(e)).map(s => \"  \" + s));\n          }, []) :\n          \"  \" + (typeof e === \"string\" ? [val.errors] : _ShExUtil.errsToSimple(val.errors));\n    } else if (val.type === \"ShapeOrFailure\") {\n      return Array.isArray(val.errors) ?\n          val.errors.reduce((ret, e) => {\n            return ret.concat(\" OR \" + (typeof e === \"string\" ? [e] : _ShExUtil.errsToSimple(e)));\n          }, []) :\n          \" OR \" + (typeof e === \"string\" ? [val.errors] : _ShExUtil.errsToSimple(val.errors));\n    } else if (val.type === \"ShapeNotFailure\") {\n      return [\"Node \" + val.errors.node + \" expected to NOT pass \" + val.errors.shape];\n    } else if (val.type === \"ExcessTripleViolation\") {\n      return [\"validating \" + n3ify(val.triple.object) + \": exceeds cardinality\"];\n    } else if (val.type === \"ClosedShapeViolation\") {\n      return [\"Unexpected triple(s): {\"].concat(\n        val.unexpectedTriples.map(t => {\n          return \"  \" + t.subject + \" \" + t.predicate + \" \" + n3ify(t.object) + \" .\"\n        })\n      ).concat([\"}\"]);\n    } else if (val.type === \"NodeConstraintViolation\") {\n      const w = __webpack_require__(/*! @shexjs/writer */ \"./node_modules/@shexjs/writer/shex-writer.js\")();\n      w._write(w._writeNodeConstraint(val.shapeExpr).join(\"\"));\n      let txt;\n      w.end((err, res) => {\n        txt = res;\n      });\n      return [\"NodeConstraintError: expected to match \" + txt];\n    } else if (val.type === \"MissingProperty\") {\n      return [\"Missing property: \" + val.property];\n    } else if (val.type === \"NegatedProperty\") {\n      return [\"Unexpected property: \" + val.property];\n    } else if (val.type === \"AbstractShapeFailure\") {\n      return [\"Abstract Shape: \" + val.shape];\n    } else if (Array.isArray(val)) {\n      return val.reduce((ret, e) => {\n        const nested = _ShExUtil.errsToSimple(e).map(s => \"  \" + s);\n        return ret.length ? ret.concat([\"AND\"]).concat(nested) : nested;\n      }, []);\n    } else if (val.type === \"SemActFailure\") {\n      const nested = Array.isArray(val.errors) ?\n          val.errors.reduce((ret, e) => {\n            return ret.concat((typeof e === \"string\" ? [e] : _ShExUtil.errsToSimple(e)).map(s => \"  \" + s));\n          }, []) :\n          \"  \" + (typeof e === \"string\" ? [val.errors] : _ShExUtil.errsToSimple(val.errors));\n      return [\"rejected by semantic action:\"].concat(nested);\n    } else if (val.type === \"SemActViolation\") {\n      return [val.message];\n    } else if (val.type === \"BooleanSemActFailure\") {\n      return [\"Failed evaluating \" + val.code + \" on context \" + JSON.stringify(val.ctx)];\n    } else {\n      debugger; // console.log(val);\n      throw Error(\"unknown shapeExpression type \\\"\" + val.type + \"\\\" in \" + JSON.stringify(val));\n    }\n    function errorList (errors) {\n      return errors.reduce(function (acc, e) {\n        const attrs = Object.keys(e);\n        return acc.concat(\n          (attrs.length === 1 && attrs[0] === \"errors\")\n            ? errorList(e.errors)\n            : e);\n      }, []);\n    }\n  },\n\n  resolveRelativeIRI: ShExTerm.resolveRelativeIRI,\n\n  resolvePrefixedIRI: function (prefixedIri, prefixes) {\n    const colon = prefixedIri.indexOf(\":\");\n    if (colon === -1)\n      return null;\n    const prefix = prefixes[prefixedIri.substr(0, colon)];\n    return prefix === undefined ? null : prefix + prefixedIri.substr(colon+1);\n  },\n\n  parsePassedNode: function (passedValue, meta, deflt, known, reportUnknown) {\n    if (passedValue === undefined || passedValue.length === 0)\n      return known && known(meta.base) ? meta.base : deflt ? deflt() : this.NotSupplied;\n    if (passedValue[0] === \"_\" && passedValue[1] === \":\")\n      return passedValue;\n    if (passedValue[0] === \"\\\"\") {\n      const m = passedValue.match(/^\"((?:[^\"\\\\]|\\\\\")*)\"(?:@(.+)|\\^\\^(?:<(.*)>|([^:]*):(.*)))?$/);\n      if (!m)\n        throw Error(\"malformed literal: \" + passedValue);\n      const lex = m[1], lang = m[2], rel = m[3], pre = m[4], local = m[5];\n      // Turn the literal into an N3.js atom.\n      const quoted = \"\\\"\"+lex+\"\\\"\";\n      if (lang !== undefined)\n        return quoted + \"@\" + lang;\n      if (pre !== undefined) {\n        if (!(pre in meta.prefixes))\n          throw Error(\"error parsing node \"+passedValue+\" no prefix for \\\"\" + pre + \"\\\"\");\n        return quoted + \"^^\" + meta.prefixes[pre] + local;\n      }\n      if (rel !== undefined)\n        return quoted + \"^^\" + ShExTerm.resolveRelativeIRI(meta.base, rel);\n      return quoted;\n    }\n    if (!meta)\n      return known(passedValue) ? passedValue : this.UnknownIRI;\n    const relIRI = passedValue[0] === \"<\" && passedValue[passedValue.length-1] === \">\";\n    if (relIRI)\n      passedValue = passedValue.substr(1, passedValue.length-2);\n    const t = ShExTerm.resolveRelativeIRI(meta.base || \"\", passedValue); // fall back to base-less mode\n    if (known(t))\n      return t;\n    if (!relIRI) {\n      const t2 = this.resolvePrefixedIRI(passedValue, meta.prefixes);\n      if (t2 !== null && known(t2))\n        return t2;\n    }\n    return reportUnknown ? reportUnknown(t) : this.UnknownIRI;\n  },\n\n  executeQueryPromise: function (query, endpoint) {\n    let rows;\n\n    const queryURL = endpoint + \"?query=\" + encodeURIComponent(query);\n    return fetch(queryURL, {\n      headers: {\n        'Accept': 'application/sparql-results+json'\n      }}).then(resp => resp.json()).then(t => {\n        const selects = t.head.vars;\n        return t.results.bindings.map(row => {\n          return selects.map(sel => {\n            const elt = row[sel];\n            switch (elt.type) {\n            case \"uri\": return elt.value;\n            case \"bnode\": return \"_:\" + elt.value;\n            case \"literal\":\n              const datatype = elt.datatype;\n              const lang = elt[\"xml:lang\"];\n              return \"\\\"\" + elt.value + \"\\\"\" + (\n                datatype ? \"^^\" + datatype :\n                  lang ? \"@\" + lang :\n                  \"\");\n            default: throw \"unknown XML results type: \" + elt.prop(\"tagName\");\n            }\n            return row[sel];\n          })\n        });\n      })// .then(x => new Promise(resolve => setTimeout(() => resolve(x), 1000)));\n  },\n\n  executeQuery: function (query, endpoint) {\n    let rows;\n    const queryURL = endpoint + \"?query=\" + encodeURIComponent(query);\n    const xhr = new XMLHttpRequest();\n    xhr.open(\"GET\", queryURL, false);\n    xhr.setRequestHeader('Accept', 'application/sparql-results+json');\n    xhr.send();\n    // const selectsBlock = query.match(/SELECT\\s*(.*?)\\s*{/)[1];\n    // const selects = selectsBlock.match(/\\?[^\\s?]+/g);\n    const t = JSON.parse(xhr.responseText);\n    const selects = t.head.vars;\n    return t.results.bindings.map(row => {\n      return selects.map(sel => {\n        const elt = row[sel];\n        switch (elt.type) {\n        case \"uri\": return elt.value;\n        case \"bnode\": return \"_:\" + elt.value;\n        case \"literal\":\n          const datatype = elt.datatype;\n          const lang = elt[\"xml:lang\"];\n          return \"\\\"\" + elt.value + \"\\\"\" + (\n            datatype ? \"^^\" + datatype :\n              lang ? \"@\" + lang :\n              \"\");\n        default: throw \"unknown XML results type: \" + elt.prop(\"tagName\");\n        }\n        return row[sel];\n      })\n    });\n\n/* TO ADD? XML results format parsed with jquery:\n        $(data).find(\"sparql > results > result\").\n          each((_, row) => {\n            rows.push($(row).find(\"binding > *:nth-child(1)\").\n              map((idx, elt) => {\n                elt = $(elt);\n                const text = elt.text();\n                switch (elt.prop(\"tagName\")) {\n                case \"uri\": return text;\n                case \"bnode\": return \"_:\" + text;\n                case \"literal\":\n                  const datatype = elt.attr(\"datatype\");\n                  const lang = elt.attr(\"xml:lang\");\n                  return \"\\\"\" + text + \"\\\"\" + (\n                    datatype ? \"^^\" + datatype :\n                    lang ? \"@\" + lang :\n                      \"\");\n                default: throw \"unknown XML results type: \" + elt.prop(\"tagName\");\n                }\n              }).get());\n          });\n*/\n  },\n\n  rdfjsDB: function (db /*:typeof N3Store*/, queryTracker /*:QueryTracker*/) {\n\n    function getSubjects () { return db.getSubjects().map(ShExTerm.internalTerm); }\n    function getPredicates () { return db.getPredicates().map(ShExTerm.internalTerm); }\n    function getObjects () { return db.getObjects().map(ShExTerm.internalTerm); }\n    function getQuads ()/*: Quad[]*/ { return db.getQuads.apply(db, arguments).map(ShExTerm.internalTriple); }\n\n    function getNeighborhood (point/*: string*/, shapeLabel/*: string*//*, shape */) {\n      // I'm guessing a local DB doesn't benefit from shape optimization.\n      let startTime;\n      if (queryTracker) {\n        startTime = new Date();\n        queryTracker.start(false, point, shapeLabel);\n      }\n      const outgoing/*: Quad[]*/ = db.getQuads(point, null, null, null).map(ShExTerm.internalTriple);\n      if (queryTracker) {\n        const time = new Date();\n        queryTracker.end(outgoing, time.valueOf() - startTime.valueOf());\n        startTime = time;\n      }\n      if (queryTracker) {\n        queryTracker.start(true, point, shapeLabel);\n      }\n      const incoming/*: Quad[]*/ = db.getQuads(null, null, point, null).map(ShExTerm.internalTriple);\n      if (queryTracker) {\n        queryTracker.end(incoming, new Date().valueOf() - startTime.valueOf());\n      }\n      return {\n        outgoing: outgoing,\n        incoming: incoming\n      };\n    }\n\n    return {\n      // size: db.size,\n      getNeighborhood: getNeighborhood,\n      getSubjects: getSubjects,\n      getPredicates: getPredicates,\n      getObjects: getObjects,\n      getQuads: getQuads,\n      get size() { return db.size; },\n      // getQuads: function (s, p, o, graph, shapeLabel) {\n      //   // console.log(Error(s + p + o).stack)\n      //   if (queryTracker)\n      //     queryTracker.start(!!s, s ? s : o, shapeLabel);\n      //   const quads = db.getQuads(s, p, o, graph)\n      //   if (queryTracker)\n      //     queryTracker.end(quads, new Date() - startTime);\n      //   return quads;\n      // }\n    }\n  },\n\n  /** Directly construct a DB from triples.\n   */\n  makeTriplesDB: function (queryTracker) {\n    var _ShExUtil = this;\n    var incoming = [];\n    var outgoing = [];\n\n    function getTriplesByIRI(s, p, o, g) {\n      return incoming.concat(outgoing).filter(\n        t =>\n          (!s || s === t.subject) &&\n          (!p || p === t.predicate) &&\n          (!s || s === t.object)\n      );\n    }\n\n    function getNeighborhood (point, shapeLabel, shape) {\n      return {\n        outgoing: outgoing,\n        incoming: incoming\n      };\n    }\n\n    return {\n      getNeighborhood: getNeighborhood,\n      getTriplesByIRI: getTriplesByIRI,\n      getSubjects: function () { return [\"!Triples DB can't index subjects\"] },\n      getPredicates: function () { return [\"!Triples DB can't index predicates\"] },\n      getObjects: function () { return [\"!Triples DB can't index objects\"] },\n      get size() { return undefined; },\n      addIncomingTriples: function (tz) { Array.prototype.push.apply(incoming, tz); },\n      addOutgoingTriples: function (tz) { Array.prototype.push.apply(outgoing, tz); }\n    };\n  },\n\n  NotSupplied: \"-- not supplied --\", UnknownIRI: \"-- not found --\",\n\n  /**\n   * unescape numerics and allowed single-character escapes.\n   * throws: if there are any unallowed sequences\n   */\n  unescapeText: function (string, replacements) {\n    const regex = /\\\\u([a-fA-F0-9]{4})|\\\\U([a-fA-F0-9]{8})|\\\\(.)/g;\n    try {\n      string = string.replace(regex, function (sequence, unicode4, unicode8, escapedChar) {\n        let charCode;\n        if (unicode4) {\n          charCode = parseInt(unicode4, 16);\n          if (isNaN(charCode)) throw new Error(); // can never happen (regex), but helps performance\n          return String.fromCharCode(charCode);\n        }\n        else if (unicode8) {\n          charCode = parseInt(unicode8, 16);\n          if (isNaN(charCode)) throw new Error(); // can never happen (regex), but helps performance\n          if (charCode < 0xFFFF) return String.fromCharCode(charCode);\n          return String.fromCharCode(0xD800 + ((charCode -= 0x10000) >> 10), 0xDC00 + (charCode & 0x3FF));\n        }\n        else {\n          const replacement = replacements[escapedChar];\n          if (!replacement) throw new Error(\"no replacement found for '\" + escapedChar + \"'\");\n          return replacement;\n        }\n      });\n      return string;\n    }\n    catch (error) { console.warn(error); return ''; }\n  },\n\n};\n\nfunction n3ify (ldterm) {\n  if (typeof ldterm !== \"object\")\n    return ldterm;\n  const ret = \"\\\"\" + ldterm.value + \"\\\"\";\n  if (\"language\" in ldterm)\n    return ret + \"@\" + ldterm.language;\n  if (\"type\" in ldterm)\n    return ret + \"^^\" + ldterm.type;\n  return ret;\n}\n\n// Add the ShExUtil functions to the given object or its prototype\nfunction AddShExUtil(parent, toPrototype) {\n  for (let name in ShExUtil)\n    if (!toPrototype)\n      parent[name] = ShExUtil[name];\n    else\n      parent.prototype[name] = ApplyToThis(ShExUtil[name]);\n\n  return parent;\n}\n\n// Returns a function that applies `f` to the `this` object\nfunction ApplyToThis(f) {\n  return function (a) { return f(this, a); };\n}\n\nreturn AddShExUtil(AddShExUtil);\n})();\n\nif (true)\n  module.exports = ShExUtilCjsModule; // node environment\n\n\n//# sourceURL=webpack://playground/./node_modules/@shexjs/util/shex-util.js?");

/***/ }),

/***/ "./node_modules/@shexjs/visitor/shex-visitor.js":
/*!******************************************************!*\
  !*** ./node_modules/@shexjs/visitor/shex-visitor.js ***!
  \******************************************************/
/***/ ((module) => {

eval("\nfunction ShExVisitor () {\n\n    function isTerm (t) {\n      return typeof t !== \"object\" || \"value\" in t && Object.keys(t).reduce((r, k) => {\n        return r === false ? r : [\"value\", \"type\", \"language\"].indexOf(k) !== -1;\n      }, true);\n    }\n\n  function isShapeRef (expr) {\n    return typeof expr === \"string\" // test for JSON-LD @ID\n  }\n  let isInclusion = isShapeRef;\n\n  // function expect (l, r) { const ls = JSON.stringify(l), rs = JSON.stringify(r); if (ls !== rs) throw Error(ls+\" !== \"+rs); }\n  const _ShExUtil = this;\n  function visitMap (map, val) {\n    const ret = {};\n    Object.keys(map).forEach(function (item) {\n      ret[item] = val(map[item]);\n    });\n    return ret;\n  }\n  const r = {\n    runtimeError: function (e) {\n      throw e;\n    },\n\n    visitSchema: function (schema) {\n      const ret = { type: \"Schema\" };\n      _expect(schema, \"type\", \"Schema\");\n      this._maybeSet(schema, ret, \"Schema\",\n                     [\"@context\", \"prefixes\", \"base\", \"imports\", \"startActs\", \"start\", \"shapes\"],\n                     [\"_base\", \"_prefixes\", \"_index\", \"_sourceMap\"]\n                    );\n      return ret;\n    },\n\n    visitPrefixes: function (prefixes) {\n      return prefixes === undefined ?\n        undefined :\n        visitMap(prefixes, function (val) {\n          return val;\n        });\n    },\n\n    visitIRI: function (i) {\n      return i;\n    },\n\n    visitImports: function (imports) {\n      const _Visitor = this;\n      return imports.map(function (imp) {\n        return _Visitor.visitIRI(imp);\n      });\n    },\n\n    visitStartActs: function (startActs) {\n      const _Visitor = this;\n      return startActs === undefined ?\n        undefined :\n        startActs.map(function (act) {\n          return _Visitor.visitSemAct(act);\n        });\n    },\n    visitSemActs: function (semActs) {\n      const _Visitor = this;\n      if (semActs === undefined)\n        return undefined;\n      const ret = []\n      Object.keys(semActs).forEach(function (label) {\n        ret.push(_Visitor.visitSemAct(semActs[label], label));\n      });\n      return ret;\n    },\n    visitSemAct: function (semAct, label) {\n      const ret = { type: \"SemAct\" };\n      _expect(semAct, \"type\", \"SemAct\");\n\n      this._maybeSet(semAct, ret, \"SemAct\",\n                     [\"name\", \"code\"]);\n      return ret;\n    },\n\n    visitShapes: function (shapes) {\n      const _Visitor = this;\n      if (shapes === undefined)\n        return undefined;\n      return shapes.map(\n        shapeExpr =>\n          _Visitor.visitShapeDecl(shapeExpr)\n      );\n    },\n\n    visitProductions999: function (productions) { // !! DELETE\n      const _Visitor = this;\n      if (productions === undefined)\n        return undefined;\n      const ret = {}\n      Object.keys(productions).forEach(function (label) {\n        ret[label] = _Visitor.visitExpression(productions[label], label);\n      });\n      return ret;\n    },\n\n    visitShapeDecl: function (decl, label) {\n      return decl.type === \"ShapeDecl\" ?\n        this._maybeSet(decl, { type: \"ShapeDecl\" }, \"ShapeDecl\",\n                       [\"id\", \"abstract\", \"restricts\", \"shapeExpr\"]) :\n        this.visitShapeExpr(decl, label);\n    },\n\n    visitShapeExpr: function (expr, label) {\n      if (isShapeRef(expr))\n        return this.visitShapeRef(expr)\n      const r =\n          expr.type === \"Shape\" ? this.visitShape(expr, label) :\n          expr.type === \"NodeConstraint\" ? this.visitNodeConstraint(expr, label) :\n          expr.type === \"ShapeAnd\" ? this.visitShapeAnd(expr, label) :\n          expr.type === \"ShapeOr\" ? this.visitShapeOr(expr, label) :\n          expr.type === \"ShapeNot\" ? this.visitShapeNot(expr, label) :\n          expr.type === \"ShapeExternal\" ? this.visitShapeExternal(expr) :\n          null;// if (expr.type === \"ShapeRef\") r = 0; // console.warn(\"visitShapeExpr:\", r);\n      if (r === null)\n        throw Error(\"unexpected shapeExpr type: \" + expr.type);\n      else\n        return r;\n    },\n\n    // _visitShapeGroup: visit a grouping expression (shapeAnd, shapeOr)\n    _visitShapeGroup: function (expr, label) {\n      this._testUnknownAttributes(expr, [\"id\", \"shapeExprs\"], expr.type, this.visitShapeNot)\n      const _Visitor = this;\n      const r = { type: expr.type };\n      if (\"id\" in expr)\n        r.id = expr.id;\n      r.shapeExprs = expr.shapeExprs.map(function (nested) {\n        return _Visitor.visitShapeExpr(nested, label);\n      });\n      return r;\n    },\n\n    // _visitShapeNot: visit negated shape\n    visitShapeNot: function (expr, label) {\n      this._testUnknownAttributes(expr, [\"id\", \"shapeExpr\"], \"ShapeNot\", this.visitShapeNot)\n      const r = { type: expr.type };\n      if (\"id\" in expr)\n        r.id = expr.id;\n      r.shapeExpr = this.visitShapeExpr(expr.shapeExpr, label);\n      return r;\n    },\n\n    // ### `visitNodeConstraint` deep-copies the structure of a shape\n    visitShape: function (shape, label) {\n      const ret = { type: \"Shape\" };\n      _expect(shape, \"type\", \"Shape\");\n\n      this._maybeSet(shape, ret, \"Shape\",\n                     [ \"id\",\n                       \"abstract\", \"extends\",\n                       \"closed\",\n                       \"expression\", \"extra\", \"semActs\", \"annotations\"]);\n      return ret;\n    },\n\n    _visitShapeExprList: function (ext) {\n      const _Visitor = this;\n      return ext.map(function (t) {\n        return _Visitor.visitShapeExpr(t, undefined);\n      });\n    },\n\n    // ### `visitNodeConstraint` deep-copies the structure of a shape\n    visitNodeConstraint: function (shape, label) {\n      const ret = { type: \"NodeConstraint\" };\n      _expect(shape, \"type\", \"NodeConstraint\");\n\n      this._maybeSet(shape, ret, \"NodeConstraint\",\n                     [ \"id\",\n                       // \"abstract\", \"extends\", \"restricts\", -- futureWork\n                       \"nodeKind\", \"datatype\", \"pattern\", \"flags\", \"length\",\n                       \"reference\", \"minlength\", \"maxlength\",\n                       \"mininclusive\", \"minexclusive\", \"maxinclusive\", \"maxexclusive\",\n                       \"totaldigits\", \"fractiondigits\", \"values\", \"annotations\", \"semActs\"]);\n      return ret;\n    },\n\n    visitShapeRef: function (reference) {\n      if (typeof reference !== \"string\") {\n        let ex = Exception(\"visitShapeRef expected a string, not \" + JSON.stringify(reference));\n        console.warn(ex);\n        throw ex;\n      }\n      return reference;\n    },\n\n    visitShapeExternal: function (expr) {\n      this._testUnknownAttributes(expr, [\"id\"], \"ShapeExternal\", this.visitShapeNot)\n      return Object.assign(\"id\" in expr ? { id: expr.id } : {}, { type: \"ShapeExternal\" });\n    },\n\n    // _visitGroup: visit a grouping expression (someOf or eachOf)\n    _visitGroup: function (expr, type) {\n      const _Visitor = this;\n      const r = Object.assign(\n        // pre-declare an id so it sorts to the top\n        \"id\" in expr ? { id: null } : { },\n        { type: expr.type }\n      );\n      r.expressions = expr.expressions.map(function (nested) {\n        return _Visitor.visitExpression(nested);\n      });\n      return this._maybeSet(expr, r, \"expr\",\n                            [\"id\", \"min\", \"max\", \"annotations\", \"semActs\"], [\"expressions\"]);\n    },\n\n    visitTripleConstraint: function (expr) {\n      return this._maybeSet(expr,\n                            Object.assign(\n                              // pre-declare an id so it sorts to the top\n                              \"id\" in expr ? { id: null } : { },\n                              { type: \"TripleConstraint\" }\n                            ),\n                            \"TripleConstraint\",\n                            [\"id\", \"inverse\", \"predicate\", \"valueExpr\",\n                             \"min\", \"max\", \"annotations\", \"semActs\"])\n    },\n\n    visitExpression: function (expr) {\n      if (typeof expr === \"string\")\n        return this.visitInclusion(expr);\n      const r = expr.type === \"TripleConstraint\" ? this.visitTripleConstraint(expr) :\n          expr.type === \"OneOf\" ? this.visitOneOf(expr) :\n          expr.type === \"EachOf\" ? this.visitEachOf(expr) :\n          null;\n      if (r === null)\n        throw Error(\"unexpected expression type: \" + expr.type);\n      else\n        return r;\n    },\n\n    visitValues: function (values) {\n      const _Visitor = this;\n      return values.map(function (t) {\n        return isTerm(t) || t.type === \"Language\" ?\n          t :\n          _Visitor.visitStemRange(t);\n      });\n    },\n\n    visitStemRange: function (t) {\n      const _Visitor = this; // console.log(Error(t.type).stack);\n      // _expect(t, \"type\", \"IriStemRange\");\n      if (!(\"type\" in t))\n        _Visitor.runtimeError(Error(\"expected \"+JSON.stringify(t)+\" to have a 'type' attribute.\"));\n      const stemRangeTypes = [\"IriStem\", \"LiteralStem\", \"LanguageStem\", \"IriStemRange\", \"LiteralStemRange\", \"LanguageStemRange\"];\n      if (stemRangeTypes.indexOf(t.type) === -1)\n        _Visitor.runtimeError(Error(\"expected type attribute '\"+t.type+\"' to be in '\"+stemRangeTypes+\"'.\"));\n      let stem;\n      if (isTerm(t)) {\n        _expect(t.stem, \"type\", \"Wildcard\");\n        stem = { type: t.type, stem: { type: \"Wildcard\" } };\n      } else {\n        stem = { type: t.type, stem: t.stem };\n      }\n      if (t.exclusions) {\n        stem.exclusions = t.exclusions.map(function (c) {\n          return _Visitor.visitExclusion(c);\n        });\n      }\n      return stem;\n    },\n\n    visitExclusion: function (c) {\n      if (!isTerm(c)) {\n        // _expect(c, \"type\", \"IriStem\");\n        if (!(\"type\" in c))\n          _Visitor.runtimeError(Error(\"expected \"+JSON.stringify(c)+\" to have a 'type' attribute.\"));\n        const stemTypes = [\"IriStem\", \"LiteralStem\", \"LanguageStem\"];\n        if (stemTypes.indexOf(c.type) === -1)\n          _Visitor.runtimeError(Error(\"expected type attribute '\"+c.type+\"' to be in '\"+stemTypes+\"'.\"));\n        return { type: c.type, stem: c.stem };\n      } else {\n        return c;\n      }\n    },\n\n    visitInclusion: function (inclusion) {\n      if (typeof inclusion !== \"string\") {\n        let ex = Exception(\"visitInclusion expected a string, not \" + JSON.stringify(inclusion));\n        console.warn(ex);\n        throw ex;\n      }\n      return inclusion;\n    },\n\n    _maybeSet: function (obj, ret, context, members, ignore) {\n      const _Visitor = this;\n      this._testUnknownAttributes(obj, ignore ? members.concat(ignore) : members, context, this._maybeSet)\n      members.forEach(function (member) {\n        const methodName = \"visit\" + member.charAt(0).toUpperCase() + member.slice(1);\n        if (member in obj) {\n          const f = _Visitor[methodName];\n          if (typeof f !== \"function\") {\n            throw Error(methodName + \" not found in Visitor\");\n          }\n          const t = f.call(_Visitor, obj[member]);\n          if (t !== undefined) {\n            ret[member] = t;\n          }\n        }\n      });\n      return ret;\n    },\n    _visitValue: function (v) {\n      return v;\n    },\n    _visitList: function (l) {\n      return l.slice();\n    },\n    _testUnknownAttributes: function (obj, expected, context, captureFrame) {\n      const unknownMembers = Object.keys(obj).reduce(function (ret, k) {\n        return k !== \"type\" && expected.indexOf(k) === -1 ? ret.concat(k) : ret;\n      }, []);\n      if (unknownMembers.length > 0) {\n        const e = Error(\"unknown propert\" + (unknownMembers.length > 1 ? \"ies\" : \"y\") + \": \" +\n                      unknownMembers.map(function (p) {\n                        return \"\\\"\" + p + \"\\\"\";\n                      }).join(\",\") +\n                      \" in \" + context + \": \" + JSON.stringify(obj));\n        Error.captureStackTrace(e, captureFrame);\n        throw e;\n      }\n    }\n\n  };\n  r.visitBase = r.visitStart = r.visitClosed = r[\"visit@context\"] = r._visitValue;\n  r.visitRestricts = r.visitExtends = r._visitShapeExprList;\n  r.visitExtra = r.visitAnnotations = r._visitList;\n  r.visitAbstract = r.visitInverse = r.visitPredicate = r._visitValue;\n  r.visitName = r.visitId = r.visitCode = r.visitMin = r.visitMax = r._visitValue;\n\n  r.visitType = r.visitNodeKind = r.visitDatatype = r.visitPattern = r.visitFlags = r.visitLength = r.visitMinlength = r.visitMaxlength = r.visitMininclusive = r.visitMinexclusive = r.visitMaxinclusive = r.visitMaxexclusive = r.visitTotaldigits = r.visitFractiondigits = r._visitValue;\n  r.visitOneOf = r.visitEachOf = r._visitGroup;\n  r.visitShapeAnd = r.visitShapeOr = r._visitShapeGroup;\n  r.visitInclude = r._visitValue;\n  r.visitValueExpr = r.visitShapeExpr;\n  return r;\n\n  // Expect property p with value v in object o\n  function _expect (o, p, v) {\n    if (!(p in o))\n      this._error(\"expected \"+JSON.stringify(o)+\" to have a .\"+p);\n    if (arguments.length > 2 && o[p] !== v)\n      this._error(\"expected \"+o[o]+\" to equal .\"+v);\n  }\n\n  function _error (str) {\n    throw new Error(str);\n  }\n}\n\n// The ShEx Vistor is here to minimize deps for ShExValidator.\n/** create indexes for schema\n */\nShExVisitor.index = function (schema) {\n  let index = {\n    shapeExprs: {},\n    tripleExprs: {}\n  };\n  let v = ShExVisitor();\n\n  let oldVisitExpression = v.visitExpression;\n  v.visitExpression = function (expression) {\n    if (typeof expression === \"object\" && \"id\" in expression)\n      index.tripleExprs[expression.id] = expression;\n    return oldVisitExpression.call(v, expression);\n  };\n\n  let oldVisitShapeExpr = v.visitShapeExpr;\n  v.visitShapeExpr = v.visitValueExpr = function (shapeExpr, label) {\n    if (typeof shapeExpr === \"object\" && \"id\" in shapeExpr)\n      index.shapeExprs[shapeExpr.id] = shapeExpr;\n    return oldVisitShapeExpr.call(v, shapeExpr, label);\n  };\n\n  let oldVisitShapeDecl = v.visitShapeDecl;\n  v.visitShapeDecl = v.visitValueExpr = function (shapeExpr, label) {\n    if (typeof shapeExpr === \"object\" && \"id\" in shapeExpr)\n      index.shapeExprs[shapeExpr.id] = shapeExpr;\n    return oldVisitShapeDecl.call(v, shapeExpr, label);\n  };\n\n  v.visitSchema(schema);\n  return index;\n}\n\nif (true)\n  module.exports = ShExVisitor;\n\n\n\n//# sourceURL=webpack://playground/./node_modules/@shexjs/visitor/shex-visitor.js?");

/***/ }),

/***/ "./node_modules/@shexjs/writer/shex-writer.js":
/*!****************************************************!*\
  !*** ./node_modules/@shexjs/writer/shex-writer.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// **ShExWriter** writes ShEx documents.\n\nconst ShExWriterCjsModule = (function () {\nconst RelateUrl = __webpack_require__(/*! relateurl */ \"./node_modules/relateurl/lib/index.js\");\nconst UNBOUNDED = -1;\n\n// Matches a literal as represented in memory by the ShEx library\nconst ShExLiteralMatcher = /^\"([^]*)\"(?:\\^\\^(.+)|@([\\-a-z]+))?$/i;\n\n// rdf:type predicate (for 'a' abbreviation)\nconst RDF_PREFIX = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n    RDF_TYPE   = RDF_PREFIX + 'type';\n\n// Characters in literals that require escaping\nconst ESCAPE_1 = /[\"\\\\\\t\\n\\r\\b\\f\\u0000-\\u0019\\ud800-\\udbff]/,\n    ESCAPE_g = /[\"\\\\\\t\\n\\r\\b\\f\\u0000-\\u0019]|[\\ud800-\\udbff][\\udc00-\\udfff]/g,\n    ESCAPE_replacements = { '\\\\': '\\\\\\\\', '\"': '\\\\\"', '/': '\\\\/', '\\t': '\\\\t',\n                            '\\n': '\\\\n', '\\r': '\\\\r', '\\b': '\\\\b', '\\f': '\\\\f' };\n\nconst nodeKinds = {\n  'iri': \"IRI\",\n  'bnode': \"BNODE\",\n  'literal': \"LITERAL\",\n  'nonliteral': \"NONLITERAL\"\n};\nconst nonLitNodeKinds = {\n  'iri': \"IRI\",\n  'bnode': \"BNODE\",\n  'literal': \"LITERAL\",\n  'nonliteral': \"NONLITERAL\"\n};\n\n// ## Constructor\nfunction ShExWriter (outputStream, options) {\n  if (!(this instanceof ShExWriter))\n    return new ShExWriter(outputStream, options);\n\n  // Shift arguments if the first argument is not a stream\n  if (outputStream && typeof outputStream.write !== 'function')\n    options = outputStream, outputStream = null;\n  options = options || {};\n\n  // If no output stream given, send the output as string through the end callback\n  if (!outputStream) {\n    let output = '';\n    this._outputStream = {\n      write: function (chunk, encoding, done) { output += chunk; done && done(); },\n      end:   function (done) { done && done(null, output); },\n    };\n    this._endStream = true;\n  }\n  else {\n    this._outputStream = outputStream;\n    this._endStream = options.end === undefined ? true : !!options.end;\n  }\n\n  // Initialize writer, depending on the format\n  this._prefixIRIs = Object.create(null);\n  this._baseIRI = options.base || null;\n  options.prefixes && this.addPrefixes(options.prefixes);\n\n  this._error = options.error || _throwError;\n  this.forceParens = !options.simplifyParentheses; // default to false\n  this._expect = options.lax ? noop : expect;\n}\n\nShExWriter.prototype = {\n  // ## Private methods\n\n  // ### `_write` writes the argument to the output stream\n  _write: function (string, callback) {\n    this._outputStream.write(string, 'utf8', callback);\n  },\n\n  // ### `_writeSchema` writes the shape to the output stream\n  _writeSchema: function (schema, done) {\n    const _ShExWriter = this;\n    this._expect(schema, \"type\", \"Schema\");\n    _ShExWriter.addPrefixes(schema._prefixes);\n    if (schema._base)\n      _ShExWriter._baseIRI = schema._base;\n\n    if (_ShExWriter._baseIRI)\n      _ShExWriter._write(\"BASE <\" + _ShExWriter._baseIRI + \">\\n\"); // don't use _encodeIriOrBlankNode()\n\n    if (schema.imports)\n      schema.imports.forEach(function (imp) {\n        _ShExWriter._write(\"IMPORT \" + _ShExWriter._encodeIriOrBlankNode(imp) + \"\\n\");\n      });\n    if (schema.startActs)\n      schema.startActs.forEach(function (act) {\n        _ShExWriter._expect(act, \"type\", \"SemAct\");\n        _ShExWriter._write(\" %\"+\n                           _ShExWriter._encodePredicate(act.name)+\n                           (\"code\" in act ? \"{\"+escapeCode(act.code)+\"%\"+\"}\" : \"%\"));\n      });\n    if (schema.start)\n      _ShExWriter._write(\"start = \" + _ShExWriter._writeShapeExpr(schema.start, done, true, 0).join('') + \"\\n\")\n    if (\"shapes\" in schema)\n      schema.shapes.forEach(function (shapeExpr) {\n        let id = shapeExpr.id;\n        let abstract = \"\";\n        if (shapeExpr.type === \"ShapeDecl\") {\n          if (shapeExpr.abstract)\n            abstract = \"abstract \"\n          shapeExpr = shapeExpr.shapeExpr;\n        }\n        _ShExWriter._write(\n          abstract +\n          _ShExWriter._encodeShapeName(id, false) +\n            \" \" +\n            _ShExWriter._writeShapeExpr(shapeExpr, done, true, 0).join(\"\")+\"\\n\",\n          done\n        );\n      })\n  },\n\n  _writeShapeExpr: function (shapeExpr, done, forceBraces, parentPrec) {\n    const _ShExWriter = this;\n    const pieces = [];\n    if (typeof shapeExpr === \"string\") // ShapeRef\n      pieces.push(\"@\", _ShExWriter._encodeShapeName(shapeExpr));\n    // !!! []s for precedence!\n    else if (shapeExpr.type === \"ShapeDecl\")\n      pieces.push(_ShExWriter._writeShapeExpr(shapeExpr.shapeExpr, done, false, 3));\n    else if (shapeExpr.type === \"ShapeExternal\")\n      pieces.push(\"EXTERNAL\");\n    else if (shapeExpr.type === \"ShapeAnd\") {\n      if (parentPrec >= 3)\n        pieces.push(\"(\");\n      let lastAndElided = false;\n      shapeExpr.shapeExprs.forEach(function (expr, ord) {\n        if (ord > 0) { // && !!! grammar rules too weird here\n          /*\n            shapeAtom:\n                  nonLitNodeConstraint shapeOrRef?\n                | shapeDecl nonLitNodeConstraint?\n\n            nonLitInlineNodeConstraint:\n                  nonLiteralKind stringFacet*\n          */\n          function nonLitNodeConstraint (idx) {\n            let c = shapeExpr.shapeExprs[idx];\n            return c.type !== \"NodeConstraint\"\n              || (\"nodeKind\" in c && c.nodeKind === \"literal\")\n              || \"datatype\" in c\n              || \"values\" in c\n              ? false\n              : true;\n          }\n\n          function shapeOrRef (idx) {\n            let c = shapeExpr.shapeExprs[idx];\n            return c.type === \"Shape\" || c.type === \"ShapeRef\";\n          }\n\n          function shapeDecl (idx) {\n            let c = shapeExpr.shapeExprs[idx];\n            return c.type === \"Shape\";\n          }\n\n          let elideAnd = !lastAndElided\n              && (nonLitNodeConstraint(ord-1) && shapeOrRef(ord)\n                  || shapeDecl(ord-1) && nonLitNodeConstraint(ord))\n          if (!elideAnd || true) { // !! temporary work-around for ShExC parser bug\n            pieces.push(\" AND \");\n          }\n          lastAndElided = elideAnd;\n        }\n        [].push.apply(pieces, _ShExWriter._writeShapeExpr(expr, done, false, 3));\n      });\n      if (parentPrec >= 3)\n        pieces.push(\")\");\n    } else if (shapeExpr.type === \"ShapeOr\") {\n      if (parentPrec >= 2)\n        pieces.push(\"(\");\n      shapeExpr.shapeExprs.forEach(function (expr, ord) {\n        if (ord > 0)\n          pieces.push(\" OR \");\n        [].push.apply(pieces, _ShExWriter._writeShapeExpr(expr, done, forceBraces, 2));\n      });\n      if (parentPrec >= 2)\n        pieces.push(\")\");\n    } else if (shapeExpr.type === \"ShapeNot\") {\n      if (parentPrec >= 4)\n        pieces.push(\"(\");\n      pieces.push(\"NOT \");\n      [].push.apply(pieces, _ShExWriter._writeShapeExpr(shapeExpr.shapeExpr, done, forceBraces, 4));\n      if (parentPrec >= 4)\n        pieces.push(\")\");\n    } else if (shapeExpr.type === \"Shape\") {\n      [].push.apply(pieces, _ShExWriter._writeShape(shapeExpr, done, forceBraces));\n    } else if (shapeExpr.type === \"NodeConstraint\") {\n      [].push.apply(pieces, _ShExWriter._writeNodeConstraint(shapeExpr, done, forceBraces));\n    } else\n      throw Error(\"expected Shape{,And,Or,Ref} or NodeConstraint in \" + JSON.stringify(shapeExpr));\n    return pieces;\n  },\n\n  // ### `_writeShape` writes the shape to the output stream\n  _writeShape: function (shape, done, forceBraces) {\n    const _ShExWriter = this;\n    try {\n      const pieces = []; // guessing push/join is faster than concat\n      this._expect(shape, \"type\", \"Shape\");\n\n      if (shape.closed) pieces.push(\"CLOSED \");\n\n      [{keyword: \"extends\", marker: \"EXTENDS \"}].forEach(pair => {\n         // pieces = pieces.concat(_ShExWriter._writeShapeExpr(expr.valueExpr, done, true, 0));\n         if (shape[pair.keyword] && shape[pair.keyword].length > 0) {\n           shape[pair.keyword].forEach(function (i, ord) {\n             if (ord)\n               pieces.push(\" \")\n             pieces.push(pair.marker);\n             [].push.apply(pieces, _ShExWriter._writeShapeExpr(i, done, true, 0));\n           });\n           pieces.push(\" \");\n         }\n       });\n\n      if (shape.extra && shape.extra.length > 0) {\n        pieces.push(\"EXTRA \");\n        shape.extra.forEach(function (i, ord) {\n          pieces.push(_ShExWriter._encodeShapeName(i, false)+\" \");\n        });\n        pieces.push(\" \");\n      }\n      const empties = [\"values\", \"length\", \"minlength\", \"maxlength\", \"pattern\", \"flags\"];\n      pieces.push(\"{\\n\");\n\n      function _writeShapeActions (semActs) {\n        if (!semActs)\n          return;\n\n        semActs.forEach(function (act) {\n          _ShExWriter._expect(act, \"type\", \"SemAct\");\n          pieces.push(\" %\",\n                      _ShExWriter._encodePredicate(act.name),\n                      (\"code\" in act ? \"{\"+escapeCode(act.code)+\"%\"+\"}\" : \"%\"));\n        });\n      }\n\n      function _writeCardinality (min, max) {\n        if      (min === 0 && max === 1)         pieces.push(\"?\");\n        else if (min === 0 && max === UNBOUNDED) pieces.push(\"*\");\n        else if (min === undefined && max === undefined)                         ;\n        else if (min === 1 && max === UNBOUNDED) pieces.push(\"+\");\n        else\n          pieces.push(\"{\", min, \",\", (max === UNBOUNDED ? \"*\" : max), \"}\"); // by coincidence, both use the same character.\n      }\n\n      function _writeExpression (expr, indent, parentPrecedence) {\n        function _writeExpressionActions (semActs) {\n          if (semActs) {\n\n            semActs.forEach(function (act) {\n              _ShExWriter._expect(act, \"type\", \"SemAct\");\n              pieces.push(\"\\n\"+indent+\"   %\");\n              pieces.push(_ShExWriter._encodeValue(act.name));\n              if (\"code\" in act)\n                pieces.push(\"{\"+escapeCode(act.code)+\"%\"+\"}\");\n              else\n                pieces.push(\"%\");\n            });\n          }\n        }\n\n        function _exprGroup (exprs, separator, precedence, forceParens) {\n          const needsParens = precedence < parentPrecedence || forceParens;\n          if (needsParens) {\n            pieces.push(\"(\");\n          }\n          exprs.forEach(function (nested, ord) {\n            _writeExpression(nested, indent+\"  \", precedence)\n            if (ord < exprs.length - 1)\n              pieces.push(separator);\n          });\n          if (needsParens) {\n            pieces.push(\")\");\n          }\n        }\n\n        if (typeof expr === \"string\") {\n          pieces.push(\"&\");\n          pieces.push(_ShExWriter._encodeShapeName(expr, false));\n        } else {\n\n        if (\"id\" in expr) {\n          pieces.push(\"$\");\n          pieces.push(_ShExWriter._encodeIriOrBlankNode(expr.id, true));\n        }\n\n        if (expr.type === \"TripleConstraint\") {\n          if (expr.inverse)\n            pieces.push(\"^\");\n          if (expr.negated)\n            pieces.push(\"!\");\n          pieces.push(indent,\n                      _ShExWriter._encodePredicate(expr.predicate),\n                      \" \");\n\n          if (\"valueExpr\" in expr)\n            [].push.apply(pieces, _ShExWriter._writeShapeExpr(expr.valueExpr, done, true, 0));\n          else\n            pieces.push(\". \");\n\n          _writeCardinality(expr.min, expr.max);\n          _ShExWriter._annotations(pieces, expr.annotations, indent);\n          _writeExpressionActions(expr.semActs);\n        }\n\n        else if (expr.type === \"OneOf\") {\n          const needsParens = \"id\" in expr || \"min\" in expr || \"max\" in expr || \"annotations\" in expr || \"semActs\" in expr;\n          _exprGroup(expr.expressions, \"\\n\"+indent+\"| \", 1, needsParens || _ShExWriter.forceParens);\n          _writeCardinality(expr.min, expr.max); // t: open1dotclosecardOpt\n          _ShExWriter._annotations(pieces, expr.annotations, indent);\n          _writeExpressionActions(expr.semActs);\n        }\n\n        else if (expr.type === \"EachOf\") {\n          const needsParens = \"id\" in expr || \"min\" in expr || \"max\" in expr || \"annotations\" in expr || \"semActs\" in expr;\n          _exprGroup(expr.expressions, \";\\n\"+indent, 2, needsParens || _ShExWriter.forceParens);\n          _writeCardinality(expr.min, expr.max); // t: open1dotclosecardOpt\n          _ShExWriter._annotations(pieces, expr.annotations, indent);\n          _writeExpressionActions(expr.semActs);\n        }\n\n        else throw Error(\"unexpected expr type: \" + expr.type);\n        }\n      }\n\n      if (shape.expression) // t: 0, 0Extend1\n        _writeExpression(shape.expression, \"  \", 0);\n      pieces.push(\"\\n}\");\n      _writeShapeActions(shape.semActs);\n      _ShExWriter._annotations(pieces, shape.annotations, \"  \");\n\n      return pieces;\n    }\n    catch (error) { done && done(error); }\n  },\n\n  // ### `_writeShape` writes the shape to the output stream\n  _writeNodeConstraint: function (v, done) {\n    const _ShExWriter = this;\n    try {\n      _ShExWriter._expect(v, \"type\", \"NodeConstraint\");\n\n      const pieces = [];\n      if (v.nodeKind in nodeKinds)       pieces.push(nodeKinds[v.nodeKind], \" \");\n      else if (v.nodeKind !== undefined) _ShExWriter._error(\"unexpected nodeKind: \" + v.nodeKind); // !!!!\n\n      this._fillNodeConstraint(pieces, v, done);\n      this._annotations(pieces, v.annotations, \"  \");\n      return pieces;\n    }\n    catch (error) { done && done(error); }\n\n  },\n\n  _annotations: function (pieces, annotations, indent) {\n    const _ShExWriter = this;\n    if (annotations) {\n      annotations.forEach(function (a) {\n        _ShExWriter._expect(a, \"type\", \"Annotation\");\n        pieces.push(\"//\\n\"+indent+\"   \");\n        pieces.push(_ShExWriter._encodeValue(a.predicate));\n        pieces.push(\" \");\n        pieces.push(_ShExWriter._encodeValue(a.object));\n      });\n    }\n  },\n\n  _fillNodeConstraint: function (pieces, v, done) {\n    const _ShExWriter = this;\n    if (v.datatype  && v.values  ) _ShExWriter._error(\"found both datatype and values in \"   +expr);\n    if (v.datatype) {\n      pieces.push(_ShExWriter._encodeShapeName(v.datatype));\n    }\n\n    if (v.values) {\n      pieces.push(\"[\");\n\n      v.values.forEach(function (t, ord) {\n        if (ord > 0)\n          pieces.push(\" \");\n\n        if (!isTerm(t)) {\n//          expect(t, \"type\", \"IriStemRange\");\n              if (!(\"type\" in t))\n                runtimeError(\"expected \"+JSON.stringify(t)+\" to have a 'type' attribute.\");\n          const stemRangeTypes = [\"Language\", \"IriStem\", \"LiteralStem\", \"LanguageStem\", \"IriStemRange\", \"LiteralStemRange\", \"LanguageStemRange\"];\n              if (stemRangeTypes.indexOf(t.type) === -1)\n                runtimeError(\"expected type attribute '\"+t.type+\"' to be in '\"+stemRangeTypes+\"'.\");\n          if (t.type === \"Language\") {\n            pieces.push(\"@\" + t.languageTag);\n          } else if (!isTerm(t.stem)) {\n            expect(t.stem, \"type\", \"Wildcard\");\n            pieces.push(\".\");\n          } else {\n            pieces.push(langOrLiteral(t, t.stem) + \"~\");\n          }\n          if (t.exclusions) {\n            t.exclusions.forEach(function (c) {\n              pieces.push(\" - \");\n              if (!isTerm(c)) {\n//                expect(c, \"type\", \"IriStem\");\n                    if (!(\"type\" in c))\n                      runtimeError(\"expected \"+JSON.stringify(c)+\" to have a 'type' attribute.\");\n                    const stemTypes = [\"IriStem\", \"LiteralStem\", \"LanguageStem\"];\n                    if (stemTypes.indexOf(c.type) === -1)\n                      runtimeError(\"expected type attribute '\"+c.type+\"' to be in '\"+stemTypes+\"'.\");\n                pieces.push(langOrLiteral(t, c.stem) + \"~\");\n              } else {\n                pieces.push(langOrLiteral(t, c));\n              }\n            });\n          }\n          function langOrLiteral (t, c) {\n            return [\"LanguageStem\", \"LanguageStemRange\"].indexOf(t.type) !== -1 ? \"@\" + c :\n              [\"LiteralStem\", \"LiteralStemRange\"].indexOf(t.type) !== -1 ? '\"' + c.replace(ESCAPE_g, c) + '\"' :\n              _ShExWriter._encodeValue(c)\n          }\n        } else {\n          pieces.push(_ShExWriter._encodeValue(t));\n        }\n      });\n\n      pieces.push(\"]\");\n    }\n\n    if ('pattern' in v) {\n      const pattern = v.pattern.\n          replace(/\\//g, \"\\\\/\");\n      // if (ESCAPE_1.test(pattern))\n      //   pattern = pattern.replace(ESCAPE_g, characterReplacer);\n      const flags = 'flags' in v ? v.flags : \"\";\n      pieces.push(\"/\" + pattern + \"/\" + flags + \" \");\n    }\n    ['length', 'minlength', 'maxlength',\n     'mininclusive', 'minexclusive', 'maxinclusive', 'maxexclusive',\n     'totaldigits', 'fractiondigits'\n    ].forEach(function (a) {\n      if (v[a])\n        pieces.push(\" \", a, \" \", v[a]);\n    });\n    return pieces;\n\n    function isTerm (t) {\n      return typeof t !== \"object\" || \"value\" in t && Object.keys(t).reduce((r, k) => {\n        return r === false ? r : [\"value\", \"type\", \"language\"].indexOf(k) !== -1;\n      }, true);\n    }\n  },\n\n  // ### `_encodeIriOrBlankNode` represents an IRI or blank node\n  _encodeIriOrBlankNode: function (iri, trailingSpace) {\n    trailingSpace = trailingSpace ? ' ' : '';\n    // A blank node is represented as-is\n    if (iri[0] === '_' && iri[1] === ':') return iri;\n    // Escape special characters\n    if (ESCAPE_1.test(iri))\n      iri = iri.replace(ESCAPE_g, characterReplacer);\n    // Try to represent the IRI as prefixed name\n    const prefixMatch = this._prefixRegex.exec(iri);\n    return !prefixMatch\n      ? this._relateUrl(iri)\n      : (!prefixMatch[1]\n         ? iri\n         : this._prefixIRIs[prefixMatch[1]] + prefixMatch[2])\n      + trailingSpace;\n  },\n\n  // ### ``\n  _relateUrl: function (iri) {\n    const base = this._baseIRI;\n    try {\n      if (base && new URL(base).host === new URL(iri).host) // https://github.com/stevenvachon/relateurl/issues/28\n        iri = RelateUrl.relate(base, iri, { output: RelateUrl.ROOT_PATH_RELATIVE });\n    } catch (e) {\n      // invalid URL for e.g. already relative IMPORTs\n    }\n    return '<' + iri + '>';\n  },\n\n  // ### `_encodeLiteral` represents a literal\n  _encodeLiteral: function (value, type, language) {\n    // Escape special characters\n    if (ESCAPE_1.test(value))\n      value = value.replace(ESCAPE_g, characterReplacer);\n    // Write the literal, possibly with type or language\n    if (language) {\n      return '\"' + value + '\"@' + language;\n    } else if (type) { // && type !== \"http://www.w3.org/2001/XMLSchema#integer\" is implied by the parsing rules.\n      if (type === \"http://www.w3.org/2001/XMLSchema#integer\" && value.match(/^[+-]?[0-9]+$/)) {\n        return value;\n      } else if (type === \"http://www.w3.org/2001/XMLSchema#decimal\" && value.match(/^[+-]?[0-9]*\\.[0-9]+$/)) {\n        return value;\n      } else if (type === \"http://www.w3.org/2001/XMLSchema#double\" && value.match(/^[+-]?([0-9]+\\.[0-9]*[eE][+-]?[0-9]+|\\.?[0-9]+[eE][+-]?[0-9]+)$/)) {\n        return value;\n      } else {\n        return '\"' + value + '\"^^' + this._encodeIriOrBlankNode(type);\n      }\n    } else {\n      return '\"' + value + '\"';\n    }\n  },\n\n  // ### `_encodeShapeName` represents a subject\n  _encodeShapeName: function (subject, trailingSpace) {\n    if (subject[0] === '\"')\n      throw new Error('A literal as subject is not allowed: ' + subject);\n    return this._encodeIriOrBlankNode(subject, trailingSpace);\n  },\n\n  // ### `_encodePredicate` represents a predicate\n  _encodePredicate: function (predicate) {\n    if (predicate[0] === '\"')\n      throw new Error('A literal as predicate is not allowed: ' + predicate);\n    return predicate === RDF_TYPE ? 'a' : this._encodeIriOrBlankNode(predicate);\n  },\n\n  // ### `_encodeValue` represents an object\n  _encodeValue: function (object) {\n    // Represent an IRI or blank node\n    if (typeof object !== \"object\")\n      return this._encodeIriOrBlankNode(object);\n    // Represent a literal\n    return this._encodeLiteral(object.value, object.type, object.language);\n  },\n\n  // ### `_blockedWrite` replaces `_write` after the writer has been closed\n  _blockedWrite: function () {\n    throw new Error('Cannot write because the writer has been closed.');\n  },\n\n  writeSchema: function (shape, done) {\n    this._writeSchema(shape, done);\n    this.end(done);\n  },\n\n  // ### `addShape` adds the shape to the output stream\n  addShape: function (shape, name, done) {\n    this._write(\n      _ShExWriter._encodeShapeName(name, false) +\n        \" \" +\n        _ShExWriter._writeShapeExpr(shape, done, true, 0).join(\"\"),\n      done\n    );\n  },\n\n  // ### `addShapes` adds the shapes to the output stream\n  addShapes: function (shapes) {\n    for (let i = 0; i < shapes.length; i++)\n      this.addShape(shapes[i]);\n  },\n\n  // ### `addPrefix` adds the prefix to the output stream\n  addPrefix: function (prefix, iri, done) {\n    const prefixes = {};\n    prefixes[prefix] = iri;\n    this.addPrefixes(prefixes, done);\n  },\n\n  // ### `addPrefixes` adds the prefixes to the output stream\n  addPrefixes: function (prefixes, done) {\n    // Add all useful prefixes\n    const prefixIRIs = this._prefixIRIs;\n    let hasPrefixes = false;\n    for (let prefix in prefixes) {\n      // Verify whether the prefix can be used and does not exist yet\n      const iri = prefixes[prefix];\n      if (// @@ /[#\\/]$/.test(iri) && !! what was that?\n          prefixIRIs[iri] !== (prefix += ':')) {\n        hasPrefixes = true;\n        prefixIRIs[iri] = prefix;\n        // Write prefix\n        this._write('PREFIX ' + prefix + ' <' + iri + '>\\n');\n      }\n    }\n    // Recreate the prefix matcher\n    if (hasPrefixes) {\n      let IRIlist = '', prefixList = '';\n      for (let prefixIRI in prefixIRIs) {\n        IRIlist += IRIlist ? '|' + prefixIRI : prefixIRI;\n        prefixList += (prefixList ? '|' : '') + prefixIRIs[prefixIRI];\n      }\n      IRIlist = IRIlist.replace(/[\\]\\/\\(\\)\\*\\+\\?\\.\\\\\\$]/g, '\\\\$&');\n      this._prefixRegex = new RegExp('^(?:' + prefixList + ')[^\\/]*$|' +\n                                     '^(' + IRIlist + ')([a-zA-Z][\\\\-_a-zA-Z0-9]*)$');\n    }\n    // End a prefix block with a newline\n    this._write(hasPrefixes ? '\\n' : '', done);\n  },\n\n  // ### `_prefixRegex` matches a prefixed name or IRI that begins with one of the added prefixes\n  _prefixRegex: /$0^/,\n\n  // ### `end` signals the end of the output stream\n  end: function (done) {\n    // Disallow further writing\n    this._write = this._blockedWrite;\n\n    // Try to end the underlying stream, ensuring done is called exactly one time\n    let singleDone = done && function (error, result) { singleDone = null, done(error, result); };\n    if (this._endStream) {\n      try { return this._outputStream.end(singleDone); }\n      catch (error) { /* error closing stream */ }\n    }\n    singleDone && singleDone();\n  },\n};\n\n// Replaces a character by its escaped version\nfunction characterReplacer(character) {\n  // Replace a single character by its escaped version\n  let result = ESCAPE_replacements[character];\n  if (result === undefined) {\n    // Replace a single character with its 4-bit unicode escape sequence\n    if (character.length === 1) {\n      result = character.charCodeAt(0).toString(16);\n      result = '\\\\u0000'.substr(0, 6 - result.length) + result;\n    }\n    // Replace a surrogate pair with its 8-bit unicode escape sequence\n    else {\n      result = ((character.charCodeAt(0) - 0xD800) * 0x400 +\n                 character.charCodeAt(1) + 0x2400).toString(16);\n      result = '\\\\U00000000'.substr(0, 10 - result.length) + result;\n    }\n  }\n  return result;\n}\n\nfunction escapeCode (code) {\n  return code.replace(/\\\\/g, \"\\\\\\\\\").replace(/%/g, \"\\\\%\")\n}\n\n/** _throwError: overridable function to throw Errors().\n *\n * @param func (optional): function at which to truncate stack trace\n * @param str: error message\n */\nfunction _throwError (func, str) {\n  if (typeof func !== \"function\") {\n    str = func;\n    func = _throwError;\n  }\n  const e = new Error(str);\n  Error.captureStackTrace(e, func);\n  throw e;\n}\n\n// Expect property p with value v in object o\nfunction expect (o, p, v) {\n  if (!(p in o))\n    this._error(expect, \"expected \"+o+\" to have a .\"+p);\n  if (arguments.length > 2 && o[p] !== v)\n    this._error(expect, \"expected \"+o[o]+\" to equal .\"+v);\n}\n\n// The empty function\nfunction noop () {}\n\nreturn ShExWriter;\n})();\n\n// Export the `ShExWriter` class as a whole.\nif (true)\n  module.exports = ShExWriterCjsModule; // node environment\n\n\n//# sourceURL=webpack://playground/./node_modules/@shexjs/writer/shex-writer.js?");

/***/ }),

/***/ "./node_modules/hierarchy-closure/hierarchy-closure.js":
/*!*************************************************************!*\
  !*** ./node_modules/hierarchy-closure/hierarchy-closure.js ***!
  \*************************************************************/
/***/ ((module) => {

eval("var HierarchyClosure = (function () {\n  /** create a hierarchy object\n   * This object keeps track of direct children and parents as well as transitive children and parents.\n   */\n  function makeHierarchy () {\n    let roots = {}\n    let parents = {}\n    let children = {}\n    let holders = {}\n    return {\n      add: function (parent, child) {\n        if (// test if this is a novel entry.\n          (parent in children && children[parent].indexOf(child) !== -1)) {\n          return\n        }\n        let target = parent in holders\n          ? getNode(parent)\n          : (roots[parent] = getNode(parent)) // add new parents to roots.\n        let value = getNode(child)\n\n        target[child] = value\n        delete roots[child]\n\n        // // maintain hierarchy (direct and confusing)\n        // children[parent] = children[parent].concat(child, children[child])\n        // children[child].forEach(c => parents[c] = parents[c].concat(parent, parents[parent]))\n        // parents[child] = parents[child].concat(parent, parents[parent])\n        // parents[parent].forEach(p => children[p] = children[p].concat(child, children[child]))\n\n        // maintain hierarchy (generic and confusing)\n        updateClosure(children, parents, child, parent)\n        updateClosure(parents, children, parent, child)\n        function updateClosure (container, members, near, far) {\n          container[far] = container[far].filter(\n            e => /* e !== near && */ container[near].indexOf(e) === -1\n          ).concat(container[near].indexOf(near) === -1 ? [near] : [], container[near])\n          container[near].forEach(\n            n => (members[n] = members[n].filter(\n              e => e !== far && members[far].indexOf(e) === -1\n            ).concat(members[far].indexOf(far) === -1 ? [far] : [], members[far]))\n          )\n        }\n\n        function getNode (node) {\n          if (!(node in holders)) {\n            parents[node] = []\n            children[node] = []\n            holders[node] = {}\n          }\n          return holders[node]\n        }\n      },\n      roots: roots,\n      parents: parents,\n      children: children\n    }\n  }\n\n  function depthFirst (n, f, p) {\n    return Object.keys(n).reduce((ret, k) => {\n      return ret.concat(\n        depthFirst(n[k], f, k),\n        p ? f(k, p) : []) // outer invocation can have null parent\n    }, [])\n  }\n\n  return { create: makeHierarchy, depthFirst }\n})()\n\n/* istanbul ignore next */\nif (true) {\n  module.exports = HierarchyClosure\n}\n\n\n//# sourceURL=webpack://playground/./node_modules/hierarchy-closure/hierarchy-closure.js?");

/***/ }),

/***/ "./node_modules/n3/lib/IRIs.js":
/*!*************************************!*\
  !*** ./node_modules/n3/lib/IRIs.js ***!
  \*************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\nvar RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n    XSD = 'http://www.w3.org/2001/XMLSchema#',\n    SWAP = 'http://www.w3.org/2000/10/swap/';\nvar _default = {\n  xsd: {\n    decimal: XSD + 'decimal',\n    boolean: XSD + 'boolean',\n    double: XSD + 'double',\n    integer: XSD + 'integer',\n    string: XSD + 'string'\n  },\n  rdf: {\n    type: RDF + 'type',\n    nil: RDF + 'nil',\n    first: RDF + 'first',\n    rest: RDF + 'rest',\n    langString: RDF + 'langString'\n  },\n  owl: {\n    sameAs: 'http://www.w3.org/2002/07/owl#sameAs'\n  },\n  r: {\n    forSome: SWAP + 'reify#forSome',\n    forAll: SWAP + 'reify#forAll'\n  },\n  log: {\n    implies: SWAP + 'log#implies'\n  }\n};\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://playground/./node_modules/n3/lib/IRIs.js?");

/***/ }),

/***/ "./node_modules/n3/lib/N3DataFactory.js":
/*!**********************************************!*\
  !*** ./node_modules/n3/lib/N3DataFactory.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nvar _IRIs = _interopRequireDefault(__webpack_require__(/*! ./IRIs */ \"./node_modules/n3/lib/IRIs.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// N3.js implementations of the RDF/JS core data types\n// See https://github.com/rdfjs/representation-task-force/blob/master/interface-spec.md\nconst {\n  rdf,\n  xsd\n} = _IRIs.default;\nvar DataFactory, DEFAULTGRAPH;\nvar _blankNodeCounter = 0; // ## Term constructor\n\nclass Term {\n  constructor(id) {\n    this.id = id;\n  } // ### The value of this term\n\n\n  get value() {\n    return this.id;\n  } // ### Returns whether this object represents the same term as the other\n\n\n  equals(other) {\n    // If both terms were created by this library,\n    // equality can be computed through ids\n    if (other instanceof Term) return this.id === other.id; // Otherwise, compare term type and value\n\n    return !!other && this.termType === other.termType && this.value === other.value;\n  } // ### Returns a plain object representation of this term\n\n\n  toJSON() {\n    return {\n      termType: this.termType,\n      value: this.value\n    };\n  }\n\n} // ## NamedNode constructor\n\n\nclass NamedNode extends Term {\n  // ### The term type of this term\n  get termType() {\n    return 'NamedNode';\n  }\n\n} // ## Literal constructor\n\n\nclass Literal extends Term {\n  // ### The term type of this term\n  get termType() {\n    return 'Literal';\n  } // ### The text value of this literal\n\n\n  get value() {\n    return this.id.substring(1, this.id.lastIndexOf('\"'));\n  } // ### The language of this literal\n\n\n  get language() {\n    // Find the last quotation mark (e.g., '\"abc\"@en-us')\n    var id = this.id,\n        atPos = id.lastIndexOf('\"') + 1; // If \"@\" it follows, return the remaining substring; empty otherwise\n\n    return atPos < id.length && id[atPos++] === '@' ? id.substr(atPos).toLowerCase() : '';\n  } // ### The datatype IRI of this literal\n\n\n  get datatype() {\n    return new NamedNode(this.datatypeString);\n  } // ### The datatype string of this literal\n\n\n  get datatypeString() {\n    // Find the last quotation mark (e.g., '\"abc\"^^http://ex.org/types#t')\n    var id = this.id,\n        dtPos = id.lastIndexOf('\"') + 1,\n        ch; // If \"^\" it follows, return the remaining substring\n\n    return dtPos < id.length && (ch = id[dtPos]) === '^' ? id.substr(dtPos + 2) : // If \"@\" follows, return rdf:langString; xsd:string otherwise\n    ch !== '@' ? xsd.string : rdf.langString;\n  } // ### Returns whether this object represents the same term as the other\n\n\n  equals(other) {\n    // If both literals were created by this library,\n    // equality can be computed through ids\n    if (other instanceof Literal) return this.id === other.id; // Otherwise, compare term type, value, language, and datatype\n\n    return !!other && !!other.datatype && this.termType === other.termType && this.value === other.value && this.language === other.language && this.datatype.value === other.datatype.value;\n  }\n\n  toJSON() {\n    return {\n      termType: this.termType,\n      value: this.value,\n      language: this.language,\n      datatype: {\n        termType: 'NamedNode',\n        value: this.datatypeString\n      }\n    };\n  }\n\n} // ## BlankNode constructor\n\n\nclass BlankNode extends Term {\n  constructor(name) {\n    super('_:' + name);\n  } // ### The term type of this term\n\n\n  get termType() {\n    return 'BlankNode';\n  } // ### The name of this blank node\n\n\n  get value() {\n    return this.id.substr(2);\n  }\n\n}\n\nclass Variable extends Term {\n  constructor(name) {\n    super('?' + name);\n  } // ### The term type of this term\n\n\n  get termType() {\n    return 'Variable';\n  } // ### The name of this variable\n\n\n  get value() {\n    return this.id.substr(1);\n  }\n\n} // ## DefaultGraph constructor\n\n\nclass DefaultGraph extends Term {\n  constructor() {\n    super('');\n    return DEFAULTGRAPH || this;\n  } // ### The term type of this term\n\n\n  get termType() {\n    return 'DefaultGraph';\n  } // ### Returns whether this object represents the same term as the other\n\n\n  equals(other) {\n    // If both terms were created by this library,\n    // equality can be computed through strict equality;\n    // otherwise, compare term types.\n    return this === other || !!other && this.termType === other.termType;\n  }\n\n} // ## DefaultGraph singleton\n\n\nDEFAULTGRAPH = new DefaultGraph(); // ### Constructs a term from the given internal string ID\n\nfunction fromId(id, factory) {\n  factory = factory || DataFactory; // Falsy value or empty string indicate the default graph\n\n  if (!id) return factory.defaultGraph(); // Identify the term type based on the first character\n\n  switch (id[0]) {\n    case '_':\n      return factory.blankNode(id.substr(2));\n\n    case '?':\n      return factory.variable(id.substr(1));\n\n    case '\"':\n      // Shortcut for internal literals\n      if (factory === DataFactory) return new Literal(id); // Literal without datatype or language\n\n      if (id[id.length - 1] === '\"') return factory.literal(id.substr(1, id.length - 2)); // Literal with datatype or language\n\n      var endPos = id.lastIndexOf('\"', id.length - 1);\n      return factory.literal(id.substr(1, endPos - 1), id[endPos + 1] === '@' ? id.substr(endPos + 2) : factory.namedNode(id.substr(endPos + 3)));\n\n    default:\n      return factory.namedNode(id);\n  }\n} // ### Constructs an internal string ID from the given term or ID string\n\n\nfunction toId(term) {\n  if (typeof term === 'string') return term;\n  if (term instanceof Term) return term.id;\n  if (!term) return DEFAULTGRAPH.id; // Term instantiated with another library\n\n  switch (term.termType) {\n    case 'NamedNode':\n      return term.value;\n\n    case 'BlankNode':\n      return '_:' + term.value;\n\n    case 'Variable':\n      return '?' + term.value;\n\n    case 'DefaultGraph':\n      return '';\n\n    case 'Literal':\n      return '\"' + term.value + '\"' + (term.language ? '@' + term.language : term.datatype && term.datatype.value !== xsd.string ? '^^' + term.datatype.value : '');\n\n    default:\n      throw new Error('Unexpected termType: ' + term.termType);\n  }\n} // ## Quad constructor\n\n\nclass Quad {\n  constructor(subject, predicate, object, graph) {\n    this.subject = subject;\n    this.predicate = predicate;\n    this.object = object;\n    this.graph = graph || DEFAULTGRAPH;\n  } // ### Returns a plain object representation of this quad\n\n\n  toJSON() {\n    return {\n      subject: this.subject.toJSON(),\n      predicate: this.predicate.toJSON(),\n      object: this.object.toJSON(),\n      graph: this.graph.toJSON()\n    };\n  } // ### Returns whether this object represents the same quad as the other\n\n\n  equals(other) {\n    return !!other && this.subject.equals(other.subject) && this.predicate.equals(other.predicate) && this.object.equals(other.object) && this.graph.equals(other.graph);\n  }\n\n} // ## DataFactory singleton\n\n\nDataFactory = {\n  // ### Public factory functions\n  namedNode,\n  blankNode,\n  variable,\n  literal,\n  defaultGraph,\n  quad,\n  triple: quad,\n  // ### Internal datatype constructors\n  internal: {\n    Term,\n    NamedNode,\n    BlankNode,\n    Variable,\n    Literal,\n    DefaultGraph,\n    Quad,\n    Triple: Quad,\n    fromId,\n    toId\n  }\n};\nvar _default = DataFactory; // ### Creates an IRI\n\nexports[\"default\"] = _default;\n\nfunction namedNode(iri) {\n  return new NamedNode(iri);\n} // ### Creates a blank node\n\n\nfunction blankNode(name) {\n  if (!name) name = 'n3-' + _blankNodeCounter++;\n  return new BlankNode(name);\n} // ### Creates a literal\n\n\nfunction literal(value, languageOrDataType) {\n  // Create a language-tagged string\n  if (typeof languageOrDataType === 'string') return new Literal('\"' + value + '\"@' + languageOrDataType.toLowerCase()); // Automatically determine datatype for booleans and numbers\n\n  let datatype = languageOrDataType ? languageOrDataType.value : '';\n\n  if (datatype === '') {\n    // Convert a boolean\n    if (typeof value === 'boolean') datatype = xsd.boolean; // Convert an integer or double\n    else if (typeof value === 'number') {\n        if (Number.isFinite(value)) datatype = Number.isInteger(value) ? xsd.integer : xsd.double;else {\n          datatype = xsd.double;\n          if (!Number.isNaN(value)) value = value > 0 ? 'INF' : '-INF';\n        }\n      }\n  } // Create a datatyped literal\n\n\n  return datatype === '' || datatype === xsd.string ? new Literal('\"' + value + '\"') : new Literal('\"' + value + '\"^^' + datatype);\n} // ### Creates a variable\n\n\nfunction variable(name) {\n  return new Variable(name);\n} // ### Returns the default graph\n\n\nfunction defaultGraph() {\n  return DEFAULTGRAPH;\n} // ### Creates a quad\n\n\nfunction quad(subject, predicate, object, graph) {\n  return new Quad(subject, predicate, object, graph);\n}\n\n//# sourceURL=webpack://playground/./node_modules/n3/lib/N3DataFactory.js?");

/***/ }),

/***/ "./node_modules/n3/lib/N3Lexer.js":
/*!****************************************!*\
  !*** ./node_modules/n3/lib/N3Lexer.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nvar _IRIs = _interopRequireDefault(__webpack_require__(/*! ./IRIs */ \"./node_modules/n3/lib/IRIs.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// **N3Lexer** tokenizes N3 documents.\nconst {\n  xsd\n} = _IRIs.default;\nconst {\n  fromCharCode\n} = String; // Regular expression and replacement string to escape N3 strings.\n// Note how we catch invalid unicode sequences separately (they will trigger an error).\n\nvar escapeSequence = /\\\\u([a-fA-F0-9]{4})|\\\\U([a-fA-F0-9]{8})|\\\\[uU]|\\\\(.)/g;\nvar escapeReplacements = {\n  '\\\\': '\\\\',\n  \"'\": \"'\",\n  '\"': '\"',\n  'n': '\\n',\n  'r': '\\r',\n  't': '\\t',\n  'f': '\\f',\n  'b': '\\b',\n  '_': '_',\n  '~': '~',\n  '.': '.',\n  '-': '-',\n  '!': '!',\n  '$': '$',\n  '&': '&',\n  '(': '(',\n  ')': ')',\n  '*': '*',\n  '+': '+',\n  ',': ',',\n  ';': ';',\n  '=': '=',\n  '/': '/',\n  '?': '?',\n  '#': '#',\n  '@': '@',\n  '%': '%'\n};\nvar illegalIriChars = /[\\x00-\\x20<>\\\\\"\\{\\}\\|\\^\\`]/;\nvar lineModeRegExps = {\n  _iri: true,\n  _unescapedIri: true,\n  _simpleQuotedString: true,\n  _langcode: true,\n  _blank: true,\n  _newline: true,\n  _comment: true,\n  _whitespace: true,\n  _endOfFile: true\n};\nvar invalidRegExp = /$0^/; // ## Constructor\n\nclass N3Lexer {\n  constructor(options) {\n    // ## Regular expressions\n    // It's slightly faster to have these as properties than as in-scope variables\n    this._iri = /^<((?:[^ <>{}\\\\]|\\\\[uU])+)>[ \\t]*/; // IRI with escape sequences; needs sanity check after unescaping\n\n    this._unescapedIri = /^<([^\\x00-\\x20<>\\\\\"\\{\\}\\|\\^\\`]*)>[ \\t]*/; // IRI without escape sequences; no unescaping\n\n    this._simpleQuotedString = /^\"([^\"\\\\\\r\\n]*)\"(?=[^\"])/; // string without escape sequences\n\n    this._simpleApostropheString = /^'([^'\\\\\\r\\n]*)'(?=[^'])/;\n    this._langcode = /^@([a-z]+(?:-[a-z0-9]+)*)(?=[^a-z0-9\\-])/i;\n    this._prefix = /^((?:[A-Za-z\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02ff\\u0370-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])(?:\\.?[\\-0-9A-Z_a-z\\xb7\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u203f\\u2040\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])*)?:(?=[#\\s<])/;\n    this._prefixed = /^((?:[A-Za-z\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02ff\\u0370-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])(?:\\.?[\\-0-9A-Z_a-z\\xb7\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u203f\\u2040\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])*)?:((?:(?:[0-:A-Z_a-z\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02ff\\u0370-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff]|%[0-9a-fA-F]{2}|\\\\[!#-\\/;=?\\-@_~])(?:(?:[\\.\\-0-:A-Z_a-z\\xb7\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u203f\\u2040\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff]|%[0-9a-fA-F]{2}|\\\\[!#-\\/;=?\\-@_~])*(?:[\\-0-:A-Z_a-z\\xb7\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u203f\\u2040\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff]|%[0-9a-fA-F]{2}|\\\\[!#-\\/;=?\\-@_~]))?)?)(?:[ \\t]+|(?=\\.?[,;!\\^\\s#()\\[\\]\\{\\}\"'<]))/;\n    this._variable = /^\\?(?:(?:[A-Z_a-z\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02ff\\u0370-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])(?:[\\-0-:A-Z_a-z\\xb7\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u203f\\u2040\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])*)(?=[.,;!\\^\\s#()\\[\\]\\{\\}\"'<])/;\n    this._blank = /^_:((?:[0-9A-Z_a-z\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02ff\\u0370-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])(?:\\.?[\\-0-9A-Z_a-z\\xb7\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u203f\\u2040\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])*)(?:[ \\t]+|(?=\\.?[,;:\\s#()\\[\\]\\{\\}\"'<]))/;\n    this._number = /^[\\-+]?(?:\\d+\\.?\\d*([eE](?:[\\-\\+])?\\d+)|\\d*\\.?\\d+)(?=\\.?[,;:\\s#()\\[\\]\\{\\}\"'<])/;\n    this._boolean = /^(?:true|false)(?=[.,;\\s#()\\[\\]\\{\\}\"'<])/;\n    this._keyword = /^@[a-z]+(?=[\\s#<:])/i;\n    this._sparqlKeyword = /^(?:PREFIX|BASE|GRAPH)(?=[\\s#<])/i;\n    this._shortPredicates = /^a(?=[\\s()\\[\\]\\{\\}\"'<])/;\n    this._newline = /^[ \\t]*(?:#[^\\n\\r]*)?(?:\\r\\n|\\n|\\r)[ \\t]*/;\n    this._comment = /#([^\\n\\r]*)/;\n    this._whitespace = /^[ \\t]+/;\n    this._endOfFile = /^(?:#[^\\n\\r]*)?$/;\n    options = options || {}; // In line mode (N-Triples or N-Quads), only simple features may be parsed\n\n    if (this._lineMode = !!options.lineMode) {\n      this._n3Mode = false; // Don't tokenize special literals\n\n      for (var key in this) {\n        if (!(key in lineModeRegExps) && this[key] instanceof RegExp) this[key] = invalidRegExp;\n      }\n    } // When not in line mode, enable N3 functionality by default\n    else {\n        this._n3Mode = options.n3 !== false;\n      } // Don't output comment tokens by default\n\n\n    this._comments = !!options.comments; // Cache the last tested closing position of long literals\n\n    this._literalClosingPos = 0;\n  } // ## Private methods\n  // ### `_tokenizeToEnd` tokenizes as for as possible, emitting tokens through the callback\n\n\n  _tokenizeToEnd(callback, inputFinished) {\n    // Continue parsing as far as possible; the loop will return eventually\n    var input = this._input,\n        outputComments = this._comments;\n\n    while (true) {\n      // Count and skip whitespace lines\n      var whiteSpaceMatch, comment;\n\n      while (whiteSpaceMatch = this._newline.exec(input)) {\n        // Try to find a comment\n        if (outputComments && (comment = this._comment.exec(whiteSpaceMatch[0]))) callback(null, {\n          line: this._line,\n          type: 'comment',\n          value: comment[1],\n          prefix: ''\n        }); // Advance the input\n\n        input = input.substr(whiteSpaceMatch[0].length, input.length);\n        this._line++;\n      } // Skip whitespace on current line\n\n\n      if (!whiteSpaceMatch && (whiteSpaceMatch = this._whitespace.exec(input))) input = input.substr(whiteSpaceMatch[0].length, input.length); // Stop for now if we're at the end\n\n      if (this._endOfFile.test(input)) {\n        // If the input is finished, emit EOF\n        if (inputFinished) {\n          // Try to find a final comment\n          if (outputComments && (comment = this._comment.exec(input))) callback(null, {\n            line: this._line,\n            type: 'comment',\n            value: comment[1],\n            prefix: ''\n          });\n          callback(input = null, {\n            line: this._line,\n            type: 'eof',\n            value: '',\n            prefix: ''\n          });\n        }\n\n        return this._input = input;\n      } // Look for specific token types based on the first character\n\n\n      var line = this._line,\n          type = '',\n          value = '',\n          prefix = '',\n          firstChar = input[0],\n          match = null,\n          matchLength = 0,\n          inconclusive = false;\n\n      switch (firstChar) {\n        case '^':\n          // We need at least 3 tokens lookahead to distinguish ^^<IRI> and ^^pre:fixed\n          if (input.length < 3) break; // Try to match a type\n          else if (input[1] === '^') {\n              this._previousMarker = '^^'; // Move to type IRI or prefixed name\n\n              input = input.substr(2);\n\n              if (input[0] !== '<') {\n                inconclusive = true;\n                break;\n              }\n            } // If no type, it must be a path expression\n            else {\n                if (this._n3Mode) {\n                  matchLength = 1;\n                  type = '^';\n                }\n\n                break;\n              }\n        // Fall through in case the type is an IRI\n\n        case '<':\n          // Try to find a full IRI without escape sequences\n          if (match = this._unescapedIri.exec(input)) type = 'IRI', value = match[1]; // Try to find a full IRI with escape sequences\n          else if (match = this._iri.exec(input)) {\n              value = this._unescape(match[1]);\n              if (value === null || illegalIriChars.test(value)) return reportSyntaxError(this);\n              type = 'IRI';\n            } // Try to find a backwards implication arrow\n            else if (this._n3Mode && input.length > 1 && input[1] === '=') type = 'inverse', matchLength = 2, value = '>';\n          break;\n\n        case '_':\n          // Try to find a blank node. Since it can contain (but not end with) a dot,\n          // we always need a non-dot character before deciding it is a blank node.\n          // Therefore, try inserting a space if we're at the end of the input.\n          if ((match = this._blank.exec(input)) || inputFinished && (match = this._blank.exec(input + ' '))) type = 'blank', prefix = '_', value = match[1];\n          break;\n\n        case '\"':\n          // Try to find a literal without escape sequences\n          if (match = this._simpleQuotedString.exec(input)) value = match[1]; // Try to find a literal wrapped in three pairs of quotes\n          else {\n              ({\n                value,\n                matchLength\n              } = this._parseLiteral(input));\n              if (value === null) return reportSyntaxError(this);\n            }\n\n          if (match !== null || matchLength !== 0) {\n            type = 'literal';\n            this._literalClosingPos = 0;\n          }\n\n          break;\n\n        case \"'\":\n          if (!this._lineMode) {\n            // Try to find a literal without escape sequences\n            if (match = this._simpleApostropheString.exec(input)) value = match[1]; // Try to find a literal wrapped in three pairs of quotes\n            else {\n                ({\n                  value,\n                  matchLength\n                } = this._parseLiteral(input));\n                if (value === null) return reportSyntaxError(this);\n              }\n\n            if (match !== null || matchLength !== 0) {\n              type = 'literal';\n              this._literalClosingPos = 0;\n            }\n          }\n\n          break;\n\n        case '?':\n          // Try to find a variable\n          if (this._n3Mode && (match = this._variable.exec(input))) type = 'var', value = match[0];\n          break;\n\n        case '@':\n          // Try to find a language code\n          if (this._previousMarker === 'literal' && (match = this._langcode.exec(input))) type = 'langcode', value = match[1]; // Try to find a keyword\n          else if (match = this._keyword.exec(input)) type = match[0];\n          break;\n\n        case '.':\n          // Try to find a dot as punctuation\n          if (input.length === 1 ? inputFinished : input[1] < '0' || input[1] > '9') {\n            type = '.';\n            matchLength = 1;\n            break;\n          }\n\n        // Fall through to numerical case (could be a decimal dot)\n\n        case '0':\n        case '1':\n        case '2':\n        case '3':\n        case '4':\n        case '5':\n        case '6':\n        case '7':\n        case '8':\n        case '9':\n        case '+':\n        case '-':\n          // Try to find a number. Since it can contain (but not end with) a dot,\n          // we always need a non-dot character before deciding it is a number.\n          // Therefore, try inserting a space if we're at the end of the input.\n          if (match = this._number.exec(input) || inputFinished && (match = this._number.exec(input + ' '))) {\n            type = 'literal', value = match[0];\n            prefix = match[1] ? xsd.double : /^[+\\-]?\\d+$/.test(match[0]) ? xsd.integer : xsd.decimal;\n          }\n\n          break;\n\n        case 'B':\n        case 'b':\n        case 'p':\n        case 'P':\n        case 'G':\n        case 'g':\n          // Try to find a SPARQL-style keyword\n          if (match = this._sparqlKeyword.exec(input)) type = match[0].toUpperCase();else inconclusive = true;\n          break;\n\n        case 'f':\n        case 't':\n          // Try to match a boolean\n          if (match = this._boolean.exec(input)) type = 'literal', value = match[0], prefix = xsd.boolean;else inconclusive = true;\n          break;\n\n        case 'a':\n          // Try to find an abbreviated predicate\n          if (match = this._shortPredicates.exec(input)) type = 'abbreviation', value = 'a';else inconclusive = true;\n          break;\n\n        case '=':\n          // Try to find an implication arrow or equals sign\n          if (this._n3Mode && input.length > 1) {\n            type = 'abbreviation';\n            if (input[1] !== '>') matchLength = 1, value = '=';else matchLength = 2, value = '>';\n          }\n\n          break;\n\n        case '!':\n          if (!this._n3Mode) break;\n\n        case ',':\n        case ';':\n        case '[':\n        case ']':\n        case '(':\n        case ')':\n        case '{':\n        case '}':\n          if (!this._lineMode) {\n            matchLength = 1;\n            type = firstChar;\n          }\n\n          break;\n\n        default:\n          inconclusive = true;\n      } // Some first characters do not allow an immediate decision, so inspect more\n\n\n      if (inconclusive) {\n        // Try to find a prefix\n        if ((this._previousMarker === '@prefix' || this._previousMarker === 'PREFIX') && (match = this._prefix.exec(input))) type = 'prefix', value = match[1] || ''; // Try to find a prefixed name. Since it can contain (but not end with) a dot,\n        // we always need a non-dot character before deciding it is a prefixed name.\n        // Therefore, try inserting a space if we're at the end of the input.\n        else if ((match = this._prefixed.exec(input)) || inputFinished && (match = this._prefixed.exec(input + ' '))) type = 'prefixed', prefix = match[1] || '', value = this._unescape(match[2]);\n      } // A type token is special: it can only be emitted after an IRI or prefixed name is read\n\n\n      if (this._previousMarker === '^^') {\n        switch (type) {\n          case 'prefixed':\n            type = 'type';\n            break;\n\n          case 'IRI':\n            type = 'typeIRI';\n            break;\n\n          default:\n            type = '';\n        }\n      } // What if nothing of the above was found?\n\n\n      if (!type) {\n        // We could be in streaming mode, and then we just wait for more input to arrive.\n        // Otherwise, a syntax error has occurred in the input.\n        // One exception: error on an unaccounted linebreak (= not inside a triple-quoted literal).\n        if (inputFinished || !/^'''|^\"\"\"/.test(input) && /\\n|\\r/.test(input)) return reportSyntaxError(this);else return this._input = input;\n      } // Emit the parsed token\n\n\n      var token = {\n        line: line,\n        type: type,\n        value: value,\n        prefix: prefix\n      };\n      callback(null, token);\n      this.previousToken = token;\n      this._previousMarker = type; // Advance to next part to tokenize\n\n      input = input.substr(matchLength || match[0].length, input.length);\n    } // Signals the syntax error through the callback\n\n\n    function reportSyntaxError(self) {\n      callback(self._syntaxError(/^\\S*/.exec(input)[0]));\n    }\n  } // ### `_unescape` replaces N3 escape codes by their corresponding characters\n\n\n  _unescape(item) {\n    try {\n      return item.replace(escapeSequence, function (sequence, unicode4, unicode8, escapedChar) {\n        var charCode;\n\n        if (unicode4) {\n          charCode = parseInt(unicode4, 16);\n          if (isNaN(charCode)) throw new Error(); // can never happen (regex), but helps performance\n\n          return fromCharCode(charCode);\n        } else if (unicode8) {\n          charCode = parseInt(unicode8, 16);\n          if (isNaN(charCode)) throw new Error(); // can never happen (regex), but helps performance\n\n          if (charCode <= 0xFFFF) return fromCharCode(charCode);\n          return fromCharCode(0xD800 + (charCode -= 0x10000) / 0x400, 0xDC00 + (charCode & 0x3FF));\n        } else {\n          var replacement = escapeReplacements[escapedChar];\n          if (!replacement) throw new Error();\n          return replacement;\n        }\n      });\n    } catch (error) {\n      return null;\n    }\n  } // ### `_parseLiteral` parses a literal into an unescaped value\n\n\n  _parseLiteral(input) {\n    // Ensure we have enough lookahead to identify triple-quoted strings\n    if (input.length >= 3) {\n      // Identify the opening quote(s)\n      const opening = input.match(/^(?:\"\"\"|\"|'''|'|)/)[0];\n      const openingLength = opening.length; // Find the next candidate closing quotes\n\n      let closingPos = Math.max(this._literalClosingPos, openingLength);\n\n      while ((closingPos = input.indexOf(opening, closingPos)) > 0) {\n        // Count backslashes right before the closing quotes\n        let backslashCount = 0;\n\n        while (input[closingPos - backslashCount - 1] === '\\\\') backslashCount++; // An even number of backslashes (in particular 0)\n        // means these are actual, non-escaped closing quotes\n\n\n        if (backslashCount % 2 === 0) {\n          // Extract and unescape the value\n          const raw = input.substring(openingLength, closingPos);\n          const lines = raw.split(/\\r\\n|\\r|\\n/).length - 1;\n          const matchLength = closingPos + openingLength; // Only triple-quoted strings can be multi-line\n\n          if (openingLength === 1 && lines !== 0 || openingLength === 3 && this._lineMode) break;\n          this._line += lines;\n          return {\n            value: this._unescape(raw),\n            matchLength\n          };\n        }\n\n        closingPos++;\n      }\n\n      this._literalClosingPos = input.length - openingLength + 1;\n    }\n\n    return {\n      value: '',\n      matchLength: 0\n    };\n  } // ### `_syntaxError` creates a syntax error for the given issue\n\n\n  _syntaxError(issue) {\n    this._input = null;\n    var err = new Error('Unexpected \"' + issue + '\" on line ' + this._line + '.');\n    err.context = {\n      token: undefined,\n      line: this._line,\n      previousToken: this.previousToken\n    };\n    return err;\n  } // ## Public methods\n  // ### `tokenize` starts the transformation of an N3 document into an array of tokens.\n  // The input can be a string or a stream.\n\n\n  tokenize(input, callback) {\n    var self = this;\n    this._line = 1; // If the input is a string, continuously emit tokens through the callback until the end\n\n    if (typeof input === 'string') {\n      this._input = input; // If a callback was passed, asynchronously call it\n\n      if (typeof callback === 'function') setImmediate(function () {\n        self._tokenizeToEnd(callback, true);\n      }); // If no callback was passed, tokenize synchronously and return\n      else {\n          var tokens = [],\n              error;\n\n          this._tokenizeToEnd(function (e, t) {\n            e ? error = e : tokens.push(t);\n          }, true);\n\n          if (error) throw error;\n          return tokens;\n        }\n    } // Otherwise, the input must be a stream\n    else {\n        this._input = '';\n        this._pendingBuffer = null;\n        if (typeof input.setEncoding === 'function') input.setEncoding('utf8'); // Adds the data chunk to the buffer and parses as far as possible\n\n        input.on('data', function (data) {\n          if (self._input !== null && data.length !== 0) {\n            // Prepend any previous pending writes\n            if (self._pendingBuffer) {\n              data = Buffer.concat([self._pendingBuffer, data]);\n              self._pendingBuffer = null;\n            } // Hold if the buffer ends in an incomplete unicode sequence\n\n\n            if (data[data.length - 1] & 0x80) {\n              self._pendingBuffer = data;\n            } // Otherwise, tokenize as far as possible\n            else {\n                self._input += data;\n\n                self._tokenizeToEnd(callback, false);\n              }\n          }\n        }); // Parses until the end\n\n        input.on('end', function () {\n          if (self._input !== null) self._tokenizeToEnd(callback, true);\n        });\n        input.on('error', callback);\n      }\n  }\n\n}\n\nexports[\"default\"] = N3Lexer;\n\n//# sourceURL=webpack://playground/./node_modules/n3/lib/N3Lexer.js?");

/***/ }),

/***/ "./node_modules/n3/lib/N3Parser.js":
/*!*****************************************!*\
  !*** ./node_modules/n3/lib/N3Parser.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nvar _N3Lexer = _interopRequireDefault(__webpack_require__(/*! ./N3Lexer */ \"./node_modules/n3/lib/N3Lexer.js\"));\n\nvar _N3DataFactory = _interopRequireDefault(__webpack_require__(/*! ./N3DataFactory */ \"./node_modules/n3/lib/N3DataFactory.js\"));\n\nvar _IRIs = _interopRequireDefault(__webpack_require__(/*! ./IRIs */ \"./node_modules/n3/lib/IRIs.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// **N3Parser** parses N3 documents.\n// The next ID for new blank nodes\nvar blankNodePrefix = 0,\n    blankNodeCount = 0; // ## Constructor\n\nclass N3Parser {\n  constructor(options) {\n    this._contextStack = [];\n    this._graph = null; // Set the document IRI\n\n    options = options || {};\n\n    this._setBase(options.baseIRI);\n\n    options.factory && initDataFactory(this, options.factory); // Set supported features depending on the format\n\n    var format = typeof options.format === 'string' ? options.format.match(/\\w*$/)[0].toLowerCase() : '',\n        isTurtle = format === 'turtle',\n        isTriG = format === 'trig',\n        isNTriples = /triple/.test(format),\n        isNQuads = /quad/.test(format),\n        isN3 = this._n3Mode = /n3/.test(format),\n        isLineMode = isNTriples || isNQuads;\n    if (!(this._supportsNamedGraphs = !(isTurtle || isN3))) this._readPredicateOrNamedGraph = this._readPredicate;\n    this._supportsQuads = !(isTurtle || isTriG || isNTriples || isN3); // Disable relative IRIs in N-Triples or N-Quads mode\n\n    if (isLineMode) this._resolveRelativeIRI = function (iri) {\n      return null;\n    };\n    this._blankNodePrefix = typeof options.blankNodePrefix !== 'string' ? '' : options.blankNodePrefix.replace(/^(?!_:)/, '_:');\n    this._lexer = options.lexer || new _N3Lexer.default({\n      lineMode: isLineMode,\n      n3: isN3\n    }); // Disable explicit quantifiers by default\n\n    this._explicitQuantifiers = !!options.explicitQuantifiers;\n  } // ## Static class methods\n  // ### `_resetBlankNodeIds` restarts blank node identification\n\n\n  static _resetBlankNodeIds() {\n    blankNodePrefix = blankNodeCount = 0;\n  } // ## Private methods\n  // ### `_blank` creates a new blank node\n\n\n  _blank() {\n    return this._blankNode('b' + blankNodeCount++);\n  } // ### `_setBase` sets the base IRI to resolve relative IRIs\n\n\n  _setBase(baseIRI) {\n    if (!baseIRI) {\n      this._base = '';\n      this._basePath = '';\n    } else {\n      // Remove fragment if present\n      var fragmentPos = baseIRI.indexOf('#');\n      if (fragmentPos >= 0) baseIRI = baseIRI.substr(0, fragmentPos); // Set base IRI and its components\n\n      this._base = baseIRI;\n      this._basePath = baseIRI.indexOf('/') < 0 ? baseIRI : baseIRI.replace(/[^\\/?]*(?:\\?.*)?$/, '');\n      baseIRI = baseIRI.match(/^(?:([a-z][a-z0-9+.-]*:))?(?:\\/\\/[^\\/]*)?/i);\n      this._baseRoot = baseIRI[0];\n      this._baseScheme = baseIRI[1];\n    }\n  } // ### `_saveContext` stores the current parsing context\n  // when entering a new scope (list, blank node, formula)\n\n\n  _saveContext(type, graph, subject, predicate, object) {\n    var n3Mode = this._n3Mode;\n\n    this._contextStack.push({\n      subject: subject,\n      predicate: predicate,\n      object: object,\n      graph: graph,\n      type: type,\n      inverse: n3Mode ? this._inversePredicate : false,\n      blankPrefix: n3Mode ? this._prefixes._ : '',\n      quantified: n3Mode ? this._quantified : null\n    }); // The settings below only apply to N3 streams\n\n\n    if (n3Mode) {\n      // Every new scope resets the predicate direction\n      this._inversePredicate = false; // In N3, blank nodes are scoped to a formula\n      // (using a dot as separator, as a blank node label cannot start with it)\n\n      this._prefixes._ = this._graph ? this._graph.id.substr(2) + '.' : '.'; // Quantifiers are scoped to a formula\n\n      this._quantified = Object.create(this._quantified);\n    }\n  } // ### `_restoreContext` restores the parent context\n  // when leaving a scope (list, blank node, formula)\n\n\n  _restoreContext() {\n    var context = this._contextStack.pop(),\n        n3Mode = this._n3Mode;\n\n    this._subject = context.subject;\n    this._predicate = context.predicate;\n    this._object = context.object;\n    this._graph = context.graph; // The settings below only apply to N3 streams\n\n    if (n3Mode) {\n      this._inversePredicate = context.inverse;\n      this._prefixes._ = context.blankPrefix;\n      this._quantified = context.quantified;\n    }\n  } // ### `_readInTopContext` reads a token when in the top context\n\n\n  _readInTopContext(token) {\n    switch (token.type) {\n      // If an EOF token arrives in the top context, signal that we're done\n      case 'eof':\n        if (this._graph !== null) return this._error('Unclosed graph', token);\n        delete this._prefixes._;\n        return this._callback(null, null, this._prefixes);\n      // It could be a prefix declaration\n\n      case 'PREFIX':\n        this._sparqlStyle = true;\n\n      case '@prefix':\n        return this._readPrefix;\n      // It could be a base declaration\n\n      case 'BASE':\n        this._sparqlStyle = true;\n\n      case '@base':\n        return this._readBaseIRI;\n      // It could be a graph\n\n      case '{':\n        if (this._supportsNamedGraphs) {\n          this._graph = '';\n          this._subject = null;\n          return this._readSubject;\n        }\n\n      case 'GRAPH':\n        if (this._supportsNamedGraphs) return this._readNamedGraphLabel;\n      // Otherwise, the next token must be a subject\n\n      default:\n        return this._readSubject(token);\n    }\n  } // ### `_readEntity` reads an IRI, prefixed name, blank node, or variable\n\n\n  _readEntity(token, quantifier) {\n    var value;\n\n    switch (token.type) {\n      // Read a relative or absolute IRI\n      case 'IRI':\n      case 'typeIRI':\n        var iri = this._resolveIRI(token.value);\n\n        if (iri === null) return this._error('Invalid IRI', token);\n        value = this._namedNode(iri);\n        break;\n      // Read a prefixed name\n\n      case 'type':\n      case 'prefixed':\n        var prefix = this._prefixes[token.prefix];\n        if (prefix === undefined) return this._error('Undefined prefix \"' + token.prefix + ':\"', token);\n        value = this._namedNode(prefix + token.value);\n        break;\n      // Read a blank node\n\n      case 'blank':\n        value = this._blankNode(this._prefixes[token.prefix] + token.value);\n        break;\n      // Read a variable\n\n      case 'var':\n        value = this._variable(token.value.substr(1));\n        break;\n      // Everything else is not an entity\n\n      default:\n        return this._error('Expected entity but got ' + token.type, token);\n    } // In N3 mode, replace the entity if it is quantified\n\n\n    if (!quantifier && this._n3Mode && value.id in this._quantified) value = this._quantified[value.id];\n    return value;\n  } // ### `_readSubject` reads a quad's subject\n\n\n  _readSubject(token) {\n    this._predicate = null;\n\n    switch (token.type) {\n      case '[':\n        // Start a new quad with a new blank node as subject\n        this._saveContext('blank', this._graph, this._subject = this._blank(), null, null);\n\n        return this._readBlankNodeHead;\n\n      case '(':\n        // Start a new list\n        this._saveContext('list', this._graph, this.RDF_NIL, null, null);\n\n        this._subject = null;\n        return this._readListItem;\n\n      case '{':\n        // Start a new formula\n        if (!this._n3Mode) return this._error('Unexpected graph', token);\n\n        this._saveContext('formula', this._graph, this._graph = this._blank(), null, null);\n\n        return this._readSubject;\n\n      case '}':\n        // No subject; the graph in which we are reading is closed instead\n        return this._readPunctuation(token);\n\n      case '@forSome':\n        if (!this._n3Mode) return this._error('Unexpected \"@forSome\"', token);\n        this._subject = null;\n        this._predicate = this.N3_FORSOME;\n        this._quantifier = this._blankNode;\n        return this._readQuantifierList;\n\n      case '@forAll':\n        if (!this._n3Mode) return this._error('Unexpected \"@forAll\"', token);\n        this._subject = null;\n        this._predicate = this.N3_FORALL;\n        this._quantifier = this._variable;\n        return this._readQuantifierList;\n\n      default:\n        // Read the subject entity\n        if ((this._subject = this._readEntity(token)) === undefined) return; // In N3 mode, the subject might be a path\n\n        if (this._n3Mode) return this._getPathReader(this._readPredicateOrNamedGraph);\n    } // The next token must be a predicate,\n    // or, if the subject was actually a graph IRI, a named graph\n\n\n    return this._readPredicateOrNamedGraph;\n  } // ### `_readPredicate` reads a quad's predicate\n\n\n  _readPredicate(token) {\n    var type = token.type;\n\n    switch (type) {\n      case 'inverse':\n        this._inversePredicate = true;\n\n      case 'abbreviation':\n        this._predicate = this.ABBREVIATIONS[token.value];\n        break;\n\n      case '.':\n      case ']':\n      case '}':\n        // Expected predicate didn't come, must have been trailing semicolon\n        if (this._predicate === null) return this._error('Unexpected ' + type, token);\n        this._subject = null;\n        return type === ']' ? this._readBlankNodeTail(token) : this._readPunctuation(token);\n\n      case ';':\n        // Additional semicolons can be safely ignored\n        return this._predicate !== null ? this._readPredicate : this._error('Expected predicate but got ;', token);\n\n      case 'blank':\n        if (!this._n3Mode) return this._error('Disallowed blank node as predicate', token);\n\n      default:\n        if ((this._predicate = this._readEntity(token)) === undefined) return;\n    } // The next token must be an object\n\n\n    return this._readObject;\n  } // ### `_readObject` reads a quad's object\n\n\n  _readObject(token) {\n    switch (token.type) {\n      case 'literal':\n        // Regular literal, can still get a datatype or language\n        if (token.prefix.length === 0) {\n          this._literalValue = token.value;\n          return this._readDataTypeOrLang;\n        } // Pre-datatyped string literal (prefix stores the datatype)\n        else this._object = this._literal(token.value, this._namedNode(token.prefix));\n\n        break;\n\n      case '[':\n        // Start a new quad with a new blank node as subject\n        this._saveContext('blank', this._graph, this._subject, this._predicate, this._subject = this._blank());\n\n        return this._readBlankNodeHead;\n\n      case '(':\n        // Start a new list\n        this._saveContext('list', this._graph, this._subject, this._predicate, this.RDF_NIL);\n\n        this._subject = null;\n        return this._readListItem;\n\n      case '{':\n        // Start a new formula\n        if (!this._n3Mode) return this._error('Unexpected graph', token);\n\n        this._saveContext('formula', this._graph, this._subject, this._predicate, this._graph = this._blank());\n\n        return this._readSubject;\n\n      default:\n        // Read the object entity\n        if ((this._object = this._readEntity(token)) === undefined) return; // In N3 mode, the object might be a path\n\n        if (this._n3Mode) return this._getPathReader(this._getContextEndReader());\n    }\n\n    return this._getContextEndReader();\n  } // ### `_readPredicateOrNamedGraph` reads a quad's predicate, or a named graph\n\n\n  _readPredicateOrNamedGraph(token) {\n    return token.type === '{' ? this._readGraph(token) : this._readPredicate(token);\n  } // ### `_readGraph` reads a graph\n\n\n  _readGraph(token) {\n    if (token.type !== '{') return this._error('Expected graph but got ' + token.type, token); // The \"subject\" we read is actually the GRAPH's label\n\n    this._graph = this._subject, this._subject = null;\n    return this._readSubject;\n  } // ### `_readBlankNodeHead` reads the head of a blank node\n\n\n  _readBlankNodeHead(token) {\n    if (token.type === ']') {\n      this._subject = null;\n      return this._readBlankNodeTail(token);\n    } else {\n      this._predicate = null;\n      return this._readPredicate(token);\n    }\n  } // ### `_readBlankNodeTail` reads the end of a blank node\n\n\n  _readBlankNodeTail(token) {\n    if (token.type !== ']') return this._readBlankNodePunctuation(token); // Store blank node quad\n\n    if (this._subject !== null) this._emit(this._subject, this._predicate, this._object, this._graph); // Restore the parent context containing this blank node\n\n    var empty = this._predicate === null;\n\n    this._restoreContext(); // If the blank node was the subject, continue reading the predicate\n\n\n    if (this._object === null) // If the blank node was empty, it could be a named graph label\n      return empty ? this._readPredicateOrNamedGraph : this._readPredicateAfterBlank; // If the blank node was the object, restore previous context and read punctuation\n    else return this._getContextEndReader();\n  } // ### `_readPredicateAfterBlank` reads a predicate after an anonymous blank node\n\n\n  _readPredicateAfterBlank(token) {\n    switch (token.type) {\n      case '.':\n      case '}':\n        // No predicate is coming if the triple is terminated here\n        this._subject = null;\n        return this._readPunctuation(token);\n\n      default:\n        return this._readPredicate(token);\n    }\n  } // ### `_readListItem` reads items from a list\n\n\n  _readListItem(token) {\n    var item = null,\n        // The item of the list\n    list = null,\n        // The list itself\n    previousList = this._subject,\n        // The previous list that contains this list\n    stack = this._contextStack,\n        // The stack of parent contexts\n    parent = stack[stack.length - 1],\n        // The parent containing the current list\n    next = this._readListItem; // The next function to execute\n\n    switch (token.type) {\n      case '[':\n        // Stack the current list quad and start a new quad with a blank node as subject\n        this._saveContext('blank', this._graph, list = this._blank(), this.RDF_FIRST, this._subject = item = this._blank());\n\n        next = this._readBlankNodeHead;\n        break;\n\n      case '(':\n        // Stack the current list quad and start a new list\n        this._saveContext('list', this._graph, list = this._blank(), this.RDF_FIRST, this.RDF_NIL);\n\n        this._subject = null;\n        break;\n\n      case ')':\n        // Closing the list; restore the parent context\n        this._restoreContext(); // If this list is contained within a parent list, return the membership quad here.\n        // This will be `<parent list element> rdf:first <this list>.`.\n\n\n        if (stack.length !== 0 && stack[stack.length - 1].type === 'list') this._emit(this._subject, this._predicate, this._object, this._graph); // Was this list the parent's subject?\n\n        if (this._predicate === null) {\n          // The next token is the predicate\n          next = this._readPredicate; // No list tail if this was an empty list\n\n          if (this._subject === this.RDF_NIL) return next;\n        } // The list was in the parent context's object\n        else {\n            next = this._getContextEndReader(); // No list tail if this was an empty list\n\n            if (this._object === this.RDF_NIL) return next;\n          } // Close the list by making the head nil\n\n\n        list = this.RDF_NIL;\n        break;\n\n      case 'literal':\n        // Regular literal, can still get a datatype or language\n        if (token.prefix.length === 0) {\n          this._literalValue = token.value;\n          next = this._readListItemDataTypeOrLang;\n        } // Pre-datatyped string literal (prefix stores the datatype)\n        else {\n            item = this._literal(token.value, this._namedNode(token.prefix));\n            next = this._getContextEndReader();\n          }\n\n        break;\n\n      default:\n        if ((item = this._readEntity(token)) === undefined) return;\n    } // Create a new blank node if no item head was assigned yet\n\n\n    if (list === null) this._subject = list = this._blank(); // Is this the first element of the list?\n\n    if (previousList === null) {\n      // This list is either the subject or the object of its parent\n      if (parent.predicate === null) parent.subject = list;else parent.object = list;\n    } else {\n      // Continue the previous list with the current list\n      this._emit(previousList, this.RDF_REST, list, this._graph);\n    } // If an item was read, add it to the list\n\n\n    if (item !== null) {\n      // In N3 mode, the item might be a path\n      if (this._n3Mode && (token.type === 'IRI' || token.type === 'prefixed')) {\n        // Create a new context to add the item's path\n        this._saveContext('item', this._graph, list, this.RDF_FIRST, item);\n\n        this._subject = item, this._predicate = null; // _readPath will restore the context and output the item\n\n        return this._getPathReader(this._readListItem);\n      } // Output the item\n\n\n      this._emit(list, this.RDF_FIRST, item, this._graph);\n    }\n\n    return next;\n  } // ### `_readDataTypeOrLang` reads an _optional_ datatype or language\n\n\n  _readDataTypeOrLang(token) {\n    return this._completeLiteral(token, false);\n  } // ### `_readListItemDataTypeOrLang` reads an _optional_ datatype or language in a list\n\n\n  _readListItemDataTypeOrLang(token) {\n    return this._completeLiteral(token, true);\n  } // ### `_completeLiteral` completes a literal with an optional datatype or language\n\n\n  _completeLiteral(token, listItem) {\n    switch (token.type) {\n      // Create a datatyped literal\n      case 'type':\n      case 'typeIRI':\n        var datatype = this._readEntity(token);\n\n        if (datatype === undefined) return; // No datatype means an error occurred\n\n        this._object = this._literal(this._literalValue, datatype);\n        token = null;\n        break;\n      // Create a language-tagged string\n\n      case 'langcode':\n        this._object = this._literal(this._literalValue, token.value);\n        token = null;\n        break;\n      // Create a simple string literal\n\n      default:\n        this._object = this._literal(this._literalValue);\n    } // If this literal was part of a list, write the item\n    // (we could also check the context stack, but passing in a flag is faster)\n\n\n    if (listItem) this._emit(this._subject, this.RDF_FIRST, this._object, this._graph); // If the token was consumed, continue with the rest of the input\n\n    if (token === null) return this._getContextEndReader(); // Otherwise, consume the token now\n    else {\n        this._readCallback = this._getContextEndReader();\n        return this._readCallback(token);\n      }\n  } // ### `_readFormulaTail` reads the end of a formula\n\n\n  _readFormulaTail(token) {\n    if (token.type !== '}') return this._readPunctuation(token); // Store the last quad of the formula\n\n    if (this._subject !== null) this._emit(this._subject, this._predicate, this._object, this._graph); // Restore the parent context containing this formula\n\n    this._restoreContext(); // If the formula was the subject, continue reading the predicate.\n    // If the formula was the object, read punctuation.\n\n\n    return this._object === null ? this._readPredicate : this._getContextEndReader();\n  } // ### `_readPunctuation` reads punctuation between quads or quad parts\n\n\n  _readPunctuation(token) {\n    var next,\n        subject = this._subject,\n        graph = this._graph,\n        inversePredicate = this._inversePredicate;\n\n    switch (token.type) {\n      // A closing brace ends a graph\n      case '}':\n        if (this._graph === null) return this._error('Unexpected graph closing', token);\n        if (this._n3Mode) return this._readFormulaTail(token);\n        this._graph = null;\n      // A dot just ends the statement, without sharing anything with the next\n\n      case '.':\n        this._subject = null;\n        next = this._contextStack.length ? this._readSubject : this._readInTopContext;\n        if (inversePredicate) this._inversePredicate = false;\n        break;\n      // Semicolon means the subject is shared; predicate and object are different\n\n      case ';':\n        next = this._readPredicate;\n        break;\n      // Comma means both the subject and predicate are shared; the object is different\n\n      case ',':\n        next = this._readObject;\n        break;\n\n      default:\n        // An entity means this is a quad (only allowed if not already inside a graph)\n        if (this._supportsQuads && this._graph === null && (graph = this._readEntity(token)) !== undefined) {\n          next = this._readQuadPunctuation;\n          break;\n        }\n\n        return this._error('Expected punctuation to follow \"' + this._object.id + '\"', token);\n    } // A quad has been completed now, so return it\n\n\n    if (subject !== null) {\n      var predicate = this._predicate,\n          object = this._object;\n      if (!inversePredicate) this._emit(subject, predicate, object, graph);else this._emit(object, predicate, subject, graph);\n    }\n\n    return next;\n  } // ### `_readBlankNodePunctuation` reads punctuation in a blank node\n\n\n  _readBlankNodePunctuation(token) {\n    var next;\n\n    switch (token.type) {\n      // Semicolon means the subject is shared; predicate and object are different\n      case ';':\n        next = this._readPredicate;\n        break;\n      // Comma means both the subject and predicate are shared; the object is different\n\n      case ',':\n        next = this._readObject;\n        break;\n\n      default:\n        return this._error('Expected punctuation to follow \"' + this._object.id + '\"', token);\n    } // A quad has been completed now, so return it\n\n\n    this._emit(this._subject, this._predicate, this._object, this._graph);\n\n    return next;\n  } // ### `_readQuadPunctuation` reads punctuation after a quad\n\n\n  _readQuadPunctuation(token) {\n    if (token.type !== '.') return this._error('Expected dot to follow quad', token);\n    return this._readInTopContext;\n  } // ### `_readPrefix` reads the prefix of a prefix declaration\n\n\n  _readPrefix(token) {\n    if (token.type !== 'prefix') return this._error('Expected prefix to follow @prefix', token);\n    this._prefix = token.value;\n    return this._readPrefixIRI;\n  } // ### `_readPrefixIRI` reads the IRI of a prefix declaration\n\n\n  _readPrefixIRI(token) {\n    if (token.type !== 'IRI') return this._error('Expected IRI to follow prefix \"' + this._prefix + ':\"', token);\n\n    var prefixNode = this._readEntity(token);\n\n    this._prefixes[this._prefix] = prefixNode.value;\n\n    this._prefixCallback(this._prefix, prefixNode);\n\n    return this._readDeclarationPunctuation;\n  } // ### `_readBaseIRI` reads the IRI of a base declaration\n\n\n  _readBaseIRI(token) {\n    var iri = token.type === 'IRI' && this._resolveIRI(token.value);\n\n    if (!iri) return this._error('Expected valid IRI to follow base declaration', token);\n\n    this._setBase(iri);\n\n    return this._readDeclarationPunctuation;\n  } // ### `_readNamedGraphLabel` reads the label of a named graph\n\n\n  _readNamedGraphLabel(token) {\n    switch (token.type) {\n      case 'IRI':\n      case 'blank':\n      case 'prefixed':\n        return this._readSubject(token), this._readGraph;\n\n      case '[':\n        return this._readNamedGraphBlankLabel;\n\n      default:\n        return this._error('Invalid graph label', token);\n    }\n  } // ### `_readNamedGraphLabel` reads a blank node label of a named graph\n\n\n  _readNamedGraphBlankLabel(token) {\n    if (token.type !== ']') return this._error('Invalid graph label', token);\n    this._subject = this._blank();\n    return this._readGraph;\n  } // ### `_readDeclarationPunctuation` reads the punctuation of a declaration\n\n\n  _readDeclarationPunctuation(token) {\n    // SPARQL-style declarations don't have punctuation\n    if (this._sparqlStyle) {\n      this._sparqlStyle = false;\n      return this._readInTopContext(token);\n    }\n\n    if (token.type !== '.') return this._error('Expected declaration to end with a dot', token);\n    return this._readInTopContext;\n  } // Reads a list of quantified symbols from a @forSome or @forAll statement\n\n\n  _readQuantifierList(token) {\n    var entity;\n\n    switch (token.type) {\n      case 'IRI':\n      case 'prefixed':\n        if ((entity = this._readEntity(token, true)) !== undefined) break;\n\n      default:\n        return this._error('Unexpected ' + token.type, token);\n    } // Without explicit quantifiers, map entities to a quantified entity\n\n\n    if (!this._explicitQuantifiers) this._quantified[entity.id] = this._quantifier('b' + blankNodeCount++); // With explicit quantifiers, output the reified quantifier\n    else {\n        // If this is the first item, start a new quantifier list\n        if (this._subject === null) this._emit(this._graph || this.DEFAULTGRAPH, this._predicate, this._subject = this._blank(), this.QUANTIFIERS_GRAPH); // Otherwise, continue the previous list\n        else this._emit(this._subject, this.RDF_REST, this._subject = this._blank(), this.QUANTIFIERS_GRAPH); // Output the list item\n\n        this._emit(this._subject, this.RDF_FIRST, entity, this.QUANTIFIERS_GRAPH);\n      }\n    return this._readQuantifierPunctuation;\n  } // Reads punctuation from a @forSome or @forAll statement\n\n\n  _readQuantifierPunctuation(token) {\n    // Read more quantifiers\n    if (token.type === ',') return this._readQuantifierList; // End of the quantifier list\n    else {\n        // With explicit quantifiers, close the quantifier list\n        if (this._explicitQuantifiers) {\n          this._emit(this._subject, this.RDF_REST, this.RDF_NIL, this.QUANTIFIERS_GRAPH);\n\n          this._subject = null;\n        } // Read a dot\n\n\n        this._readCallback = this._getContextEndReader();\n        return this._readCallback(token);\n      }\n  } // ### `_getPathReader` reads a potential path and then resumes with the given function\n\n\n  _getPathReader(afterPath) {\n    this._afterPath = afterPath;\n    return this._readPath;\n  } // ### `_readPath` reads a potential path\n\n\n  _readPath(token) {\n    switch (token.type) {\n      // Forward path\n      case '!':\n        return this._readForwardPath;\n      // Backward path\n\n      case '^':\n        return this._readBackwardPath;\n      // Not a path; resume reading where we left off\n\n      default:\n        var stack = this._contextStack,\n            parent = stack.length && stack[stack.length - 1]; // If we were reading a list item, we still need to output it\n\n        if (parent && parent.type === 'item') {\n          // The list item is the remaining subejct after reading the path\n          var item = this._subject; // Switch back to the context of the list\n\n          this._restoreContext(); // Output the list item\n\n\n          this._emit(this._subject, this.RDF_FIRST, item, this._graph);\n        }\n\n        return this._afterPath(token);\n    }\n  } // ### `_readForwardPath` reads a '!' path\n\n\n  _readForwardPath(token) {\n    var subject,\n        predicate,\n        object = this._blank(); // The next token is the predicate\n\n\n    if ((predicate = this._readEntity(token)) === undefined) return; // If we were reading a subject, replace the subject by the path's object\n\n    if (this._predicate === null) subject = this._subject, this._subject = object; // If we were reading an object, replace the subject by the path's object\n    else subject = this._object, this._object = object; // Emit the path's current quad and read its next section\n\n    this._emit(subject, predicate, object, this._graph);\n\n    return this._readPath;\n  } // ### `_readBackwardPath` reads a '^' path\n\n\n  _readBackwardPath(token) {\n    var subject = this._blank(),\n        predicate,\n        object; // The next token is the predicate\n\n\n    if ((predicate = this._readEntity(token)) === undefined) return; // If we were reading a subject, replace the subject by the path's subject\n\n    if (this._predicate === null) object = this._subject, this._subject = subject; // If we were reading an object, replace the subject by the path's subject\n    else object = this._object, this._object = subject; // Emit the path's current quad and read its next section\n\n    this._emit(subject, predicate, object, this._graph);\n\n    return this._readPath;\n  } // ### `_getContextEndReader` gets the next reader function at the end of a context\n\n\n  _getContextEndReader() {\n    var contextStack = this._contextStack;\n    if (!contextStack.length) return this._readPunctuation;\n\n    switch (contextStack[contextStack.length - 1].type) {\n      case 'blank':\n        return this._readBlankNodeTail;\n\n      case 'list':\n        return this._readListItem;\n\n      case 'formula':\n        return this._readFormulaTail;\n    }\n  } // ### `_emit` sends a quad through the callback\n\n\n  _emit(subject, predicate, object, graph) {\n    this._callback(null, this._quad(subject, predicate, object, graph || this.DEFAULTGRAPH));\n  } // ### `_error` emits an error message through the callback\n\n\n  _error(message, token) {\n    var err = new Error(message + ' on line ' + token.line + '.');\n    err.context = {\n      token: token,\n      line: token.line,\n      previousToken: this._lexer.previousToken\n    };\n\n    this._callback(err);\n\n    this._callback = noop;\n  } // ### `_resolveIRI` resolves an IRI against the base path\n\n\n  _resolveIRI(iri) {\n    return /^[a-z][a-z0-9+.-]*:/i.test(iri) ? iri : this._resolveRelativeIRI(iri);\n  } // ### `_resolveRelativeIRI` resolves an IRI against the base path,\n  // assuming that a base path has been set and that the IRI is indeed relative\n\n\n  _resolveRelativeIRI(iri) {\n    // An empty relative IRI indicates the base IRI\n    if (!iri.length) return this._base; // Decide resolving strategy based in the first character\n\n    switch (iri[0]) {\n      // Resolve relative fragment IRIs against the base IRI\n      case '#':\n        return this._base + iri;\n      // Resolve relative query string IRIs by replacing the query string\n\n      case '?':\n        return this._base.replace(/(?:\\?.*)?$/, iri);\n      // Resolve root-relative IRIs at the root of the base IRI\n\n      case '/':\n        // Resolve scheme-relative IRIs to the scheme\n        return (iri[1] === '/' ? this._baseScheme : this._baseRoot) + this._removeDotSegments(iri);\n      // Resolve all other IRIs at the base IRI's path\n\n      default:\n        // Relative IRIs cannot contain a colon in the first path segment\n        return /^[^/:]*:/.test(iri) ? null : this._removeDotSegments(this._basePath + iri);\n    }\n  } // ### `_removeDotSegments` resolves './' and '../' path segments in an IRI as per RFC3986\n\n\n  _removeDotSegments(iri) {\n    // Don't modify the IRI if it does not contain any dot segments\n    if (!/(^|\\/)\\.\\.?($|[/#?])/.test(iri)) return iri; // Start with an imaginary slash before the IRI in order to resolve trailing './' and '../'\n\n    var result = '',\n        length = iri.length,\n        i = -1,\n        pathStart = -1,\n        segmentStart = 0,\n        next = '/';\n\n    while (i < length) {\n      switch (next) {\n        // The path starts with the first slash after the authority\n        case ':':\n          if (pathStart < 0) {\n            // Skip two slashes before the authority\n            if (iri[++i] === '/' && iri[++i] === '/') // Skip to slash after the authority\n              while ((pathStart = i + 1) < length && iri[pathStart] !== '/') i = pathStart;\n          }\n\n          break;\n        // Don't modify a query string or fragment\n\n        case '?':\n        case '#':\n          i = length;\n          break;\n        // Handle '/.' or '/..' path segments\n\n        case '/':\n          if (iri[i + 1] === '.') {\n            next = iri[++i + 1];\n\n            switch (next) {\n              // Remove a '/.' segment\n              case '/':\n                result += iri.substring(segmentStart, i - 1);\n                segmentStart = i + 1;\n                break;\n              // Remove a trailing '/.' segment\n\n              case undefined:\n              case '?':\n              case '#':\n                return result + iri.substring(segmentStart, i) + iri.substr(i + 1);\n              // Remove a '/..' segment\n\n              case '.':\n                next = iri[++i + 1];\n\n                if (next === undefined || next === '/' || next === '?' || next === '#') {\n                  result += iri.substring(segmentStart, i - 2); // Try to remove the parent path from result\n\n                  if ((segmentStart = result.lastIndexOf('/')) >= pathStart) result = result.substr(0, segmentStart); // Remove a trailing '/..' segment\n\n                  if (next !== '/') return result + '/' + iri.substr(i + 1);\n                  segmentStart = i + 1;\n                }\n\n            }\n          }\n\n      }\n\n      next = iri[++i];\n    }\n\n    return result + iri.substring(segmentStart);\n  } // ## Public methods\n  // ### `parse` parses the N3 input and emits each parsed quad through the callback\n\n\n  parse(input, quadCallback, prefixCallback) {\n    var self = this; // The read callback is the next function to be executed when a token arrives.\n    // We start reading in the top context.\n\n    this._readCallback = this._readInTopContext;\n    this._sparqlStyle = false;\n    this._prefixes = Object.create(null);\n    this._prefixes._ = this._blankNodePrefix ? this._blankNodePrefix.substr(2) : 'b' + blankNodePrefix++ + '_';\n    this._prefixCallback = prefixCallback || noop;\n    this._inversePredicate = false;\n    this._quantified = Object.create(null); // Parse synchronously if no quad callback is given\n\n    if (!quadCallback) {\n      var quads = [],\n          error;\n\n      this._callback = function (e, t) {\n        e ? error = e : t && quads.push(t);\n      };\n\n      this._lexer.tokenize(input).every(function (token) {\n        return self._readCallback = self._readCallback(token);\n      });\n\n      if (error) throw error;\n      return quads;\n    } // Parse asynchronously otherwise, executing the read callback when a token arrives\n\n\n    this._callback = quadCallback;\n\n    this._lexer.tokenize(input, function (error, token) {\n      if (error !== null) self._callback(error), self._callback = noop;else if (self._readCallback) self._readCallback = self._readCallback(token);\n    });\n  }\n\n} // The empty function\n\n\nexports[\"default\"] = N3Parser;\n\nfunction noop() {} // Initializes the parser with the given data factory\n\n\nfunction initDataFactory(parser, factory) {\n  // Set factory methods\n  var namedNode = factory.namedNode;\n  parser._namedNode = namedNode;\n  parser._blankNode = factory.blankNode;\n  parser._literal = factory.literal;\n  parser._variable = factory.variable;\n  parser._quad = factory.quad;\n  parser.DEFAULTGRAPH = factory.defaultGraph(); // Set common named nodes\n\n  parser.RDF_FIRST = namedNode(_IRIs.default.rdf.first);\n  parser.RDF_REST = namedNode(_IRIs.default.rdf.rest);\n  parser.RDF_NIL = namedNode(_IRIs.default.rdf.nil);\n  parser.N3_FORALL = namedNode(_IRIs.default.r.forAll);\n  parser.N3_FORSOME = namedNode(_IRIs.default.r.forSome);\n  parser.ABBREVIATIONS = {\n    'a': namedNode(_IRIs.default.rdf.type),\n    '=': namedNode(_IRIs.default.owl.sameAs),\n    '>': namedNode(_IRIs.default.log.implies)\n  };\n  parser.QUANTIFIERS_GRAPH = namedNode('urn:n3:quantifiers');\n}\n\ninitDataFactory(N3Parser.prototype, _N3DataFactory.default);\n\n//# sourceURL=webpack://playground/./node_modules/n3/lib/N3Parser.js?");

/***/ }),

/***/ "./node_modules/n3/lib/N3Store.js":
/*!****************************************!*\
  !*** ./node_modules/n3/lib/N3Store.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nvar _N3DataFactory = _interopRequireDefault(__webpack_require__(/*! ./N3DataFactory */ \"./node_modules/n3/lib/N3DataFactory.js\"));\n\nvar _stream = __webpack_require__(/*! stream */ \"?4032\");\n\nvar _IRIs = _interopRequireDefault(__webpack_require__(/*! ./IRIs */ \"./node_modules/n3/lib/IRIs.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// **N3Store** objects store N3 quads by graph in memory.\nconst {\n  toId,\n  fromId\n} = _N3DataFactory.default.internal; // ## Constructor\n\nclass N3Store {\n  constructor(quads, options) {\n    // The number of quads is initially zero\n    this._size = 0; // `_graphs` contains subject, predicate, and object indexes per graph\n\n    this._graphs = Object.create(null); // `_ids` maps entities such as `http://xmlns.com/foaf/0.1/name` to numbers,\n    // saving memory by using only numbers as keys in `_graphs`\n\n    this._id = 0;\n    this._ids = Object.create(null);\n    this._ids['><'] = 0; // dummy entry, so the first actual key is non-zero\n\n    this._entities = Object.create(null); // inverse of `_ids`\n    // `_blankNodeIndex` is the index of the last automatically named blank node\n\n    this._blankNodeIndex = 0; // Shift parameters if `quads` is not given\n\n    if (!options && quads && !quads[0]) options = quads, quads = null;\n    options = options || {};\n    this._factory = options.factory || _N3DataFactory.default; // Add quads if passed\n\n    if (quads) this.addQuads(quads);\n  } // ## Public properties\n  // ### `size` returns the number of quads in the store\n\n\n  get size() {\n    // Return the quad count if if was cached\n    var size = this._size;\n    if (size !== null) return size; // Calculate the number of quads by counting to the deepest level\n\n    size = 0;\n    var graphs = this._graphs,\n        subjects,\n        subject;\n\n    for (var graphKey in graphs) for (var subjectKey in subjects = graphs[graphKey].subjects) for (var predicateKey in subject = subjects[subjectKey]) size += Object.keys(subject[predicateKey]).length;\n\n    return this._size = size;\n  } // ## Private methods\n  // ### `_addToIndex` adds a quad to a three-layered index.\n  // Returns if the index has changed, if the entry did not already exist.\n\n\n  _addToIndex(index0, key0, key1, key2) {\n    // Create layers as necessary\n    var index1 = index0[key0] || (index0[key0] = {});\n    var index2 = index1[key1] || (index1[key1] = {}); // Setting the key to _any_ value signals the presence of the quad\n\n    var existed = key2 in index2;\n    if (!existed) index2[key2] = null;\n    return !existed;\n  } // ### `_removeFromIndex` removes a quad from a three-layered index\n\n\n  _removeFromIndex(index0, key0, key1, key2) {\n    // Remove the quad from the index\n    var index1 = index0[key0],\n        index2 = index1[key1],\n        key;\n    delete index2[key2]; // Remove intermediary index layers if they are empty\n\n    for (key in index2) return;\n\n    delete index1[key1];\n\n    for (key in index1) return;\n\n    delete index0[key0];\n  } // ### `_findInIndex` finds a set of quads in a three-layered index.\n  // The index base is `index0` and the keys at each level are `key0`, `key1`, and `key2`.\n  // Any of these keys can be undefined, which is interpreted as a wildcard.\n  // `name0`, `name1`, and `name2` are the names of the keys at each level,\n  // used when reconstructing the resulting quad\n  // (for instance: _subject_, _predicate_, and _object_).\n  // Finally, `graph` will be the graph of the created quads.\n  // If `callback` is given, each result is passed through it\n  // and iteration halts when it returns truthy for any quad.\n  // If instead `array` is given, each result is added to the array.\n\n\n  _findInIndex(index0, key0, key1, key2, name0, name1, name2, graph, callback, array) {\n    var tmp,\n        index1,\n        index2,\n        varCount = !key0 + !key1 + !key2,\n        // depending on the number of variables, keys or reverse index are faster\n    entityKeys = varCount > 1 ? Object.keys(this._ids) : this._entities; // If a key is specified, use only that part of index 0.\n\n    if (key0) (tmp = index0, index0 = {})[key0] = tmp[key0];\n\n    for (var value0 in index0) {\n      var entity0 = entityKeys[value0];\n\n      if (index1 = index0[value0]) {\n        // If a key is specified, use only that part of index 1.\n        if (key1) (tmp = index1, index1 = {})[key1] = tmp[key1];\n\n        for (var value1 in index1) {\n          var entity1 = entityKeys[value1];\n\n          if (index2 = index1[value1]) {\n            // If a key is specified, use only that part of index 2, if it exists.\n            var values = key2 ? key2 in index2 ? [key2] : [] : Object.keys(index2); // Create quads for all items found in index 2.\n\n            for (var l = 0; l < values.length; l++) {\n              var parts = {\n                subject: null,\n                predicate: null,\n                object: null\n              };\n              parts[name0] = fromId(entity0, this._factory);\n              parts[name1] = fromId(entity1, this._factory);\n              parts[name2] = fromId(entityKeys[values[l]], this._factory);\n\n              var quad = this._factory.quad(parts.subject, parts.predicate, parts.object, fromId(graph, this._factory));\n\n              if (array) array.push(quad);else if (callback(quad)) return true;\n            }\n          }\n        }\n      }\n    }\n\n    return array;\n  } // ### `_loop` executes the callback on all keys of index 0\n\n\n  _loop(index0, callback) {\n    for (var key0 in index0) callback(key0);\n  } // ### `_loopByKey0` executes the callback on all keys of a certain entry in index 0\n\n\n  _loopByKey0(index0, key0, callback) {\n    var index1, key1;\n\n    if (index1 = index0[key0]) {\n      for (key1 in index1) callback(key1);\n    }\n  } // ### `_loopByKey1` executes the callback on given keys of all entries in index 0\n\n\n  _loopByKey1(index0, key1, callback) {\n    var key0, index1;\n\n    for (key0 in index0) {\n      index1 = index0[key0];\n      if (index1[key1]) callback(key0);\n    }\n  } // ### `_loopBy2Keys` executes the callback on given keys of certain entries in index 2\n\n\n  _loopBy2Keys(index0, key0, key1, callback) {\n    var index1, index2, key2;\n\n    if ((index1 = index0[key0]) && (index2 = index1[key1])) {\n      for (key2 in index2) callback(key2);\n    }\n  } // ### `_countInIndex` counts matching quads in a three-layered index.\n  // The index base is `index0` and the keys at each level are `key0`, `key1`, and `key2`.\n  // Any of these keys can be undefined, which is interpreted as a wildcard.\n\n\n  _countInIndex(index0, key0, key1, key2) {\n    var count = 0,\n        tmp,\n        index1,\n        index2; // If a key is specified, count only that part of index 0\n\n    if (key0) (tmp = index0, index0 = {})[key0] = tmp[key0];\n\n    for (var value0 in index0) {\n      if (index1 = index0[value0]) {\n        // If a key is specified, count only that part of index 1\n        if (key1) (tmp = index1, index1 = {})[key1] = tmp[key1];\n\n        for (var value1 in index1) {\n          if (index2 = index1[value1]) {\n            // If a key is specified, count the quad if it exists\n            if (key2) key2 in index2 && count++; // Otherwise, count all quads\n            else count += Object.keys(index2).length;\n          }\n        }\n      }\n    }\n\n    return count;\n  } // ### `_getGraphs` returns an array with the given graph,\n  // or all graphs if the argument is null or undefined.\n\n\n  _getGraphs(graph) {\n    if (!isString(graph)) return this._graphs;\n    var graphs = {};\n    graphs[graph] = this._graphs[graph];\n    return graphs;\n  } // ### `_uniqueEntities` returns a function that accepts an entity ID\n  // and passes the corresponding entity to callback if it hasn't occurred before.\n\n\n  _uniqueEntities(callback) {\n    var uniqueIds = Object.create(null),\n        entities = this._entities;\n    return function (id) {\n      if (!(id in uniqueIds)) {\n        uniqueIds[id] = true;\n        callback(fromId(entities[id]));\n      }\n    };\n  } // ## Public methods\n  // ### `addQuad` adds a new quad to the store.\n  // Returns if the quad index has changed, if the quad did not already exist.\n\n\n  addQuad(subject, predicate, object, graph) {\n    // Shift arguments if a quad object is given instead of components\n    if (!predicate) graph = subject.graph, object = subject.object, predicate = subject.predicate, subject = subject.subject; // Convert terms to internal string representation\n\n    subject = toId(subject);\n    predicate = toId(predicate);\n    object = toId(object);\n    graph = toId(graph); // Find the graph that will contain the triple\n\n    var graphItem = this._graphs[graph]; // Create the graph if it doesn't exist yet\n\n    if (!graphItem) {\n      graphItem = this._graphs[graph] = {\n        subjects: {},\n        predicates: {},\n        objects: {}\n      }; // Freezing a graph helps subsequent `add` performance,\n      // and properties will never be modified anyway\n\n      Object.freeze(graphItem);\n    } // Since entities can often be long IRIs, we avoid storing them in every index.\n    // Instead, we have a separate index that maps entities to numbers,\n    // which are then used as keys in the other indexes.\n\n\n    var ids = this._ids;\n    var entities = this._entities;\n    subject = ids[subject] || (ids[entities[++this._id] = subject] = this._id);\n    predicate = ids[predicate] || (ids[entities[++this._id] = predicate] = this._id);\n    object = ids[object] || (ids[entities[++this._id] = object] = this._id);\n\n    var changed = this._addToIndex(graphItem.subjects, subject, predicate, object);\n\n    this._addToIndex(graphItem.predicates, predicate, object, subject);\n\n    this._addToIndex(graphItem.objects, object, subject, predicate); // The cached quad count is now invalid\n\n\n    this._size = null;\n    return changed;\n  } // ### `addQuads` adds multiple quads to the store\n\n\n  addQuads(quads) {\n    for (var i = 0; i < quads.length; i++) this.addQuad(quads[i]);\n  } // ### `import` adds a stream of quads to the store\n\n\n  import(stream) {\n    var self = this;\n    stream.on('data', function (quad) {\n      self.addQuad(quad);\n    });\n    return stream;\n  } // ### `removeQuad` removes a quad from the store if it exists\n\n\n  removeQuad(subject, predicate, object, graph) {\n    // Shift arguments if a quad object is given instead of components\n    if (!predicate) graph = subject.graph, object = subject.object, predicate = subject.predicate, subject = subject.subject; // Convert terms to internal string representation\n\n    subject = toId(subject);\n    predicate = toId(predicate);\n    object = toId(object);\n    graph = toId(graph); // Find internal identifiers for all components\n    // and verify the quad exists.\n\n    var graphItem,\n        ids = this._ids,\n        graphs = this._graphs,\n        subjects,\n        predicates;\n    if (!(subject = ids[subject]) || !(predicate = ids[predicate]) || !(object = ids[object]) || !(graphItem = graphs[graph]) || !(subjects = graphItem.subjects[subject]) || !(predicates = subjects[predicate]) || !(object in predicates)) return false; // Remove it from all indexes\n\n    this._removeFromIndex(graphItem.subjects, subject, predicate, object);\n\n    this._removeFromIndex(graphItem.predicates, predicate, object, subject);\n\n    this._removeFromIndex(graphItem.objects, object, subject, predicate);\n\n    if (this._size !== null) this._size--; // Remove the graph if it is empty\n\n    for (subject in graphItem.subjects) return true;\n\n    delete graphs[graph];\n    return true;\n  } // ### `removeQuads` removes multiple quads from the store\n\n\n  removeQuads(quads) {\n    for (var i = 0; i < quads.length; i++) this.removeQuad(quads[i]);\n  } // ### `remove` removes a stream of quads from the store\n\n\n  remove(stream) {\n    var self = this;\n    stream.on('data', function (quad) {\n      self.removeQuad(quad);\n    });\n    return stream;\n  } // ### `removeMatches` removes all matching quads from the store\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  removeMatches(subject, predicate, object, graph) {\n    return this.remove(this.match(subject, predicate, object, graph));\n  } // ### `deleteGraph` removes all triples with the given graph from the store\n\n\n  deleteGraph(graph) {\n    return this.removeMatches(null, null, null, graph);\n  } // ### `getQuads` returns an array of quads matching a pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  getQuads(subject, predicate, object, graph) {\n    // Convert terms to internal string representation\n    subject = subject && toId(subject);\n    predicate = predicate && toId(predicate);\n    object = object && toId(object);\n    graph = graph && toId(graph);\n\n    var quads = [],\n        graphs = this._getGraphs(graph),\n        content,\n        ids = this._ids,\n        subjectId,\n        predicateId,\n        objectId; // Translate IRIs to internal index keys.\n\n\n    if (isString(subject) && !(subjectId = ids[subject]) || isString(predicate) && !(predicateId = ids[predicate]) || isString(object) && !(objectId = ids[object])) return quads;\n\n    for (var graphId in graphs) {\n      // Only if the specified graph contains triples, there can be results\n      if (content = graphs[graphId]) {\n        // Choose the optimal index, based on what fields are present\n        if (subjectId) {\n          if (objectId) // If subject and object are given, the object index will be the fastest\n            this._findInIndex(content.objects, objectId, subjectId, predicateId, 'object', 'subject', 'predicate', graphId, null, quads);else // If only subject and possibly predicate are given, the subject index will be the fastest\n            this._findInIndex(content.subjects, subjectId, predicateId, null, 'subject', 'predicate', 'object', graphId, null, quads);\n        } else if (predicateId) // If only predicate and possibly object are given, the predicate index will be the fastest\n          this._findInIndex(content.predicates, predicateId, objectId, null, 'predicate', 'object', 'subject', graphId, null, quads);else if (objectId) // If only object is given, the object index will be the fastest\n          this._findInIndex(content.objects, objectId, null, null, 'object', 'subject', 'predicate', graphId, null, quads);else // If nothing is given, iterate subjects and predicates first\n          this._findInIndex(content.subjects, null, null, null, 'subject', 'predicate', 'object', graphId, null, quads);\n      }\n    }\n\n    return quads;\n  } // ### `match` returns a stream of quads matching a pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  match(subject, predicate, object, graph) {\n    var stream = new _stream.Readable({\n      objectMode: true\n    }); // Initialize stream once it is being read\n\n    stream._read = () => {\n      for (var quad of this.getQuads(subject, predicate, object, graph)) stream.push(quad);\n\n      stream.push(null);\n    };\n\n    return stream;\n  } // ### `countQuads` returns the number of quads matching a pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  countQuads(subject, predicate, object, graph) {\n    // Convert terms to internal string representation\n    subject = subject && toId(subject);\n    predicate = predicate && toId(predicate);\n    object = object && toId(object);\n    graph = graph && toId(graph);\n\n    var count = 0,\n        graphs = this._getGraphs(graph),\n        content,\n        ids = this._ids,\n        subjectId,\n        predicateId,\n        objectId; // Translate IRIs to internal index keys.\n\n\n    if (isString(subject) && !(subjectId = ids[subject]) || isString(predicate) && !(predicateId = ids[predicate]) || isString(object) && !(objectId = ids[object])) return 0;\n\n    for (var graphId in graphs) {\n      // Only if the specified graph contains triples, there can be results\n      if (content = graphs[graphId]) {\n        // Choose the optimal index, based on what fields are present\n        if (subject) {\n          if (object) // If subject and object are given, the object index will be the fastest\n            count += this._countInIndex(content.objects, objectId, subjectId, predicateId);else // If only subject and possibly predicate are given, the subject index will be the fastest\n            count += this._countInIndex(content.subjects, subjectId, predicateId, objectId);\n        } else if (predicate) {\n          // If only predicate and possibly object are given, the predicate index will be the fastest\n          count += this._countInIndex(content.predicates, predicateId, objectId, subjectId);\n        } else {\n          // If only object is possibly given, the object index will be the fastest\n          count += this._countInIndex(content.objects, objectId, subjectId, predicateId);\n        }\n      }\n    }\n\n    return count;\n  } // ### `forEach` executes the callback on all quads.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  forEach(callback, subject, predicate, object, graph) {\n    this.some(function (quad) {\n      callback(quad);\n      return false;\n    }, subject, predicate, object, graph);\n  } // ### `every` executes the callback on all quads,\n  // and returns `true` if it returns truthy for all them.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  every(callback, subject, predicate, object, graph) {\n    var some = false;\n    var every = !this.some(function (quad) {\n      some = true;\n      return !callback(quad);\n    }, subject, predicate, object, graph);\n    return some && every;\n  } // ### `some` executes the callback on all quads,\n  // and returns `true` if it returns truthy for any of them.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  some(callback, subject, predicate, object, graph) {\n    // Convert terms to internal string representation\n    subject = subject && toId(subject);\n    predicate = predicate && toId(predicate);\n    object = object && toId(object);\n    graph = graph && toId(graph);\n\n    var graphs = this._getGraphs(graph),\n        content,\n        ids = this._ids,\n        subjectId,\n        predicateId,\n        objectId; // Translate IRIs to internal index keys.\n\n\n    if (isString(subject) && !(subjectId = ids[subject]) || isString(predicate) && !(predicateId = ids[predicate]) || isString(object) && !(objectId = ids[object])) return false;\n\n    for (var graphId in graphs) {\n      // Only if the specified graph contains triples, there can be results\n      if (content = graphs[graphId]) {\n        // Choose the optimal index, based on what fields are present\n        if (subjectId) {\n          if (objectId) {\n            // If subject and object are given, the object index will be the fastest\n            if (this._findInIndex(content.objects, objectId, subjectId, predicateId, 'object', 'subject', 'predicate', graphId, callback, null)) return true;\n          } else // If only subject and possibly predicate are given, the subject index will be the fastest\n            if (this._findInIndex(content.subjects, subjectId, predicateId, null, 'subject', 'predicate', 'object', graphId, callback, null)) return true;\n        } else if (predicateId) {\n          // If only predicate and possibly object are given, the predicate index will be the fastest\n          if (this._findInIndex(content.predicates, predicateId, objectId, null, 'predicate', 'object', 'subject', graphId, callback, null)) {\n            return true;\n          }\n        } else if (objectId) {\n          // If only object is given, the object index will be the fastest\n          if (this._findInIndex(content.objects, objectId, null, null, 'object', 'subject', 'predicate', graphId, callback, null)) {\n            return true;\n          }\n        } else // If nothing is given, iterate subjects and predicates first\n          if (this._findInIndex(content.subjects, null, null, null, 'subject', 'predicate', 'object', graphId, callback, null)) {\n            return true;\n          }\n      }\n    }\n\n    return false;\n  } // ### `getSubjects` returns all subjects that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  getSubjects(predicate, object, graph) {\n    var results = [];\n    this.forSubjects(function (s) {\n      results.push(s);\n    }, predicate, object, graph);\n    return results;\n  } // ### `forSubjects` executes the callback on all subjects that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  forSubjects(callback, predicate, object, graph) {\n    // Convert terms to internal string representation\n    predicate = predicate && toId(predicate);\n    object = object && toId(object);\n    graph = graph && toId(graph);\n\n    var ids = this._ids,\n        graphs = this._getGraphs(graph),\n        content,\n        predicateId,\n        objectId;\n\n    callback = this._uniqueEntities(callback); // Translate IRIs to internal index keys.\n\n    if (isString(predicate) && !(predicateId = ids[predicate]) || isString(object) && !(objectId = ids[object])) return;\n\n    for (graph in graphs) {\n      // Only if the specified graph contains triples, there can be results\n      if (content = graphs[graph]) {\n        // Choose optimal index based on which fields are wildcards\n        if (predicateId) {\n          if (objectId) // If predicate and object are given, the POS index is best.\n            this._loopBy2Keys(content.predicates, predicateId, objectId, callback);else // If only predicate is given, the SPO index is best.\n            this._loopByKey1(content.subjects, predicateId, callback);\n        } else if (objectId) // If only object is given, the OSP index is best.\n          this._loopByKey0(content.objects, objectId, callback);else // If no params given, iterate all the subjects\n          this._loop(content.subjects, callback);\n      }\n    }\n  } // ### `getPredicates` returns all predicates that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  getPredicates(subject, object, graph) {\n    var results = [];\n    this.forPredicates(function (p) {\n      results.push(p);\n    }, subject, object, graph);\n    return results;\n  } // ### `forPredicates` executes the callback on all predicates that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  forPredicates(callback, subject, object, graph) {\n    // Convert terms to internal string representation\n    subject = subject && toId(subject);\n    object = object && toId(object);\n    graph = graph && toId(graph);\n\n    var ids = this._ids,\n        graphs = this._getGraphs(graph),\n        content,\n        subjectId,\n        objectId;\n\n    callback = this._uniqueEntities(callback); // Translate IRIs to internal index keys.\n\n    if (isString(subject) && !(subjectId = ids[subject]) || isString(object) && !(objectId = ids[object])) return;\n\n    for (graph in graphs) {\n      // Only if the specified graph contains triples, there can be results\n      if (content = graphs[graph]) {\n        // Choose optimal index based on which fields are wildcards\n        if (subjectId) {\n          if (objectId) // If subject and object are given, the OSP index is best.\n            this._loopBy2Keys(content.objects, objectId, subjectId, callback);else // If only subject is given, the SPO index is best.\n            this._loopByKey0(content.subjects, subjectId, callback);\n        } else if (objectId) // If only object is given, the POS index is best.\n          this._loopByKey1(content.predicates, objectId, callback);else // If no params given, iterate all the predicates.\n          this._loop(content.predicates, callback);\n      }\n    }\n  } // ### `getObjects` returns all objects that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  getObjects(subject, predicate, graph) {\n    var results = [];\n    this.forObjects(function (o) {\n      results.push(o);\n    }, subject, predicate, graph);\n    return results;\n  } // ### `forObjects` executes the callback on all objects that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  forObjects(callback, subject, predicate, graph) {\n    // Convert terms to internal string representation\n    subject = subject && toId(subject);\n    predicate = predicate && toId(predicate);\n    graph = graph && toId(graph);\n\n    var ids = this._ids,\n        graphs = this._getGraphs(graph),\n        content,\n        subjectId,\n        predicateId;\n\n    callback = this._uniqueEntities(callback); // Translate IRIs to internal index keys.\n\n    if (isString(subject) && !(subjectId = ids[subject]) || isString(predicate) && !(predicateId = ids[predicate])) return;\n\n    for (graph in graphs) {\n      // Only if the specified graph contains triples, there can be results\n      if (content = graphs[graph]) {\n        // Choose optimal index based on which fields are wildcards\n        if (subjectId) {\n          if (predicateId) // If subject and predicate are given, the SPO index is best.\n            this._loopBy2Keys(content.subjects, subjectId, predicateId, callback);else // If only subject is given, the OSP index is best.\n            this._loopByKey1(content.objects, subjectId, callback);\n        } else if (predicateId) // If only predicate is given, the POS index is best.\n          this._loopByKey0(content.predicates, predicateId, callback);else // If no params given, iterate all the objects.\n          this._loop(content.objects, callback);\n      }\n    }\n  } // ### `getGraphs` returns all graphs that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  getGraphs(subject, predicate, object) {\n    var results = [];\n    this.forGraphs(function (g) {\n      results.push(g);\n    }, subject, predicate, object);\n    return results;\n  } // ### `forGraphs` executes the callback on all graphs that match the pattern.\n  // Setting any field to `undefined` or `null` indicates a wildcard.\n\n\n  forGraphs(callback, subject, predicate, object) {\n    for (var graph in this._graphs) {\n      this.some(function (quad) {\n        callback(quad.graph);\n        return true; // Halt iteration of some()\n      }, subject, predicate, object, graph);\n    }\n  } // ### `createBlankNode` creates a new blank node, returning its name\n\n\n  createBlankNode(suggestedName) {\n    var name, index; // Generate a name based on the suggested name\n\n    if (suggestedName) {\n      name = suggestedName = '_:' + suggestedName, index = 1;\n\n      while (this._ids[name]) name = suggestedName + index++;\n    } // Generate a generic blank node name\n    else {\n        do {\n          name = '_:b' + this._blankNodeIndex++;\n        } while (this._ids[name]);\n      } // Add the blank node to the entities, avoiding the generation of duplicates\n\n\n    this._ids[name] = ++this._id;\n    this._entities[this._id] = name;\n    return this._factory.blankNode(name.substr(2));\n  } // ### `extractLists` finds and removes all list triples\n  // and returns the items per list.\n\n\n  extractLists({\n    remove = false,\n    ignoreErrors = false\n  } = {}) {\n    var lists = {}; // has scalar keys so could be a simple Object\n\n    var onError = ignoreErrors ? () => true : (node, message) => {\n      throw new Error(`${node.value} ${message}`);\n    }; // Traverse each list from its tail\n\n    var tails = this.getQuads(null, _IRIs.default.rdf.rest, _IRIs.default.rdf.nil, null);\n    var toRemove = remove ? [...tails] : [];\n    tails.forEach(tailQuad => {\n      var items = []; // the members found as objects of rdf:first quads\n\n      var malformed = false; // signals whether the current list is malformed\n\n      var head; // the head of the list (_:b1 in above example)\n\n      var headPos; // set to subject or object when head is set\n\n      var graph = tailQuad.graph; // make sure list is in exactly one graph\n      // Traverse the list from tail to end\n\n      var current = tailQuad.subject;\n\n      while (current && !malformed) {\n        var objectQuads = this.getQuads(null, null, current, null);\n        var subjectQuads = this.getQuads(current, null, null, null);\n        var i,\n            quad,\n            first = null,\n            rest = null,\n            parent = null; // Find the first and rest of this list node\n\n        for (i = 0; i < subjectQuads.length && !malformed; i++) {\n          quad = subjectQuads[i];\n          if (!quad.graph.equals(graph)) malformed = onError(current, 'not confined to single graph');else if (head) malformed = onError(current, 'has non-list arcs out'); // one rdf:first\n          else if (quad.predicate.value === _IRIs.default.rdf.first) {\n              if (first) malformed = onError(current, 'has multiple rdf:first arcs');else toRemove.push(first = quad);\n            } // one rdf:rest\n            else if (quad.predicate.value === _IRIs.default.rdf.rest) {\n                if (rest) malformed = onError(current, 'has multiple rdf:rest arcs');else toRemove.push(rest = quad);\n              } // alien triple\n              else if (objectQuads.length) malformed = onError(current, 'can\\'t be subject and object');else {\n                  head = quad; // e.g. { (1 2 3) :p :o }\n\n                  headPos = 'subject';\n                }\n        } // { :s :p (1 2) } arrives here with no head\n        // { (1 2) :p :o } arrives here with head set to the list.\n\n\n        for (i = 0; i < objectQuads.length && !malformed; ++i) {\n          quad = objectQuads[i];\n          if (head) malformed = onError(current, 'can\\'t have coreferences'); // one rdf:rest\n          else if (quad.predicate.value === _IRIs.default.rdf.rest) {\n              if (parent) malformed = onError(current, 'has incoming rdf:rest arcs');else parent = quad;\n            } else {\n              head = quad; // e.g. { :s :p (1 2) }\n\n              headPos = 'object';\n            }\n        } // Store the list item and continue with parent\n\n\n        if (!first) malformed = onError(current, 'has no list head');else items.unshift(first.object);\n        current = parent && parent.subject;\n      } // Don't remove any quads if the list is malformed\n\n\n      if (malformed) remove = false; // Store the list under the value of its head\n      else if (head) lists[head[headPos].value] = items;\n    }); // Remove list quads if requested\n\n    if (remove) this.removeQuads(toRemove);\n    return lists;\n  }\n\n} // Determines whether the argument is a string\n\n\nexports[\"default\"] = N3Store;\n\nfunction isString(s) {\n  return typeof s === 'string' || s instanceof String;\n}\n\n//# sourceURL=webpack://playground/./node_modules/n3/lib/N3Store.js?");

/***/ }),

/***/ "./node_modules/n3/lib/N3Writer.js":
/*!*****************************************!*\
  !*** ./node_modules/n3/lib/N3Writer.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nvar _IRIs = _interopRequireDefault(__webpack_require__(/*! ./IRIs */ \"./node_modules/n3/lib/IRIs.js\"));\n\nvar _N3DataFactory = _interopRequireDefault(__webpack_require__(/*! ./N3DataFactory */ \"./node_modules/n3/lib/N3DataFactory.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// **N3Writer** writes N3 documents.\nconst DEFAULTGRAPH = _N3DataFactory.default.defaultGraph();\n\nconst {\n  rdf,\n  xsd\n} = _IRIs.default; // Characters in literals that require escaping\n\nvar escape = /[\"\\\\\\t\\n\\r\\b\\f\\u0000-\\u0019\\ud800-\\udbff]/,\n    escapeAll = /[\"\\\\\\t\\n\\r\\b\\f\\u0000-\\u0019]|[\\ud800-\\udbff][\\udc00-\\udfff]/g,\n    escapedCharacters = {\n  '\\\\': '\\\\\\\\',\n  '\"': '\\\\\"',\n  '\\t': '\\\\t',\n  '\\n': '\\\\n',\n  '\\r': '\\\\r',\n  '\\b': '\\\\b',\n  '\\f': '\\\\f'\n}; // ## Placeholder class to represent already pretty-printed terms\n\nclass SerializedTerm extends _N3DataFactory.default.internal.Term {\n  // Pretty-printed nodes are not equal to any other node\n  // (e.g., [] does not equal [])\n  equals() {\n    return false;\n  }\n\n} // ## Constructor\n\n\nclass N3Writer {\n  constructor(outputStream, options) {\n    // ### `_prefixRegex` matches a prefixed name or IRI that begins with one of the added prefixes\n    this._prefixRegex = /$0^/; // Shift arguments if the first argument is not a stream\n\n    if (outputStream && typeof outputStream.write !== 'function') options = outputStream, outputStream = null;\n    options = options || {};\n    this._lists = options.lists; // If no output stream given, send the output as string through the end callback\n\n    if (!outputStream) {\n      var output = '';\n      this._outputStream = {\n        write(chunk, encoding, done) {\n          output += chunk;\n          done && done();\n        },\n\n        end: function (done) {\n          done && done(null, output);\n        }\n      };\n      this._endStream = true;\n    } else {\n      this._outputStream = outputStream;\n      this._endStream = options.end === undefined ? true : !!options.end;\n    } // Initialize writer, depending on the format\n\n\n    this._subject = null;\n\n    if (!/triple|quad/i.test(options.format)) {\n      this._graph = DEFAULTGRAPH;\n      this._prefixIRIs = Object.create(null);\n      options.prefixes && this.addPrefixes(options.prefixes);\n    } else {\n      this._writeQuad = this._writeQuadLine;\n    }\n  } // ## Private methods\n  // ### Whether the current graph is the default graph\n\n\n  get _inDefaultGraph() {\n    return DEFAULTGRAPH.equals(this._graph);\n  } // ### `_write` writes the argument to the output stream\n\n\n  _write(string, callback) {\n    this._outputStream.write(string, 'utf8', callback);\n  } // ### `_writeQuad` writes the quad to the output stream\n\n\n  _writeQuad(subject, predicate, object, graph, done) {\n    try {\n      // Write the graph's label if it has changed\n      if (!graph.equals(this._graph)) {\n        // Close the previous graph and start the new one\n        this._write((this._subject === null ? '' : this._inDefaultGraph ? '.\\n' : '\\n}\\n') + (DEFAULTGRAPH.equals(graph) ? '' : this._encodeIriOrBlank(graph) + ' {\\n'));\n\n        this._graph = graph;\n        this._subject = null;\n      } // Don't repeat the subject if it's the same\n\n\n      if (subject.equals(this._subject)) {\n        // Don't repeat the predicate if it's the same\n        if (predicate.equals(this._predicate)) this._write(', ' + this._encodeObject(object), done); // Same subject, different predicate\n        else this._write(';\\n    ' + this._encodePredicate(this._predicate = predicate) + ' ' + this._encodeObject(object), done);\n      } // Different subject; write the whole quad\n      else this._write((this._subject === null ? '' : '.\\n') + this._encodeIriOrBlank(this._subject = subject) + ' ' + this._encodePredicate(this._predicate = predicate) + ' ' + this._encodeObject(object), done);\n    } catch (error) {\n      done && done(error);\n    }\n  } // ### `_writeQuadLine` writes the quad to the output stream as a single line\n\n\n  _writeQuadLine(subject, predicate, object, graph, done) {\n    // Write the quad without prefixes\n    delete this._prefixMatch;\n\n    this._write(this.quadToString(subject, predicate, object, graph), done);\n  } // ### `quadToString` serializes a quad as a string\n\n\n  quadToString(subject, predicate, object, graph) {\n    return this._encodeIriOrBlank(subject) + ' ' + this._encodeIriOrBlank(predicate) + ' ' + this._encodeObject(object) + (graph && graph.value ? ' ' + this._encodeIriOrBlank(graph) + ' .\\n' : ' .\\n');\n  } // ### `quadsToString` serializes an array of quads as a string\n\n\n  quadsToString(quads) {\n    return quads.map(function (t) {\n      return this.quadToString(t.subject, t.predicate, t.object, t.graph);\n    }, this).join('');\n  } // ### `_encodeIriOrBlank` represents an IRI or blank node\n\n\n  _encodeIriOrBlank(entity) {\n    // A blank node or list is represented as-is\n    if (entity.termType !== 'NamedNode') {\n      // If it is a list head, pretty-print it\n      if (this._lists && entity.value in this._lists) entity = this.list(this._lists[entity.value]);\n      return 'id' in entity ? entity.id : '_:' + entity.value;\n    } // Escape special characters\n\n\n    var iri = entity.value;\n    if (escape.test(iri)) iri = iri.replace(escapeAll, characterReplacer); // Try to represent the IRI as prefixed name\n\n    var prefixMatch = this._prefixRegex.exec(iri);\n\n    return !prefixMatch ? '<' + iri + '>' : !prefixMatch[1] ? iri : this._prefixIRIs[prefixMatch[1]] + prefixMatch[2];\n  } // ### `_encodeLiteral` represents a literal\n\n\n  _encodeLiteral(literal) {\n    // Escape special characters\n    var value = literal.value;\n    if (escape.test(value)) value = value.replace(escapeAll, characterReplacer); // Write the literal, possibly with type or language\n\n    if (literal.language) return '\"' + value + '\"@' + literal.language;else if (literal.datatype.value !== xsd.string) return '\"' + value + '\"^^' + this._encodeIriOrBlank(literal.datatype);else return '\"' + value + '\"';\n  } // ### `_encodePredicate` represents a predicate\n\n\n  _encodePredicate(predicate) {\n    return predicate.value === rdf.type ? 'a' : this._encodeIriOrBlank(predicate);\n  } // ### `_encodeObject` represents an object\n\n\n  _encodeObject(object) {\n    return object.termType === 'Literal' ? this._encodeLiteral(object) : this._encodeIriOrBlank(object);\n  } // ### `_blockedWrite` replaces `_write` after the writer has been closed\n\n\n  _blockedWrite() {\n    throw new Error('Cannot write because the writer has been closed.');\n  } // ### `addQuad` adds the quad to the output stream\n\n\n  addQuad(subject, predicate, object, graph, done) {\n    // The quad was given as an object, so shift parameters\n    if (object === undefined) this._writeQuad(subject.subject, subject.predicate, subject.object, subject.graph, predicate); // The optional `graph` parameter was not provided\n    else if (typeof graph === 'function') this._writeQuad(subject, predicate, object, DEFAULTGRAPH, graph); // The `graph` parameter was provided\n      else this._writeQuad(subject, predicate, object, graph || DEFAULTGRAPH, done);\n  } // ### `addQuads` adds the quads to the output stream\n\n\n  addQuads(quads) {\n    for (var i = 0; i < quads.length; i++) this.addQuad(quads[i]);\n  } // ### `addPrefix` adds the prefix to the output stream\n\n\n  addPrefix(prefix, iri, done) {\n    var prefixes = {};\n    prefixes[prefix] = iri;\n    this.addPrefixes(prefixes, done);\n  } // ### `addPrefixes` adds the prefixes to the output stream\n\n\n  addPrefixes(prefixes, done) {\n    var prefixIRIs = this._prefixIRIs,\n        hasPrefixes = false;\n\n    for (var prefix in prefixes) {\n      var iri = prefixes[prefix];\n      if (typeof iri !== 'string') iri = iri.value;\n      hasPrefixes = true; // Finish a possible pending quad\n\n      if (this._subject !== null) {\n        this._write(this._inDefaultGraph ? '.\\n' : '\\n}\\n');\n\n        this._subject = null, this._graph = '';\n      } // Store and write the prefix\n\n\n      prefixIRIs[iri] = prefix += ':';\n\n      this._write('@prefix ' + prefix + ' <' + iri + '>.\\n');\n    } // Recreate the prefix matcher\n\n\n    if (hasPrefixes) {\n      var IRIlist = '',\n          prefixList = '';\n\n      for (var prefixIRI in prefixIRIs) {\n        IRIlist += IRIlist ? '|' + prefixIRI : prefixIRI;\n        prefixList += (prefixList ? '|' : '') + prefixIRIs[prefixIRI];\n      }\n\n      IRIlist = IRIlist.replace(/[\\]\\/\\(\\)\\*\\+\\?\\.\\\\\\$]/g, '\\\\$&');\n      this._prefixRegex = new RegExp('^(?:' + prefixList + ')[^\\/]*$|' + '^(' + IRIlist + ')([a-zA-Z][\\\\-_a-zA-Z0-9]*)$');\n    } // End a prefix block with a newline\n\n\n    this._write(hasPrefixes ? '\\n' : '', done);\n  } // ### `blank` creates a blank node with the given content\n\n\n  blank(predicate, object) {\n    var children = predicate,\n        child,\n        length; // Empty blank node\n\n    if (predicate === undefined) children = []; // Blank node passed as blank(Term(\"predicate\"), Term(\"object\"))\n    else if (predicate.termType) children = [{\n        predicate: predicate,\n        object: object\n      }]; // Blank node passed as blank({ predicate: predicate, object: object })\n      else if (!('length' in predicate)) children = [predicate];\n\n    switch (length = children.length) {\n      // Generate an empty blank node\n      case 0:\n        return new SerializedTerm('[]');\n      // Generate a non-nested one-triple blank node\n\n      case 1:\n        child = children[0];\n        if (!(child.object instanceof SerializedTerm)) return new SerializedTerm('[ ' + this._encodePredicate(child.predicate) + ' ' + this._encodeObject(child.object) + ' ]');\n      // Generate a multi-triple or nested blank node\n\n      default:\n        var contents = '['; // Write all triples in order\n\n        for (var i = 0; i < length; i++) {\n          child = children[i]; // Write only the object is the predicate is the same as the previous\n\n          if (child.predicate.equals(predicate)) contents += ', ' + this._encodeObject(child.object); // Otherwise, write the predicate and the object\n          else {\n              contents += (i ? ';\\n  ' : '\\n  ') + this._encodePredicate(child.predicate) + ' ' + this._encodeObject(child.object);\n              predicate = child.predicate;\n            }\n        }\n\n        return new SerializedTerm(contents + '\\n]');\n    }\n  } // ### `list` creates a list node with the given content\n\n\n  list(elements) {\n    var length = elements && elements.length || 0,\n        contents = new Array(length);\n\n    for (var i = 0; i < length; i++) contents[i] = this._encodeObject(elements[i]);\n\n    return new SerializedTerm('(' + contents.join(' ') + ')');\n  } // ### `end` signals the end of the output stream\n\n\n  end(done) {\n    // Finish a possible pending quad\n    if (this._subject !== null) {\n      this._write(this._inDefaultGraph ? '.\\n' : '\\n}\\n');\n\n      this._subject = null;\n    } // Disallow further writing\n\n\n    this._write = this._blockedWrite; // Try to end the underlying stream, ensuring done is called exactly one time\n\n    var singleDone = done && function (error, result) {\n      singleDone = null, done(error, result);\n    };\n\n    if (this._endStream) {\n      try {\n        return this._outputStream.end(singleDone);\n      } catch (error) {\n        /* error closing stream */\n      }\n    }\n\n    singleDone && singleDone();\n  }\n\n} // Replaces a character by its escaped version\n\n\nexports[\"default\"] = N3Writer;\n\nfunction characterReplacer(character) {\n  // Replace a single character by its escaped version\n  var result = escapedCharacters[character];\n\n  if (result === undefined) {\n    // Replace a single character with its 4-bit unicode escape sequence\n    if (character.length === 1) {\n      result = character.charCodeAt(0).toString(16);\n      result = '\\\\u0000'.substr(0, 6 - result.length) + result;\n    } // Replace a surrogate pair with its 8-bit unicode escape sequence\n    else {\n        result = ((character.charCodeAt(0) - 0xD800) * 0x400 + character.charCodeAt(1) + 0x2400).toString(16);\n        result = '\\\\U00000000'.substr(0, 10 - result.length) + result;\n      }\n  }\n\n  return result;\n}\n\n//# sourceURL=webpack://playground/./node_modules/n3/lib/N3Writer.js?");

/***/ }),

/***/ "./node_modules/punycode/punycode.js":
/*!*******************************************!*\
  !*** ./node_modules/punycode/punycode.js ***!
  \*******************************************/
/***/ (function(module, exports, __webpack_require__) {

eval("/* module decorator */ module = __webpack_require__.nmd(module);\nvar __WEBPACK_AMD_DEFINE_RESULT__;/*! https://mths.be/punycode v1.3.2 by @mathias */\n;(function(root) {\n\n\t/** Detect free variables */\n\tvar freeExports =  true && exports &&\n\t\t!exports.nodeType && exports;\n\tvar freeModule =  true && module &&\n\t\t!module.nodeType && module;\n\tvar freeGlobal = typeof __webpack_require__.g == 'object' && __webpack_require__.g;\n\tif (\n\t\tfreeGlobal.global === freeGlobal ||\n\t\tfreeGlobal.window === freeGlobal ||\n\t\tfreeGlobal.self === freeGlobal\n\t) {\n\t\troot = freeGlobal;\n\t}\n\n\t/**\n\t * The `punycode` object.\n\t * @name punycode\n\t * @type Object\n\t */\n\tvar punycode,\n\n\t/** Highest positive signed 32-bit float value */\n\tmaxInt = 2147483647, // aka. 0x7FFFFFFF or 2^31-1\n\n\t/** Bootstring parameters */\n\tbase = 36,\n\ttMin = 1,\n\ttMax = 26,\n\tskew = 38,\n\tdamp = 700,\n\tinitialBias = 72,\n\tinitialN = 128, // 0x80\n\tdelimiter = '-', // '\\x2D'\n\n\t/** Regular expressions */\n\tregexPunycode = /^xn--/,\n\tregexNonASCII = /[^\\x20-\\x7E]/, // unprintable ASCII chars + non-ASCII chars\n\tregexSeparators = /[\\x2E\\u3002\\uFF0E\\uFF61]/g, // RFC 3490 separators\n\n\t/** Error messages */\n\terrors = {\n\t\t'overflow': 'Overflow: input needs wider integers to process',\n\t\t'not-basic': 'Illegal input >= 0x80 (not a basic code point)',\n\t\t'invalid-input': 'Invalid input'\n\t},\n\n\t/** Convenience shortcuts */\n\tbaseMinusTMin = base - tMin,\n\tfloor = Math.floor,\n\tstringFromCharCode = String.fromCharCode,\n\n\t/** Temporary variable */\n\tkey;\n\n\t/*--------------------------------------------------------------------------*/\n\n\t/**\n\t * A generic error utility function.\n\t * @private\n\t * @param {String} type The error type.\n\t * @returns {Error} Throws a `RangeError` with the applicable error message.\n\t */\n\tfunction error(type) {\n\t\tthrow RangeError(errors[type]);\n\t}\n\n\t/**\n\t * A generic `Array#map` utility function.\n\t * @private\n\t * @param {Array} array The array to iterate over.\n\t * @param {Function} callback The function that gets called for every array\n\t * item.\n\t * @returns {Array} A new array of values returned by the callback function.\n\t */\n\tfunction map(array, fn) {\n\t\tvar length = array.length;\n\t\tvar result = [];\n\t\twhile (length--) {\n\t\t\tresult[length] = fn(array[length]);\n\t\t}\n\t\treturn result;\n\t}\n\n\t/**\n\t * A simple `Array#map`-like wrapper to work with domain name strings or email\n\t * addresses.\n\t * @private\n\t * @param {String} domain The domain name or email address.\n\t * @param {Function} callback The function that gets called for every\n\t * character.\n\t * @returns {Array} A new string of characters returned by the callback\n\t * function.\n\t */\n\tfunction mapDomain(string, fn) {\n\t\tvar parts = string.split('@');\n\t\tvar result = '';\n\t\tif (parts.length > 1) {\n\t\t\t// In email addresses, only the domain name should be punycoded. Leave\n\t\t\t// the local part (i.e. everything up to `@`) intact.\n\t\t\tresult = parts[0] + '@';\n\t\t\tstring = parts[1];\n\t\t}\n\t\t// Avoid `split(regex)` for IE8 compatibility. See #17.\n\t\tstring = string.replace(regexSeparators, '\\x2E');\n\t\tvar labels = string.split('.');\n\t\tvar encoded = map(labels, fn).join('.');\n\t\treturn result + encoded;\n\t}\n\n\t/**\n\t * Creates an array containing the numeric code points of each Unicode\n\t * character in the string. While JavaScript uses UCS-2 internally,\n\t * this function will convert a pair of surrogate halves (each of which\n\t * UCS-2 exposes as separate characters) into a single code point,\n\t * matching UTF-16.\n\t * @see `punycode.ucs2.encode`\n\t * @see <https://mathiasbynens.be/notes/javascript-encoding>\n\t * @memberOf punycode.ucs2\n\t * @name decode\n\t * @param {String} string The Unicode input string (UCS-2).\n\t * @returns {Array} The new array of code points.\n\t */\n\tfunction ucs2decode(string) {\n\t\tvar output = [],\n\t\t    counter = 0,\n\t\t    length = string.length,\n\t\t    value,\n\t\t    extra;\n\t\twhile (counter < length) {\n\t\t\tvalue = string.charCodeAt(counter++);\n\t\t\tif (value >= 0xD800 && value <= 0xDBFF && counter < length) {\n\t\t\t\t// high surrogate, and there is a next character\n\t\t\t\textra = string.charCodeAt(counter++);\n\t\t\t\tif ((extra & 0xFC00) == 0xDC00) { // low surrogate\n\t\t\t\t\toutput.push(((value & 0x3FF) << 10) + (extra & 0x3FF) + 0x10000);\n\t\t\t\t} else {\n\t\t\t\t\t// unmatched surrogate; only append this code unit, in case the next\n\t\t\t\t\t// code unit is the high surrogate of a surrogate pair\n\t\t\t\t\toutput.push(value);\n\t\t\t\t\tcounter--;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\toutput.push(value);\n\t\t\t}\n\t\t}\n\t\treturn output;\n\t}\n\n\t/**\n\t * Creates a string based on an array of numeric code points.\n\t * @see `punycode.ucs2.decode`\n\t * @memberOf punycode.ucs2\n\t * @name encode\n\t * @param {Array} codePoints The array of numeric code points.\n\t * @returns {String} The new Unicode string (UCS-2).\n\t */\n\tfunction ucs2encode(array) {\n\t\treturn map(array, function(value) {\n\t\t\tvar output = '';\n\t\t\tif (value > 0xFFFF) {\n\t\t\t\tvalue -= 0x10000;\n\t\t\t\toutput += stringFromCharCode(value >>> 10 & 0x3FF | 0xD800);\n\t\t\t\tvalue = 0xDC00 | value & 0x3FF;\n\t\t\t}\n\t\t\toutput += stringFromCharCode(value);\n\t\t\treturn output;\n\t\t}).join('');\n\t}\n\n\t/**\n\t * Converts a basic code point into a digit/integer.\n\t * @see `digitToBasic()`\n\t * @private\n\t * @param {Number} codePoint The basic numeric code point value.\n\t * @returns {Number} The numeric value of a basic code point (for use in\n\t * representing integers) in the range `0` to `base - 1`, or `base` if\n\t * the code point does not represent a value.\n\t */\n\tfunction basicToDigit(codePoint) {\n\t\tif (codePoint - 48 < 10) {\n\t\t\treturn codePoint - 22;\n\t\t}\n\t\tif (codePoint - 65 < 26) {\n\t\t\treturn codePoint - 65;\n\t\t}\n\t\tif (codePoint - 97 < 26) {\n\t\t\treturn codePoint - 97;\n\t\t}\n\t\treturn base;\n\t}\n\n\t/**\n\t * Converts a digit/integer into a basic code point.\n\t * @see `basicToDigit()`\n\t * @private\n\t * @param {Number} digit The numeric value of a basic code point.\n\t * @returns {Number} The basic code point whose value (when used for\n\t * representing integers) is `digit`, which needs to be in the range\n\t * `0` to `base - 1`. If `flag` is non-zero, the uppercase form is\n\t * used; else, the lowercase form is used. The behavior is undefined\n\t * if `flag` is non-zero and `digit` has no uppercase form.\n\t */\n\tfunction digitToBasic(digit, flag) {\n\t\t//  0..25 map to ASCII a..z or A..Z\n\t\t// 26..35 map to ASCII 0..9\n\t\treturn digit + 22 + 75 * (digit < 26) - ((flag != 0) << 5);\n\t}\n\n\t/**\n\t * Bias adaptation function as per section 3.4 of RFC 3492.\n\t * http://tools.ietf.org/html/rfc3492#section-3.4\n\t * @private\n\t */\n\tfunction adapt(delta, numPoints, firstTime) {\n\t\tvar k = 0;\n\t\tdelta = firstTime ? floor(delta / damp) : delta >> 1;\n\t\tdelta += floor(delta / numPoints);\n\t\tfor (/* no initialization */; delta > baseMinusTMin * tMax >> 1; k += base) {\n\t\t\tdelta = floor(delta / baseMinusTMin);\n\t\t}\n\t\treturn floor(k + (baseMinusTMin + 1) * delta / (delta + skew));\n\t}\n\n\t/**\n\t * Converts a Punycode string of ASCII-only symbols to a string of Unicode\n\t * symbols.\n\t * @memberOf punycode\n\t * @param {String} input The Punycode string of ASCII-only symbols.\n\t * @returns {String} The resulting string of Unicode symbols.\n\t */\n\tfunction decode(input) {\n\t\t// Don't use UCS-2\n\t\tvar output = [],\n\t\t    inputLength = input.length,\n\t\t    out,\n\t\t    i = 0,\n\t\t    n = initialN,\n\t\t    bias = initialBias,\n\t\t    basic,\n\t\t    j,\n\t\t    index,\n\t\t    oldi,\n\t\t    w,\n\t\t    k,\n\t\t    digit,\n\t\t    t,\n\t\t    /** Cached calculation results */\n\t\t    baseMinusT;\n\n\t\t// Handle the basic code points: let `basic` be the number of input code\n\t\t// points before the last delimiter, or `0` if there is none, then copy\n\t\t// the first basic code points to the output.\n\n\t\tbasic = input.lastIndexOf(delimiter);\n\t\tif (basic < 0) {\n\t\t\tbasic = 0;\n\t\t}\n\n\t\tfor (j = 0; j < basic; ++j) {\n\t\t\t// if it's not a basic code point\n\t\t\tif (input.charCodeAt(j) >= 0x80) {\n\t\t\t\terror('not-basic');\n\t\t\t}\n\t\t\toutput.push(input.charCodeAt(j));\n\t\t}\n\n\t\t// Main decoding loop: start just after the last delimiter if any basic code\n\t\t// points were copied; start at the beginning otherwise.\n\n\t\tfor (index = basic > 0 ? basic + 1 : 0; index < inputLength; /* no final expression */) {\n\n\t\t\t// `index` is the index of the next character to be consumed.\n\t\t\t// Decode a generalized variable-length integer into `delta`,\n\t\t\t// which gets added to `i`. The overflow checking is easier\n\t\t\t// if we increase `i` as we go, then subtract off its starting\n\t\t\t// value at the end to obtain `delta`.\n\t\t\tfor (oldi = i, w = 1, k = base; /* no condition */; k += base) {\n\n\t\t\t\tif (index >= inputLength) {\n\t\t\t\t\terror('invalid-input');\n\t\t\t\t}\n\n\t\t\t\tdigit = basicToDigit(input.charCodeAt(index++));\n\n\t\t\t\tif (digit >= base || digit > floor((maxInt - i) / w)) {\n\t\t\t\t\terror('overflow');\n\t\t\t\t}\n\n\t\t\t\ti += digit * w;\n\t\t\t\tt = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\n\t\t\t\tif (digit < t) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tbaseMinusT = base - t;\n\t\t\t\tif (w > floor(maxInt / baseMinusT)) {\n\t\t\t\t\terror('overflow');\n\t\t\t\t}\n\n\t\t\t\tw *= baseMinusT;\n\n\t\t\t}\n\n\t\t\tout = output.length + 1;\n\t\t\tbias = adapt(i - oldi, out, oldi == 0);\n\n\t\t\t// `i` was supposed to wrap around from `out` to `0`,\n\t\t\t// incrementing `n` each time, so we'll fix that now:\n\t\t\tif (floor(i / out) > maxInt - n) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\tn += floor(i / out);\n\t\t\ti %= out;\n\n\t\t\t// Insert `n` at position `i` of the output\n\t\t\toutput.splice(i++, 0, n);\n\n\t\t}\n\n\t\treturn ucs2encode(output);\n\t}\n\n\t/**\n\t * Converts a string of Unicode symbols (e.g. a domain name label) to a\n\t * Punycode string of ASCII-only symbols.\n\t * @memberOf punycode\n\t * @param {String} input The string of Unicode symbols.\n\t * @returns {String} The resulting Punycode string of ASCII-only symbols.\n\t */\n\tfunction encode(input) {\n\t\tvar n,\n\t\t    delta,\n\t\t    handledCPCount,\n\t\t    basicLength,\n\t\t    bias,\n\t\t    j,\n\t\t    m,\n\t\t    q,\n\t\t    k,\n\t\t    t,\n\t\t    currentValue,\n\t\t    output = [],\n\t\t    /** `inputLength` will hold the number of code points in `input`. */\n\t\t    inputLength,\n\t\t    /** Cached calculation results */\n\t\t    handledCPCountPlusOne,\n\t\t    baseMinusT,\n\t\t    qMinusT;\n\n\t\t// Convert the input in UCS-2 to Unicode\n\t\tinput = ucs2decode(input);\n\n\t\t// Cache the length\n\t\tinputLength = input.length;\n\n\t\t// Initialize the state\n\t\tn = initialN;\n\t\tdelta = 0;\n\t\tbias = initialBias;\n\n\t\t// Handle the basic code points\n\t\tfor (j = 0; j < inputLength; ++j) {\n\t\t\tcurrentValue = input[j];\n\t\t\tif (currentValue < 0x80) {\n\t\t\t\toutput.push(stringFromCharCode(currentValue));\n\t\t\t}\n\t\t}\n\n\t\thandledCPCount = basicLength = output.length;\n\n\t\t// `handledCPCount` is the number of code points that have been handled;\n\t\t// `basicLength` is the number of basic code points.\n\n\t\t// Finish the basic string - if it is not empty - with a delimiter\n\t\tif (basicLength) {\n\t\t\toutput.push(delimiter);\n\t\t}\n\n\t\t// Main encoding loop:\n\t\twhile (handledCPCount < inputLength) {\n\n\t\t\t// All non-basic code points < n have been handled already. Find the next\n\t\t\t// larger one:\n\t\t\tfor (m = maxInt, j = 0; j < inputLength; ++j) {\n\t\t\t\tcurrentValue = input[j];\n\t\t\t\tif (currentValue >= n && currentValue < m) {\n\t\t\t\t\tm = currentValue;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Increase `delta` enough to advance the decoder's <n,i> state to <m,0>,\n\t\t\t// but guard against overflow\n\t\t\thandledCPCountPlusOne = handledCPCount + 1;\n\t\t\tif (m - n > floor((maxInt - delta) / handledCPCountPlusOne)) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\tdelta += (m - n) * handledCPCountPlusOne;\n\t\t\tn = m;\n\n\t\t\tfor (j = 0; j < inputLength; ++j) {\n\t\t\t\tcurrentValue = input[j];\n\n\t\t\t\tif (currentValue < n && ++delta > maxInt) {\n\t\t\t\t\terror('overflow');\n\t\t\t\t}\n\n\t\t\t\tif (currentValue == n) {\n\t\t\t\t\t// Represent delta as a generalized variable-length integer\n\t\t\t\t\tfor (q = delta, k = base; /* no condition */; k += base) {\n\t\t\t\t\t\tt = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\t\t\t\t\t\tif (q < t) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tqMinusT = q - t;\n\t\t\t\t\t\tbaseMinusT = base - t;\n\t\t\t\t\t\toutput.push(\n\t\t\t\t\t\t\tstringFromCharCode(digitToBasic(t + qMinusT % baseMinusT, 0))\n\t\t\t\t\t\t);\n\t\t\t\t\t\tq = floor(qMinusT / baseMinusT);\n\t\t\t\t\t}\n\n\t\t\t\t\toutput.push(stringFromCharCode(digitToBasic(q, 0)));\n\t\t\t\t\tbias = adapt(delta, handledCPCountPlusOne, handledCPCount == basicLength);\n\t\t\t\t\tdelta = 0;\n\t\t\t\t\t++handledCPCount;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t++delta;\n\t\t\t++n;\n\n\t\t}\n\t\treturn output.join('');\n\t}\n\n\t/**\n\t * Converts a Punycode string representing a domain name or an email address\n\t * to Unicode. Only the Punycoded parts of the input will be converted, i.e.\n\t * it doesn't matter if you call it on a string that has already been\n\t * converted to Unicode.\n\t * @memberOf punycode\n\t * @param {String} input The Punycoded domain name or email address to\n\t * convert to Unicode.\n\t * @returns {String} The Unicode representation of the given Punycode\n\t * string.\n\t */\n\tfunction toUnicode(input) {\n\t\treturn mapDomain(input, function(string) {\n\t\t\treturn regexPunycode.test(string)\n\t\t\t\t? decode(string.slice(4).toLowerCase())\n\t\t\t\t: string;\n\t\t});\n\t}\n\n\t/**\n\t * Converts a Unicode string representing a domain name or an email address to\n\t * Punycode. Only the non-ASCII parts of the domain name will be converted,\n\t * i.e. it doesn't matter if you call it with a domain that's already in\n\t * ASCII.\n\t * @memberOf punycode\n\t * @param {String} input The domain name or email address to convert, as a\n\t * Unicode string.\n\t * @returns {String} The Punycode representation of the given domain name or\n\t * email address.\n\t */\n\tfunction toASCII(input) {\n\t\treturn mapDomain(input, function(string) {\n\t\t\treturn regexNonASCII.test(string)\n\t\t\t\t? 'xn--' + encode(string)\n\t\t\t\t: string;\n\t\t});\n\t}\n\n\t/*--------------------------------------------------------------------------*/\n\n\t/** Define the public API */\n\tpunycode = {\n\t\t/**\n\t\t * A string representing the current Punycode.js version number.\n\t\t * @memberOf punycode\n\t\t * @type String\n\t\t */\n\t\t'version': '1.3.2',\n\t\t/**\n\t\t * An object of methods to convert from JavaScript's internal character\n\t\t * representation (UCS-2) to Unicode code points, and back.\n\t\t * @see <https://mathiasbynens.be/notes/javascript-encoding>\n\t\t * @memberOf punycode\n\t\t * @type Object\n\t\t */\n\t\t'ucs2': {\n\t\t\t'decode': ucs2decode,\n\t\t\t'encode': ucs2encode\n\t\t},\n\t\t'decode': decode,\n\t\t'encode': encode,\n\t\t'toASCII': toASCII,\n\t\t'toUnicode': toUnicode\n\t};\n\n\t/** Expose `punycode` */\n\t// Some AMD build optimizers, like r.js, check for specific condition patterns\n\t// like the following:\n\tif (\n\t\ttrue\n\t) {\n\t\t!(__WEBPACK_AMD_DEFINE_RESULT__ = (function() {\n\t\t\treturn punycode;\n\t\t}).call(exports, __webpack_require__, exports, module),\n\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\t} else {}\n\n}(this));\n\n\n//# sourceURL=webpack://playground/./node_modules/punycode/punycode.js?");

/***/ }),

/***/ "./node_modules/querystring/decode.js":
/*!********************************************!*\
  !*** ./node_modules/querystring/decode.js ***!
  \********************************************/
/***/ ((module) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n// If obj.hasOwnProperty has been overridden, then calling\n// obj.hasOwnProperty(prop) will break.\n// See: https://github.com/joyent/node/issues/1707\nfunction hasOwnProperty(obj, prop) {\n  return Object.prototype.hasOwnProperty.call(obj, prop);\n}\n\nmodule.exports = function(qs, sep, eq, options) {\n  sep = sep || '&';\n  eq = eq || '=';\n  var obj = {};\n\n  if (typeof qs !== 'string' || qs.length === 0) {\n    return obj;\n  }\n\n  var regexp = /\\+/g;\n  qs = qs.split(sep);\n\n  var maxKeys = 1000;\n  if (options && typeof options.maxKeys === 'number') {\n    maxKeys = options.maxKeys;\n  }\n\n  var len = qs.length;\n  // maxKeys <= 0 means that we should not limit keys count\n  if (maxKeys > 0 && len > maxKeys) {\n    len = maxKeys;\n  }\n\n  for (var i = 0; i < len; ++i) {\n    var x = qs[i].replace(regexp, '%20'),\n        idx = x.indexOf(eq),\n        kstr, vstr, k, v;\n\n    if (idx >= 0) {\n      kstr = x.substr(0, idx);\n      vstr = x.substr(idx + 1);\n    } else {\n      kstr = x;\n      vstr = '';\n    }\n\n    k = decodeURIComponent(kstr);\n    v = decodeURIComponent(vstr);\n\n    if (!hasOwnProperty(obj, k)) {\n      obj[k] = v;\n    } else if (Array.isArray(obj[k])) {\n      obj[k].push(v);\n    } else {\n      obj[k] = [obj[k], v];\n    }\n  }\n\n  return obj;\n};\n\n\n//# sourceURL=webpack://playground/./node_modules/querystring/decode.js?");

/***/ }),

/***/ "./node_modules/querystring/encode.js":
/*!********************************************!*\
  !*** ./node_modules/querystring/encode.js ***!
  \********************************************/
/***/ ((module) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar stringifyPrimitive = function(v) {\n  switch (typeof v) {\n    case 'string':\n      return v;\n\n    case 'boolean':\n      return v ? 'true' : 'false';\n\n    case 'number':\n      return isFinite(v) ? v : '';\n\n    default:\n      return '';\n  }\n};\n\nmodule.exports = function(obj, sep, eq, name) {\n  sep = sep || '&';\n  eq = eq || '=';\n  if (obj === null) {\n    obj = undefined;\n  }\n\n  if (typeof obj === 'object') {\n    return Object.keys(obj).map(function(k) {\n      var ks = encodeURIComponent(stringifyPrimitive(k)) + eq;\n      if (Array.isArray(obj[k])) {\n        return obj[k].map(function(v) {\n          return ks + encodeURIComponent(stringifyPrimitive(v));\n        }).join(sep);\n      } else {\n        return ks + encodeURIComponent(stringifyPrimitive(obj[k]));\n      }\n    }).join(sep);\n\n  }\n\n  if (!name) return '';\n  return encodeURIComponent(stringifyPrimitive(name)) + eq +\n         encodeURIComponent(stringifyPrimitive(obj));\n};\n\n\n//# sourceURL=webpack://playground/./node_modules/querystring/encode.js?");

/***/ }),

/***/ "./node_modules/querystring/index.js":
/*!*******************************************!*\
  !*** ./node_modules/querystring/index.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nexports.decode = exports.parse = __webpack_require__(/*! ./decode */ \"./node_modules/querystring/decode.js\");\nexports.encode = exports.stringify = __webpack_require__(/*! ./encode */ \"./node_modules/querystring/encode.js\");\n\n\n//# sourceURL=webpack://playground/./node_modules/querystring/index.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/constants.js":
/*!*************************************************!*\
  !*** ./node_modules/relateurl/lib/constants.js ***!
  \*************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports =\n{\n\t// Output\n\tABSOLUTE:      \"absolute\",\n\tPATH_RELATIVE: \"pathRelative\",\n\tROOT_RELATIVE: \"rootRelative\",\n\tSHORTEST:      \"shortest\"\n};\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/constants.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/format.js":
/*!**********************************************!*\
  !*** ./node_modules/relateurl/lib/format.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar constants = __webpack_require__(/*! ./constants */ \"./node_modules/relateurl/lib/constants.js\");\n\n\n\nfunction formatAuth(urlObj, options)\n{\n\tif (urlObj.auth && !options.removeAuth && (urlObj.extra.relation.maximumHost || options.output===constants.ABSOLUTE))\n\t{\n\t\treturn urlObj.auth + \"@\";\n\t}\n\t\n\treturn \"\";\n}\n\n\n\nfunction formatHash(urlObj, options)\n{\n\treturn urlObj.hash ? urlObj.hash : \"\";\n}\n\n\n\nfunction formatHost(urlObj, options)\n{\n\tif (urlObj.host.full && (urlObj.extra.relation.maximumAuth || options.output===constants.ABSOLUTE))\n\t{\n\t\treturn urlObj.host.full;\n\t}\n\t\n\treturn \"\";\n}\n\n\n\nfunction formatPath(urlObj, options)\n{\n\tvar str = \"\";\n\t\n\tvar absolutePath = urlObj.path.absolute.string;\n\tvar relativePath = urlObj.path.relative.string;\n\tvar resource = showResource(urlObj, options);\n\t\n\tif (urlObj.extra.relation.maximumHost || options.output===constants.ABSOLUTE || options.output===constants.ROOT_RELATIVE)\n\t{\n\t\tstr = absolutePath;\n\t}\n\telse if (relativePath.length<=absolutePath.length && options.output===constants.SHORTEST || options.output===constants.PATH_RELATIVE)\n\t{\n\t\tstr = relativePath;\n\t\t\n\t\tif (str === \"\")\n\t\t{\n\t\t\tvar query = showQuery(urlObj,options) && !!getQuery(urlObj,options);\n\t\t\t\n\t\t\tif (urlObj.extra.relation.maximumPath && !resource)\n\t\t\t{\n\t\t\t\tstr = \"./\";\n\t\t\t}\n\t\t\telse if (urlObj.extra.relation.overridesQuery && !resource && !query)\n\t\t\t{\n\t\t\t\tstr = \"./\";\n\t\t\t}\n\t\t}\n\t}\n\telse\n\t{\n\t\tstr = absolutePath;\n\t}\n\t\n\tif ( str===\"/\" && !resource && options.removeRootTrailingSlash && (!urlObj.extra.relation.minimumPort || options.output===constants.ABSOLUTE) )\n\t{\n\t\tstr = \"\";\n\t}\n\t\n\treturn str;\n}\n\n\n\nfunction formatPort(urlObj, options)\n{\n\tif (urlObj.port && !urlObj.extra.portIsDefault && urlObj.extra.relation.maximumHost)\n\t{\n\t\treturn \":\" + urlObj.port;\n\t}\n\t\n\treturn \"\";\n}\n\n\n\nfunction formatQuery(urlObj, options)\n{\n\treturn showQuery(urlObj,options) ? getQuery(urlObj, options) : \"\";\n}\n\n\n\nfunction formatResource(urlObj, options)\n{\n\treturn showResource(urlObj,options) ? urlObj.resource : \"\";\n}\n\n\n\nfunction formatScheme(urlObj, options)\n{\n\tvar str = \"\";\n\t\n\tif (urlObj.extra.relation.maximumHost || options.output===constants.ABSOLUTE)\n\t{\n\t\tif (!urlObj.extra.relation.minimumScheme || !options.schemeRelative || options.output===constants.ABSOLUTE)\n\t\t{\n\t\t\tstr += urlObj.scheme + \"://\";\n\t\t}\n\t\telse\n\t\t{\n\t\t\tstr += \"//\";\n\t\t}\n\t}\n\t\n\treturn str;\n}\n\n\n\nfunction formatUrl(urlObj, options)\n{\n\tvar url = \"\";\n\t\n\turl += formatScheme(urlObj, options);\n\turl += formatAuth(urlObj, options);\n\turl += formatHost(urlObj, options);\n\turl += formatPort(urlObj, options);\n\turl += formatPath(urlObj, options);\n\turl += formatResource(urlObj, options);\n\turl += formatQuery(urlObj, options);\n\turl += formatHash(urlObj, options);\n\t\n\treturn url;\n}\n\n\n\nfunction getQuery(urlObj, options)\n{\n\tvar stripQuery = options.removeEmptyQueries && urlObj.extra.relation.minimumPort;\n\t\n\treturn urlObj.query.string[ stripQuery ? \"stripped\" : \"full\" ];\n}\n\n\n\nfunction showQuery(urlObj, options)\n{\n\treturn !urlObj.extra.relation.minimumQuery || options.output===constants.ABSOLUTE || options.output===constants.ROOT_RELATIVE;\n}\n\n\n\nfunction showResource(urlObj, options)\n{\n\tvar removeIndex = options.removeDirectoryIndexes && urlObj.extra.resourceIsIndex;\n\tvar removeMatchingResource = urlObj.extra.relation.minimumResource && options.output!==constants.ABSOLUTE && options.output!==constants.ROOT_RELATIVE;\n\t\n\treturn !!urlObj.resource && !removeMatchingResource && !removeIndex;\n}\n\n\n\nmodule.exports = formatUrl;\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/format.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/index.js":
/*!*********************************************!*\
  !*** ./node_modules/relateurl/lib/index.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar constants  = __webpack_require__(/*! ./constants */ \"./node_modules/relateurl/lib/constants.js\");\nvar formatUrl  = __webpack_require__(/*! ./format */ \"./node_modules/relateurl/lib/format.js\");\nvar getOptions = __webpack_require__(/*! ./options */ \"./node_modules/relateurl/lib/options.js\");\nvar objUtils   = __webpack_require__(/*! ./util/object */ \"./node_modules/relateurl/lib/util/object.js\");\nvar parseUrl   = __webpack_require__(/*! ./parse */ \"./node_modules/relateurl/lib/parse/index.js\");\nvar relateUrl  = __webpack_require__(/*! ./relate */ \"./node_modules/relateurl/lib/relate/index.js\");\n\n\n\nfunction RelateUrl(from, options)\n{\n\tthis.options = getOptions(options,\n\t{\n\t\tdefaultPorts: {ftp:21, http:80, https:443},\n\t\tdirectoryIndexes: [\"index.html\"],\n\t\tignore_www: false,\n\t\toutput: RelateUrl.SHORTEST,\n\t\trejectedSchemes: [\"data\",\"javascript\",\"mailto\"],\n\t\tremoveAuth: false,\n\t\tremoveDirectoryIndexes: true,\n\t\tremoveEmptyQueries: false,\n\t\tremoveRootTrailingSlash: true,\n\t\tschemeRelative: true,\n\t\tsite: undefined,\n\t\tslashesDenoteHost: true\n\t});\n\t\n\tthis.from = parseUrl.from(from, this.options, null);\n}\n\n\n\n/*\n\tUsage: instance=new RelateUrl(); instance.relate();\n*/\nRelateUrl.prototype.relate = function(from, to, options)\n{\n\t// relate(to,options)\n\tif ( objUtils.isPlainObject(to) )\n\t{\n\t\toptions = to;\n\t\tto = from;\n\t\tfrom = null;\n\t}\n\t// relate(to)\n\telse if (!to)\n\t{\n\t\tto = from;\n\t\tfrom = null;\n\t}\n\t\n\toptions = getOptions(options, this.options);\n\tfrom = from || options.site;\n\tfrom = parseUrl.from(from, options, this.from);\n\t\n\tif (!from || !from.href)\n\t{\n\t\tthrow new Error(\"from value not defined.\");\n\t}\n\telse if (from.extra.hrefInfo.minimumPathOnly)\n\t{\n\t\tthrow new Error(\"from value supplied is not absolute: \"+from.href);\n\t}\n\t\n\tto = parseUrl.to(to, options);\n\t\n\tif (to.valid===false) return to.href;\n\t\n\tto = relateUrl(from, to, options);\n\tto = formatUrl(to, options);\n\t\n\treturn to;\n}\n\n\n\n/*\n\tUsage: RelateUrl.relate();\n*/\nRelateUrl.relate = function(from, to, options)\n{\n\treturn new RelateUrl().relate(from, to, options);\n}\n\n\n\n// Make constants accessible from API\nobjUtils.shallowMerge(RelateUrl, constants);\n\n\n\nmodule.exports = RelateUrl;\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/index.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/options.js":
/*!***********************************************!*\
  !*** ./node_modules/relateurl/lib/options.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar objUtils = __webpack_require__(/*! ./util/object */ \"./node_modules/relateurl/lib/util/object.js\");\n\n\n\nfunction getOptions(options, defaults)\n{\n\tif ( objUtils.isPlainObject(options) )\n\t{\n\t\tvar newOptions = {};\n\t\t\n\t\tfor (var i in defaults)\n\t\t{\n\t\t\tif ( defaults.hasOwnProperty(i) )\n\t\t\t{\n\t\t\t\tif (options[i] !== undefined)\n\t\t\t\t{\n\t\t\t\t\tnewOptions[i] = mergeOption(options[i], defaults[i]);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tnewOptions[i] = defaults[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn newOptions;\n\t}\n\telse\n\t{\n\t\treturn defaults;\n\t}\n}\n\n\n\nfunction mergeOption(newValues, defaultValues)\n{\n\tif (defaultValues instanceof Object && newValues instanceof Object)\n\t{\n\t\tif (defaultValues instanceof Array && newValues instanceof Array)\n\t\t{\n\t\t\treturn defaultValues.concat(newValues);\n\t\t}\n\t\telse\n\t\t{\n\t\t\treturn objUtils.shallowMerge(newValues, defaultValues);\n\t\t}\n\t}\n\t\n\treturn newValues;\n}\n\n\n\nmodule.exports = getOptions;\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/options.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/parse/host.js":
/*!**************************************************!*\
  !*** ./node_modules/relateurl/lib/parse/host.js ***!
  \**************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction parseHost(urlObj, options)\n{\n\t// TWEAK :: condition only for speed optimization\n\tif (options.ignore_www)\n\t{\n\t\tvar host = urlObj.host.full;\n\t\t\n\t\tif (host)\n\t\t{\n\t\t\tvar stripped = host;\n\t\t\t\n\t\t\tif (host.indexOf(\"www.\") === 0)\n\t\t\t{\n\t\t\t\tstripped = host.substr(4);\n\t\t\t}\n\t\t\t\n\t\t\turlObj.host.stripped = stripped;\n\t\t}\n\t}\n}\n\n\n\nmodule.exports = parseHost;\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/parse/host.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/parse/hrefInfo.js":
/*!******************************************************!*\
  !*** ./node_modules/relateurl/lib/parse/hrefInfo.js ***!
  \******************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction hrefInfo(urlObj)\n{\n\tvar minimumPathOnly     = (!urlObj.scheme && !urlObj.auth && !urlObj.host.full && !urlObj.port);\n\tvar minimumResourceOnly = (minimumPathOnly && !urlObj.path.absolute.string);\n\tvar minimumQueryOnly    = (minimumResourceOnly && !urlObj.resource);\n\tvar minimumHashOnly     = (minimumQueryOnly && !urlObj.query.string.full.length);\n\tvar empty               = (minimumHashOnly && !urlObj.hash);\n\t\n\turlObj.extra.hrefInfo.minimumPathOnly     = minimumPathOnly;\n\turlObj.extra.hrefInfo.minimumResourceOnly = minimumResourceOnly;\n\turlObj.extra.hrefInfo.minimumQueryOnly    = minimumQueryOnly;\n\turlObj.extra.hrefInfo.minimumHashOnly     = minimumHashOnly;\n\turlObj.extra.hrefInfo.empty = empty;\n}\n\n\n\nmodule.exports = hrefInfo;\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/parse/hrefInfo.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/parse/index.js":
/*!***************************************************!*\
  !*** ./node_modules/relateurl/lib/parse/index.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar hrefInfo   = __webpack_require__(/*! ./hrefInfo */ \"./node_modules/relateurl/lib/parse/hrefInfo.js\");\nvar parseHost  = __webpack_require__(/*! ./host */ \"./node_modules/relateurl/lib/parse/host.js\");\nvar parsePath  = __webpack_require__(/*! ./path */ \"./node_modules/relateurl/lib/parse/path.js\");\nvar parsePort  = __webpack_require__(/*! ./port */ \"./node_modules/relateurl/lib/parse/port.js\");\nvar parseQuery = __webpack_require__(/*! ./query */ \"./node_modules/relateurl/lib/parse/query.js\");\nvar parseUrlString = __webpack_require__(/*! ./urlstring */ \"./node_modules/relateurl/lib/parse/urlstring.js\");\nvar pathUtils      = __webpack_require__(/*! ../util/path */ \"./node_modules/relateurl/lib/util/path.js\");\n\n\n\nfunction parseFromUrl(url, options, fallback)\n{\n\tif (url)\n\t{\n\t\tvar urlObj = parseUrl(url, options);\n\t\t\n\t\t// Because the following occurs in the relate stage for \"to\" URLs,\n\t\t// such had to be mostly duplicated here\n\t\t\n\t\tvar pathArray = pathUtils.resolveDotSegments(urlObj.path.absolute.array);\n\t\t\n\t\turlObj.path.absolute.array  = pathArray;\n\t\turlObj.path.absolute.string = \"/\" + pathUtils.join(pathArray);\n\t\t\n\t\treturn urlObj;\n\t}\n\telse\n\t{\n\t\treturn fallback;\n\t}\n}\n\n\n\nfunction parseUrl(url, options)\n{\n\tvar urlObj = parseUrlString(url, options);\n\t\n\tif (urlObj.valid===false) return urlObj;\n\t\n\tparseHost(urlObj, options);\n\tparsePort(urlObj, options);\n\tparsePath(urlObj, options);\n\tparseQuery(urlObj, options);\n\threfInfo(urlObj);\n\t\n\treturn urlObj;\n}\n\n\n\nmodule.exports =\n{\n\tfrom: parseFromUrl,\n\tto:   parseUrl\n};\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/parse/index.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/parse/path.js":
/*!**************************************************!*\
  !*** ./node_modules/relateurl/lib/parse/path.js ***!
  \**************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction isDirectoryIndex(resource, options)\n{\n\tvar verdict = false;\n\t\n\toptions.directoryIndexes.every( function(index)\n\t{\n\t\tif (index === resource)\n\t\t{\n\t\t\tverdict = true;\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\treturn true;\n\t});\n\t\n\treturn verdict;\n}\n\n\n\nfunction parsePath(urlObj, options)\n{\n\tvar path = urlObj.path.absolute.string;\n\t\n\tif (path)\n\t{\n\t\tvar lastSlash = path.lastIndexOf(\"/\");\n\t\t\n\t\tif (lastSlash > -1)\n\t\t{\n\t\t\tif (++lastSlash < path.length)\n\t\t\t{\n\t\t\t\tvar resource = path.substr(lastSlash);\n\t\t\t\t\n\t\t\t\tif (resource!==\".\" && resource!==\"..\")\n\t\t\t\t{\n\t\t\t\t\turlObj.resource = resource;\n\t\t\t\t\tpath = path.substr(0, lastSlash);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tpath += \"/\";\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\turlObj.path.absolute.string = path;\n\t\t\turlObj.path.absolute.array = splitPath(path);\n\t\t}\n\t\telse if (path===\".\" || path===\"..\")\n\t\t{\n\t\t\t// \"..?var\", \"..#anchor\", etc ... not \"..index.html\"\n\t\t\tpath += \"/\";\n\t\t\t\n\t\t\turlObj.path.absolute.string = path;\n\t\t\turlObj.path.absolute.array = splitPath(path);\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Resource-only\n\t\t\turlObj.resource = path;\n\t\t\turlObj.path.absolute.string = null;\n\t\t}\n\t\t\n\t\turlObj.extra.resourceIsIndex = isDirectoryIndex(urlObj.resource, options);\n\t}\n\t// Else: query/hash-only or empty\n}\n\n\n\nfunction splitPath(path)\n{\n\t// TWEAK :: condition only for speed optimization\n\tif (path !== \"/\")\n\t{\n\t\tvar cleaned = [];\n\t\t\n\t\tpath.split(\"/\").forEach( function(dir)\n\t\t{\n\t\t\t// Cleanup -- splitting \"/dir/\" becomes [\"\",\"dir\",\"\"]\n\t\t\tif (dir !== \"\")\n\t\t\t{\n\t\t\t\tcleaned.push(dir);\n\t\t\t}\n\t\t});\n\t\t\n\t\treturn cleaned;\n\t}\n\telse\n\t{\n\t\t// Faster to skip the above block and just create an array\n\t\treturn [];\n\t}\n}\n\n\n\nmodule.exports = parsePath;\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/parse/path.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/parse/port.js":
/*!**************************************************!*\
  !*** ./node_modules/relateurl/lib/parse/port.js ***!
  \**************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction parsePort(urlObj, options)\n{\n\tvar defaultPort = -1;\n\t\n\tfor (var i in options.defaultPorts)\n\t{\n\t\tif ( i===urlObj.scheme && options.defaultPorts.hasOwnProperty(i) )\n\t\t{\n\t\t\tdefaultPort = options.defaultPorts[i];\n\t\t\tbreak;\n\t\t}\n\t}\n\t\n\tif (defaultPort > -1)\n\t{\n\t\t// Force same type as urlObj.port\n\t\tdefaultPort = defaultPort.toString();\n\t\t\n\t\tif (urlObj.port === null)\n\t\t{\n\t\t\turlObj.port = defaultPort;\n\t\t}\n\t\t\n\t\turlObj.extra.portIsDefault = (urlObj.port === defaultPort);\n\t}\n}\n\n\n\nmodule.exports = parsePort;\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/parse/port.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/parse/query.js":
/*!***************************************************!*\
  !*** ./node_modules/relateurl/lib/parse/query.js ***!
  \***************************************************/
/***/ ((module) => {

"use strict";
eval("\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\n\n\n\nfunction parseQuery(urlObj, options)\n{\n\turlObj.query.string.full = stringify(urlObj.query.object, false);\n\t\n\t// TWEAK :: condition only for speed optimization\n\tif (options.removeEmptyQueries)\n\t{\n\t\turlObj.query.string.stripped = stringify(urlObj.query.object, true);\n\t}\n}\n\n\n\nfunction stringify(queryObj, removeEmptyQueries)\n{\n\tvar count = 0;\n\tvar str = \"\";\n\t\n\tfor (var i in queryObj)\n\t{\n\t\tif ( i!==\"\" && hasOwnProperty.call(queryObj, i)===true )\n\t\t{\n\t\t\tvar value = queryObj[i];\n\t\t\t\n\t\t\tif (value !== \"\" || !removeEmptyQueries)\n\t\t\t{\n\t\t\t\tstr += (++count===1) ? \"?\" : \"&\";\n\t\t\t\t\n\t\t\t\ti = encodeURIComponent(i);\n\t\t\t\t\n\t\t\t\tif (value !== \"\")\n\t\t\t\t{\n\t\t\t\t\tstr += i +\"=\"+ encodeURIComponent(value).replace(/%20/g,\"+\");\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tstr += i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn str;\n}\n\n\n\nmodule.exports = parseQuery;\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/parse/query.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/parse/urlstring.js":
/*!*******************************************************!*\
  !*** ./node_modules/relateurl/lib/parse/urlstring.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar _parseUrl = (__webpack_require__(/*! url */ \"./node_modules/url/url.js\").parse);\n\n\n\n/*\n\tCustomize the URL object that Node generates\n\tbecause:\n\t\n\t* necessary data for later\n\t* urlObj.host is useless\n\t* urlObj.hostname is too long\n\t* urlObj.path is useless\n\t* urlObj.pathname is too long\n\t* urlObj.protocol is inaccurate; should be called \"scheme\"\n\t* urlObj.search is mostly useless\n*/\nfunction clean(urlObj)\n{\n\tvar scheme = urlObj.protocol;\n\t\n\tif (scheme)\n\t{\n\t\t// Remove \":\" suffix\n\t\tif (scheme.indexOf(\":\") === scheme.length-1)\n\t\t{\n\t\t\tscheme = scheme.substr(0, scheme.length-1);\n\t\t}\n\t}\n\t\n\turlObj.host =\n\t{\n\t\t// TODO :: unescape(encodeURIComponent(s)) ? ... http://ecmanaut.blogspot.ca/2006/07/encoding-decoding-utf8-in-javascript.html\n\t\tfull: urlObj.hostname,\n\t\tstripped: null\n\t};\n\t\n\turlObj.path =\n\t{\n\t\tabsolute:\n\t\t{\n\t\t\tarray: null,\n\t\t\tstring: urlObj.pathname\n\t\t},\n\t\trelative:\n\t\t{\n\t\t\tarray: null,\n\t\t\tstring: null\n\t\t}\n\t};\n\t\n\turlObj.query =\n\t{\n\t\tobject: urlObj.query,\n\t\tstring:\n\t\t{\n\t\t\tfull: null,\n\t\t\tstripped: null\n\t\t}\n\t};\n\t\n\turlObj.extra =\n\t{\n\t\threfInfo:\n\t\t{\n\t\t\tminimumPathOnly: null,\n\t\t\tminimumResourceOnly: null,\n\t\t\tminimumQueryOnly: null,\n\t\t\tminimumHashOnly: null,\n\t\t\tempty: null,\n\t\t\t\n\t\t\tseparatorOnlyQuery: urlObj.search===\"?\"\n\t\t},\n\t\tportIsDefault: null,\n\t\trelation:\n\t\t{\n\t\t\tmaximumScheme: null,\n\t\t\tmaximumAuth: null,\n\t\t\tmaximumHost: null,\n\t\t\tmaximumPort: null,\n\t\t\tmaximumPath: null,\n\t\t\tmaximumResource: null,\n\t\t\tmaximumQuery: null,\n\t\t\tmaximumHash: null,\n\t\t\t\n\t\t\tminimumScheme: null,\n\t\t\tminimumAuth: null,\n\t\t\tminimumHost: null,\n\t\t\tminimumPort: null,\n\t\t\tminimumPath: null,\n\t\t\tminimumResource: null,\n\t\t\tminimumQuery: null,\n\t\t\tminimumHash: null,\n\t\t\t\n\t\t\toverridesQuery: null\n\t\t},\n\t\tresourceIsIndex: null,\n\t\tslashes: urlObj.slashes\n\t};\n\t\n\turlObj.resource = null;\n\turlObj.scheme = scheme;\n\tdelete urlObj.hostname;\n\tdelete urlObj.pathname;\n\tdelete urlObj.protocol;\n\tdelete urlObj.search;\n\tdelete urlObj.slashes;\n\t\n\treturn urlObj;\n}\n\n\n\nfunction validScheme(url, options)\n{\n\tvar valid = true;\n\t\n\toptions.rejectedSchemes.every( function(rejectedScheme)\n\t{\n\t\tvalid = !(url.indexOf(rejectedScheme+\":\") === 0);\n\t\t\n\t\t// Break loop\n\t\treturn valid;\n\t});\n\t\n\treturn valid;\n}\n\n\n\nfunction parseUrlString(url, options)\n{\n\tif ( validScheme(url,options) )\n\t{\n\t\treturn clean( _parseUrl(url, true, options.slashesDenoteHost) );\n\t}\n\telse\n\t{\n\t\treturn {href:url, valid:false};\n\t}\n}\n\n\n\nmodule.exports = parseUrlString;\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/parse/urlstring.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/relate/absolutize.js":
/*!*********************************************************!*\
  !*** ./node_modules/relateurl/lib/relate/absolutize.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar findRelation = __webpack_require__(/*! ./findRelation */ \"./node_modules/relateurl/lib/relate/findRelation.js\");\nvar objUtils     = __webpack_require__(/*! ../util/object */ \"./node_modules/relateurl/lib/util/object.js\");\nvar pathUtils    = __webpack_require__(/*! ../util/path */ \"./node_modules/relateurl/lib/util/path.js\");\n\n\n\nfunction absolutize(urlObj, siteUrlObj, options)\n{\n\tfindRelation.upToPath(urlObj, siteUrlObj, options);\n\t\n\t// Fill in relative URLs\n\tif (urlObj.extra.relation.minimumScheme) urlObj.scheme = siteUrlObj.scheme;\n\tif (urlObj.extra.relation.minimumAuth)   urlObj.auth   = siteUrlObj.auth;\n\tif (urlObj.extra.relation.minimumHost)   urlObj.host   = objUtils.clone(siteUrlObj.host);\n\tif (urlObj.extra.relation.minimumPort)   copyPort(urlObj, siteUrlObj);\n\tif (urlObj.extra.relation.minimumScheme) copyPath(urlObj, siteUrlObj);\n\t\n\t// Check remaining relativeness now that path has been copied and/or resolved\n\tfindRelation.pathOn(urlObj, siteUrlObj, options);\n\t\n\t// Fill in relative URLs\n\tif (urlObj.extra.relation.minimumResource) copyResource(urlObj, siteUrlObj);\n\tif (urlObj.extra.relation.minimumQuery)    urlObj.query = objUtils.clone(siteUrlObj.query);\n\tif (urlObj.extra.relation.minimumHash)     urlObj.hash  = siteUrlObj.hash;\n}\n\n\n\n/*\n\tGet an absolute path that's relative to site url.\n*/\nfunction copyPath(urlObj, siteUrlObj)\n{\n\tif (urlObj.extra.relation.maximumHost || !urlObj.extra.hrefInfo.minimumResourceOnly)\n\t{\n\t\tvar pathArray = urlObj.path.absolute.array;\n\t\tvar pathString = \"/\";\n\t\t\n\t\t// If not erroneous URL\n\t\tif (pathArray)\n\t\t{\n\t\t\t// If is relative path\n\t\t\tif (urlObj.extra.hrefInfo.minimumPathOnly && urlObj.path.absolute.string.indexOf(\"/\")!==0)\n\t\t\t{\n\t\t\t\t// Append path to site path\n\t\t\t\tpathArray = siteUrlObj.path.absolute.array.concat(pathArray);\n\t\t\t}\n\t\t\t\n\t\t\tpathArray   = pathUtils.resolveDotSegments(pathArray);\n\t\t\tpathString += pathUtils.join(pathArray);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tpathArray = [];\n\t\t}\n\t\t\n\t\turlObj.path.absolute.array  = pathArray;\n\t\turlObj.path.absolute.string = pathString;\n\t}\n\telse\n\t{\n\t\t// Resource-, query- or hash-only or empty\n\t\turlObj.path = objUtils.clone(siteUrlObj.path);\n\t}\n}\n\n\n\nfunction copyPort(urlObj, siteUrlObj)\n{\n\turlObj.port = siteUrlObj.port;\n\t\n\turlObj.extra.portIsDefault = siteUrlObj.extra.portIsDefault;\n}\n\n\n\nfunction copyResource(urlObj, siteUrlObj)\n{\n\turlObj.resource = siteUrlObj.resource;\n\t\n\turlObj.extra.resourceIsIndex = siteUrlObj.extra.resourceIsIndex;\n}\n\n\n\nmodule.exports = absolutize;\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/relate/absolutize.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/relate/findRelation.js":
/*!***********************************************************!*\
  !*** ./node_modules/relateurl/lib/relate/findRelation.js ***!
  \***********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction findRelation_upToPath(urlObj, siteUrlObj, options)\n{\n\t// Path- or root-relative URL\n\tvar pathOnly = urlObj.extra.hrefInfo.minimumPathOnly;\n\t\n\t// Matching scheme, scheme-relative or path-only\n\tvar minimumScheme = (urlObj.scheme===siteUrlObj.scheme || !urlObj.scheme);\n\t\n\t// Matching auth, ignoring auth or path-only\n\tvar minimumAuth = minimumScheme && (urlObj.auth===siteUrlObj.auth || options.removeAuth || pathOnly);\n\t\n\t// Matching host or path-only\n\tvar www = options.ignore_www ? \"stripped\" : \"full\";\n\tvar minimumHost = minimumAuth && (urlObj.host[www]===siteUrlObj.host[www] || pathOnly);\n\t\n\t// Matching port or path-only\n\tvar minimumPort = minimumHost && (urlObj.port===siteUrlObj.port || pathOnly);\n\t\n\turlObj.extra.relation.minimumScheme = minimumScheme;\n\turlObj.extra.relation.minimumAuth   = minimumAuth;\n\turlObj.extra.relation.minimumHost   = minimumHost;\n\turlObj.extra.relation.minimumPort   = minimumPort;\n\t\n\turlObj.extra.relation.maximumScheme = !minimumScheme || minimumScheme && !minimumAuth;\n\turlObj.extra.relation.maximumAuth   = !minimumScheme || minimumScheme && !minimumHost;\n\turlObj.extra.relation.maximumHost   = !minimumScheme || minimumScheme && !minimumPort;\n}\n\n\n\nfunction findRelation_pathOn(urlObj, siteUrlObj, options)\n{\n\tvar queryOnly = urlObj.extra.hrefInfo.minimumQueryOnly;\n\tvar hashOnly  = urlObj.extra.hrefInfo.minimumHashOnly;\n\tvar empty     = urlObj.extra.hrefInfo.empty;\t// not required, but self-documenting\n\t\n\t// From upToPath()\n\tvar minimumPort   = urlObj.extra.relation.minimumPort;\n\tvar minimumScheme = urlObj.extra.relation.minimumScheme;\n\t\n\t// Matching port and path\n\tvar minimumPath = minimumPort && urlObj.path.absolute.string===siteUrlObj.path.absolute.string;\n\t\n\t// Matching resource or query/hash-only or empty\n\tvar matchingResource = (urlObj.resource===siteUrlObj.resource || !urlObj.resource && siteUrlObj.extra.resourceIsIndex) || (options.removeDirectoryIndexes && urlObj.extra.resourceIsIndex && !siteUrlObj.resource);\n\tvar minimumResource = minimumPath && (matchingResource || queryOnly || hashOnly || empty);\n\t\n\t// Matching query or hash-only/empty\n\tvar query = options.removeEmptyQueries ? \"stripped\" : \"full\";\n\tvar urlQuery = urlObj.query.string[query];\n\tvar siteUrlQuery = siteUrlObj.query.string[query];\n\tvar minimumQuery = (minimumResource && !!urlQuery && urlQuery===siteUrlQuery) || ((hashOnly || empty) && !urlObj.extra.hrefInfo.separatorOnlyQuery);\n\t\n\tvar minimumHash = minimumQuery && urlObj.hash===siteUrlObj.hash;\n\t\n\turlObj.extra.relation.minimumPath     = minimumPath;\n\turlObj.extra.relation.minimumResource = minimumResource;\n\turlObj.extra.relation.minimumQuery    = minimumQuery;\n\turlObj.extra.relation.minimumHash     = minimumHash;\n\t\n\turlObj.extra.relation.maximumPort     = !minimumScheme || minimumScheme && !minimumPath;\n\turlObj.extra.relation.maximumPath     = !minimumScheme || minimumScheme && !minimumResource;\n\turlObj.extra.relation.maximumResource = !minimumScheme || minimumScheme && !minimumQuery;\n\turlObj.extra.relation.maximumQuery    = !minimumScheme || minimumScheme && !minimumHash;\n\turlObj.extra.relation.maximumHash     = !minimumScheme || minimumScheme && !minimumHash;\t// there's nothing after hash, so it's the same as maximumQuery\n\t\n\t// Matching path and/or resource with existing but non-matching site query\n\turlObj.extra.relation.overridesQuery  = minimumPath && urlObj.extra.relation.maximumResource && !minimumQuery && !!siteUrlQuery;\n}\n\n\n\nmodule.exports =\n{\n\tpathOn:   findRelation_pathOn,\n\tupToPath: findRelation_upToPath\n};\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/relate/findRelation.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/relate/index.js":
/*!****************************************************!*\
  !*** ./node_modules/relateurl/lib/relate/index.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar absolutize = __webpack_require__(/*! ./absolutize */ \"./node_modules/relateurl/lib/relate/absolutize.js\");\nvar relativize = __webpack_require__(/*! ./relativize */ \"./node_modules/relateurl/lib/relate/relativize.js\");\n\n\n\nfunction relateUrl(siteUrlObj, urlObj, options)\n{\n\tabsolutize(urlObj, siteUrlObj, options);\n\trelativize(urlObj, siteUrlObj, options);\n\t\n\treturn urlObj;\n}\n\n\n\nmodule.exports = relateUrl;\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/relate/index.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/relate/relativize.js":
/*!*********************************************************!*\
  !*** ./node_modules/relateurl/lib/relate/relativize.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar pathUtils = __webpack_require__(/*! ../util/path */ \"./node_modules/relateurl/lib/util/path.js\");\n\n\n\n/*\n\tGet a path relative to the site path.\n*/\nfunction relatePath(absolutePath, siteAbsolutePath)\n{\n\tvar relativePath = [];\n\t\n\t// At this point, it's related to the host/port\n\tvar related = true;\n\tvar parentIndex = -1;\n\t\n\t// Find parents\n\tsiteAbsolutePath.forEach( function(siteAbsoluteDir, i)\n\t{\n\t\tif (related)\n\t\t{\n\t\t\tif (absolutePath[i] !== siteAbsoluteDir)\n\t\t\t{\n\t\t\t\trelated = false;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tparentIndex = i;\n\t\t\t}\n\t\t}\n\t\t\n\t\tif (!related)\n\t\t{\n\t\t\t// Up one level\n\t\t\trelativePath.push(\"..\");\n\t\t}\n\t});\n\t\n\t// Form path\n\tabsolutePath.forEach( function(dir, i)\n\t{\n\t\tif (i > parentIndex)\n\t\t{\n\t\t\trelativePath.push(dir);\n\t\t}\n\t});\n\t\n\treturn relativePath;\n}\n\n\n\nfunction relativize(urlObj, siteUrlObj, options)\n{\n\tif (urlObj.extra.relation.minimumScheme)\n\t{\n\t\tvar pathArray = relatePath(urlObj.path.absolute.array, siteUrlObj.path.absolute.array);\n\t\t\n\t\turlObj.path.relative.array  = pathArray;\n\t\turlObj.path.relative.string = pathUtils.join(pathArray);\n\t}\n}\n\n\n\nmodule.exports = relativize;\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/relate/relativize.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/util/object.js":
/*!***************************************************!*\
  !*** ./node_modules/relateurl/lib/util/object.js ***!
  \***************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*\n\tDeep-clone an object.\n*/\nfunction clone(obj)\n{\n\tif (obj instanceof Object)\n\t{\n\t\tvar clonedObj = (obj instanceof Array) ? [] : {};\n\t\t\n\t\tfor (var i in obj)\n\t\t{\n\t\t\tif ( obj.hasOwnProperty(i) )\n\t\t\t{\n\t\t\t\tclonedObj[i] = clone( obj[i] );\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn clonedObj;\n\t}\n\t\n\treturn obj;\n}\n\n\n\n/*\n\thttps://github.com/jonschlinkert/is-plain-object\n*/\nfunction isPlainObject(obj)\n{\n\treturn !!obj && typeof obj===\"object\" && obj.constructor===Object;\n}\n\n\n\n/*\n\tShallow-merge two objects.\n*/\nfunction shallowMerge(target, source)\n{\n\tif (target instanceof Object && source instanceof Object)\n\t{\n\t\tfor (var i in source)\n\t\t{\n\t\t\tif ( source.hasOwnProperty(i) )\n\t\t\t{\n\t\t\t\ttarget[i] = source[i];\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn target;\n}\n\n\n\nmodule.exports =\n{\n\tclone: clone,\n\tisPlainObject: isPlainObject,\n\tshallowMerge: shallowMerge\n};\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/util/object.js?");

/***/ }),

/***/ "./node_modules/relateurl/lib/util/path.js":
/*!*************************************************!*\
  !*** ./node_modules/relateurl/lib/util/path.js ***!
  \*************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction joinPath(pathArray)\n{\n\tif (pathArray.length > 0)\n\t{\n\t\treturn pathArray.join(\"/\") + \"/\";\n\t}\n\telse\n\t{\n\t\treturn \"\";\n\t}\n}\n\n\n\nfunction resolveDotSegments(pathArray)\n{\n\tvar pathAbsolute = [];\n\t\n\tpathArray.forEach( function(dir)\n\t{\n\t\tif (dir !== \"..\")\n\t\t{\n\t\t\tif (dir !== \".\")\n\t\t\t{\n\t\t\t\tpathAbsolute.push(dir);\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Remove parent\n\t\t\tif (pathAbsolute.length > 0)\n\t\t\t{\n\t\t\t\tpathAbsolute.splice(pathAbsolute.length-1, 1);\n\t\t\t}\n\t\t}\n\t});\n\t\n\treturn pathAbsolute;\n}\n\n\n\nmodule.exports =\n{\n\tjoin: joinPath,\n\tresolveDotSegments: resolveDotSegments\n};\n\n\n//# sourceURL=webpack://playground/./node_modules/relateurl/lib/util/path.js?");

/***/ }),

/***/ "./node_modules/url/url.js":
/*!*********************************!*\
  !*** ./node_modules/url/url.js ***!
  \*********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar punycode = __webpack_require__(/*! punycode */ \"./node_modules/punycode/punycode.js\");\nvar util = __webpack_require__(/*! ./util */ \"./node_modules/url/util.js\");\n\nexports.parse = urlParse;\nexports.resolve = urlResolve;\nexports.resolveObject = urlResolveObject;\nexports.format = urlFormat;\n\nexports.Url = Url;\n\nfunction Url() {\n  this.protocol = null;\n  this.slashes = null;\n  this.auth = null;\n  this.host = null;\n  this.port = null;\n  this.hostname = null;\n  this.hash = null;\n  this.search = null;\n  this.query = null;\n  this.pathname = null;\n  this.path = null;\n  this.href = null;\n}\n\n// Reference: RFC 3986, RFC 1808, RFC 2396\n\n// define these here so at least they only have to be\n// compiled once on the first module load.\nvar protocolPattern = /^([a-z0-9.+-]+:)/i,\n    portPattern = /:[0-9]*$/,\n\n    // Special case for a simple path URL\n    simplePathPattern = /^(\\/\\/?(?!\\/)[^\\?\\s]*)(\\?[^\\s]*)?$/,\n\n    // RFC 2396: characters reserved for delimiting URLs.\n    // We actually just auto-escape these.\n    delims = ['<', '>', '\"', '`', ' ', '\\r', '\\n', '\\t'],\n\n    // RFC 2396: characters not allowed for various reasons.\n    unwise = ['{', '}', '|', '\\\\', '^', '`'].concat(delims),\n\n    // Allowed by RFCs, but cause of XSS attacks.  Always escape these.\n    autoEscape = ['\\''].concat(unwise),\n    // Characters that are never ever allowed in a hostname.\n    // Note that any invalid chars are also handled, but these\n    // are the ones that are *expected* to be seen, so we fast-path\n    // them.\n    nonHostChars = ['%', '/', '?', ';', '#'].concat(autoEscape),\n    hostEndingChars = ['/', '?', '#'],\n    hostnameMaxLen = 255,\n    hostnamePartPattern = /^[+a-z0-9A-Z_-]{0,63}$/,\n    hostnamePartStart = /^([+a-z0-9A-Z_-]{0,63})(.*)$/,\n    // protocols that can allow \"unsafe\" and \"unwise\" chars.\n    unsafeProtocol = {\n      'javascript': true,\n      'javascript:': true\n    },\n    // protocols that never have a hostname.\n    hostlessProtocol = {\n      'javascript': true,\n      'javascript:': true\n    },\n    // protocols that always contain a // bit.\n    slashedProtocol = {\n      'http': true,\n      'https': true,\n      'ftp': true,\n      'gopher': true,\n      'file': true,\n      'http:': true,\n      'https:': true,\n      'ftp:': true,\n      'gopher:': true,\n      'file:': true\n    },\n    querystring = __webpack_require__(/*! querystring */ \"./node_modules/querystring/index.js\");\n\nfunction urlParse(url, parseQueryString, slashesDenoteHost) {\n  if (url && util.isObject(url) && url instanceof Url) return url;\n\n  var u = new Url;\n  u.parse(url, parseQueryString, slashesDenoteHost);\n  return u;\n}\n\nUrl.prototype.parse = function(url, parseQueryString, slashesDenoteHost) {\n  if (!util.isString(url)) {\n    throw new TypeError(\"Parameter 'url' must be a string, not \" + typeof url);\n  }\n\n  // Copy chrome, IE, opera backslash-handling behavior.\n  // Back slashes before the query string get converted to forward slashes\n  // See: https://code.google.com/p/chromium/issues/detail?id=25916\n  var queryIndex = url.indexOf('?'),\n      splitter =\n          (queryIndex !== -1 && queryIndex < url.indexOf('#')) ? '?' : '#',\n      uSplit = url.split(splitter),\n      slashRegex = /\\\\/g;\n  uSplit[0] = uSplit[0].replace(slashRegex, '/');\n  url = uSplit.join(splitter);\n\n  var rest = url;\n\n  // trim before proceeding.\n  // This is to support parse stuff like \"  http://foo.com  \\n\"\n  rest = rest.trim();\n\n  if (!slashesDenoteHost && url.split('#').length === 1) {\n    // Try fast path regexp\n    var simplePath = simplePathPattern.exec(rest);\n    if (simplePath) {\n      this.path = rest;\n      this.href = rest;\n      this.pathname = simplePath[1];\n      if (simplePath[2]) {\n        this.search = simplePath[2];\n        if (parseQueryString) {\n          this.query = querystring.parse(this.search.substr(1));\n        } else {\n          this.query = this.search.substr(1);\n        }\n      } else if (parseQueryString) {\n        this.search = '';\n        this.query = {};\n      }\n      return this;\n    }\n  }\n\n  var proto = protocolPattern.exec(rest);\n  if (proto) {\n    proto = proto[0];\n    var lowerProto = proto.toLowerCase();\n    this.protocol = lowerProto;\n    rest = rest.substr(proto.length);\n  }\n\n  // figure out if it's got a host\n  // user@server is *always* interpreted as a hostname, and url\n  // resolution will treat //foo/bar as host=foo,path=bar because that's\n  // how the browser resolves relative URLs.\n  if (slashesDenoteHost || proto || rest.match(/^\\/\\/[^@\\/]+@[^@\\/]+/)) {\n    var slashes = rest.substr(0, 2) === '//';\n    if (slashes && !(proto && hostlessProtocol[proto])) {\n      rest = rest.substr(2);\n      this.slashes = true;\n    }\n  }\n\n  if (!hostlessProtocol[proto] &&\n      (slashes || (proto && !slashedProtocol[proto]))) {\n\n    // there's a hostname.\n    // the first instance of /, ?, ;, or # ends the host.\n    //\n    // If there is an @ in the hostname, then non-host chars *are* allowed\n    // to the left of the last @ sign, unless some host-ending character\n    // comes *before* the @-sign.\n    // URLs are obnoxious.\n    //\n    // ex:\n    // http://a@b@c/ => user:a@b host:c\n    // http://a@b?@c => user:a host:c path:/?@c\n\n    // v0.12 TODO(isaacs): This is not quite how Chrome does things.\n    // Review our test case against browsers more comprehensively.\n\n    // find the first instance of any hostEndingChars\n    var hostEnd = -1;\n    for (var i = 0; i < hostEndingChars.length; i++) {\n      var hec = rest.indexOf(hostEndingChars[i]);\n      if (hec !== -1 && (hostEnd === -1 || hec < hostEnd))\n        hostEnd = hec;\n    }\n\n    // at this point, either we have an explicit point where the\n    // auth portion cannot go past, or the last @ char is the decider.\n    var auth, atSign;\n    if (hostEnd === -1) {\n      // atSign can be anywhere.\n      atSign = rest.lastIndexOf('@');\n    } else {\n      // atSign must be in auth portion.\n      // http://a@b/c@d => host:b auth:a path:/c@d\n      atSign = rest.lastIndexOf('@', hostEnd);\n    }\n\n    // Now we have a portion which is definitely the auth.\n    // Pull that off.\n    if (atSign !== -1) {\n      auth = rest.slice(0, atSign);\n      rest = rest.slice(atSign + 1);\n      this.auth = decodeURIComponent(auth);\n    }\n\n    // the host is the remaining to the left of the first non-host char\n    hostEnd = -1;\n    for (var i = 0; i < nonHostChars.length; i++) {\n      var hec = rest.indexOf(nonHostChars[i]);\n      if (hec !== -1 && (hostEnd === -1 || hec < hostEnd))\n        hostEnd = hec;\n    }\n    // if we still have not hit it, then the entire thing is a host.\n    if (hostEnd === -1)\n      hostEnd = rest.length;\n\n    this.host = rest.slice(0, hostEnd);\n    rest = rest.slice(hostEnd);\n\n    // pull out port.\n    this.parseHost();\n\n    // we've indicated that there is a hostname,\n    // so even if it's empty, it has to be present.\n    this.hostname = this.hostname || '';\n\n    // if hostname begins with [ and ends with ]\n    // assume that it's an IPv6 address.\n    var ipv6Hostname = this.hostname[0] === '[' &&\n        this.hostname[this.hostname.length - 1] === ']';\n\n    // validate a little.\n    if (!ipv6Hostname) {\n      var hostparts = this.hostname.split(/\\./);\n      for (var i = 0, l = hostparts.length; i < l; i++) {\n        var part = hostparts[i];\n        if (!part) continue;\n        if (!part.match(hostnamePartPattern)) {\n          var newpart = '';\n          for (var j = 0, k = part.length; j < k; j++) {\n            if (part.charCodeAt(j) > 127) {\n              // we replace non-ASCII char with a temporary placeholder\n              // we need this to make sure size of hostname is not\n              // broken by replacing non-ASCII by nothing\n              newpart += 'x';\n            } else {\n              newpart += part[j];\n            }\n          }\n          // we test again with ASCII char only\n          if (!newpart.match(hostnamePartPattern)) {\n            var validParts = hostparts.slice(0, i);\n            var notHost = hostparts.slice(i + 1);\n            var bit = part.match(hostnamePartStart);\n            if (bit) {\n              validParts.push(bit[1]);\n              notHost.unshift(bit[2]);\n            }\n            if (notHost.length) {\n              rest = '/' + notHost.join('.') + rest;\n            }\n            this.hostname = validParts.join('.');\n            break;\n          }\n        }\n      }\n    }\n\n    if (this.hostname.length > hostnameMaxLen) {\n      this.hostname = '';\n    } else {\n      // hostnames are always lower case.\n      this.hostname = this.hostname.toLowerCase();\n    }\n\n    if (!ipv6Hostname) {\n      // IDNA Support: Returns a punycoded representation of \"domain\".\n      // It only converts parts of the domain name that\n      // have non-ASCII characters, i.e. it doesn't matter if\n      // you call it with a domain that already is ASCII-only.\n      this.hostname = punycode.toASCII(this.hostname);\n    }\n\n    var p = this.port ? ':' + this.port : '';\n    var h = this.hostname || '';\n    this.host = h + p;\n    this.href += this.host;\n\n    // strip [ and ] from the hostname\n    // the host field still retains them, though\n    if (ipv6Hostname) {\n      this.hostname = this.hostname.substr(1, this.hostname.length - 2);\n      if (rest[0] !== '/') {\n        rest = '/' + rest;\n      }\n    }\n  }\n\n  // now rest is set to the post-host stuff.\n  // chop off any delim chars.\n  if (!unsafeProtocol[lowerProto]) {\n\n    // First, make 100% sure that any \"autoEscape\" chars get\n    // escaped, even if encodeURIComponent doesn't think they\n    // need to be.\n    for (var i = 0, l = autoEscape.length; i < l; i++) {\n      var ae = autoEscape[i];\n      if (rest.indexOf(ae) === -1)\n        continue;\n      var esc = encodeURIComponent(ae);\n      if (esc === ae) {\n        esc = escape(ae);\n      }\n      rest = rest.split(ae).join(esc);\n    }\n  }\n\n\n  // chop off from the tail first.\n  var hash = rest.indexOf('#');\n  if (hash !== -1) {\n    // got a fragment string.\n    this.hash = rest.substr(hash);\n    rest = rest.slice(0, hash);\n  }\n  var qm = rest.indexOf('?');\n  if (qm !== -1) {\n    this.search = rest.substr(qm);\n    this.query = rest.substr(qm + 1);\n    if (parseQueryString) {\n      this.query = querystring.parse(this.query);\n    }\n    rest = rest.slice(0, qm);\n  } else if (parseQueryString) {\n    // no query string, but parseQueryString still requested\n    this.search = '';\n    this.query = {};\n  }\n  if (rest) this.pathname = rest;\n  if (slashedProtocol[lowerProto] &&\n      this.hostname && !this.pathname) {\n    this.pathname = '/';\n  }\n\n  //to support http.request\n  if (this.pathname || this.search) {\n    var p = this.pathname || '';\n    var s = this.search || '';\n    this.path = p + s;\n  }\n\n  // finally, reconstruct the href based on what has been validated.\n  this.href = this.format();\n  return this;\n};\n\n// format a parsed object into a url string\nfunction urlFormat(obj) {\n  // ensure it's an object, and not a string url.\n  // If it's an obj, this is a no-op.\n  // this way, you can call url_format() on strings\n  // to clean up potentially wonky urls.\n  if (util.isString(obj)) obj = urlParse(obj);\n  if (!(obj instanceof Url)) return Url.prototype.format.call(obj);\n  return obj.format();\n}\n\nUrl.prototype.format = function() {\n  var auth = this.auth || '';\n  if (auth) {\n    auth = encodeURIComponent(auth);\n    auth = auth.replace(/%3A/i, ':');\n    auth += '@';\n  }\n\n  var protocol = this.protocol || '',\n      pathname = this.pathname || '',\n      hash = this.hash || '',\n      host = false,\n      query = '';\n\n  if (this.host) {\n    host = auth + this.host;\n  } else if (this.hostname) {\n    host = auth + (this.hostname.indexOf(':') === -1 ?\n        this.hostname :\n        '[' + this.hostname + ']');\n    if (this.port) {\n      host += ':' + this.port;\n    }\n  }\n\n  if (this.query &&\n      util.isObject(this.query) &&\n      Object.keys(this.query).length) {\n    query = querystring.stringify(this.query);\n  }\n\n  var search = this.search || (query && ('?' + query)) || '';\n\n  if (protocol && protocol.substr(-1) !== ':') protocol += ':';\n\n  // only the slashedProtocols get the //.  Not mailto:, xmpp:, etc.\n  // unless they had them to begin with.\n  if (this.slashes ||\n      (!protocol || slashedProtocol[protocol]) && host !== false) {\n    host = '//' + (host || '');\n    if (pathname && pathname.charAt(0) !== '/') pathname = '/' + pathname;\n  } else if (!host) {\n    host = '';\n  }\n\n  if (hash && hash.charAt(0) !== '#') hash = '#' + hash;\n  if (search && search.charAt(0) !== '?') search = '?' + search;\n\n  pathname = pathname.replace(/[?#]/g, function(match) {\n    return encodeURIComponent(match);\n  });\n  search = search.replace('#', '%23');\n\n  return protocol + host + pathname + search + hash;\n};\n\nfunction urlResolve(source, relative) {\n  return urlParse(source, false, true).resolve(relative);\n}\n\nUrl.prototype.resolve = function(relative) {\n  return this.resolveObject(urlParse(relative, false, true)).format();\n};\n\nfunction urlResolveObject(source, relative) {\n  if (!source) return relative;\n  return urlParse(source, false, true).resolveObject(relative);\n}\n\nUrl.prototype.resolveObject = function(relative) {\n  if (util.isString(relative)) {\n    var rel = new Url();\n    rel.parse(relative, false, true);\n    relative = rel;\n  }\n\n  var result = new Url();\n  var tkeys = Object.keys(this);\n  for (var tk = 0; tk < tkeys.length; tk++) {\n    var tkey = tkeys[tk];\n    result[tkey] = this[tkey];\n  }\n\n  // hash is always overridden, no matter what.\n  // even href=\"\" will remove it.\n  result.hash = relative.hash;\n\n  // if the relative url is empty, then there's nothing left to do here.\n  if (relative.href === '') {\n    result.href = result.format();\n    return result;\n  }\n\n  // hrefs like //foo/bar always cut to the protocol.\n  if (relative.slashes && !relative.protocol) {\n    // take everything except the protocol from relative\n    var rkeys = Object.keys(relative);\n    for (var rk = 0; rk < rkeys.length; rk++) {\n      var rkey = rkeys[rk];\n      if (rkey !== 'protocol')\n        result[rkey] = relative[rkey];\n    }\n\n    //urlParse appends trailing / to urls like http://www.example.com\n    if (slashedProtocol[result.protocol] &&\n        result.hostname && !result.pathname) {\n      result.path = result.pathname = '/';\n    }\n\n    result.href = result.format();\n    return result;\n  }\n\n  if (relative.protocol && relative.protocol !== result.protocol) {\n    // if it's a known url protocol, then changing\n    // the protocol does weird things\n    // first, if it's not file:, then we MUST have a host,\n    // and if there was a path\n    // to begin with, then we MUST have a path.\n    // if it is file:, then the host is dropped,\n    // because that's known to be hostless.\n    // anything else is assumed to be absolute.\n    if (!slashedProtocol[relative.protocol]) {\n      var keys = Object.keys(relative);\n      for (var v = 0; v < keys.length; v++) {\n        var k = keys[v];\n        result[k] = relative[k];\n      }\n      result.href = result.format();\n      return result;\n    }\n\n    result.protocol = relative.protocol;\n    if (!relative.host && !hostlessProtocol[relative.protocol]) {\n      var relPath = (relative.pathname || '').split('/');\n      while (relPath.length && !(relative.host = relPath.shift()));\n      if (!relative.host) relative.host = '';\n      if (!relative.hostname) relative.hostname = '';\n      if (relPath[0] !== '') relPath.unshift('');\n      if (relPath.length < 2) relPath.unshift('');\n      result.pathname = relPath.join('/');\n    } else {\n      result.pathname = relative.pathname;\n    }\n    result.search = relative.search;\n    result.query = relative.query;\n    result.host = relative.host || '';\n    result.auth = relative.auth;\n    result.hostname = relative.hostname || relative.host;\n    result.port = relative.port;\n    // to support http.request\n    if (result.pathname || result.search) {\n      var p = result.pathname || '';\n      var s = result.search || '';\n      result.path = p + s;\n    }\n    result.slashes = result.slashes || relative.slashes;\n    result.href = result.format();\n    return result;\n  }\n\n  var isSourceAbs = (result.pathname && result.pathname.charAt(0) === '/'),\n      isRelAbs = (\n          relative.host ||\n          relative.pathname && relative.pathname.charAt(0) === '/'\n      ),\n      mustEndAbs = (isRelAbs || isSourceAbs ||\n                    (result.host && relative.pathname)),\n      removeAllDots = mustEndAbs,\n      srcPath = result.pathname && result.pathname.split('/') || [],\n      relPath = relative.pathname && relative.pathname.split('/') || [],\n      psychotic = result.protocol && !slashedProtocol[result.protocol];\n\n  // if the url is a non-slashed url, then relative\n  // links like ../.. should be able\n  // to crawl up to the hostname, as well.  This is strange.\n  // result.protocol has already been set by now.\n  // Later on, put the first path part into the host field.\n  if (psychotic) {\n    result.hostname = '';\n    result.port = null;\n    if (result.host) {\n      if (srcPath[0] === '') srcPath[0] = result.host;\n      else srcPath.unshift(result.host);\n    }\n    result.host = '';\n    if (relative.protocol) {\n      relative.hostname = null;\n      relative.port = null;\n      if (relative.host) {\n        if (relPath[0] === '') relPath[0] = relative.host;\n        else relPath.unshift(relative.host);\n      }\n      relative.host = null;\n    }\n    mustEndAbs = mustEndAbs && (relPath[0] === '' || srcPath[0] === '');\n  }\n\n  if (isRelAbs) {\n    // it's absolute.\n    result.host = (relative.host || relative.host === '') ?\n                  relative.host : result.host;\n    result.hostname = (relative.hostname || relative.hostname === '') ?\n                      relative.hostname : result.hostname;\n    result.search = relative.search;\n    result.query = relative.query;\n    srcPath = relPath;\n    // fall through to the dot-handling below.\n  } else if (relPath.length) {\n    // it's relative\n    // throw away the existing file, and take the new path instead.\n    if (!srcPath) srcPath = [];\n    srcPath.pop();\n    srcPath = srcPath.concat(relPath);\n    result.search = relative.search;\n    result.query = relative.query;\n  } else if (!util.isNullOrUndefined(relative.search)) {\n    // just pull out the search.\n    // like href='?foo'.\n    // Put this after the other two cases because it simplifies the booleans\n    if (psychotic) {\n      result.hostname = result.host = srcPath.shift();\n      //occationaly the auth can get stuck only in host\n      //this especially happens in cases like\n      //url.resolveObject('mailto:local1@domain1', 'local2@domain2')\n      var authInHost = result.host && result.host.indexOf('@') > 0 ?\n                       result.host.split('@') : false;\n      if (authInHost) {\n        result.auth = authInHost.shift();\n        result.host = result.hostname = authInHost.shift();\n      }\n    }\n    result.search = relative.search;\n    result.query = relative.query;\n    //to support http.request\n    if (!util.isNull(result.pathname) || !util.isNull(result.search)) {\n      result.path = (result.pathname ? result.pathname : '') +\n                    (result.search ? result.search : '');\n    }\n    result.href = result.format();\n    return result;\n  }\n\n  if (!srcPath.length) {\n    // no path at all.  easy.\n    // we've already handled the other stuff above.\n    result.pathname = null;\n    //to support http.request\n    if (result.search) {\n      result.path = '/' + result.search;\n    } else {\n      result.path = null;\n    }\n    result.href = result.format();\n    return result;\n  }\n\n  // if a url ENDs in . or .., then it must get a trailing slash.\n  // however, if it ends in anything else non-slashy,\n  // then it must NOT get a trailing slash.\n  var last = srcPath.slice(-1)[0];\n  var hasTrailingSlash = (\n      (result.host || relative.host || srcPath.length > 1) &&\n      (last === '.' || last === '..') || last === '');\n\n  // strip single dots, resolve double dots to parent dir\n  // if the path tries to go above the root, `up` ends up > 0\n  var up = 0;\n  for (var i = srcPath.length; i >= 0; i--) {\n    last = srcPath[i];\n    if (last === '.') {\n      srcPath.splice(i, 1);\n    } else if (last === '..') {\n      srcPath.splice(i, 1);\n      up++;\n    } else if (up) {\n      srcPath.splice(i, 1);\n      up--;\n    }\n  }\n\n  // if the path is allowed to go above the root, restore leading ..s\n  if (!mustEndAbs && !removeAllDots) {\n    for (; up--; up) {\n      srcPath.unshift('..');\n    }\n  }\n\n  if (mustEndAbs && srcPath[0] !== '' &&\n      (!srcPath[0] || srcPath[0].charAt(0) !== '/')) {\n    srcPath.unshift('');\n  }\n\n  if (hasTrailingSlash && (srcPath.join('/').substr(-1) !== '/')) {\n    srcPath.push('');\n  }\n\n  var isAbsolute = srcPath[0] === '' ||\n      (srcPath[0] && srcPath[0].charAt(0) === '/');\n\n  // put the host back\n  if (psychotic) {\n    result.hostname = result.host = isAbsolute ? '' :\n                                    srcPath.length ? srcPath.shift() : '';\n    //occationaly the auth can get stuck only in host\n    //this especially happens in cases like\n    //url.resolveObject('mailto:local1@domain1', 'local2@domain2')\n    var authInHost = result.host && result.host.indexOf('@') > 0 ?\n                     result.host.split('@') : false;\n    if (authInHost) {\n      result.auth = authInHost.shift();\n      result.host = result.hostname = authInHost.shift();\n    }\n  }\n\n  mustEndAbs = mustEndAbs || (result.host && srcPath.length);\n\n  if (mustEndAbs && !isAbsolute) {\n    srcPath.unshift('');\n  }\n\n  if (!srcPath.length) {\n    result.pathname = null;\n    result.path = null;\n  } else {\n    result.pathname = srcPath.join('/');\n  }\n\n  //to support request.http\n  if (!util.isNull(result.pathname) || !util.isNull(result.search)) {\n    result.path = (result.pathname ? result.pathname : '') +\n                  (result.search ? result.search : '');\n  }\n  result.auth = relative.auth || result.auth;\n  result.slashes = result.slashes || relative.slashes;\n  result.href = result.format();\n  return result;\n};\n\nUrl.prototype.parseHost = function() {\n  var host = this.host;\n  var port = portPattern.exec(host);\n  if (port) {\n    port = port[0];\n    if (port !== ':') {\n      this.port = port.substr(1);\n    }\n    host = host.substr(0, host.length - port.length);\n  }\n  if (host) this.hostname = host;\n};\n\n\n//# sourceURL=webpack://playground/./node_modules/url/url.js?");

/***/ }),

/***/ "./node_modules/url/util.js":
/*!**********************************!*\
  !*** ./node_modules/url/util.js ***!
  \**********************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = {\n  isString: function(arg) {\n    return typeof(arg) === 'string';\n  },\n  isObject: function(arg) {\n    return typeof(arg) === 'object' && arg !== null;\n  },\n  isNull: function(arg) {\n    return arg === null;\n  },\n  isNullOrUndefined: function(arg) {\n    return arg == null;\n  }\n};\n\n\n//# sourceURL=webpack://playground/./node_modules/url/util.js?");

/***/ }),

/***/ "?1214":
/*!************************!*\
  !*** buffer (ignored) ***!
  \************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://playground/buffer_(ignored)?");

/***/ }),

/***/ "?883b":
/*!************************!*\
  !*** events (ignored) ***!
  \************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://playground/events_(ignored)?");

/***/ }),

/***/ "?bf66":
/*!**********************!*\
  !*** util (ignored) ***!
  \**********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://playground/util_(ignored)?");

/***/ }),

/***/ "?463b":
/*!************************!*\
  !*** buffer (ignored) ***!
  \************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://playground/buffer_(ignored)?");

/***/ }),

/***/ "?5ee0":
/*!************************!*\
  !*** events (ignored) ***!
  \************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://playground/events_(ignored)?");

/***/ }),

/***/ "?910f":
/*!**********************!*\
  !*** util (ignored) ***!
  \**********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://playground/util_(ignored)?");

/***/ }),

/***/ "?57ce":
/*!************************!*\
  !*** buffer (ignored) ***!
  \************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://playground/buffer_(ignored)?");

/***/ }),

/***/ "?4032":
/*!************************!*\
  !*** stream (ignored) ***!
  \************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://playground/stream_(ignored)?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			id: moduleId,
/******/ 			loaded: false,
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Flag the module as loaded
/******/ 		module.loaded = true;
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/global */
/******/ 	(() => {
/******/ 		__webpack_require__.g = (function() {
/******/ 			if (typeof globalThis === 'object') return globalThis;
/******/ 			try {
/******/ 				return this || new Function('return this')();
/******/ 			} catch (e) {
/******/ 				if (typeof window === 'object') return window;
/******/ 			}
/******/ 		})();
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/node module decorator */
/******/ 	(() => {
/******/ 		__webpack_require__.nmd = (module) => {
/******/ 			module.paths = [];
/******/ 			if (!module.children) module.children = [];
/******/ 			return module;
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./fhircat-addons.js");
/******/ 	
/******/ })()
;